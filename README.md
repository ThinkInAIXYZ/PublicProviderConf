# PublicProviderConf

Automated tool to fetch AI model information from various providers (PPInfra, OpenRouter, OpenAI, Google, etc.) and generate standardized JSON files for easy consumption by chatbots and other applications.

## âœ¨ Features

- ğŸ¤– **Standardized Format**: Unified JSON output format for easy chatbot parsing
- ğŸ”„ **Auto Detection**: Intelligent detection of model capabilities (vision, function calling, reasoning)
- ğŸŒ **Multi-Provider Support**: Extensible architecture supporting multiple AI model providers
- âš¡ **Concurrent Fetching**: Efficient concurrent data retrieval from multiple providers
- ğŸ¯ **Aggregated Output**: Generate both individual provider files and complete aggregated files
- ğŸš€ **GitHub Actions**: Automated scheduled updates for model information

## ğŸ“¦ Installation

### Prerequisites
- Rust 1.70+ 
- Cargo

### Build
```bash
git clone https://github.com/your-repo/PublicProviderConf.git
cd PublicProviderConf
cargo build --release
```

## ğŸš€ Usage

### Basic Usage

Fetch model information from all providers:
```bash
cargo run -- fetch-all
```

Specify output directory:
```bash
cargo run -- fetch-all -o ./output
```

Fetch from specific providers:
```bash
cargo run -- fetch-providers -p ppinfra,openai
```

### CLI Options

```bash
# Fetch from all providers
cargo run -- fetch-all [OPTIONS]

# Fetch from specific providers
cargo run -- fetch-providers -p <PROVIDERS> [OPTIONS]

Options:
  -o, --output <OUTPUT>    Output directory [default: dist]
  -c, --config <CONFIG>    Config file path [default: config/providers.toml]
  -h, --help              Show help information
```

## ğŸ“‹ Output Format

### Individual Provider JSON
```json
{
  "provider": "ppinfra",
  "providerName": "PPInfra", 
  "lastUpdated": "2025-01-15T10:30:00Z",
  "models": [
    {
      "id": "deepseek/deepseek-v3.1",
      "name": "Deepseek V3.1",
      "contextLength": 163840,
      "maxTokens": 163840,
      "vision": false,
      "functionCall": true,
      "reasoning": true,
      "type": "chat",
      "description": "DeepSeek-V3.1 latest model with mixed reasoning modes..."
    }
  ]
}
```

### Aggregated JSON
```json
{
  "version": "1.0.0",
  "generatedAt": "2025-01-15T10:30:00Z",
  "providers": {
    "ppinfra": {
      "providerName": "PPInfra",
      "modelCount": 38,
      "lastUpdated": "2025-01-15T10:30:00Z"
    }
  },
  "totalModels": 38,
  "allModels": [
    // Flattened list of all models with providerId
  ]
}
```

## ğŸ”§ Configuration

### Provider Configuration (Optional)
Create `config/providers.toml` file:
```toml
[ppinfra]
api_url = "https://api.ppinfra.com/openai/v1/models"
rate_limit = 10
timeout = 30

[openrouter]
api_url = "https://openrouter.ai/api/v1/models"
api_key_env = "OPENROUTER_API_KEY"
rate_limit = 5

[openai]
api_url = "https://api.openai.com/v1/models" 
api_key_env = "OPENAI_API_KEY"
rate_limit = 20
```

### Environment Variables
If providers require API keys, set corresponding environment variables:
```bash
export OPENAI_API_KEY="your-key-here"
export OPENROUTER_API_KEY="your-key-here"
```

## ğŸ¤– GitHub Actions Automation

The project includes GitHub Actions workflow with support for:
- â° Daily automated runs at UTC 06:00
- ğŸ–±ï¸ Manual trigger
- ğŸ“¤ Auto commit updates to `provider_configs/`
- ğŸ—œï¸ Create packaged releases

Manual trigger:
```bash
# Click "Run workflow" in the Actions tab of the GitHub repository
```

## ğŸ“ Project Structure

```
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ models/          # Data structure definitions
â”‚   â”œâ”€â”€ providers/       # Provider implementations
â”‚   â”œâ”€â”€ fetcher/         # Data fetching logic
â”‚   â”œâ”€â”€ output/          # Output processing
â”‚   â””â”€â”€ config/          # Configuration management
â”œâ”€â”€ dist/                # Generated JSON files
â”œâ”€â”€ provider_configs/    # Git-tracked JSON files
â”œâ”€â”€ docs/                # Detailed documentation
â””â”€â”€ .claude/            # Claude Code configuration
```

## ğŸ”Œ Adding New Providers

1. Create a new file in `src/providers/` (e.g., `openai.rs`)
2. Implement the `Provider` trait:
```rust
#[async_trait]
impl Provider for OpenAIProvider {
    async fn fetch_models(&self) -> Result<Vec<ModelInfo>> {
        // Implement API calls and data conversion
    }
    
    fn provider_id(&self) -> &str { "openai" }
    fn provider_name(&self) -> &str { "OpenAI" }
}
```
3. Add the module in `src/providers/mod.rs`
4. Register the provider in `src/main.rs`

For detailed development guide, see [Architecture Documentation](docs/architecture-overview.md).

## ğŸ“Š Currently Supported Providers

- âœ… **PPInfra** - 38 models with reasoning, function calling, and vision capability detection
- ğŸš§ **OpenRouter** - Planned
- ğŸš§ **OpenAI** - Planned  
- ğŸš§ **Google Gemini** - Planned

## ğŸ› ï¸ Development

### Run Tests
```bash
cargo test
```

### Debug Mode
```bash
RUST_LOG=debug cargo run -- fetch-all
```

### Code Formatting
```bash
cargo fmt
cargo clippy
```

## ğŸ“„ Documentation

- [Architecture Design](docs/architecture-overview.md) - Complete architecture documentation
- [Claude Code Configuration](CLAUDE.md) - Development environment setup
- [Provider Implementation Guide](.claude/provider_implementer.md) - Guide for developing new providers
- [Data Conversion Standards](.claude/data_converter.md) - Data standardization specifications
- [Format Validation Standards](.claude/format_validator.md) - JSON format validation

## ğŸ“ˆ Usage Examples

### Chatbot Integration Example
```javascript
// Fetch all models
const response = await fetch('https://your-domain.com/provider_configs/aggregated.json');
const data = await response.json();

// Filter models that support function calling
const toolModels = data.allModels.filter(model => model.functionCall);

// Sort by context length
const sortedModels = data.allModels.sort((a, b) => b.contextLength - a.contextLength);

// Find models from specific provider
const ppinfraModels = data.allModels.filter(model => model.providerId === 'ppinfra');
```

### Data Analysis
Generated JSON files can be used for:
- ğŸ“Š Model capability statistical analysis
- ğŸ” Model search and filtering
- ğŸ’° Price comparison analysis
- ğŸ“ˆ Model trend tracking

## ğŸ¤ Contributing

Issues and Pull Requests are welcome!

1. Fork the project
2. Create a feature branch
3. Implement new features or fixes
4. Submit a Pull Request

## ğŸ“ License

[MIT License](LICENSE)

## ğŸ™ Acknowledgments

Thanks to all AI model providers for offering open API interfaces, making this project possible.