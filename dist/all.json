{"providers":{"moonshotai-cn":{"id":"moonshotai-cn","api":"https://api.moonshot.cn/v1","name":"Moonshot AI (China)","doc":"https://platform.moonshot.cn/docs/api/chat","display_name":"Moonshot AI (China)","models":[{"id":"kimi-k2-0905-preview","name":"Kimi K2 0905","attachment":false,"reasoning":false,"temperature":true,"tool_call":true,"knowledge":"2024-10","release_date":"2025-09-05","last_updated":"2025-09-05","modalities":{"input":["text"],"output":["text"]},"open_weights":true,"cost":{"input":0.6,"output":2.5,"cache_read":0.15},"limit":{"context":262144,"output":262144},"display_name":"Kimi K2 0905"},{"id":"kimi-k2-0711-preview","name":"Kimi K2 0711","attachment":false,"reasoning":false,"temperature":true,"tool_call":true,"knowledge":"2024-10","release_date":"2025-07-14","last_updated":"2025-07-14","modalities":{"input":["text"],"output":["text"]},"open_weights":true,"cost":{"input":0.6,"output":2.5,"cache_read":0.15},"limit":{"context":131072,"output":16384},"display_name":"Kimi K2 0711"},{"id":"kimi-k2-turbo-preview","name":"Kimi K2 Turbo","attachment":false,"reasoning":false,"temperature":true,"tool_call":true,"knowledge":"2024-10","release_date":"2025-09-05","last_updated":"2025-09-05","modalities":{"input":["text"],"output":["text"]},"open_weights":true,"cost":{"input":2.4,"output":10,"cache_read":0.6},"limit":{"context":262144,"output":262144},"display_name":"Kimi K2 Turbo"}]},"lucidquery":{"id":"lucidquery","api":"https://lucidquery.com/api/v1","name":"LucidQuery AI","doc":"https://lucidquery.com/api/docs","display_name":"LucidQuery AI","models":[{"id":"lucidquery-nexus-coder","name":"LucidQuery Nexus Coder","attachment":true,"reasoning":true,"temperature":false,"tool_call":true,"knowledge":"2025-08-01","release_date":"2025-09-01","last_updated":"2025-09-01","modalities":{"input":["text"],"output":["text"]},"open_weights":false,"cost":{"input":2,"output":5},"limit":{"context":250000,"output":60000},"display_name":"LucidQuery Nexus Coder"},{"id":"lucidnova-rf1-100b","name":"LucidNova RF1 100B","attachment":true,"reasoning":true,"temperature":false,"tool_call":true,"knowledge":"2025-09-16","release_date":"2024-12-28","last_updated":"2025-09-10","modalities":{"input":["text"],"output":["text"]},"open_weights":false,"cost":{"input":2,"output":5},"limit":{"context":120000,"output":8000},"display_name":"LucidNova RF1 100B"}]},"moonshotai":{"id":"moonshotai","api":"https://api.moonshot.ai/v1","name":"Moonshot AI","doc":"https://platform.moonshot.ai/docs/api/chat","display_name":"Moonshot AI","models":[{"id":"kimi-k2-turbo-preview","name":"Kimi K2 Turbo","attachment":false,"reasoning":false,"temperature":true,"tool_call":true,"knowledge":"2024-10","release_date":"2025-09-05","last_updated":"2025-09-05","modalities":{"input":["text"],"output":["text"]},"open_weights":true,"cost":{"input":2.4,"output":10,"cache_read":0.6},"limit":{"context":262144,"output":262144},"display_name":"Kimi K2 Turbo"},{"id":"kimi-k2-0711-preview","name":"Kimi K2 0711","attachment":false,"reasoning":false,"temperature":true,"tool_call":true,"knowledge":"2024-10","release_date":"2025-07-14","last_updated":"2025-07-14","modalities":{"input":["text"],"output":["text"]},"open_weights":true,"cost":{"input":0.6,"output":2.5,"cache_read":0.15},"limit":{"context":131072,"output":16384},"display_name":"Kimi K2 0711"},{"id":"kimi-k2-0905-preview","name":"Kimi K2 0905","attachment":false,"reasoning":false,"temperature":true,"tool_call":true,"knowledge":"2024-10","release_date":"2025-09-05","last_updated":"2025-09-05","modalities":{"input":["text"],"output":["text"]},"open_weights":true,"cost":{"input":0.6,"output":2.5,"cache_read":0.15},"limit":{"context":262144,"output":262144},"display_name":"Kimi K2 0905"}]},"zai-coding-plan":{"id":"zai-coding-plan","api":"https://api.z.ai/api/coding/paas/v4","name":"Z.AI Coding Plan","doc":"https://docs.z.ai/devpack/overview","display_name":"Z.AI Coding Plan","models":[{"id":"glm-4.5-flash","name":"GLM-4.5-Flash","attachment":false,"reasoning":true,"temperature":true,"tool_call":true,"knowledge":"2025-04","release_date":"2025-07-28","last_updated":"2025-07-28","modalities":{"input":["text"],"output":["text"]},"open_weights":true,"cost":{"input":0,"output":0,"cache_read":0,"cache_write":0},"limit":{"context":131072,"output":98304},"display_name":"GLM-4.5-Flash"},{"id":"glm-4.5","name":"GLM-4.5","attachment":false,"reasoning":true,"temperature":true,"tool_call":true,"knowledge":"2025-04","release_date":"2025-07-28","last_updated":"2025-07-28","modalities":{"input":["text"],"output":["text"]},"open_weights":true,"cost":{"input":0,"output":0,"cache_read":0,"cache_write":0},"limit":{"context":131072,"output":98304},"display_name":"GLM-4.5"},{"id":"glm-4.5-air","name":"GLM-4.5-Air","attachment":false,"reasoning":true,"temperature":true,"tool_call":true,"knowledge":"2025-04","release_date":"2025-07-28","last_updated":"2025-07-28","modalities":{"input":["text"],"output":["text"]},"open_weights":true,"cost":{"input":0,"output":0,"cache_read":0,"cache_write":0},"limit":{"context":131072,"output":98304},"display_name":"GLM-4.5-Air"},{"id":"glm-4.5v","name":"GLM 4.5V","attachment":true,"reasoning":true,"temperature":true,"tool_call":true,"knowledge":"2025-04","release_date":"2025-08-11","last_updated":"2025-08-11","modalities":{"input":["text","image","video"],"output":["text"]},"open_weights":true,"cost":{"input":0,"output":0},"limit":{"context":64000,"output":16384},"display_name":"GLM 4.5V"},{"id":"glm-4.6","name":"GLM-4.6","attachment":false,"reasoning":true,"temperature":true,"tool_call":true,"knowledge":"2025-04","release_date":"2025-09-30","last_updated":"2025-09-30","modalities":{"input":["text"],"output":["text"]},"open_weights":true,"cost":{"input":0,"output":0,"cache_read":0,"cache_write":0},"limit":{"context":204800,"output":131072},"display_name":"GLM-4.6"}]},"alibaba":{"id":"alibaba","api":"https://dashscope-intl.aliyuncs.com/compatible-mode/v1","name":"alibaba","doc":"https://www.alibabacloud.com/help/en/model-studio/models","display_name":"alibaba","models":[{"id":"qwen3-coder-plus","name":"Qwen3 Coder Plus","attachment":false,"reasoning":false,"temperature":true,"tool_call":true,"knowledge":"2025-04","release_date":"2025-07-23","last_updated":"2025-07-23","modalities":{"input":["text"],"output":["text"]},"open_weights":true,"cost":{"input":1,"output":5},"limit":{"context":1048576,"output":65536},"display_name":"Qwen3 Coder Plus"},{"id":"qwen-turbo-latest","type":"chat","context_length":1000000,"max_output_tokens":16384,"capabilities":{"vision":false,"function_calling":true,"reasoning":false},"search_strategy":"turbo","name":"qwen-turbo-latest","display_name":"qwen-turbo-latest"},{"id":"qwen-turbo-2025-07-15","type":"chat","context_length":131072,"max_output_tokens":16384,"capabilities":{"vision":false,"function_calling":true,"reasoning":false},"search_strategy":"turbo","name":"qwen-turbo-2025-07-15","display_name":"qwen-turbo-2025-07-15"},{"id":"qwen-turbo","type":"chat","context_length":131072,"max_output_tokens":16384,"capabilities":{"vision":false,"function_calling":true,"reasoning":false},"search_strategy":"turbo","name":"qwen-turbo","display_name":"qwen-turbo"},{"id":"qwen-flash","type":"chat","context_length":1000000,"max_output_tokens":32768,"capabilities":{"vision":false,"function_calling":true,"reasoning":false},"search_strategy":"turbo","name":"qwen-flash","display_name":"qwen-flash"},{"id":"qwen-flash-2025-07-28","type":"chat","context_length":1000000,"max_output_tokens":32768,"capabilities":{"vision":false,"function_calling":true,"reasoning":false},"search_strategy":"turbo","name":"qwen-flash-2025-07-28","display_name":"qwen-flash-2025-07-28"},{"id":"qwen-plus-latest","type":"chat","context_length":1000000,"max_output_tokens":32768,"capabilities":{"vision":false,"function_calling":true,"reasoning":false},"search_strategy":"turbo","name":"qwen-plus-latest","display_name":"qwen-plus-latest"},{"id":"qwen-plus-2025-07-14","type":"chat","context_length":131072,"max_output_tokens":8192,"capabilities":{"vision":false,"function_calling":true,"reasoning":false},"search_strategy":"turbo","name":"qwen-plus-2025-07-14","display_name":"qwen-plus-2025-07-14"},{"id":"qwen-plus-2025-07-28","type":"chat","context_length":1000000,"max_output_tokens":32768,"capabilities":{"vision":false,"function_calling":true,"reasoning":false},"search_strategy":"turbo","name":"qwen-plus-2025-07-28","display_name":"qwen-plus-2025-07-28"},{"id":"qwen-plus","type":"chat","context_length":131072,"max_output_tokens":16384,"capabilities":{"vision":false,"function_calling":true,"reasoning":false},"search_strategy":"turbo","name":"qwen-plus","display_name":"qwen-plus"},{"id":"qwen-max-latest","type":"chat","context_length":131072,"max_output_tokens":8192,"capabilities":{"vision":false,"function_calling":true,"reasoning":false},"search_strategy":"turbo","name":"qwen-max-latest","display_name":"qwen-max-latest"},{"id":"qwen-max","type":"chat","context_length":32768,"max_output_tokens":8192,"capabilities":{"vision":false,"function_calling":true,"reasoning":false},"search_strategy":"turbo","name":"qwen-max","display_name":"qwen-max"},{"id":"qwen3-max-2025-09-23","type":"chat","context_length":262144,"max_output_tokens":65536,"capabilities":{"vision":false,"function_calling":true,"reasoning":false},"search_strategy":"turbo","name":"qwen3-max-2025-09-23","display_name":"qwen3-max-2025-09-23"},{"id":"qwen3-max-preview","type":"chat","context_length":262144,"max_output_tokens":65536,"capabilities":{"vision":false,"function_calling":true,"reasoning":false},"search_strategy":"turbo","name":"qwen3-max-preview","display_name":"qwen3-max-preview"},{"id":"qwen3-235b-a22b-thinking-2507","type":"chat","context_length":40960,"max_output_tokens":8192,"capabilities":{"vision":false,"function_calling":true,"reasoning":true},"thinking_budget":81920,"name":"qwen3-235b-a22b-thinking-2507","display_name":"qwen3-235b-a22b-thinking-2507"},{"id":"qwen3-235b-a22b","type":"chat","context_length":40960,"max_output_tokens":8192,"capabilities":{"vision":false,"function_calling":true,"reasoning":true},"thinking_budget":81920,"name":"qwen3-235b-a22b","display_name":"qwen3-235b-a22b"},{"id":"qwen3-30b-a3b-thinking-2507","type":"chat","context_length":40960,"max_output_tokens":8192,"capabilities":{"vision":false,"function_calling":true,"reasoning":true},"thinking_budget":81920,"name":"qwen3-30b-a3b-thinking-2507","display_name":"qwen3-30b-a3b-thinking-2507"},{"id":"qwen3-32b","type":"chat","context_length":40960,"max_output_tokens":8192,"capabilities":{"vision":false,"function_calling":true,"reasoning":true},"thinking_budget":38912,"name":"qwen3-32b","display_name":"qwen3-32b"},{"id":"qwen3-30b-a3b","type":"chat","context_length":40960,"max_output_tokens":8192,"capabilities":{"vision":false,"function_calling":true,"reasoning":true},"thinking_budget":38912,"name":"qwen3-30b-a3b","display_name":"qwen3-30b-a3b"},{"id":"qwen3-14b","type":"chat","context_length":40960,"max_output_tokens":8192,"capabilities":{"vision":false,"function_calling":true,"reasoning":true},"thinking_budget":38912,"name":"qwen3-14b","display_name":"qwen3-14b"},{"id":"qwen3-8b","type":"chat","context_length":40960,"max_output_tokens":8192,"capabilities":{"vision":false,"function_calling":true,"reasoning":true},"thinking_budget":38912,"name":"qwen3-8b","display_name":"qwen3-8b"},{"id":"qwen3-4b","type":"chat","context_length":40960,"max_output_tokens":8192,"capabilities":{"vision":false,"function_calling":true,"reasoning":true},"thinking_budget":38912,"name":"qwen3-4b","display_name":"qwen3-4b"},{"id":"qwen3-1.7b","type":"chat","context_length":40960,"max_output_tokens":8192,"capabilities":{"vision":false,"function_calling":true,"reasoning":true},"thinking_budget":20000,"name":"qwen3-1.7b","display_name":"qwen3-1.7b"},{"id":"qwen3-0.6b","type":"chat","context_length":40960,"max_output_tokens":8192,"capabilities":{"vision":false,"function_calling":true,"reasoning":true},"thinking_budget":20000,"name":"qwen3-0.6b","display_name":"qwen3-0.6b"},{"id":"qwen3-vl-plus","type":"chat","context_length":262144,"max_output_tokens":32768,"capabilities":{"vision":true,"function_calling":false,"reasoning":true},"thinking_budget":81920,"name":"qwen3-vl-plus","display_name":"qwen3-vl-plus"},{"id":"qwq-plus","type":"chat","context_length":131072,"max_output_tokens":8192,"capabilities":{"vision":false,"function_calling":false,"reasoning":true},"search_strategy":"turbo","name":"qwq-plus","display_name":"qwq-plus"},{"id":"qwq-plus-latest","type":"chat","context_length":131072,"max_output_tokens":8192,"capabilities":{"vision":false,"function_calling":false,"reasoning":true},"name":"qwq-plus-latest","display_name":"qwq-plus-latest"},{"id":"qwen3-next-80b-a3b-thinking","type":"chat","context_length":131072,"max_output_tokens":32768,"capabilities":{"vision":false,"function_calling":false,"reasoning":true},"thinking_budget":81920,"name":"qwen3-next-80b-a3b-thinking","display_name":"qwen3-next-80b-a3b-thinking"},{"id":"qwen3-next-80b-a3b-instruct","type":"chat","context_length":131072,"max_output_tokens":32768,"capabilities":{"vision":false,"function_calling":true,"reasoning":false},"name":"qwen3-next-80b-a3b-instruct","display_name":"qwen3-next-80b-a3b-instruct"}]},"xai":{"id":"xai","name":"xAI","doc":"https://docs.x.ai/docs/models","display_name":"xAI","models":[{"id":"grok-4-fast-non-reasoning","name":"Grok 4 Fast (Non-Reasoning)","attachment":true,"reasoning":false,"temperature":true,"tool_call":true,"knowledge":"2025-07","release_date":"2025-09-19","last_updated":"2025-09-19","modalities":{"input":["text","image"],"output":["text"]},"open_weights":false,"cost":{"input":0.2,"output":0.5,"cache_read":0.05},"limit":{"context":2000000,"output":30000},"display_name":"Grok 4 Fast (Non-Reasoning)"},{"id":"grok-3-fast","name":"Grok 3 Fast","attachment":false,"reasoning":false,"temperature":true,"tool_call":true,"knowledge":"2024-11","release_date":"2025-02-17","last_updated":"2025-02-17","modalities":{"input":["text"],"output":["text"]},"open_weights":false,"cost":{"input":5,"output":25,"cache_read":1.25},"limit":{"context":131072,"output":8192},"display_name":"Grok 3 Fast"},{"id":"grok-4","name":"Grok 4","attachment":false,"reasoning":true,"temperature":true,"tool_call":true,"knowledge":"2025-07","release_date":"2025-07-09","last_updated":"2025-07-09","modalities":{"input":["text"],"output":["text"]},"open_weights":false,"cost":{"input":3,"output":15,"reasoning":15,"cache_read":0.75},"limit":{"context":256000,"output":64000},"display_name":"Grok 4"},{"id":"grok-2-vision","name":"Grok 2 Vision","attachment":true,"reasoning":false,"temperature":true,"tool_call":true,"knowledge":"2024-08","release_date":"2024-08-20","last_updated":"2024-08-20","modalities":{"input":["text","image"],"output":["text"]},"open_weights":false,"cost":{"input":2,"output":10,"cache_read":2},"limit":{"context":8192,"output":4096},"display_name":"Grok 2 Vision"},{"id":"grok-code-fast-1","name":"Grok Code Fast 1","attachment":false,"reasoning":true,"temperature":true,"tool_call":true,"knowledge":"2023-10","release_date":"2025-08-28","last_updated":"2025-08-28","modalities":{"input":["text"],"output":["text"]},"open_weights":false,"cost":{"input":0.2,"output":1.5,"cache_read":0.02},"limit":{"context":256000,"output":10000},"display_name":"Grok Code Fast 1"},{"id":"grok-2","name":"Grok 2","attachment":false,"reasoning":false,"temperature":true,"tool_call":true,"knowledge":"2024-08","release_date":"2024-08-20","last_updated":"2024-08-20","modalities":{"input":["text"],"output":["text"]},"open_weights":false,"cost":{"input":2,"output":10,"cache_read":2},"limit":{"context":131072,"output":8192},"display_name":"Grok 2"},{"id":"grok-3-mini-fast-latest","name":"Grok 3 Mini Fast Latest","attachment":false,"reasoning":true,"temperature":true,"tool_call":true,"knowledge":"2024-11","release_date":"2025-02-17","last_updated":"2025-02-17","modalities":{"input":["text"],"output":["text"]},"open_weights":false,"cost":{"input":0.6,"output":4,"reasoning":4,"cache_read":0.15},"limit":{"context":131072,"output":8192},"display_name":"Grok 3 Mini Fast Latest"},{"id":"grok-2-vision-1212","name":"Grok 2 Vision (1212)","attachment":true,"reasoning":false,"temperature":true,"tool_call":true,"knowledge":"2024-08","release_date":"2024-08-20","last_updated":"2024-12-12","modalities":{"input":["text","image"],"output":["text"]},"open_weights":false,"cost":{"input":2,"output":10,"cache_read":2},"limit":{"context":8192,"output":4096},"display_name":"Grok 2 Vision (1212)"},{"id":"grok-3","name":"Grok 3","attachment":false,"reasoning":false,"temperature":true,"tool_call":true,"knowledge":"2024-11","release_date":"2025-02-17","last_updated":"2025-02-17","modalities":{"input":["text"],"output":["text"]},"open_weights":false,"cost":{"input":3,"output":15,"cache_read":0.75},"limit":{"context":131072,"output":8192},"display_name":"Grok 3"},{"id":"grok-4-fast","name":"Grok 4 Fast","attachment":true,"reasoning":true,"temperature":true,"tool_call":true,"knowledge":"2025-07","release_date":"2025-09-19","last_updated":"2025-09-19","modalities":{"input":["text","image"],"output":["text"]},"open_weights":false,"cost":{"input":0.2,"output":0.5,"cache_read":0.05},"limit":{"context":2000000,"output":30000},"display_name":"Grok 4 Fast"},{"id":"grok-2-latest","name":"Grok 2 Latest","attachment":false,"reasoning":false,"temperature":true,"tool_call":true,"knowledge":"2024-08","release_date":"2024-08-20","last_updated":"2024-12-12","modalities":{"input":["text"],"output":["text"]},"open_weights":false,"cost":{"input":2,"output":10,"cache_read":2},"limit":{"context":131072,"output":8192},"display_name":"Grok 2 Latest"},{"id":"grok-2-1212","name":"Grok 2 (1212)","attachment":false,"reasoning":false,"temperature":true,"tool_call":true,"knowledge":"2024-08","release_date":"2024-12-12","last_updated":"2024-12-12","modalities":{"input":["text"],"output":["text"]},"open_weights":false,"cost":{"input":2,"output":10,"cache_read":2},"limit":{"context":131072,"output":8192},"display_name":"Grok 2 (1212)"},{"id":"grok-3-fast-latest","name":"Grok 3 Fast Latest","attachment":false,"reasoning":false,"temperature":true,"tool_call":true,"knowledge":"2024-11","release_date":"2025-02-17","last_updated":"2025-02-17","modalities":{"input":["text"],"output":["text"]},"open_weights":false,"cost":{"input":5,"output":25,"cache_read":1.25},"limit":{"context":131072,"output":8192},"display_name":"Grok 3 Fast Latest"},{"id":"grok-3-latest","name":"Grok 3 Latest","attachment":false,"reasoning":false,"temperature":true,"tool_call":true,"knowledge":"2024-11","release_date":"2025-02-17","last_updated":"2025-02-17","modalities":{"input":["text"],"output":["text"]},"open_weights":false,"cost":{"input":3,"output":15,"cache_read":0.75},"limit":{"context":131072,"output":8192},"display_name":"Grok 3 Latest"},{"id":"grok-2-vision-latest","name":"Grok 2 Vision Latest","attachment":true,"reasoning":false,"temperature":true,"tool_call":true,"knowledge":"2024-08","release_date":"2024-08-20","last_updated":"2024-12-12","modalities":{"input":["text","image"],"output":["text"]},"open_weights":false,"cost":{"input":2,"output":10,"cache_read":2},"limit":{"context":8192,"output":4096},"display_name":"Grok 2 Vision Latest"},{"id":"grok-vision-beta","name":"Grok Vision Beta","attachment":true,"reasoning":false,"temperature":true,"tool_call":true,"knowledge":"2024-08","release_date":"2024-11-01","last_updated":"2024-11-01","modalities":{"input":["text","image"],"output":["text"]},"open_weights":false,"cost":{"input":5,"output":15,"cache_read":5},"limit":{"context":8192,"output":4096},"display_name":"Grok Vision Beta"},{"id":"grok-3-mini","name":"Grok 3 Mini","attachment":false,"reasoning":true,"temperature":true,"tool_call":true,"knowledge":"2024-11","release_date":"2025-02-17","last_updated":"2025-02-17","modalities":{"input":["text"],"output":["text"]},"open_weights":false,"cost":{"input":0.3,"output":0.5,"reasoning":0.5,"cache_read":0.075},"limit":{"context":131072,"output":8192},"display_name":"Grok 3 Mini"},{"id":"grok-beta","name":"Grok Beta","attachment":false,"reasoning":false,"temperature":true,"tool_call":true,"knowledge":"2024-08","release_date":"2024-11-01","last_updated":"2024-11-01","modalities":{"input":["text"],"output":["text"]},"open_weights":false,"cost":{"input":5,"output":15,"cache_read":5},"limit":{"context":131072,"output":4096},"display_name":"Grok Beta"},{"id":"grok-3-mini-latest","name":"Grok 3 Mini Latest","attachment":false,"reasoning":true,"temperature":true,"tool_call":true,"knowledge":"2024-11","release_date":"2025-02-17","last_updated":"2025-02-17","modalities":{"input":["text"],"output":["text"]},"open_weights":false,"cost":{"input":0.3,"output":0.5,"reasoning":0.5,"cache_read":0.075},"limit":{"context":131072,"output":8192},"display_name":"Grok 3 Mini Latest"},{"id":"grok-3-mini-fast","name":"Grok 3 Mini Fast","attachment":false,"reasoning":true,"temperature":true,"tool_call":true,"knowledge":"2024-11","release_date":"2025-02-17","last_updated":"2025-02-17","modalities":{"input":["text"],"output":["text"]},"open_weights":false,"cost":{"input":0.6,"output":4,"reasoning":4,"cache_read":0.15},"limit":{"context":131072,"output":8192},"display_name":"Grok 3 Mini Fast"}]},"nvidia":{"id":"nvidia","api":"https://integrate.api.nvidia.com/v1","name":"Nvidia","doc":"https://docs.api.nvidia.com/nim/","display_name":"Nvidia","models":[{"id":"moonshotai/kimi-k2-instruct","name":"Kimi K2 Instruct","attachment":false,"reasoning":true,"temperature":true,"tool_call":true,"knowledge":"2024-01","release_date":"2025-01-01","last_updated":"2025-09-05","modalities":{"input":["text"],"output":["text"]},"open_weights":false,"cost":{"input":0,"output":0},"limit":{"context":128000,"output":8192},"display_name":"Kimi K2 Instruct"},{"id":"nvidia/cosmos-nemotron-34b","name":"Cosmos Nemotron 34B","attachment":false,"reasoning":true,"temperature":true,"tool_call":false,"knowledge":"2024-01","release_date":"2024-01-01","last_updated":"2025-09-05","modalities":{"input":["text","image","video"],"output":["text"]},"open_weights":false,"cost":{"input":0,"output":0},"limit":{"context":131072,"output":8192},"display_name":"Cosmos Nemotron 34B"},{"id":"nvidia/parakeet-tdt-0.6b-v2","name":"Parakeet TDT 0.6B v2","attachment":false,"reasoning":false,"temperature":false,"tool_call":false,"knowledge":"2024-01","release_date":"2024-01-01","last_updated":"2025-09-05","modalities":{"input":["audio"],"output":["text"]},"open_weights":false,"cost":{"input":0,"output":0},"limit":{"context":0,"output":4096},"display_name":"Parakeet TDT 0.6B v2"},{"id":"nvidia/nemoretriever-ocr-v1","name":"NeMo Retriever OCR v1","attachment":false,"reasoning":false,"temperature":false,"tool_call":false,"knowledge":"2024-01","release_date":"2024-01-01","last_updated":"2025-09-05","modalities":{"input":["image"],"output":["text"]},"open_weights":false,"cost":{"input":0,"output":0},"limit":{"context":0,"output":4096},"display_name":"NeMo Retriever OCR v1"},{"id":"nvidia/llama-3.1-nemotron-ultra-253b-v1","name":"Llama-3.1-Nemotron-Ultra-253B-v1","attachment":false,"reasoning":true,"temperature":true,"tool_call":true,"knowledge":"2024-07","release_date":"2024-07-01","last_updated":"2025-09-05","modalities":{"input":["text"],"output":["text"]},"open_weights":false,"cost":{"input":0,"output":0},"limit":{"context":131072,"output":8192},"display_name":"Llama-3.1-Nemotron-Ultra-253B-v1"},{"id":"google/gemma-3-27b-it","name":"Gemma-3-27B-IT","attachment":true,"reasoning":true,"temperature":true,"tool_call":true,"knowledge":"2024-12","release_date":"2024-12-01","last_updated":"2025-09-05","modalities":{"input":["text","image"],"output":["text"]},"open_weights":false,"cost":{"input":0,"output":0},"limit":{"context":131072,"output":8192},"display_name":"Gemma-3-27B-IT"},{"id":"microsoft/phi-4-mini-instruct","name":"Phi-4-Mini","attachment":true,"reasoning":true,"temperature":true,"tool_call":true,"knowledge":"2024-12","release_date":"2024-12-01","last_updated":"2025-09-05","modalities":{"input":["text","image","audio"],"output":["text"]},"open_weights":false,"cost":{"input":0,"output":0},"limit":{"context":131072,"output":8192},"display_name":"Phi-4-Mini"},{"id":"openai/whisper-large-v3","name":"Whisper Large v3","attachment":false,"reasoning":false,"temperature":false,"tool_call":false,"knowledge":"2023-09","release_date":"2023-09-01","last_updated":"2025-09-05","modalities":{"input":["audio"],"output":["text"]},"open_weights":true,"cost":{"input":0,"output":0},"limit":{"context":0,"output":4096},"display_name":"Whisper Large v3"},{"id":"openai/gpt-oss-120b","name":"GPT-OSS-120B","attachment":true,"reasoning":true,"temperature":true,"tool_call":false,"knowledge":"2024-01","release_date":"2024-01-01","last_updated":"2025-09-05","modalities":{"input":["text"],"output":["text"]},"open_weights":false,"cost":{"input":0,"output":0},"limit":{"context":128000,"output":8192},"display_name":"GPT-OSS-120B"},{"id":"qwen/qwen3-235b-a22b","name":"Qwen3-235B-A22B","attachment":false,"reasoning":true,"temperature":true,"tool_call":true,"knowledge":"2024-12","release_date":"2024-12-01","last_updated":"2025-09-05","modalities":{"input":["text"],"output":["text"]},"open_weights":false,"cost":{"input":0,"output":0},"limit":{"context":131072,"output":8192},"display_name":"Qwen3-235B-A22B"},{"id":"qwen/qwen3-coder-480b-a35b-instruct","name":"Qwen3 Coder 480B A35B Instruct","attachment":false,"reasoning":false,"temperature":true,"tool_call":true,"knowledge":"2025-04","release_date":"2025-07-23","last_updated":"2025-07-23","modalities":{"input":["text"],"output":["text"]},"open_weights":false,"cost":{"input":0,"output":0},"limit":{"context":262144,"output":66536},"display_name":"Qwen3 Coder 480B A35B Instruct"},{"id":"deepseek-ai/deepseek-v3.1","name":"DeepSeek V3.1","attachment":false,"reasoning":true,"temperature":true,"tool_call":true,"knowledge":"2024-07","release_date":"2025-08-20","last_updated":"2025-08-26","modalities":{"input":["text"],"output":["text"]},"open_weights":false,"cost":{"input":0,"output":0},"limit":{"context":128000,"output":8192},"display_name":"DeepSeek V3.1"},{"id":"black-forest-labs/flux.1-dev","name":"FLUX.1-dev","attachment":false,"reasoning":false,"temperature":true,"tool_call":false,"knowledge":"2024-08","release_date":"2024-08-01","last_updated":"2025-09-05","modalities":{"input":["text"],"output":["image"]},"open_weights":false,"cost":{"input":0,"output":0},"limit":{"context":4096,"output":0},"display_name":"FLUX.1-dev"}]},"upstage":{"id":"upstage","api":"https://api.upstage.ai","name":"Upstage","doc":"https://developers.upstage.ai/docs/apis/chat","display_name":"Upstage","models":[{"id":"solar-mini","name":"solar-mini","attachment":false,"reasoning":false,"temperature":true,"tool_call":true,"knowledge":"2024-09","release_date":"2024-06-12","last_updated":"2025-04-22","modalities":{"input":["text"],"output":["text"]},"open_weights":false,"cost":{"input":0.15,"output":0.15},"limit":{"context":32768,"output":4096},"display_name":"solar-mini"},{"id":"solar-pro2","name":"solar-pro2","attachment":false,"reasoning":true,"temperature":true,"tool_call":true,"knowledge":"2025-03","release_date":"2025-05-20","last_updated":"2025-05-20","modalities":{"input":["text"],"output":["text"]},"open_weights":false,"cost":{"input":0.25,"output":0.25},"limit":{"context":65536,"output":8192},"display_name":"solar-pro2"}]},"groq":{"id":"groq","name":"Groq","doc":"https://console.groq.com/docs/models","display_name":"Groq","models":[{"id":"llama-3.1-8b-instant","name":"Llama 3.1 8B Instant","attachment":false,"reasoning":false,"temperature":true,"tool_call":true,"knowledge":"2023-12","release_date":"2024-07-23","last_updated":"2024-07-23","modalities":{"input":["text"],"output":["text"]},"open_weights":true,"cost":{"input":0.05,"output":0.08},"limit":{"context":131072,"output":8192},"display_name":"Llama 3.1 8B Instant"},{"id":"mistral-saba-24b","name":"Mistral Saba 24B","attachment":false,"reasoning":false,"temperature":true,"tool_call":true,"knowledge":"2024-08","release_date":"2025-02-06","last_updated":"2025-02-06","modalities":{"input":["text"],"output":["text"]},"open_weights":false,"cost":{"input":0.79,"output":0.79},"limit":{"context":32768,"output":32768},"display_name":"Mistral Saba 24B"},{"id":"llama3-8b-8192","name":"Llama 3 8B","attachment":false,"reasoning":false,"temperature":true,"tool_call":true,"knowledge":"2023-03","release_date":"2024-04-18","last_updated":"2024-04-18","modalities":{"input":["text"],"output":["text"]},"open_weights":true,"cost":{"input":0.05,"output":0.08},"limit":{"context":8192,"output":8192},"display_name":"Llama 3 8B"},{"id":"qwen-qwq-32b","name":"Qwen QwQ 32B","attachment":false,"reasoning":true,"temperature":true,"tool_call":true,"knowledge":"2024-09","release_date":"2024-11-27","last_updated":"2024-11-27","modalities":{"input":["text"],"output":["text"]},"open_weights":true,"cost":{"input":0.29,"output":0.39},"limit":{"context":131072,"output":16384},"display_name":"Qwen QwQ 32B"},{"id":"llama3-70b-8192","name":"Llama 3 70B","attachment":false,"reasoning":false,"temperature":true,"tool_call":true,"knowledge":"2023-03","release_date":"2024-04-18","last_updated":"2024-04-18","modalities":{"input":["text"],"output":["text"]},"open_weights":true,"cost":{"input":0.59,"output":0.79},"limit":{"context":8192,"output":8192},"display_name":"Llama 3 70B"},{"id":"deepseek-r1-distill-llama-70b","name":"DeepSeek R1 Distill Llama 70B","attachment":false,"reasoning":true,"temperature":true,"tool_call":true,"knowledge":"2024-07","release_date":"2025-01-20","last_updated":"2025-01-20","modalities":{"input":["text"],"output":["text"]},"open_weights":true,"cost":{"input":0.75,"output":0.99},"limit":{"context":131072,"output":8192},"display_name":"DeepSeek R1 Distill Llama 70B"},{"id":"llama-guard-3-8b","name":"Llama Guard 3 8B","attachment":false,"reasoning":false,"temperature":true,"tool_call":false,"release_date":"2024-07-23","last_updated":"2024-07-23","modalities":{"input":["text"],"output":["text"]},"open_weights":true,"cost":{"input":0.2,"output":0.2},"limit":{"context":8192,"output":8192},"display_name":"Llama Guard 3 8B"},{"id":"gemma2-9b-it","name":"Gemma 2 9B","attachment":false,"reasoning":false,"temperature":true,"tool_call":true,"knowledge":"2024-06","release_date":"2024-06-27","last_updated":"2024-06-27","modalities":{"input":["text"],"output":["text"]},"open_weights":true,"cost":{"input":0.2,"output":0.2},"limit":{"context":8192,"output":8192},"display_name":"Gemma 2 9B"},{"id":"llama-3.3-70b-versatile","name":"Llama 3.3 70B Versatile","attachment":false,"reasoning":false,"temperature":true,"tool_call":true,"knowledge":"2023-12","release_date":"2024-12-06","last_updated":"2024-12-06","modalities":{"input":["text"],"output":["text"]},"open_weights":true,"cost":{"input":0.59,"output":0.79},"limit":{"context":131072,"output":32768},"display_name":"Llama 3.3 70B Versatile"},{"id":"moonshotai/kimi-k2-instruct-0905","name":"Kimi K2 Instruct 0905","attachment":false,"reasoning":false,"temperature":true,"tool_call":true,"knowledge":"2024-10","release_date":"2025-09-05","last_updated":"2025-09-05","modalities":{"input":["text"],"output":["text"]},"open_weights":true,"cost":{"input":1,"output":3},"limit":{"context":262144,"output":16384},"display_name":"Kimi K2 Instruct 0905"},{"id":"moonshotai/kimi-k2-instruct","name":"Kimi K2 Instruct","attachment":false,"reasoning":false,"temperature":true,"tool_call":true,"knowledge":"2024-10","release_date":"2025-07-14","last_updated":"2025-07-14","modalities":{"input":["text"],"output":["text"]},"open_weights":true,"cost":{"input":1,"output":3},"limit":{"context":131072,"output":16384},"display_name":"Kimi K2 Instruct"},{"id":"openai/gpt-oss-20b","name":"GPT OSS 20B","attachment":false,"reasoning":true,"temperature":true,"tool_call":true,"release_date":"2025-08-05","last_updated":"2025-08-05","modalities":{"input":["text"],"output":["text"]},"open_weights":true,"cost":{"input":0.1,"output":0.5},"limit":{"context":131072,"output":32768},"display_name":"GPT OSS 20B"},{"id":"openai/gpt-oss-120b","name":"GPT OSS 120B","attachment":false,"reasoning":true,"temperature":true,"tool_call":true,"release_date":"2025-08-05","last_updated":"2025-08-05","modalities":{"input":["text"],"output":["text"]},"open_weights":true,"cost":{"input":0.15,"output":0.75},"limit":{"context":131072,"output":32768},"display_name":"GPT OSS 120B"},{"id":"qwen/qwen3-32b","name":"Qwen3 32B","attachment":false,"reasoning":true,"temperature":true,"tool_call":true,"knowledge":"2024-11-08","release_date":"2024-12-23","last_updated":"2024-12-23","modalities":{"input":["text"],"output":["text"]},"open_weights":true,"cost":{"input":0.29,"output":0.59},"limit":{"context":131072,"output":16384},"display_name":"Qwen3 32B"},{"id":"meta-llama/llama-4-scout-17b-16e-instruct","name":"Llama 4 Scout 17B","attachment":false,"reasoning":false,"temperature":true,"tool_call":true,"knowledge":"2024-08","release_date":"2025-04-05","last_updated":"2025-04-05","modalities":{"input":["text","image"],"output":["text"]},"open_weights":true,"cost":{"input":0.11,"output":0.34},"limit":{"context":131072,"output":8192},"display_name":"Llama 4 Scout 17B"},{"id":"meta-llama/llama-4-maverick-17b-128e-instruct","name":"Llama 4 Maverick 17B","attachment":false,"reasoning":false,"temperature":true,"tool_call":true,"knowledge":"2024-08","release_date":"2025-04-05","last_updated":"2025-04-05","modalities":{"input":["text","image"],"output":["text"]},"open_weights":true,"cost":{"input":0.2,"output":0.6},"limit":{"context":131072,"output":8192},"display_name":"Llama 4 Maverick 17B"},{"id":"meta-llama/llama-guard-4-12b","name":"Llama Guard 4 12B","attachment":false,"reasoning":false,"temperature":true,"tool_call":false,"release_date":"2025-04-05","last_updated":"2025-04-05","modalities":{"input":["text","image"],"output":["text"]},"open_weights":true,"cost":{"input":0.2,"output":0.2},"limit":{"context":131072,"output":128},"display_name":"Llama Guard 4 12B"}]},"github-copilot":{"id":"github-copilot","api":"https://api.githubcopilot.com","name":"GitHub Copilot","doc":"https://docs.github.com/en/copilot","display_name":"GitHub Copilot","models":[{"id":"gemini-2.0-flash-001","name":"Gemini 2.0 Flash","attachment":true,"reasoning":false,"temperature":true,"tool_call":true,"knowledge":"2024-06","release_date":"2024-12-11","last_updated":"2024-12-11","modalities":{"input":["text","image","audio","video"],"output":["text"]},"open_weights":false,"limit":{"context":1000000,"output":8192},"display_name":"Gemini 2.0 Flash"},{"id":"claude-opus-4","name":"Claude Opus 4","attachment":true,"reasoning":true,"temperature":false,"tool_call":false,"knowledge":"2025-03-31","release_date":"2025-05-22","last_updated":"2025-05-22","modalities":{"input":["text","image"],"output":["text"]},"open_weights":false,"limit":{"context":80000,"output":16000},"display_name":"Claude Opus 4"},{"id":"grok-code-fast-1","name":"Grok Code Fast 1","attachment":false,"reasoning":true,"temperature":true,"tool_call":true,"knowledge":"2025-08","release_date":"2025-08-27","last_updated":"2025-08-27","modalities":{"input":["text"],"output":["text"]},"open_weights":false,"limit":{"context":256000,"output":10000},"display_name":"Grok Code Fast 1"},{"id":"claude-3.5-sonnet","name":"Claude Sonnet 3.5","attachment":true,"reasoning":false,"temperature":true,"tool_call":true,"knowledge":"2024-04","release_date":"2024-10-22","last_updated":"2024-10-22","modalities":{"input":["text","image"],"output":["text"]},"open_weights":false,"limit":{"context":90000,"output":8192},"display_name":"Claude Sonnet 3.5"},{"id":"o3-mini","name":"o3-mini","attachment":false,"reasoning":true,"temperature":false,"tool_call":false,"knowledge":"2024-10","release_date":"2024-12-20","last_updated":"2025-01-29","modalities":{"input":["text"],"output":["text"]},"open_weights":false,"limit":{"context":128000,"output":65536},"display_name":"o3-mini"},{"id":"gpt-5-codex","name":"GPT-5-Codex","attachment":false,"reasoning":true,"temperature":false,"tool_call":true,"knowledge":"2024-09-30","release_date":"2025-09-15","last_updated":"2025-09-15","modalities":{"input":["text","image"],"output":["text"]},"open_weights":false,"limit":{"context":128000,"output":64000},"display_name":"GPT-5-Codex"},{"id":"gpt-4o","name":"GPT-4o","attachment":true,"reasoning":false,"temperature":true,"tool_call":true,"knowledge":"2023-09","release_date":"2024-05-13","last_updated":"2024-05-13","modalities":{"input":["text","image"],"output":["text"]},"open_weights":false,"limit":{"context":128000,"output":16384},"display_name":"GPT-4o"},{"id":"gpt-4.1","name":"GPT-4.1","attachment":true,"reasoning":false,"temperature":true,"tool_call":true,"knowledge":"2024-04","release_date":"2025-04-14","last_updated":"2025-04-14","modalities":{"input":["text","image"],"output":["text"]},"open_weights":false,"limit":{"context":128000,"output":16384},"display_name":"GPT-4.1"},{"id":"o4-mini","name":"o4-mini (Preview)","attachment":false,"reasoning":true,"temperature":false,"tool_call":false,"knowledge":"2024-10","release_date":"2025-04-16","last_updated":"2025-04-16","modalities":{"input":["text"],"output":["text"]},"open_weights":false,"limit":{"context":128000,"output":65536},"display_name":"o4-mini (Preview)"},{"id":"claude-opus-41","name":"Claude Opus 4.1","attachment":true,"reasoning":true,"temperature":true,"tool_call":false,"knowledge":"2025-03-31","release_date":"2025-08-05","last_updated":"2025-08-05","modalities":{"input":["text","image"],"output":["text"]},"open_weights":false,"limit":{"context":80000,"output":16000},"display_name":"Claude Opus 4.1"},{"id":"gpt-5-mini","name":"GPT-5-mini","attachment":true,"reasoning":true,"temperature":true,"tool_call":true,"knowledge":"2024-06","release_date":"2025-08-13","last_updated":"2025-08-13","modalities":{"input":["text","image"],"output":["text"]},"open_weights":false,"limit":{"context":128000,"output":64000},"display_name":"GPT-5-mini"},{"id":"claude-3.7-sonnet","name":"Claude Sonnet 3.7","attachment":true,"reasoning":false,"temperature":true,"tool_call":true,"knowledge":"2024-04","release_date":"2025-02-19","last_updated":"2025-02-19","modalities":{"input":["text","image"],"output":["text"]},"open_weights":false,"limit":{"context":200000,"output":16384},"display_name":"Claude Sonnet 3.7"},{"id":"gemini-2.5-pro","name":"Gemini 2.5 Pro","attachment":true,"reasoning":false,"temperature":true,"tool_call":true,"knowledge":"2025-01","release_date":"2025-03-20","last_updated":"2025-06-05","modalities":{"input":["text","image","audio","video"],"output":["text"]},"open_weights":false,"limit":{"context":128000,"output":64000},"display_name":"Gemini 2.5 Pro"},{"id":"o3","name":"o3 (Preview)","attachment":true,"reasoning":true,"temperature":false,"tool_call":true,"knowledge":"2024-05","release_date":"2025-04-16","last_updated":"2025-04-16","modalities":{"input":["text","image"],"output":["text"]},"open_weights":false,"limit":{"context":128000,"output":16384},"display_name":"o3 (Preview)"},{"id":"claude-sonnet-4","name":"Claude Sonnet 4","attachment":true,"reasoning":true,"temperature":true,"tool_call":true,"knowledge":"2025-03-31","release_date":"2025-05-22","last_updated":"2025-05-22","modalities":{"input":["text","image"],"output":["text"]},"open_weights":false,"limit":{"context":128000,"output":16000},"display_name":"Claude Sonnet 4"},{"id":"gpt-5","name":"GPT-5","attachment":true,"reasoning":true,"temperature":true,"tool_call":true,"knowledge":"2024-10","release_date":"2025-08-07","last_updated":"2025-08-07","modalities":{"input":["text","image"],"output":["text"]},"open_weights":false,"limit":{"context":128000,"output":64000},"display_name":"GPT-5"},{"id":"claude-3.7-sonnet-thought","name":"Claude Sonnet 3.7 Thinking","attachment":true,"reasoning":true,"temperature":true,"tool_call":true,"knowledge":"2024-04","release_date":"2025-02-19","last_updated":"2025-02-19","modalities":{"input":["text","image"],"output":["text"]},"open_weights":false,"limit":{"context":200000,"output":16384},"display_name":"Claude Sonnet 3.7 Thinking"},{"id":"claude-sonnet-4.5","name":"Claude Sonnet 4.5 (Preview)","attachment":true,"reasoning":true,"temperature":true,"tool_call":true,"knowledge":"2025-03-31","release_date":"2025-09-29","last_updated":"2025-09-29","modalities":{"input":["text","image"],"output":["text"]},"open_weights":false,"limit":{"context":128000,"output":16000},"display_name":"Claude Sonnet 4.5 (Preview)"}]},"mistral":{"id":"mistral","name":"Mistral","doc":"https://docs.mistral.ai/getting-started/models/","display_name":"Mistral","models":[{"id":"devstral-medium-2507","name":"Devstral Medium","attachment":false,"reasoning":false,"temperature":true,"tool_call":true,"knowledge":"2025-05","release_date":"2025-07-10","last_updated":"2025-07-10","modalities":{"input":["text"],"output":["text"]},"open_weights":true,"cost":{"input":0.4,"output":2},"limit":{"context":128000,"output":128000},"display_name":"Devstral Medium"},{"id":"open-mixtral-8x22b","name":"Mixtral 8x22B","attachment":false,"reasoning":false,"temperature":true,"tool_call":true,"knowledge":"2024-04","release_date":"2024-04-17","last_updated":"2024-04-17","modalities":{"input":["text"],"output":["text"]},"open_weights":true,"cost":{"input":2,"output":6},"limit":{"context":64000,"output":64000},"display_name":"Mixtral 8x22B"},{"id":"ministral-8b-latest","name":"Ministral 8B","attachment":false,"reasoning":false,"temperature":true,"tool_call":true,"knowledge":"2024-10","release_date":"2024-10-01","last_updated":"2024-10-04","modalities":{"input":["text"],"output":["text"]},"open_weights":true,"cost":{"input":0.1,"output":0.1},"limit":{"context":128000,"output":128000},"display_name":"Ministral 8B"},{"id":"pixtral-large-latest","name":"Pixtral Large","attachment":true,"reasoning":false,"temperature":true,"tool_call":true,"knowledge":"2024-11","release_date":"2024-11-01","last_updated":"2024-11-04","modalities":{"input":["text","image"],"output":["text"]},"open_weights":true,"cost":{"input":2,"output":6},"limit":{"context":128000,"output":128000},"display_name":"Pixtral Large"},{"id":"ministral-3b-latest","name":"Ministral 3B","attachment":false,"reasoning":false,"temperature":true,"tool_call":true,"knowledge":"2024-10","release_date":"2024-10-01","last_updated":"2024-10-04","modalities":{"input":["text"],"output":["text"]},"open_weights":true,"cost":{"input":0.04,"output":0.04},"limit":{"context":128000,"output":128000},"display_name":"Ministral 3B"},{"id":"pixtral-12b","name":"Pixtral 12B","attachment":true,"reasoning":false,"temperature":true,"tool_call":true,"knowledge":"2024-09","release_date":"2024-09-01","last_updated":"2024-09-01","modalities":{"input":["text","image"],"output":["text"]},"open_weights":true,"cost":{"input":0.15,"output":0.15},"limit":{"context":128000,"output":128000},"display_name":"Pixtral 12B"},{"id":"mistral-medium-2505","name":"Mistral Medium 3","attachment":true,"reasoning":false,"temperature":true,"tool_call":true,"knowledge":"2025-05","release_date":"2025-05-07","last_updated":"2025-05-07","modalities":{"input":["text","image"],"output":["text"]},"open_weights":false,"cost":{"input":0.4,"output":2},"limit":{"context":131072,"output":131072},"display_name":"Mistral Medium 3"},{"id":"devstral-small-2505","name":"Devstral Small 2505","attachment":false,"reasoning":false,"temperature":true,"tool_call":true,"knowledge":"2025-05","release_date":"2025-05-07","last_updated":"2025-05-07","modalities":{"input":["text"],"output":["text"]},"open_weights":true,"cost":{"input":0.1,"output":0.3},"limit":{"context":128000,"output":128000},"display_name":"Devstral Small 2505"},{"id":"mistral-medium-2508","name":"Mistral Medium 3.1","attachment":true,"reasoning":false,"temperature":true,"tool_call":true,"knowledge":"2025-05","release_date":"2025-08-12","last_updated":"2025-08-12","modalities":{"input":["text","image"],"output":["text"]},"open_weights":false,"cost":{"input":0.4,"output":2},"limit":{"context":262144,"output":262144},"display_name":"Mistral Medium 3.1"},{"id":"mistral-small-latest","name":"Mistral Small","attachment":false,"reasoning":false,"temperature":true,"tool_call":true,"knowledge":"2025-03","release_date":"2024-09-01","last_updated":"2024-09-04","modalities":{"input":["text","image"],"output":["text"]},"open_weights":true,"cost":{"input":0.1,"output":0.3},"limit":{"context":128000,"output":16384},"display_name":"Mistral Small"},{"id":"magistral-small","name":"Magistral Small","attachment":false,"reasoning":true,"temperature":true,"tool_call":true,"knowledge":"2025-06","release_date":"2025-03-17","last_updated":"2025-03-17","modalities":{"input":["text"],"output":["text"]},"open_weights":true,"cost":{"input":0.5,"output":1.5},"limit":{"context":128000,"output":128000},"display_name":"Magistral Small"},{"id":"devstral-small-2507","name":"Devstral Small","attachment":false,"reasoning":false,"temperature":true,"tool_call":true,"knowledge":"2025-05","release_date":"2025-07-10","last_updated":"2025-07-10","modalities":{"input":["text"],"output":["text"]},"open_weights":true,"cost":{"input":0.1,"output":0.3},"limit":{"context":128000,"output":128000},"display_name":"Devstral Small"},{"id":"codestral-latest","name":"Codestral","attachment":false,"reasoning":false,"temperature":true,"tool_call":true,"knowledge":"2024-10","release_date":"2024-05-29","last_updated":"2025-01-04","modalities":{"input":["text"],"output":["text"]},"open_weights":true,"cost":{"input":0.3,"output":0.9},"limit":{"context":256000,"output":4096},"display_name":"Codestral"},{"id":"open-mixtral-8x7b","name":"Mixtral 8x7B","attachment":false,"reasoning":false,"temperature":true,"tool_call":true,"knowledge":"2024-01","release_date":"2023-12-11","last_updated":"2023-12-11","modalities":{"input":["text"],"output":["text"]},"open_weights":true,"cost":{"input":0.7,"output":0.7},"limit":{"context":32000,"output":32000},"display_name":"Mixtral 8x7B"},{"id":"mistral-nemo","name":"Mistral Nemo","attachment":false,"reasoning":false,"temperature":true,"tool_call":true,"knowledge":"2024-07","release_date":"2024-07-01","last_updated":"2024-07-01","modalities":{"input":["text"],"output":["text"]},"open_weights":true,"cost":{"input":0.15,"output":0.15},"limit":{"context":128000,"output":128000},"display_name":"Mistral Nemo"},{"id":"open-mistral-7b","name":"Mistral 7B","attachment":false,"reasoning":false,"temperature":true,"tool_call":true,"knowledge":"2023-12","release_date":"2023-09-27","last_updated":"2023-09-27","modalities":{"input":["text"],"output":["text"]},"open_weights":true,"cost":{"input":0.25,"output":0.25},"limit":{"context":8000,"output":8000},"display_name":"Mistral 7B"},{"id":"mistral-large-latest","name":"Mistral Large","attachment":false,"reasoning":false,"temperature":true,"tool_call":true,"knowledge":"2024-11","release_date":"2024-11-01","last_updated":"2024-11-04","modalities":{"input":["text"],"output":["text"]},"open_weights":true,"cost":{"input":2,"output":6},"limit":{"context":131072,"output":16384},"display_name":"Mistral Large"},{"id":"mistral-medium-latest","name":"Mistral Medium","attachment":false,"reasoning":false,"temperature":true,"tool_call":true,"knowledge":"2025-05","release_date":"2025-05-07","last_updated":"2025-05-10","modalities":{"input":["text","image"],"output":["text"]},"open_weights":true,"cost":{"input":0.4,"output":2},"limit":{"context":128000,"output":16384},"display_name":"Mistral Medium"},{"id":"magistral-medium-latest","name":"Magistral Medium","attachment":false,"reasoning":true,"temperature":true,"tool_call":true,"knowledge":"2025-06","release_date":"2025-03-17","last_updated":"2025-03-20","modalities":{"input":["text"],"output":["text"]},"open_weights":true,"cost":{"input":2,"output":5},"limit":{"context":128000,"output":16384},"display_name":"Magistral Medium"}]},"vercel":{"id":"vercel","name":"Vercel AI Gateway","doc":"https://github.com/vercel/ai/tree/5eb85cc45a259553501f535b8ac79a77d0e79223/packages/gateway","display_name":"Vercel AI Gateway","models":[{"id":"moonshotai/kimi-k2","name":"Kimi K2 Instruct","attachment":false,"reasoning":false,"temperature":true,"tool_call":true,"knowledge":"2024-10","release_date":"2025-07-14","last_updated":"2025-07-14","modalities":{"input":["text"],"output":["text"]},"open_weights":true,"cost":{"input":1,"output":3},"limit":{"context":131072,"output":16384},"display_name":"Kimi K2 Instruct"},{"id":"xai/grok-3-mini-fast","name":"Grok 3 Mini Fast","attachment":false,"reasoning":true,"temperature":true,"tool_call":true,"knowledge":"2024-11","release_date":"2025-02-17","last_updated":"2025-02-17","modalities":{"input":["text"],"output":["text"]},"open_weights":false,"cost":{"input":0.6,"output":4,"reasoning":4,"cache_read":0.15},"limit":{"context":131072,"output":8192},"display_name":"Grok 3 Mini Fast"},{"id":"xai/grok-3-mini","name":"Grok 3 Mini","attachment":false,"reasoning":true,"temperature":true,"tool_call":true,"knowledge":"2024-11","release_date":"2025-02-17","last_updated":"2025-02-17","modalities":{"input":["text"],"output":["text"]},"open_weights":false,"cost":{"input":0.3,"output":0.5,"reasoning":0.5,"cache_read":0.075},"limit":{"context":131072,"output":8192},"display_name":"Grok 3 Mini"},{"id":"xai/grok-4-fast","name":"Grok 4 Fast","attachment":true,"reasoning":true,"temperature":true,"tool_call":true,"knowledge":"2025-07","release_date":"2025-09-19","last_updated":"2025-09-19","modalities":{"input":["text","image"],"output":["text"]},"open_weights":false,"cost":{"input":0.2,"output":0.5,"cache_read":0.05},"limit":{"context":2000000,"output":30000},"display_name":"Grok 4 Fast"},{"id":"xai/grok-3","name":"Grok 3","attachment":false,"reasoning":false,"temperature":true,"tool_call":true,"knowledge":"2024-11","release_date":"2025-02-17","last_updated":"2025-02-17","modalities":{"input":["text"],"output":["text"]},"open_weights":false,"cost":{"input":3,"output":15,"cache_read":0.75},"limit":{"context":131072,"output":8192},"display_name":"Grok 3"},{"id":"xai/grok-2","name":"Grok 2","attachment":false,"reasoning":false,"temperature":true,"tool_call":true,"knowledge":"2024-08","release_date":"2024-08-20","last_updated":"2024-08-20","modalities":{"input":["text"],"output":["text"]},"open_weights":false,"cost":{"input":2,"output":10,"cache_read":2},"limit":{"context":131072,"output":8192},"display_name":"Grok 2"},{"id":"xai/grok-code-fast-1","name":"Grok Code Fast 1","attachment":false,"reasoning":true,"temperature":true,"tool_call":true,"knowledge":"2023-10","release_date":"2025-08-28","last_updated":"2025-08-28","modalities":{"input":["text"],"output":["text"]},"open_weights":false,"cost":{"input":0.2,"output":1.5,"cache_read":0.02},"limit":{"context":256000,"output":10000},"display_name":"Grok Code Fast 1"},{"id":"xai/grok-2-vision","name":"Grok 2 Vision","attachment":true,"reasoning":false,"temperature":true,"tool_call":true,"knowledge":"2024-08","release_date":"2024-08-20","last_updated":"2024-08-20","modalities":{"input":["text","image"],"output":["text"]},"open_weights":false,"cost":{"input":2,"output":10,"cache_read":2},"limit":{"context":8192,"output":4096},"display_name":"Grok 2 Vision"},{"id":"xai/grok-4","name":"Grok 4","attachment":false,"reasoning":true,"temperature":true,"tool_call":true,"knowledge":"2025-07","release_date":"2025-07-09","last_updated":"2025-07-09","modalities":{"input":["text"],"output":["text"]},"open_weights":false,"cost":{"input":3,"output":15,"reasoning":15,"cache_read":0.75},"limit":{"context":256000,"output":64000},"display_name":"Grok 4"},{"id":"xai/grok-3-fast","name":"Grok 3 Fast","attachment":false,"reasoning":false,"temperature":true,"tool_call":true,"knowledge":"2024-11","release_date":"2025-02-17","last_updated":"2025-02-17","modalities":{"input":["text"],"output":["text"]},"open_weights":false,"cost":{"input":5,"output":25,"cache_read":1.25},"limit":{"context":131072,"output":8192},"display_name":"Grok 3 Fast"},{"id":"xai/grok-4-fast-non-reasoning","name":"Grok 4 Fast (Non-Reasoning)","attachment":true,"reasoning":false,"temperature":true,"tool_call":true,"knowledge":"2025-07","release_date":"2025-09-19","last_updated":"2025-09-19","modalities":{"input":["text","image"],"output":["text"]},"open_weights":false,"cost":{"input":0.2,"output":0.5,"cache_read":0.05},"limit":{"context":2000000,"output":30000},"display_name":"Grok 4 Fast (Non-Reasoning)"},{"id":"mistral/codestral","name":"Codestral","attachment":false,"reasoning":false,"temperature":true,"tool_call":true,"knowledge":"2024-10","release_date":"2024-05-29","last_updated":"2025-01-04","modalities":{"input":["text"],"output":["text"]},"open_weights":true,"cost":{"input":0.3,"output":0.9},"limit":{"context":256000,"output":4096},"display_name":"Codestral"},{"id":"mistral/magistral-medium","name":"Magistral Medium","attachment":false,"reasoning":true,"temperature":true,"tool_call":true,"knowledge":"2025-06","release_date":"2025-03-17","last_updated":"2025-03-20","modalities":{"input":["text"],"output":["text"]},"open_weights":true,"cost":{"input":2,"output":5},"limit":{"context":128000,"output":16384},"display_name":"Magistral Medium"},{"id":"mistral/mistral-large","name":"Mistral Large","attachment":false,"reasoning":false,"temperature":true,"tool_call":true,"knowledge":"2024-11","release_date":"2024-11-01","last_updated":"2024-11-04","modalities":{"input":["text"],"output":["text"]},"open_weights":true,"cost":{"input":2,"output":6},"limit":{"context":131072,"output":16384},"display_name":"Mistral Large"},{"id":"mistral/pixtral-large","name":"Pixtral Large","attachment":true,"reasoning":false,"temperature":true,"tool_call":true,"knowledge":"2024-11","release_date":"2024-11-01","last_updated":"2024-11-04","modalities":{"input":["text","image"],"output":["text"]},"open_weights":true,"cost":{"input":2,"output":6},"limit":{"context":128000,"output":128000},"display_name":"Pixtral Large"},{"id":"mistral/ministral-8b","name":"Ministral 8B","attachment":false,"reasoning":false,"temperature":true,"tool_call":true,"knowledge":"2024-10","release_date":"2024-10-01","last_updated":"2024-10-04","modalities":{"input":["text"],"output":["text"]},"open_weights":true,"cost":{"input":0.1,"output":0.1},"limit":{"context":128000,"output":128000},"display_name":"Ministral 8B"},{"id":"mistral/ministral-3b","name":"Ministral 3B","attachment":false,"reasoning":false,"temperature":true,"tool_call":true,"knowledge":"2024-10","release_date":"2024-10-01","last_updated":"2024-10-04","modalities":{"input":["text"],"output":["text"]},"open_weights":true,"cost":{"input":0.04,"output":0.04},"limit":{"context":128000,"output":128000},"display_name":"Ministral 3B"},{"id":"mistral/magistral-small","name":"Magistral Small","attachment":false,"reasoning":true,"temperature":true,"tool_call":true,"knowledge":"2025-06","release_date":"2025-03-17","last_updated":"2025-03-17","modalities":{"input":["text"],"output":["text"]},"open_weights":true,"cost":{"input":0.5,"output":1.5},"limit":{"context":128000,"output":128000},"display_name":"Magistral Small"},{"id":"mistral/mistral-small","name":"Mistral Small","attachment":false,"reasoning":false,"temperature":true,"tool_call":true,"knowledge":"2025-03","release_date":"2024-09-01","last_updated":"2024-09-04","modalities":{"input":["text","image"],"output":["text"]},"open_weights":true,"cost":{"input":0.1,"output":0.3},"limit":{"context":128000,"output":16384},"display_name":"Mistral Small"},{"id":"mistral/pixtral-12b","name":"Pixtral 12B","attachment":true,"reasoning":false,"temperature":true,"tool_call":true,"knowledge":"2024-09","release_date":"2024-09-01","last_updated":"2024-09-01","modalities":{"input":["text","image"],"output":["text"]},"open_weights":true,"cost":{"input":0.15,"output":0.15},"limit":{"context":128000,"output":128000},"display_name":"Pixtral 12B"},{"id":"mistral/mixtral-8x22b-instruct","name":"Mixtral 8x22B","attachment":false,"reasoning":false,"temperature":true,"tool_call":true,"knowledge":"2024-04","release_date":"2024-04-17","last_updated":"2024-04-17","modalities":{"input":["text"],"output":["text"]},"open_weights":true,"cost":{"input":2,"output":6},"limit":{"context":64000,"output":64000},"display_name":"Mixtral 8x22B"},{"id":"vercel/v0-1.0-md","name":"v0-1.0-md","attachment":true,"reasoning":true,"temperature":true,"tool_call":true,"release_date":"2025-05-22","last_updated":"2025-05-22","modalities":{"input":["text","image"],"output":["text"]},"open_weights":false,"cost":{"input":3,"output":15},"limit":{"context":128000,"output":32000},"display_name":"v0-1.0-md"},{"id":"vercel/v0-1.5-md","name":"v0-1.5-md","attachment":true,"reasoning":true,"temperature":true,"tool_call":true,"release_date":"2025-06-09","last_updated":"2025-06-09","modalities":{"input":["text","image"],"output":["text"]},"open_weights":false,"cost":{"input":3,"output":15},"limit":{"context":128000,"output":32000},"display_name":"v0-1.5-md"},{"id":"deepseek/deepseek-r1-distill-llama-70b","name":"DeepSeek R1 Distill Llama 70B","attachment":false,"reasoning":true,"temperature":true,"tool_call":true,"knowledge":"2024-07","release_date":"2025-01-20","last_updated":"2025-01-20","modalities":{"input":["text"],"output":["text"]},"open_weights":true,"cost":{"input":0.75,"output":0.99},"limit":{"context":131072,"output":8192},"display_name":"DeepSeek R1 Distill Llama 70B"},{"id":"deepseek/deepseek-r1","name":"DeepSeek-R1","attachment":false,"reasoning":true,"temperature":true,"tool_call":true,"knowledge":"2024-07","release_date":"2025-01-20","last_updated":"2025-05-29","modalities":{"input":["text"],"output":["text"]},"open_weights":false,"cost":{"input":1.35,"output":5.4},"limit":{"context":128000,"output":32768},"display_name":"DeepSeek-R1"},{"id":"google/gemini-2.5-pro","name":"Gemini 2.5 Pro","attachment":true,"reasoning":true,"temperature":true,"tool_call":true,"knowledge":"2025-01","release_date":"2025-03-20","last_updated":"2025-06-05","modalities":{"input":["text","image","audio","video","pdf"],"output":["text"]},"open_weights":false,"cost":{"input":1.25,"output":10,"cache_read":0.31},"limit":{"context":1048576,"output":65536},"display_name":"Gemini 2.5 Pro"},{"id":"google/gemini-2.0-flash","name":"Gemini 2.0 Flash","attachment":true,"reasoning":false,"temperature":true,"tool_call":true,"knowledge":"2024-06","release_date":"2024-12-11","last_updated":"2024-12-11","modalities":{"input":["text","image","audio","video","pdf"],"output":["text"]},"open_weights":false,"cost":{"input":0.1,"output":0.4,"cache_read":0.025},"limit":{"context":1048576,"output":8192},"display_name":"Gemini 2.0 Flash"},{"id":"google/gemini-2.0-flash-lite","name":"Gemini 2.0 Flash Lite","attachment":true,"reasoning":false,"temperature":true,"tool_call":true,"knowledge":"2024-06","release_date":"2024-12-11","last_updated":"2024-12-11","modalities":{"input":["text","image","audio","video","pdf"],"output":["text"]},"open_weights":false,"cost":{"input":0.075,"output":0.3},"limit":{"context":1048576,"output":8192},"display_name":"Gemini 2.0 Flash Lite"},{"id":"google/gemini-2.5-flash","name":"Gemini 2.5 Flash","attachment":true,"reasoning":true,"temperature":true,"tool_call":true,"knowledge":"2025-01","release_date":"2025-03-20","last_updated":"2025-06-05","modalities":{"input":["text","image","audio","video","pdf"],"output":["text"]},"open_weights":false,"cost":{"input":0.3,"output":2.5,"cache_read":0.075,"input_audio":1},"limit":{"context":1048576,"output":65536},"display_name":"Gemini 2.5 Flash"},{"id":"openai/gpt-oss-20b","name":"GPT OSS 20B","attachment":false,"reasoning":true,"temperature":true,"tool_call":true,"release_date":"2025-08-05","last_updated":"2025-08-05","modalities":{"input":["text"],"output":["text"]},"open_weights":true,"cost":{"input":0.07,"output":0.3},"limit":{"context":131072,"output":32768},"display_name":"GPT OSS 20B"},{"id":"openai/gpt-oss-120b","name":"GPT OSS 120B","attachment":false,"reasoning":true,"temperature":true,"tool_call":true,"release_date":"2025-08-05","last_updated":"2025-08-05","modalities":{"input":["text"],"output":["text"]},"open_weights":true,"cost":{"input":0.1,"output":0.5},"limit":{"context":131072,"output":32768},"display_name":"GPT OSS 120B"},{"id":"openai/gpt-5","name":"GPT-5","attachment":true,"reasoning":true,"temperature":false,"tool_call":true,"knowledge":"2024-09-30","release_date":"2025-08-07","last_updated":"2025-08-07","modalities":{"input":["text","image"],"output":["text"]},"open_weights":false,"cost":{"input":1.25,"output":10,"cache_read":0.13},"limit":{"context":400000,"output":128000},"display_name":"GPT-5"},{"id":"openai/gpt-4o-mini","name":"GPT-4o mini","attachment":true,"reasoning":false,"temperature":true,"tool_call":true,"knowledge":"2023-09","release_date":"2024-07-18","last_updated":"2024-07-18","modalities":{"input":["text","image"],"output":["text"]},"open_weights":false,"cost":{"input":0.15,"output":0.6,"cache_read":0.08},"limit":{"context":128000,"output":16384},"display_name":"GPT-4o mini"},{"id":"openai/o3","name":"o3","attachment":true,"reasoning":true,"temperature":false,"tool_call":true,"knowledge":"2024-05","release_date":"2025-04-16","last_updated":"2025-04-16","modalities":{"input":["text","image"],"output":["text"]},"open_weights":false,"cost":{"input":2,"output":8,"cache_read":0.5},"limit":{"context":200000,"output":100000},"display_name":"o3"},{"id":"openai/gpt-5-mini","name":"GPT-5 Mini","attachment":true,"reasoning":true,"temperature":false,"tool_call":true,"knowledge":"2024-05-30","release_date":"2025-08-07","last_updated":"2025-08-07","modalities":{"input":["text","image"],"output":["text"]},"open_weights":false,"cost":{"input":0.25,"output":2,"cache_read":0.03},"limit":{"context":400000,"output":128000},"display_name":"GPT-5 Mini"},{"id":"openai/o1","name":"o1","attachment":true,"reasoning":true,"temperature":false,"tool_call":true,"knowledge":"2023-09","release_date":"2024-12-05","last_updated":"2024-12-05","modalities":{"input":["text","image"],"output":["text"]},"open_weights":false,"cost":{"input":15,"output":60,"cache_read":7.5},"limit":{"context":200000,"output":100000},"display_name":"o1"},{"id":"openai/o4-mini","name":"o4-mini","attachment":true,"reasoning":true,"temperature":false,"tool_call":true,"knowledge":"2024-05","release_date":"2025-04-16","last_updated":"2025-04-16","modalities":{"input":["text","image"],"output":["text"]},"open_weights":false,"cost":{"input":1.1,"output":4.4,"cache_read":0.28},"limit":{"context":200000,"output":100000},"display_name":"o4-mini"},{"id":"openai/gpt-4.1","name":"GPT-4.1","attachment":true,"reasoning":false,"temperature":true,"tool_call":true,"knowledge":"2024-04","release_date":"2025-04-14","last_updated":"2025-04-14","modalities":{"input":["text","image"],"output":["text"]},"open_weights":false,"cost":{"input":2,"output":8,"cache_read":0.5},"limit":{"context":1047576,"output":32768},"display_name":"GPT-4.1"},{"id":"openai/gpt-4o","name":"GPT-4o","attachment":true,"reasoning":false,"temperature":true,"tool_call":true,"knowledge":"2023-09","release_date":"2024-05-13","last_updated":"2024-08-06","modalities":{"input":["text","image"],"output":["text"]},"open_weights":false,"cost":{"input":2.5,"output":10,"cache_read":1.25},"limit":{"context":128000,"output":16384},"display_name":"GPT-4o"},{"id":"openai/gpt-5-codex","name":"GPT-5-Codex","attachment":false,"reasoning":true,"temperature":false,"tool_call":true,"knowledge":"2024-09-30","release_date":"2025-09-15","last_updated":"2025-09-15","modalities":{"input":["text","image"],"output":["text"]},"open_weights":false,"limit":{"context":400000,"output":128000},"display_name":"GPT-5-Codex"},{"id":"openai/gpt-5-nano","name":"GPT-5 Nano","attachment":true,"reasoning":true,"temperature":false,"tool_call":true,"knowledge":"2024-05-30","release_date":"2025-08-07","last_updated":"2025-08-07","modalities":{"input":["text","image"],"output":["text"]},"open_weights":false,"cost":{"input":0.05,"output":0.4,"cache_read":0.01},"limit":{"context":400000,"output":128000},"display_name":"GPT-5 Nano"},{"id":"openai/o3-mini","name":"o3-mini","attachment":false,"reasoning":true,"temperature":false,"tool_call":true,"knowledge":"2024-05","release_date":"2024-12-20","last_updated":"2025-01-29","modalities":{"input":["text"],"output":["text"]},"open_weights":false,"cost":{"input":1.1,"output":4.4,"cache_read":0.55},"limit":{"context":200000,"output":100000},"display_name":"o3-mini"},{"id":"openai/gpt-4-turbo","name":"GPT-4 Turbo","attachment":true,"reasoning":false,"temperature":true,"tool_call":true,"knowledge":"2023-12","release_date":"2023-11-06","last_updated":"2024-04-09","modalities":{"input":["text","image"],"output":["text"]},"open_weights":false,"cost":{"input":10,"output":30},"limit":{"context":128000,"output":4096},"display_name":"GPT-4 Turbo"},{"id":"openai/gpt-4.1-mini","name":"GPT-4.1 mini","attachment":true,"reasoning":false,"temperature":true,"tool_call":true,"knowledge":"2024-04","release_date":"2025-04-14","last_updated":"2025-04-14","modalities":{"input":["text","image"],"output":["text"]},"open_weights":false,"cost":{"input":0.4,"output":1.6,"cache_read":0.1},"limit":{"context":1047576,"output":32768},"display_name":"GPT-4.1 mini"},{"id":"openai/gpt-4.1-nano","name":"GPT-4.1 nano","attachment":true,"reasoning":false,"temperature":true,"tool_call":true,"knowledge":"2024-04","release_date":"2025-04-14","last_updated":"2025-04-14","modalities":{"input":["text","image"],"output":["text"]},"open_weights":false,"cost":{"input":0.1,"output":0.4,"cache_read":0.03},"limit":{"context":1047576,"output":32768},"display_name":"GPT-4.1 nano"},{"id":"amazon/nova-micro","name":"Nova Micro","attachment":false,"reasoning":false,"temperature":true,"tool_call":true,"knowledge":"2024-10","release_date":"2024-12-03","last_updated":"2024-12-03","modalities":{"input":["text"],"output":["text"]},"open_weights":false,"cost":{"input":0.035,"output":0.14,"cache_read":0.00875},"limit":{"context":128000,"output":8192},"display_name":"Nova Micro"},{"id":"amazon/nova-pro","name":"Nova Pro","attachment":true,"reasoning":false,"temperature":true,"tool_call":true,"knowledge":"2024-10","release_date":"2024-12-03","last_updated":"2024-12-03","modalities":{"input":["text","image","video"],"output":["text"]},"open_weights":false,"cost":{"input":0.8,"output":3.2,"cache_read":0.2},"limit":{"context":300000,"output":8192},"display_name":"Nova Pro"},{"id":"amazon/nova-lite","name":"Nova Lite","attachment":true,"reasoning":false,"temperature":true,"tool_call":true,"knowledge":"2024-10","release_date":"2024-12-03","last_updated":"2024-12-03","modalities":{"input":["text","image","video"],"output":["text"]},"open_weights":false,"cost":{"input":0.06,"output":0.24,"cache_read":0.015},"limit":{"context":300000,"output":8192},"display_name":"Nova Lite"},{"id":"morph/morph-v3-fast","name":"Morph v3 Fast","attachment":false,"reasoning":false,"temperature":false,"tool_call":false,"release_date":"2024-08-15","last_updated":"2024-08-15","modalities":{"input":["text"],"output":["text"]},"open_weights":false,"cost":{"input":0.8,"output":1.2},"limit":{"context":16000,"output":16000},"display_name":"Morph v3 Fast"},{"id":"morph/morph-v3-large","name":"Morph v3 Large","attachment":false,"reasoning":false,"temperature":false,"tool_call":false,"release_date":"2024-08-15","last_updated":"2024-08-15","modalities":{"input":["text"],"output":["text"]},"open_weights":false,"cost":{"input":0.9,"output":1.9},"limit":{"context":32000,"output":32000},"display_name":"Morph v3 Large"},{"id":"meta/llama-4-scout","name":"Llama-4-Scout-17B-16E-Instruct-FP8","attachment":true,"reasoning":false,"temperature":true,"tool_call":true,"knowledge":"2024-08","release_date":"2025-04-05","last_updated":"2025-04-05","modalities":{"input":["text","image"],"output":["text"]},"open_weights":true,"cost":{"input":0,"output":0},"limit":{"context":128000,"output":4096},"display_name":"Llama-4-Scout-17B-16E-Instruct-FP8"},{"id":"meta/llama-3.3-70b","name":"Llama-3.3-70B-Instruct","attachment":true,"reasoning":false,"temperature":true,"tool_call":true,"knowledge":"2023-12","release_date":"2024-12-06","last_updated":"2024-12-06","modalities":{"input":["text"],"output":["text"]},"open_weights":true,"cost":{"input":0,"output":0},"limit":{"context":128000,"output":4096},"display_name":"Llama-3.3-70B-Instruct"},{"id":"meta/llama-4-maverick","name":"Llama-4-Maverick-17B-128E-Instruct-FP8","attachment":true,"reasoning":false,"temperature":true,"tool_call":true,"knowledge":"2024-08","release_date":"2025-04-05","last_updated":"2025-04-05","modalities":{"input":["text","image"],"output":["text"]},"open_weights":true,"cost":{"input":0,"output":0},"limit":{"context":128000,"output":4096},"display_name":"Llama-4-Maverick-17B-128E-Instruct-FP8"},{"id":"anthropic/claude-3.7-sonnet","name":"Claude Sonnet 3.7","attachment":true,"reasoning":true,"temperature":true,"tool_call":true,"knowledge":"2024-10-31","release_date":"2025-02-19","last_updated":"2025-02-19","modalities":{"input":["text","image"],"output":["text"]},"open_weights":false,"cost":{"input":3,"output":15,"cache_read":0.3,"cache_write":3.75},"limit":{"context":200000,"output":64000},"display_name":"Claude Sonnet 3.7"},{"id":"anthropic/claude-3-5-haiku","name":"Claude Haiku 3.5","attachment":true,"reasoning":false,"temperature":true,"tool_call":true,"knowledge":"2024-07-31","release_date":"2024-10-22","last_updated":"2024-10-22","modalities":{"input":["text","image"],"output":["text"]},"open_weights":false,"cost":{"input":0.8,"output":4,"cache_read":0.08,"cache_write":1},"limit":{"context":200000,"output":8192},"display_name":"Claude Haiku 3.5"},{"id":"anthropic/claude-4.5-sonnet","name":"Claude Sonnet 4.5","attachment":true,"reasoning":true,"temperature":true,"tool_call":true,"knowledge":"2025-07-31","release_date":"2025-09-29","last_updated":"2025-09-29","modalities":{"input":["text","image"],"output":["text"]},"open_weights":false,"cost":{"input":3,"output":15,"cache_read":0.3,"cache_write":3.75},"limit":{"context":200000,"output":64000},"display_name":"Claude Sonnet 4.5"},{"id":"anthropic/claude-3.5-sonnet","name":"Claude Sonnet 3.5 v2","attachment":true,"reasoning":false,"temperature":true,"tool_call":true,"knowledge":"2024-04-30","release_date":"2024-10-22","last_updated":"2024-10-22","modalities":{"input":["text","image"],"output":["text"]},"open_weights":false,"cost":{"input":3,"output":15,"cache_read":0.3,"cache_write":3.75},"limit":{"context":200000,"output":8192},"display_name":"Claude Sonnet 3.5 v2"},{"id":"anthropic/claude-4-1-opus","name":"Claude Opus 4","attachment":true,"reasoning":true,"temperature":true,"tool_call":true,"knowledge":"2025-03-31","release_date":"2025-05-22","last_updated":"2025-05-22","modalities":{"input":["text","image"],"output":["text"]},"open_weights":false,"cost":{"input":15,"output":75,"cache_read":1.5,"cache_write":18.75},"limit":{"context":200000,"output":32000},"display_name":"Claude Opus 4"},{"id":"anthropic/claude-4-sonnet","name":"Claude Sonnet 4","attachment":true,"reasoning":true,"temperature":true,"tool_call":true,"knowledge":"2025-03-31","release_date":"2025-05-22","last_updated":"2025-05-22","modalities":{"input":["text","image"],"output":["text"]},"open_weights":false,"cost":{"input":3,"output":15,"cache_read":0.3,"cache_write":3.75},"limit":{"context":200000,"output":64000},"display_name":"Claude Sonnet 4"},{"id":"anthropic/claude-3-opus","name":"Claude Opus 3","attachment":true,"reasoning":false,"temperature":true,"tool_call":true,"knowledge":"2023-08-31","release_date":"2024-02-29","last_updated":"2024-02-29","modalities":{"input":["text","image"],"output":["text"]},"open_weights":false,"cost":{"input":15,"output":75,"cache_read":1.5,"cache_write":18.75},"limit":{"context":200000,"output":4096},"display_name":"Claude Opus 3"},{"id":"anthropic/claude-3-haiku","name":"Claude Haiku 3","attachment":true,"reasoning":false,"temperature":true,"tool_call":true,"knowledge":"2023-08-31","release_date":"2024-03-13","last_updated":"2024-03-13","modalities":{"input":["text","image"],"output":["text"]},"open_weights":false,"cost":{"input":0.25,"output":1.25,"cache_read":0.03,"cache_write":0.3},"limit":{"context":200000,"output":4096},"display_name":"Claude Haiku 3"},{"id":"anthropic/claude-4-opus","name":"Claude Opus 4","attachment":true,"reasoning":true,"temperature":true,"tool_call":true,"knowledge":"2025-03-31","release_date":"2025-05-22","last_updated":"2025-05-22","modalities":{"input":["text","image"],"output":["text"]},"open_weights":false,"cost":{"input":15,"output":75,"cache_read":1.5,"cache_write":18.75},"limit":{"context":200000,"output":32000},"display_name":"Claude Opus 4"},{"id":"cerebras/qwen3-coder","name":"Qwen 3 Coder 480B","attachment":false,"reasoning":false,"temperature":true,"tool_call":true,"knowledge":"2025-04","release_date":"2025-07-23","last_updated":"2025-07-23","modalities":{"input":["text"],"output":["text"]},"open_weights":true,"cost":{"input":2,"output":2},"limit":{"context":131000,"output":32000},"display_name":"Qwen 3 Coder 480B"}]},"deepseek":{"id":"deepseek","api":"https://api.deepseek.com","name":"DeepSeek","doc":"https://platform.deepseek.com/api-docs/pricing","display_name":"DeepSeek","models":[{"id":"deepseek-chat","name":"DeepSeek Chat","attachment":true,"reasoning":false,"temperature":true,"tool_call":true,"knowledge":"2024-07","release_date":"2024-12-26","last_updated":"2025-08-21","modalities":{"input":["text"],"output":["text"]},"open_weights":false,"cost":{"input":0.57,"output":1.68,"cache_read":0.07},"limit":{"context":128000,"output":8192},"display_name":"DeepSeek Chat"},{"id":"deepseek-reasoner","name":"DeepSeek Reasoner","attachment":true,"reasoning":true,"temperature":true,"tool_call":true,"knowledge":"2024-07","release_date":"2025-01-20","last_updated":"2025-08-21","modalities":{"input":["text"],"output":["text"]},"open_weights":false,"cost":{"input":0.57,"output":1.68,"cache_read":0.07},"limit":{"context":128000,"output":128000},"display_name":"DeepSeek Reasoner"}]},"alibaba-cn":{"id":"alibaba-cn","api":"https://dashscope.aliyuncs.com/compatible-mode/v1","name":"Alibaba (China)","doc":"https://www.alibabacloud.com/help/en/model-studio/models","display_name":"Alibaba (China)","models":[{"id":"qwen3-coder-plus","name":"Qwen3 Coder Plus","attachment":false,"reasoning":false,"temperature":true,"tool_call":true,"knowledge":"2025-04","release_date":"2025-07-23","last_updated":"2025-07-23","modalities":{"input":["text"],"output":["text"]},"open_weights":true,"cost":{"input":1,"output":5},"limit":{"context":1048576,"output":65536},"display_name":"Qwen3 Coder Plus"}]},"google-vertex-anthropic":{"id":"google-vertex-anthropic","name":"Vertex","doc":"https://cloud.google.com/vertex-ai/generative-ai/docs/partner-models/claude","display_name":"Vertex","models":[{"id":"claude-3-5-sonnet@20241022","name":"Claude Sonnet 3.5 v2","attachment":true,"reasoning":false,"temperature":true,"tool_call":true,"knowledge":"2024-04-30","release_date":"2024-10-22","last_updated":"2024-10-22","modalities":{"input":["text","image"],"output":["text"]},"open_weights":false,"cost":{"input":3,"output":15,"cache_read":0.3,"cache_write":3.75},"limit":{"context":200000,"output":8192},"display_name":"Claude Sonnet 3.5 v2"},{"id":"claude-3-5-haiku@20241022","name":"Claude Haiku 3.5","attachment":true,"reasoning":false,"temperature":true,"tool_call":true,"knowledge":"2024-07-31","release_date":"2024-10-22","last_updated":"2024-10-22","modalities":{"input":["text","image"],"output":["text"]},"open_weights":false,"cost":{"input":0.8,"output":4,"cache_read":0.08,"cache_write":1},"limit":{"context":200000,"output":8192},"display_name":"Claude Haiku 3.5"},{"id":"claude-sonnet-4@20250514","name":"Claude Sonnet 4","attachment":true,"reasoning":true,"temperature":true,"tool_call":true,"knowledge":"2025-03-31","release_date":"2025-05-22","last_updated":"2025-05-22","modalities":{"input":["text","image"],"output":["text"]},"open_weights":false,"cost":{"input":3,"output":15,"cache_read":0.3,"cache_write":3.75},"limit":{"context":200000,"output":64000},"display_name":"Claude Sonnet 4"},{"id":"claude-opus-4-1@20250805","name":"Claude Opus 4.1","attachment":true,"reasoning":true,"temperature":true,"tool_call":true,"knowledge":"2025-03-31","release_date":"2025-08-05","last_updated":"2025-08-05","modalities":{"input":["text","image"],"output":["text"]},"open_weights":false,"cost":{"input":15,"output":75,"cache_read":1.5,"cache_write":18.75},"limit":{"context":200000,"output":32000},"display_name":"Claude Opus 4.1"},{"id":"claude-3-7-sonnet@20250219","name":"Claude Sonnet 3.7","attachment":true,"reasoning":true,"temperature":true,"tool_call":true,"knowledge":"2024-10-31","release_date":"2025-02-19","last_updated":"2025-02-19","modalities":{"input":["text","image"],"output":["text"]},"open_weights":false,"cost":{"input":3,"output":15,"cache_read":0.3,"cache_write":3.75},"limit":{"context":200000,"output":64000},"display_name":"Claude Sonnet 3.7"},{"id":"claude-opus-4@20250514","name":"Claude Opus 4","attachment":true,"reasoning":true,"temperature":true,"tool_call":true,"knowledge":"2025-03-31","release_date":"2025-05-22","last_updated":"2025-05-22","modalities":{"input":["text","image"],"output":["text"]},"open_weights":false,"cost":{"input":15,"output":75,"cache_read":1.5,"cache_write":18.75},"limit":{"context":200000,"output":32000},"display_name":"Claude Opus 4"}]},"venice":{"id":"venice","api":"https://api.venice.ai/api/v1","name":"Venice AI","doc":"https://docs.venice.ai","display_name":"Venice AI","models":[{"id":"dolphin-2.9.2-qwen2-72b","name":"Dolphin 72B","attachment":false,"reasoning":false,"temperature":true,"tool_call":false,"knowledge":"2021-09","release_date":"2025-05-21","last_updated":"2025-05-21","modalities":{"input":["text"],"output":["text"]},"open_weights":true,"cost":{"input":0.7,"output":2.8},"limit":{"context":32768,"output":8192},"display_name":"Dolphin 72B"},{"id":"mistral-31-24b","name":"Venice Medium","attachment":false,"reasoning":false,"temperature":true,"tool_call":true,"knowledge":"2023-10","release_date":"2025-07-15","last_updated":"2025-07-15","modalities":{"input":["text","image"],"output":["text"]},"open_weights":true,"cost":{"input":0.5,"output":2},"limit":{"context":131072,"output":8192},"display_name":"Venice Medium"},{"id":"venice-uncensored","name":"Venice Uncensored 1.1","attachment":false,"reasoning":false,"temperature":true,"tool_call":false,"knowledge":"2023-10","release_date":"2025-07-15","last_updated":"2025-07-15","modalities":{"input":["text"],"output":["text"]},"open_weights":true,"cost":{"input":0.5,"output":2},"limit":{"context":32768,"output":8192},"display_name":"Venice Uncensored 1.1"},{"id":"qwen-2.5-vl","name":"Qwen 2.5 VL 72B","attachment":false,"reasoning":false,"temperature":true,"tool_call":false,"knowledge":"2023-10","release_date":"2025-06-09","last_updated":"2025-06-09","modalities":{"input":["text","image"],"output":["text"]},"open_weights":true,"cost":{"input":0.7,"output":2.8},"limit":{"context":32768,"output":8192},"display_name":"Qwen 2.5 VL 72B"},{"id":"qwen3-235b","name":"Venice Large","attachment":false,"reasoning":true,"temperature":true,"tool_call":true,"knowledge":"2024-10","release_date":"2025-07-27","last_updated":"2025-07-27","modalities":{"input":["text"],"output":["text"]},"open_weights":true,"cost":{"input":1.5,"output":6},"limit":{"context":131072,"output":8192},"display_name":"Venice Large"},{"id":"qwen-2.5-qwq-32b","name":"Venice Reasoning","attachment":false,"reasoning":true,"temperature":true,"tool_call":false,"knowledge":"2023-10","release_date":"2025-07-08","last_updated":"2025-07-08","modalities":{"input":["text"],"output":["text"]},"open_weights":true,"cost":{"input":0.5,"output":2},"limit":{"context":32768,"output":8192},"display_name":"Venice Reasoning"},{"id":"deepseek-coder-v2-lite","name":"DeepSeek Coder V2 Lite","attachment":false,"reasoning":false,"temperature":true,"tool_call":false,"knowledge":"2021-09","release_date":"2025-06-22","last_updated":"2025-06-22","modalities":{"input":["text"],"output":["text"]},"open_weights":true,"cost":{"input":0.5,"output":2},"limit":{"context":131072,"output":8192},"display_name":"DeepSeek Coder V2 Lite"},{"id":"qwen3-4b","name":"Venice Small","attachment":false,"reasoning":true,"temperature":true,"tool_call":true,"knowledge":"2024-07","release_date":"2025-07-27","last_updated":"2025-07-27","modalities":{"input":["text"],"output":["text"]},"open_weights":true,"cost":{"input":0.15,"output":0.6},"limit":{"context":32768,"output":8192},"display_name":"Venice Small"},{"id":"llama-3.3-70b","name":"Llama 3.3 70B","attachment":false,"reasoning":false,"temperature":true,"tool_call":true,"knowledge":"2023-12","release_date":"2025-06-09","last_updated":"2025-06-09","modalities":{"input":["text"],"output":["text"]},"open_weights":true,"cost":{"input":0.7,"output":2.8},"limit":{"context":65536,"output":8192},"display_name":"Llama 3.3 70B"},{"id":"qwen-2.5-coder-32b","name":"Qwen 2.5 Coder 32B","attachment":false,"reasoning":false,"temperature":true,"tool_call":false,"knowledge":"2023-10","release_date":"2025-06-14","last_updated":"2025-06-14","modalities":{"input":["text"],"output":["text"]},"open_weights":true,"cost":{"input":0.5,"output":2},"limit":{"context":32768,"output":8192},"display_name":"Qwen 2.5 Coder 32B"},{"id":"deepseek-r1-671b","name":"DeepSeek R1 671B","attachment":false,"reasoning":true,"temperature":true,"tool_call":false,"knowledge":"2023-10","release_date":"2025-06-05","last_updated":"2025-06-05","modalities":{"input":["text"],"output":["text"]},"open_weights":true,"cost":{"input":3.5,"output":14},"limit":{"context":131072,"output":8192},"display_name":"DeepSeek R1 671B"},{"id":"llama-3.2-3b","name":"Llama 3.2 3B","attachment":false,"reasoning":false,"temperature":true,"tool_call":true,"knowledge":"2023-12","release_date":"2025-05-23","last_updated":"2025-05-23","modalities":{"input":["text"],"output":["text"]},"open_weights":true,"cost":{"input":0.15,"output":0.6},"limit":{"context":131072,"output":8192},"display_name":"Llama 3.2 3B"},{"id":"llama-3.1-405b","name":"Llama 3.1 405B","attachment":false,"reasoning":false,"temperature":true,"tool_call":false,"knowledge":"2023-12","release_date":"2025-06-30","last_updated":"2025-06-30","modalities":{"input":["text"],"output":["text"]},"open_weights":true,"cost":{"input":1.5,"output":6},"limit":{"context":65536,"output":8192},"display_name":"Llama 3.1 405B"}]},"chutes":{"id":"chutes","api":"https://llm.chutes.ai/v1","name":"Chutes","doc":"https://llm.chutes.ai/v1/models","display_name":"Chutes","models":[{"id":"moonshotai/Kimi-Dev-72B","name":"Kimi Dev 72B","attachment":false,"reasoning":false,"temperature":true,"tool_call":true,"release_date":"2024-12-01","last_updated":"2024-12-01","modalities":{"input":["text"],"output":["text"]},"open_weights":false,"cost":{"input":0.06664,"output":0.266688},"limit":{"context":131072,"output":131072},"display_name":"Kimi Dev 72B"},{"id":"moonshotai/Kimi-K2-Instruct-75k","name":"Kimi K2 Instruct","attachment":false,"reasoning":false,"temperature":true,"tool_call":true,"release_date":"2025-08-01","last_updated":"2025-08-01","modalities":{"input":["text"],"output":["text"]},"open_weights":false,"cost":{"input":0.15,"output":0.59},"limit":{"context":75000,"output":75000},"display_name":"Kimi K2 Instruct"},{"id":"moonshotai/Kimi-K2-Instruct-0905","name":"Kimi K2 Instruct 0905","attachment":false,"reasoning":false,"temperature":true,"tool_call":true,"release_date":"2024-09-05","last_updated":"2024-09-05","modalities":{"input":["text"],"output":["text"]},"open_weights":false,"cost":{"input":0.296176,"output":1.18528},"limit":{"context":262144,"output":262144},"display_name":"Kimi K2 Instruct 0905"},{"id":"moonshotai/Kimi-VL-A3B-Thinking","name":"Kimi VL A3B Thinking","attachment":false,"reasoning":true,"temperature":true,"tool_call":true,"release_date":"2024-12-01","last_updated":"2024-12-01","modalities":{"input":["text","image"],"output":["text"]},"open_weights":false,"cost":{"input":0.02499,"output":0.100008},"limit":{"context":131072,"output":131072},"display_name":"Kimi VL A3B Thinking"},{"id":"meituan-longcat/LongCat-Flash-Chat-FP8","name":"LongCat Flash Chat FP8","attachment":false,"reasoning":false,"temperature":true,"tool_call":true,"release_date":"2025-09-10","last_updated":"2025-09-10","modalities":{"input":["text"],"output":["text"]},"open_weights":true,"cost":{"input":0.25,"output":1},"limit":{"context":131072,"output":131072},"display_name":"LongCat Flash Chat FP8"},{"id":"tngtech/DeepSeek-R1T-Chimera","name":"DeepSeek R1T Chimera","attachment":false,"reasoning":true,"temperature":true,"tool_call":false,"knowledge":"2025-04","release_date":"2025-04-26","last_updated":"2025-04-26","modalities":{"input":["text"],"output":["text"]},"open_weights":true,"cost":{"input":0.18,"output":0.72},"limit":{"context":163840,"output":163840},"display_name":"DeepSeek R1T Chimera"},{"id":"tngtech/DeepSeek-TNG-R1T2-Chimera","name":"DeepSeek TNG R1T2 Chimera","attachment":false,"reasoning":true,"temperature":true,"tool_call":false,"knowledge":"2025-07","release_date":"2025-07-08","last_updated":"2025-07-08","modalities":{"input":["text"],"output":["text"]},"open_weights":true,"cost":{"input":0.2,"output":0.8},"limit":{"context":163840,"output":163840},"display_name":"DeepSeek TNG R1T2 Chimera"},{"id":"openai/gpt-oss-120b","name":"GPT OSS 120B","attachment":false,"reasoning":true,"temperature":true,"tool_call":true,"release_date":"2025-08-05","last_updated":"2025-08-05","modalities":{"input":["text"],"output":["text"]},"open_weights":true,"cost":{"input":0.1,"output":0.41},"limit":{"context":131072,"output":32768},"display_name":"GPT OSS 120B"},{"id":"chutesai/Devstral-Small-2505","name":"Devstral Small (2505)","attachment":false,"reasoning":false,"temperature":true,"tool_call":true,"release_date":"2025-05-21","last_updated":"2025-05-21","modalities":{"input":["text"],"output":["text"]},"open_weights":true,"cost":{"input":0.02,"output":0.08},"limit":{"context":32768,"output":32768},"display_name":"Devstral Small (2505)"},{"id":"chutesai/Mistral-Small-3.2-24B-Instruct-2506","name":"Mistral Small 3.2 24B Instruct (2506)","attachment":false,"reasoning":false,"temperature":true,"tool_call":true,"release_date":"2025-06-20","last_updated":"2025-06-20","modalities":{"input":["text"],"output":["text"]},"open_weights":true,"cost":{"input":0.02,"output":0.08},"limit":{"context":131072,"output":131072},"display_name":"Mistral Small 3.2 24B Instruct (2506)"},{"id":"Qwen/Qwen3-30B-A3B","name":"Qwen3 30B A3B","attachment":false,"reasoning":true,"temperature":true,"tool_call":true,"knowledge":"2025-04","release_date":"2025-04-28","last_updated":"2025-04-28","modalities":{"input":["text"],"output":["text"]},"open_weights":true,"cost":{"input":0.02,"output":0.08},"limit":{"context":40960,"output":40960},"display_name":"Qwen3 30B A3B"},{"id":"Qwen/Qwen3-30B-A3B-Thinking-2507","name":"Qwen3 30B A3B Thinking 2507","attachment":false,"reasoning":true,"temperature":true,"tool_call":true,"knowledge":"2025-04","release_date":"2025-07-30","last_updated":"2025-07-30","modalities":{"input":["text"],"output":["text"]},"open_weights":true,"cost":{"input":0.08,"output":0.29},"limit":{"context":262144,"output":262144},"display_name":"Qwen3 30B A3B Thinking 2507"},{"id":"Qwen/Qwen3-235B-A22B-Instruct-2507","name":"Qwen3 235B A22B Instruct 2507","attachment":false,"reasoning":false,"temperature":true,"tool_call":true,"knowledge":"2025-04","release_date":"2025-04-28","last_updated":"2025-07-21","modalities":{"input":["text"],"output":["text"]},"open_weights":true,"cost":{"input":0.078,"output":0.312},"limit":{"context":262144,"output":131072},"display_name":"Qwen3 235B A22B Instruct 2507"},{"id":"Qwen/Qwen3-Coder-30B-A3B-Instruct","name":"Qwen3 Coder 30B A3B Instruct","attachment":false,"reasoning":false,"temperature":true,"tool_call":true,"knowledge":"2025-04","release_date":"2025-07-25","last_updated":"2025-07-25","modalities":{"input":["text"],"output":["text"]},"open_weights":true,"cost":{"input":0,"output":0},"limit":{"context":262144,"output":262144},"display_name":"Qwen3 Coder 30B A3B Instruct"},{"id":"Qwen/Qwen3-Coder-480B-A35B-Instruct-FP8","name":"Qwen3 Coder 480B A35B Instruct (FP8)","attachment":false,"reasoning":false,"temperature":true,"tool_call":true,"release_date":"2025-08-01","last_updated":"2025-08-01","modalities":{"input":["text"],"output":["text"]},"open_weights":false,"cost":{"input":0.2,"output":0.8},"limit":{"context":262144,"output":262144},"display_name":"Qwen3 Coder 480B A35B Instruct (FP8)"},{"id":"Qwen/Qwen3-30B-A3B-Instruct-2507","name":"Qwen3 30B A3B Instruct 2507","attachment":false,"reasoning":false,"temperature":true,"tool_call":true,"knowledge":"2025-04","release_date":"2025-07-25","last_updated":"2025-07-25","modalities":{"input":["text"],"output":["text"]},"open_weights":true,"cost":{"input":0.05,"output":0.2},"limit":{"context":262144,"output":262144},"display_name":"Qwen3 30B A3B Instruct 2507"},{"id":"Qwen/Qwen3-235B-A22B-Thinking-2507","name":"Qwen3-235B-A22B-Thinking-2507","attachment":false,"reasoning":true,"temperature":true,"tool_call":true,"knowledge":"2025-04","release_date":"2025-07-25","last_updated":"2025-07-25","modalities":{"input":["text"],"output":["text"]},"open_weights":true,"cost":{"input":0.078,"output":0.312},"limit":{"context":262144,"output":262144},"display_name":"Qwen3-235B-A22B-Thinking-2507"},{"id":"Qwen/Qwen3-Next-80B-A3B-Instruct","name":"Qwen3 Next 80B A3B Instruct","attachment":false,"reasoning":false,"temperature":true,"tool_call":true,"knowledge":"2025-04","release_date":"2025-09-11","last_updated":"2025-09-11","modalities":{"input":["text"],"output":["text"]},"open_weights":true,"cost":{"input":0.1,"output":0.8},"limit":{"context":262144,"output":262144},"display_name":"Qwen3 Next 80B A3B Instruct"},{"id":"Qwen/Qwen3-Next-80B-A3B-Thinking","name":"Qwen3 Next 80B A3B Thinking","attachment":false,"reasoning":true,"temperature":true,"tool_call":true,"knowledge":"2025-04","release_date":"2025-09-11","last_updated":"2025-09-11","modalities":{"input":["text"],"output":["text"]},"open_weights":true,"cost":{"input":0.1,"output":0.8},"limit":{"context":262144,"output":262144},"display_name":"Qwen3 Next 80B A3B Thinking"},{"id":"zai-org/GLM-4.5-turbo","name":"GLM 4.5 Turbo","attachment":false,"reasoning":true,"temperature":true,"tool_call":true,"knowledge":"2025-04","release_date":"2025-07-28","last_updated":"2025-07-28","modalities":{"input":["text"],"output":["text"]},"open_weights":true,"cost":{"input":1,"output":3},"limit":{"context":131072,"output":131072},"display_name":"GLM 4.5 Turbo"},{"id":"zai-org/GLM-4.6-FP8","name":"GLM 4.6 FP8","attachment":false,"reasoning":true,"temperature":true,"tool_call":true,"knowledge":"2025-04","release_date":"2025-09-30","last_updated":"2025-09-30","modalities":{"input":["text"],"output":["text"]},"open_weights":true,"cost":{"input":0.39,"output":1.55},"limit":{"context":204800,"output":131072},"display_name":"GLM 4.6 FP8"},{"id":"zai-org/GLM-4.5-FP8","name":"GLM 4.5 FP8","attachment":false,"reasoning":true,"temperature":true,"tool_call":true,"knowledge":"2025-04","release_date":"2025-07-28","last_updated":"2025-07-28","modalities":{"input":["text"],"output":["text"]},"open_weights":true,"cost":{"input":0,"output":0},"limit":{"context":131072,"output":131072},"display_name":"GLM 4.5 FP8"},{"id":"zai-org/GLM-4.5-Air","name":"GLM 4.5 Air","attachment":false,"reasoning":true,"temperature":true,"tool_call":true,"knowledge":"2025-04","release_date":"2025-07-28","last_updated":"2025-07-28","modalities":{"input":["text"],"output":["text"]},"open_weights":true,"cost":{"input":0,"output":0},"limit":{"context":131072,"output":98304},"display_name":"GLM 4.5 Air"},{"id":"deepseek-ai/DeepSeek-R1-0528-Qwen3-8B","name":"DeepSeek R1 0528 Qwen3 8B","attachment":false,"reasoning":true,"temperature":true,"tool_call":true,"knowledge":"2025-05","release_date":"2025-05-29","last_updated":"2025-05-29","modalities":{"input":["text"],"output":["text"]},"open_weights":true,"cost":{"input":0.02,"output":0.07},"limit":{"context":131072,"output":131072},"display_name":"DeepSeek R1 0528 Qwen3 8B"},{"id":"deepseek-ai/DeepSeek-R1-0528","name":"DeepSeek R1 (0528)","attachment":false,"reasoning":true,"temperature":true,"tool_call":true,"release_date":"2025-08-01","last_updated":"2025-08-01","modalities":{"input":["text"],"output":["text"]},"open_weights":false,"cost":{"input":0.18,"output":0.72},"limit":{"context":75000,"output":163840},"display_name":"DeepSeek R1 (0528)"},{"id":"deepseek-ai/DeepSeek-V3.1-Terminus","name":"DeepSeek V3.1 Terminus","attachment":false,"reasoning":true,"temperature":true,"tool_call":true,"knowledge":"2025-07","release_date":"2025-09-22","last_updated":"2025-09-22","modalities":{"input":["text"],"output":["text"]},"open_weights":true,"cost":{"input":0.25,"output":1},"limit":{"context":131072,"output":65536},"display_name":"DeepSeek V3.1 Terminus"},{"id":"deepseek-ai/DeepSeek-V3.1-turbo","name":"DeepSeek V3.1 Turbo","attachment":false,"reasoning":false,"temperature":true,"tool_call":true,"release_date":"2025-08-21","last_updated":"2025-08-21","modalities":{"input":["text"],"output":["text"]},"open_weights":false,"cost":{"input":1,"output":3},"limit":{"context":128000,"output":128000},"display_name":"DeepSeek V3.1 Turbo"},{"id":"deepseek-ai/DeepSeek-V3.1:THINKING","name":"DeepSeek V3.1 Reasoning","attachment":false,"reasoning":true,"temperature":true,"tool_call":true,"release_date":"2025-08-21","last_updated":"2025-08-21","modalities":{"input":["text"],"output":["text"]},"open_weights":false,"cost":{"input":0.2,"output":0.8},"limit":{"context":163840,"output":163840},"display_name":"DeepSeek V3.1 Reasoning"},{"id":"deepseek-ai/DeepSeek-R1-Distill-Llama-70B","name":"DeepSeek R1 Distill Llama 70B","attachment":false,"reasoning":true,"temperature":true,"tool_call":false,"knowledge":"2024-10","release_date":"2025-01-23","last_updated":"2025-01-23","modalities":{"input":["text"],"output":["text"]},"open_weights":true,"cost":{"input":0.03,"output":0.14},"limit":{"context":131072,"output":131072},"display_name":"DeepSeek R1 Distill Llama 70B"},{"id":"deepseek-ai/DeepSeek-V3.1","name":"DeepSeek V3.1","attachment":false,"reasoning":false,"temperature":true,"tool_call":true,"release_date":"2025-08-21","last_updated":"2025-08-21","modalities":{"input":["text"],"output":["text"]},"open_weights":false,"cost":{"input":0.2,"output":0.8},"limit":{"context":163840,"output":163840},"display_name":"DeepSeek V3.1"},{"id":"deepseek-ai/DeepSeek-V3-0324","name":"DeepSeek V3 (0324)","attachment":false,"reasoning":false,"temperature":true,"tool_call":true,"release_date":"2025-08-01","last_updated":"2025-08-01","modalities":{"input":["text"],"output":["text"]},"open_weights":false,"cost":{"input":0.18,"output":0.72},"limit":{"context":75000,"output":163840},"display_name":"DeepSeek V3 (0324)"}]},"cortecs":{"id":"cortecs","api":"https://api.cortecs.ai/v1","name":"Cortecs","doc":"https://api.cortecs.ai/v1/models","display_name":"Cortecs","models":[{"id":"nova-pro-v1","name":"Nova Pro 1.0","attachment":false,"reasoning":false,"temperature":true,"tool_call":true,"knowledge":"2024-04","release_date":"2024-12-03","last_updated":"2024-12-03","modalities":{"input":["text","image"],"output":["text"]},"open_weights":false,"cost":{"input":0.824,"output":3.295},"limit":{"context":300000,"output":5000},"display_name":"Nova Pro 1.0"},{"id":"deepseek-v3-0324","name":"DeepSeek V3 0324","attachment":false,"reasoning":false,"temperature":true,"tool_call":true,"knowledge":"2024-07","release_date":"2025-03-24","last_updated":"2025-03-24","modalities":{"input":["text"],"output":["text"]},"open_weights":true,"cost":{"input":0.447,"output":1.342},"limit":{"context":128000,"output":128000},"display_name":"DeepSeek V3 0324"},{"id":"kimi-k2-instruct","name":"Kimi K2 Instruct","attachment":false,"reasoning":false,"temperature":true,"tool_call":true,"knowledge":"2024-07","release_date":"2025-07-11","last_updated":"2025-09-05","modalities":{"input":["text"],"output":["text"]},"open_weights":true,"cost":{"input":0.447,"output":2.147},"limit":{"context":131000,"output":131000},"display_name":"Kimi K2 Instruct"},{"id":"gpt-4.1","name":"GPT 4.1","attachment":false,"reasoning":false,"temperature":true,"tool_call":true,"knowledge":"2024-06","release_date":"2025-04-14","last_updated":"2025-04-14","modalities":{"input":["text","image"],"output":["text"]},"open_weights":false,"cost":{"input":1.91,"output":7.64},"limit":{"context":1047576,"output":32768},"display_name":"GPT 4.1"},{"id":"gemini-2.5-pro","name":"Gemini 2.5 Pro","attachment":false,"reasoning":false,"temperature":true,"tool_call":true,"knowledge":"2025-01","release_date":"2025-03-20","last_updated":"2025-06-17","modalities":{"input":["text","image"],"output":["text"]},"open_weights":false,"cost":{"input":1.3416,"output":8.944},"limit":{"context":1048576,"output":65535},"display_name":"Gemini 2.5 Pro"},{"id":"gpt-oss-120b","name":"GPT Oss 120b","attachment":false,"reasoning":false,"temperature":true,"tool_call":true,"knowledge":"2024-01","release_date":"2025-08-05","last_updated":"2025-08-05","modalities":{"input":["text"],"output":["text"]},"open_weights":true,"cost":{"input":0,"output":0},"limit":{"context":128000,"output":128000},"display_name":"GPT Oss 120b"},{"id":"qwen3-coder-480b-a35b-instruct","name":"Qwen3 Coder 480B A35B Instruct","attachment":false,"reasoning":false,"temperature":true,"tool_call":true,"knowledge":"2025-01","release_date":"2025-07-25","last_updated":"2025-07-25","modalities":{"input":["text"],"output":["text"]},"open_weights":true,"cost":{"input":0.358,"output":1.61},"limit":{"context":262000,"output":262000},"display_name":"Qwen3 Coder 480B A35B Instruct"},{"id":"claude-sonnet-4","name":"Claude Sonnet 4","attachment":false,"reasoning":false,"temperature":true,"tool_call":true,"knowledge":"2025-03","release_date":"2025-05-22","last_updated":"2025-05-22","modalities":{"input":["text","image"],"output":["text"]},"open_weights":false,"cost":{"input":2.683,"output":13.416},"limit":{"context":200000,"output":64000},"display_name":"Claude Sonnet 4"},{"id":"llama-3.1-405b-instruct","name":"Llama 3.1 405B Instruct","attachment":false,"reasoning":false,"temperature":true,"tool_call":true,"knowledge":"2023-12","release_date":"2024-07-23","last_updated":"2024-07-23","modalities":{"input":["text"],"output":["text"]},"open_weights":true,"cost":{"input":0,"output":0},"limit":{"context":128000,"output":128000},"display_name":"Llama 3.1 405B Instruct"},{"id":"qwen3-32b","name":"Qwen3 32B","attachment":false,"reasoning":false,"temperature":true,"tool_call":true,"knowledge":"2024-12","release_date":"2025-04-29","last_updated":"2025-04-29","modalities":{"input":["text"],"output":["text"]},"open_weights":true,"cost":{"input":0.08,"output":0.268},"limit":{"context":16384,"output":16384},"display_name":"Qwen3 32B"}]},"github-models":{"id":"github-models","api":"https://models.github.ai/inference","name":"GitHub Models","doc":"https://docs.github.com/en/github-models","display_name":"GitHub Models","models":[{"id":"core42/jais-30b-chat","name":"JAIS 30b Chat","attachment":false,"reasoning":true,"temperature":true,"tool_call":true,"knowledge":"2023-03","release_date":"2023-08-30","last_updated":"2023-08-30","modalities":{"input":["text"],"output":["text"]},"open_weights":true,"cost":{"input":0,"output":0},"limit":{"context":8192,"output":2048},"display_name":"JAIS 30b Chat"},{"id":"xai/grok-3","name":"Grok 3","attachment":false,"reasoning":true,"temperature":true,"tool_call":true,"knowledge":"2024-10","release_date":"2024-12-09","last_updated":"2024-12-09","modalities":{"input":["text"],"output":["text"]},"open_weights":false,"cost":{"input":0,"output":0},"limit":{"context":128000,"output":8192},"display_name":"Grok 3"},{"id":"xai/grok-3-mini","name":"Grok 3 Mini","attachment":false,"reasoning":true,"temperature":true,"tool_call":true,"knowledge":"2024-10","release_date":"2024-12-09","last_updated":"2024-12-09","modalities":{"input":["text"],"output":["text"]},"open_weights":false,"cost":{"input":0,"output":0},"limit":{"context":128000,"output":8192},"display_name":"Grok 3 Mini"},{"id":"cohere/cohere-command-r-08-2024","name":"Cohere Command R 08-2024","attachment":false,"reasoning":true,"temperature":true,"tool_call":true,"knowledge":"2024-03","release_date":"2024-08-01","last_updated":"2024-08-01","modalities":{"input":["text"],"output":["text"]},"open_weights":false,"cost":{"input":0,"output":0},"limit":{"context":128000,"output":4096},"display_name":"Cohere Command R 08-2024"},{"id":"cohere/cohere-command-a","name":"Cohere Command A","attachment":false,"reasoning":true,"temperature":true,"tool_call":true,"knowledge":"2024-03","release_date":"2024-11-01","last_updated":"2024-11-01","modalities":{"input":["text"],"output":["text"]},"open_weights":false,"cost":{"input":0,"output":0},"limit":{"context":128000,"output":4096},"display_name":"Cohere Command A"},{"id":"cohere/cohere-command-r-plus-08-2024","name":"Cohere Command R+ 08-2024","attachment":false,"reasoning":true,"temperature":true,"tool_call":true,"knowledge":"2024-03","release_date":"2024-08-01","last_updated":"2024-08-01","modalities":{"input":["text"],"output":["text"]},"open_weights":false,"cost":{"input":0,"output":0},"limit":{"context":128000,"output":4096},"display_name":"Cohere Command R+ 08-2024"},{"id":"cohere/cohere-command-r","name":"Cohere Command R","attachment":false,"reasoning":true,"temperature":true,"tool_call":true,"knowledge":"2024-03","release_date":"2024-03-11","last_updated":"2024-08-01","modalities":{"input":["text"],"output":["text"]},"open_weights":false,"cost":{"input":0,"output":0},"limit":{"context":128000,"output":4096},"display_name":"Cohere Command R"},{"id":"cohere/cohere-command-r-plus","name":"Cohere Command R+","attachment":false,"reasoning":true,"temperature":true,"tool_call":true,"knowledge":"2024-03","release_date":"2024-04-04","last_updated":"2024-08-01","modalities":{"input":["text"],"output":["text"]},"open_weights":false,"cost":{"input":0,"output":0},"limit":{"context":128000,"output":4096},"display_name":"Cohere Command R+"},{"id":"deepseek/deepseek-r1-0528","name":"DeepSeek-R1-0528","attachment":false,"reasoning":true,"temperature":true,"tool_call":true,"knowledge":"2024-06","release_date":"2025-05-28","last_updated":"2025-05-28","modalities":{"input":["text"],"output":["text"]},"open_weights":true,"cost":{"input":0,"output":0},"limit":{"context":65536,"output":8192},"display_name":"DeepSeek-R1-0528"},{"id":"deepseek/deepseek-r1","name":"DeepSeek-R1","attachment":false,"reasoning":true,"temperature":true,"tool_call":true,"knowledge":"2024-06","release_date":"2025-01-20","last_updated":"2025-01-20","modalities":{"input":["text"],"output":["text"]},"open_weights":true,"cost":{"input":0,"output":0},"limit":{"context":65536,"output":8192},"display_name":"DeepSeek-R1"},{"id":"deepseek/deepseek-v3-0324","name":"DeepSeek-V3-0324","attachment":false,"reasoning":true,"temperature":true,"tool_call":true,"knowledge":"2024-06","release_date":"2025-03-24","last_updated":"2025-03-24","modalities":{"input":["text"],"output":["text"]},"open_weights":true,"cost":{"input":0,"output":0},"limit":{"context":128000,"output":8192},"display_name":"DeepSeek-V3-0324"},{"id":"mistral-ai/mistral-medium-2505","name":"Mistral Medium 3 (25.05)","attachment":false,"reasoning":true,"temperature":true,"tool_call":true,"knowledge":"2024-09","release_date":"2025-05-01","last_updated":"2025-05-01","modalities":{"input":["text","image"],"output":["text"]},"open_weights":false,"cost":{"input":0,"output":0},"limit":{"context":128000,"output":32768},"display_name":"Mistral Medium 3 (25.05)"},{"id":"mistral-ai/ministral-3b","name":"Ministral 3B","attachment":false,"reasoning":true,"temperature":true,"tool_call":true,"knowledge":"2024-03","release_date":"2024-10-22","last_updated":"2024-10-22","modalities":{"input":["text"],"output":["text"]},"open_weights":true,"cost":{"input":0,"output":0},"limit":{"context":128000,"output":8192},"display_name":"Ministral 3B"},{"id":"mistral-ai/mistral-nemo","name":"Mistral Nemo","attachment":false,"reasoning":true,"temperature":true,"tool_call":true,"knowledge":"2024-03","release_date":"2024-07-18","last_updated":"2024-07-18","modalities":{"input":["text"],"output":["text"]},"open_weights":true,"cost":{"input":0,"output":0},"limit":{"context":128000,"output":8192},"display_name":"Mistral Nemo"},{"id":"mistral-ai/mistral-large-2411","name":"Mistral Large 24.11","attachment":false,"reasoning":true,"temperature":true,"tool_call":true,"knowledge":"2024-09","release_date":"2024-11-01","last_updated":"2024-11-01","modalities":{"input":["text"],"output":["text"]},"open_weights":false,"cost":{"input":0,"output":0},"limit":{"context":128000,"output":32768},"display_name":"Mistral Large 24.11"},{"id":"mistral-ai/codestral-2501","name":"Codestral 25.01","attachment":false,"reasoning":true,"temperature":true,"tool_call":true,"knowledge":"2024-03","release_date":"2025-01-01","last_updated":"2025-01-01","modalities":{"input":["text"],"output":["text"]},"open_weights":false,"cost":{"input":0,"output":0},"limit":{"context":32000,"output":8192},"display_name":"Codestral 25.01"},{"id":"mistral-ai/mistral-small-2503","name":"Mistral Small 3.1","attachment":false,"reasoning":true,"temperature":true,"tool_call":true,"knowledge":"2024-09","release_date":"2025-03-01","last_updated":"2025-03-01","modalities":{"input":["text","image"],"output":["text"]},"open_weights":false,"cost":{"input":0,"output":0},"limit":{"context":128000,"output":32768},"display_name":"Mistral Small 3.1"},{"id":"microsoft/phi-3-medium-128k-instruct","name":"Phi-3-medium instruct (128k)","attachment":false,"reasoning":true,"temperature":true,"tool_call":true,"knowledge":"2023-10","release_date":"2024-04-23","last_updated":"2024-04-23","modalities":{"input":["text"],"output":["text"]},"open_weights":true,"cost":{"input":0,"output":0},"limit":{"context":128000,"output":4096},"display_name":"Phi-3-medium instruct (128k)"},{"id":"microsoft/phi-3-mini-4k-instruct","name":"Phi-3-mini instruct (4k)","attachment":false,"reasoning":true,"temperature":true,"tool_call":true,"knowledge":"2023-10","release_date":"2024-04-23","last_updated":"2024-04-23","modalities":{"input":["text"],"output":["text"]},"open_weights":true,"cost":{"input":0,"output":0},"limit":{"context":4096,"output":1024},"display_name":"Phi-3-mini instruct (4k)"},{"id":"microsoft/phi-3-small-128k-instruct","name":"Phi-3-small instruct (128k)","attachment":false,"reasoning":true,"temperature":true,"tool_call":true,"knowledge":"2023-10","release_date":"2024-04-23","last_updated":"2024-04-23","modalities":{"input":["text"],"output":["text"]},"open_weights":true,"cost":{"input":0,"output":0},"limit":{"context":128000,"output":4096},"display_name":"Phi-3-small instruct (128k)"},{"id":"microsoft/phi-3.5-vision-instruct","name":"Phi-3.5-vision instruct (128k)","attachment":false,"reasoning":true,"temperature":true,"tool_call":true,"knowledge":"2023-10","release_date":"2024-08-20","last_updated":"2024-08-20","modalities":{"input":["text","image"],"output":["text"]},"open_weights":true,"cost":{"input":0,"output":0},"limit":{"context":128000,"output":4096},"display_name":"Phi-3.5-vision instruct (128k)"},{"id":"microsoft/phi-4","name":"Phi-4","attachment":false,"reasoning":true,"temperature":true,"tool_call":true,"knowledge":"2023-10","release_date":"2024-12-11","last_updated":"2024-12-11","modalities":{"input":["text"],"output":["text"]},"open_weights":true,"cost":{"input":0,"output":0},"limit":{"context":16000,"output":4096},"display_name":"Phi-4"},{"id":"microsoft/phi-4-mini-reasoning","name":"Phi-4-mini-reasoning","attachment":false,"reasoning":true,"temperature":true,"tool_call":true,"knowledge":"2023-10","release_date":"2024-12-11","last_updated":"2024-12-11","modalities":{"input":["text"],"output":["text"]},"open_weights":true,"cost":{"input":0,"output":0},"limit":{"context":128000,"output":4096},"display_name":"Phi-4-mini-reasoning"},{"id":"microsoft/phi-3-small-8k-instruct","name":"Phi-3-small instruct (8k)","attachment":false,"reasoning":true,"temperature":true,"tool_call":true,"knowledge":"2023-10","release_date":"2024-04-23","last_updated":"2024-04-23","modalities":{"input":["text"],"output":["text"]},"open_weights":true,"cost":{"input":0,"output":0},"limit":{"context":8192,"output":2048},"display_name":"Phi-3-small instruct (8k)"},{"id":"microsoft/phi-3.5-mini-instruct","name":"Phi-3.5-mini instruct (128k)","attachment":false,"reasoning":true,"temperature":true,"tool_call":true,"knowledge":"2023-10","release_date":"2024-08-20","last_updated":"2024-08-20","modalities":{"input":["text"],"output":["text"]},"open_weights":true,"cost":{"input":0,"output":0},"limit":{"context":128000,"output":4096},"display_name":"Phi-3.5-mini instruct (128k)"},{"id":"microsoft/phi-4-multimodal-instruct","name":"Phi-4-multimodal-instruct","attachment":false,"reasoning":true,"temperature":true,"tool_call":true,"knowledge":"2023-10","release_date":"2024-12-11","last_updated":"2024-12-11","modalities":{"input":["text","image","audio"],"output":["text"]},"open_weights":true,"cost":{"input":0,"output":0},"limit":{"context":128000,"output":4096},"display_name":"Phi-4-multimodal-instruct"},{"id":"microsoft/phi-3-mini-128k-instruct","name":"Phi-3-mini instruct (128k)","attachment":false,"reasoning":true,"temperature":true,"tool_call":true,"knowledge":"2023-10","release_date":"2024-04-23","last_updated":"2024-04-23","modalities":{"input":["text"],"output":["text"]},"open_weights":true,"cost":{"input":0,"output":0},"limit":{"context":128000,"output":4096},"display_name":"Phi-3-mini instruct (128k)"},{"id":"microsoft/phi-3.5-moe-instruct","name":"Phi-3.5-MoE instruct (128k)","attachment":false,"reasoning":true,"temperature":true,"tool_call":true,"knowledge":"2023-10","release_date":"2024-08-20","last_updated":"2024-08-20","modalities":{"input":["text"],"output":["text"]},"open_weights":true,"cost":{"input":0,"output":0},"limit":{"context":128000,"output":4096},"display_name":"Phi-3.5-MoE instruct (128k)"},{"id":"microsoft/phi-4-mini-instruct","name":"Phi-4-mini-instruct","attachment":false,"reasoning":true,"temperature":true,"tool_call":true,"knowledge":"2023-10","release_date":"2024-12-11","last_updated":"2024-12-11","modalities":{"input":["text"],"output":["text"]},"open_weights":true,"cost":{"input":0,"output":0},"limit":{"context":128000,"output":4096},"display_name":"Phi-4-mini-instruct"},{"id":"microsoft/phi-3-medium-4k-instruct","name":"Phi-3-medium instruct (4k)","attachment":false,"reasoning":true,"temperature":true,"tool_call":true,"knowledge":"2023-10","release_date":"2024-04-23","last_updated":"2024-04-23","modalities":{"input":["text"],"output":["text"]},"open_weights":true,"cost":{"input":0,"output":0},"limit":{"context":4096,"output":1024},"display_name":"Phi-3-medium instruct (4k)"},{"id":"microsoft/phi-4-reasoning","name":"Phi-4-Reasoning","attachment":false,"reasoning":true,"temperature":true,"tool_call":true,"knowledge":"2023-10","release_date":"2024-12-11","last_updated":"2024-12-11","modalities":{"input":["text"],"output":["text"]},"open_weights":true,"cost":{"input":0,"output":0},"limit":{"context":128000,"output":4096},"display_name":"Phi-4-Reasoning"},{"id":"microsoft/mai-ds-r1","name":"MAI-DS-R1","attachment":false,"reasoning":true,"temperature":true,"tool_call":true,"knowledge":"2024-06","release_date":"2025-01-20","last_updated":"2025-01-20","modalities":{"input":["text"],"output":["text"]},"open_weights":false,"cost":{"input":0,"output":0},"limit":{"context":65536,"output":8192},"display_name":"MAI-DS-R1"},{"id":"openai/gpt-4.1-nano","name":"GPT-4.1-nano","attachment":true,"reasoning":false,"temperature":true,"tool_call":true,"knowledge":"2024-04","release_date":"2025-04-14","last_updated":"2025-04-14","modalities":{"input":["text","image"],"output":["text"]},"open_weights":false,"cost":{"input":0,"output":0},"limit":{"context":128000,"output":16384},"display_name":"GPT-4.1-nano"},{"id":"openai/gpt-4.1-mini","name":"GPT-4.1-mini","attachment":true,"reasoning":false,"temperature":true,"tool_call":true,"knowledge":"2024-04","release_date":"2025-04-14","last_updated":"2025-04-14","modalities":{"input":["text","image"],"output":["text"]},"open_weights":false,"cost":{"input":0,"output":0},"limit":{"context":128000,"output":16384},"display_name":"GPT-4.1-mini"},{"id":"openai/o1-preview","name":"OpenAI o1-preview","attachment":false,"reasoning":true,"temperature":false,"tool_call":false,"knowledge":"2023-10","release_date":"2024-09-12","last_updated":"2024-09-12","modalities":{"input":["text"],"output":["text"]},"open_weights":false,"cost":{"input":0,"output":0},"limit":{"context":128000,"output":32768},"display_name":"OpenAI o1-preview"},{"id":"openai/o3-mini","name":"OpenAI o3-mini","attachment":false,"reasoning":true,"temperature":false,"tool_call":false,"knowledge":"2024-04","release_date":"2025-01-31","last_updated":"2025-01-31","modalities":{"input":["text"],"output":["text"]},"open_weights":false,"cost":{"input":0,"output":0},"limit":{"context":200000,"output":100000},"display_name":"OpenAI o3-mini"},{"id":"openai/gpt-4o","name":"GPT-4o","attachment":true,"reasoning":false,"temperature":true,"tool_call":true,"knowledge":"2023-10","release_date":"2024-05-13","last_updated":"2024-05-13","modalities":{"input":["text","image","audio"],"output":["text"]},"open_weights":false,"cost":{"input":0,"output":0},"limit":{"context":128000,"output":16384},"display_name":"GPT-4o"},{"id":"openai/gpt-4.1","name":"GPT-4.1","attachment":true,"reasoning":false,"temperature":true,"tool_call":true,"knowledge":"2024-04","release_date":"2025-04-14","last_updated":"2025-04-14","modalities":{"input":["text","image"],"output":["text"]},"open_weights":false,"cost":{"input":0,"output":0},"limit":{"context":128000,"output":16384},"display_name":"GPT-4.1"},{"id":"openai/o4-mini","name":"OpenAI o4-mini","attachment":false,"reasoning":true,"temperature":false,"tool_call":false,"knowledge":"2024-04","release_date":"2025-01-31","last_updated":"2025-01-31","modalities":{"input":["text","image"],"output":["text"]},"open_weights":false,"cost":{"input":0,"output":0},"limit":{"context":200000,"output":100000},"display_name":"OpenAI o4-mini"},{"id":"openai/o1","name":"OpenAI o1","attachment":false,"reasoning":true,"temperature":false,"tool_call":false,"knowledge":"2023-10","release_date":"2024-09-12","last_updated":"2024-12-17","modalities":{"input":["text","image"],"output":["text"]},"open_weights":false,"cost":{"input":0,"output":0},"limit":{"context":200000,"output":100000},"display_name":"OpenAI o1"},{"id":"openai/o1-mini","name":"OpenAI o1-mini","attachment":false,"reasoning":true,"temperature":false,"tool_call":false,"knowledge":"2023-10","release_date":"2024-09-12","last_updated":"2024-12-17","modalities":{"input":["text"],"output":["text"]},"open_weights":false,"cost":{"input":0,"output":0},"limit":{"context":128000,"output":65536},"display_name":"OpenAI o1-mini"},{"id":"openai/o3","name":"OpenAI o3","attachment":false,"reasoning":true,"temperature":false,"tool_call":false,"knowledge":"2024-04","release_date":"2025-01-31","last_updated":"2025-01-31","modalities":{"input":["text","image"],"output":["text"]},"open_weights":false,"cost":{"input":0,"output":0},"limit":{"context":200000,"output":100000},"display_name":"OpenAI o3"},{"id":"openai/gpt-4o-mini","name":"GPT-4o mini","attachment":true,"reasoning":false,"temperature":true,"tool_call":true,"knowledge":"2023-10","release_date":"2024-07-18","last_updated":"2024-07-18","modalities":{"input":["text","image","audio"],"output":["text"]},"open_weights":false,"cost":{"input":0,"output":0},"limit":{"context":128000,"output":16384},"display_name":"GPT-4o mini"},{"id":"meta/llama-3.2-11b-vision-instruct","name":"Llama-3.2-11B-Vision-Instruct","attachment":false,"reasoning":true,"temperature":true,"tool_call":true,"knowledge":"2023-12","release_date":"2024-09-25","last_updated":"2024-09-25","modalities":{"input":["text","image","audio"],"output":["text"]},"open_weights":true,"cost":{"input":0,"output":0},"limit":{"context":128000,"output":8192},"display_name":"Llama-3.2-11B-Vision-Instruct"},{"id":"meta/meta-llama-3.1-405b-instruct","name":"Meta-Llama-3.1-405B-Instruct","attachment":false,"reasoning":true,"temperature":true,"tool_call":true,"knowledge":"2023-12","release_date":"2024-07-23","last_updated":"2024-07-23","modalities":{"input":["text"],"output":["text"]},"open_weights":true,"cost":{"input":0,"output":0},"limit":{"context":128000,"output":32768},"display_name":"Meta-Llama-3.1-405B-Instruct"},{"id":"meta/llama-4-maverick-17b-128e-instruct-fp8","name":"Llama 4 Maverick 17B 128E Instruct FP8","attachment":false,"reasoning":true,"temperature":true,"tool_call":true,"knowledge":"2024-12","release_date":"2025-01-31","last_updated":"2025-01-31","modalities":{"input":["text","image"],"output":["text"]},"open_weights":true,"cost":{"input":0,"output":0},"limit":{"context":128000,"output":8192},"display_name":"Llama 4 Maverick 17B 128E Instruct FP8"},{"id":"meta/meta-llama-3-70b-instruct","name":"Meta-Llama-3-70B-Instruct","attachment":false,"reasoning":true,"temperature":true,"tool_call":true,"knowledge":"2023-12","release_date":"2024-04-18","last_updated":"2024-04-18","modalities":{"input":["text"],"output":["text"]},"open_weights":true,"cost":{"input":0,"output":0},"limit":{"context":8192,"output":2048},"display_name":"Meta-Llama-3-70B-Instruct"},{"id":"meta/meta-llama-3.1-70b-instruct","name":"Meta-Llama-3.1-70B-Instruct","attachment":false,"reasoning":true,"temperature":true,"tool_call":true,"knowledge":"2023-12","release_date":"2024-07-23","last_updated":"2024-07-23","modalities":{"input":["text"],"output":["text"]},"open_weights":true,"cost":{"input":0,"output":0},"limit":{"context":128000,"output":32768},"display_name":"Meta-Llama-3.1-70B-Instruct"},{"id":"meta/llama-3.3-70b-instruct","name":"Llama-3.3-70B-Instruct","attachment":false,"reasoning":true,"temperature":true,"tool_call":true,"knowledge":"2023-12","release_date":"2024-12-06","last_updated":"2024-12-06","modalities":{"input":["text"],"output":["text"]},"open_weights":true,"cost":{"input":0,"output":0},"limit":{"context":128000,"output":32768},"display_name":"Llama-3.3-70B-Instruct"},{"id":"meta/llama-3.2-90b-vision-instruct","name":"Llama-3.2-90B-Vision-Instruct","attachment":false,"reasoning":true,"temperature":true,"tool_call":true,"knowledge":"2023-12","release_date":"2024-09-25","last_updated":"2024-09-25","modalities":{"input":["text","image","audio"],"output":["text"]},"open_weights":true,"cost":{"input":0,"output":0},"limit":{"context":128000,"output":8192},"display_name":"Llama-3.2-90B-Vision-Instruct"},{"id":"meta/meta-llama-3-8b-instruct","name":"Meta-Llama-3-8B-Instruct","attachment":false,"reasoning":true,"temperature":true,"tool_call":true,"knowledge":"2023-12","release_date":"2024-04-18","last_updated":"2024-04-18","modalities":{"input":["text"],"output":["text"]},"open_weights":true,"cost":{"input":0,"output":0},"limit":{"context":8192,"output":2048},"display_name":"Meta-Llama-3-8B-Instruct"},{"id":"meta/llama-4-scout-17b-16e-instruct","name":"Llama 4 Scout 17B 16E Instruct","attachment":false,"reasoning":true,"temperature":true,"tool_call":true,"knowledge":"2024-12","release_date":"2025-01-31","last_updated":"2025-01-31","modalities":{"input":["text","image"],"output":["text"]},"open_weights":true,"cost":{"input":0,"output":0},"limit":{"context":128000,"output":8192},"display_name":"Llama 4 Scout 17B 16E Instruct"},{"id":"meta/meta-llama-3.1-8b-instruct","name":"Meta-Llama-3.1-8B-Instruct","attachment":false,"reasoning":true,"temperature":true,"tool_call":true,"knowledge":"2023-12","release_date":"2024-07-23","last_updated":"2024-07-23","modalities":{"input":["text"],"output":["text"]},"open_weights":true,"cost":{"input":0,"output":0},"limit":{"context":128000,"output":32768},"display_name":"Meta-Llama-3.1-8B-Instruct"},{"id":"ai21-labs/ai21-jamba-1.5-large","name":"AI21 Jamba 1.5 Large","attachment":false,"reasoning":true,"temperature":true,"tool_call":true,"knowledge":"2024-03","release_date":"2024-08-29","last_updated":"2024-08-29","modalities":{"input":["text"],"output":["text"]},"open_weights":false,"cost":{"input":0,"output":0},"limit":{"context":256000,"output":4096},"display_name":"AI21 Jamba 1.5 Large"},{"id":"ai21-labs/ai21-jamba-1.5-mini","name":"AI21 Jamba 1.5 Mini","attachment":false,"reasoning":true,"temperature":true,"tool_call":true,"knowledge":"2024-03","release_date":"2024-08-29","last_updated":"2024-08-29","modalities":{"input":["text"],"output":["text"]},"open_weights":false,"cost":{"input":0,"output":0},"limit":{"context":256000,"output":4096},"display_name":"AI21 Jamba 1.5 Mini"}]},"togetherai":{"id":"togetherai","name":"Together AI","doc":"https://docs.together.ai/docs/serverless-models","display_name":"Together AI","models":[{"id":"moonshotai/Kimi-K2-Instruct","name":"Kimi K2 Instruct","attachment":false,"reasoning":false,"temperature":true,"tool_call":true,"knowledge":"2024-10","release_date":"2025-07-14","last_updated":"2025-07-14","modalities":{"input":["text"],"output":["text"]},"open_weights":true,"cost":{"input":1,"output":3},"limit":{"context":131072,"output":32768},"display_name":"Kimi K2 Instruct"},{"id":"openai/gpt-oss-120b","name":"GPT OSS 120B","attachment":false,"reasoning":true,"temperature":true,"tool_call":true,"release_date":"2025-08-05","last_updated":"2025-08-05","modalities":{"input":["text"],"output":["text"]},"open_weights":true,"cost":{"input":0.15,"output":0.6},"limit":{"context":131072,"output":131072},"display_name":"GPT OSS 120B"},{"id":"meta-llama/Llama-3.3-70B-Instruct-Turbo","name":"Llama 3.3 70B","attachment":false,"reasoning":false,"temperature":true,"tool_call":true,"knowledge":"2023-12","release_date":"2024-12-06","last_updated":"2024-12-06","modalities":{"input":["text"],"output":["text"]},"open_weights":true,"cost":{"input":0.88,"output":0.88},"limit":{"context":131072,"output":66536},"display_name":"Llama 3.3 70B"},{"id":"Qwen/Qwen3-Coder-480B-A35B-Instruct-FP8","name":"Qwen3 Coder 480B A35B Instruct","attachment":false,"reasoning":false,"temperature":true,"tool_call":true,"knowledge":"2025-04","release_date":"2025-07-23","last_updated":"2025-07-23","modalities":{"input":["text"],"output":["text"]},"open_weights":true,"cost":{"input":2,"output":2},"limit":{"context":262144,"output":66536},"display_name":"Qwen3 Coder 480B A35B Instruct"},{"id":"deepseek-ai/DeepSeek-R1","name":"DeepSeek R1","attachment":false,"reasoning":true,"temperature":true,"tool_call":false,"knowledge":"2024-07","release_date":"2024-12-26","last_updated":"2025-03-24","modalities":{"input":["text"],"output":["text"]},"open_weights":true,"cost":{"input":3,"output":7},"limit":{"context":163839,"output":12288},"display_name":"DeepSeek R1"},{"id":"deepseek-ai/DeepSeek-V3","name":"DeepSeek V3","attachment":false,"reasoning":true,"temperature":true,"tool_call":true,"knowledge":"2024-07","release_date":"2025-01-20","last_updated":"2025-05-29","modalities":{"input":["text"],"output":["text"]},"open_weights":true,"cost":{"input":1.25,"output":1.25},"limit":{"context":131072,"output":12288},"display_name":"DeepSeek V3"}]},"azure":{"id":"azure","name":"Azure","doc":"https://learn.microsoft.com/en-us/azure/ai-services/openai/concepts/models","display_name":"Azure","models":[{"id":"gpt-4.1-nano","name":"GPT-4.1 nano","attachment":true,"reasoning":false,"temperature":true,"tool_call":true,"knowledge":"2024-05","release_date":"2025-04-14","last_updated":"2025-04-14","modalities":{"input":["text","image"],"output":["text"]},"open_weights":false,"cost":{"input":0.1,"output":0.4,"cache_read":0.03},"limit":{"context":1047576,"output":32768},"display_name":"GPT-4.1 nano"},{"id":"gpt-4","name":"GPT-4","attachment":false,"reasoning":false,"temperature":true,"tool_call":true,"knowledge":"2023-11","release_date":"2023-03-14","last_updated":"2023-03-14","modalities":{"input":["text"],"output":["text"]},"open_weights":false,"cost":{"input":60,"output":120},"limit":{"context":8192,"output":8192},"display_name":"GPT-4"},{"id":"gpt-4-32k","name":"GPT-4 32K","attachment":false,"reasoning":false,"temperature":true,"tool_call":true,"knowledge":"2023-11","release_date":"2023-03-14","last_updated":"2023-03-14","modalities":{"input":["text"],"output":["text"]},"open_weights":false,"cost":{"input":60,"output":120},"limit":{"context":32768,"output":32768},"display_name":"GPT-4 32K"},{"id":"gpt-4.1-mini","name":"GPT-4.1 mini","attachment":true,"reasoning":false,"temperature":true,"tool_call":true,"knowledge":"2024-05","release_date":"2025-04-14","last_updated":"2025-04-14","modalities":{"input":["text","image"],"output":["text"]},"open_weights":false,"cost":{"input":0.4,"output":1.6,"cache_read":0.1},"limit":{"context":1047576,"output":32768},"display_name":"GPT-4.1 mini"},{"id":"gpt-5-chat","name":"GPT-5 Chat","attachment":true,"reasoning":true,"temperature":false,"tool_call":false,"knowledge":"2024-10-24","release_date":"2025-08-07","last_updated":"2025-08-07","modalities":{"input":["text","image"],"output":["text"]},"open_weights":false,"cost":{"input":1.25,"output":10,"cache_read":0.13},"limit":{"context":128000,"output":16384},"display_name":"GPT-5 Chat"},{"id":"gpt-3.5-turbo-0125","name":"GPT-3.5 Turbo 0125","attachment":false,"reasoning":false,"temperature":true,"tool_call":false,"knowledge":"2021-08","release_date":"2024-01-25","last_updated":"2024-01-25","modalities":{"input":["text"],"output":["text"]},"open_weights":false,"cost":{"input":0.5,"output":1.5},"limit":{"context":16384,"output":16384},"display_name":"GPT-3.5 Turbo 0125"},{"id":"gpt-4-turbo","name":"GPT-4 Turbo","attachment":true,"reasoning":false,"temperature":true,"tool_call":true,"knowledge":"2023-11","release_date":"2023-11-06","last_updated":"2024-04-09","modalities":{"input":["text","image"],"output":["text"]},"open_weights":false,"cost":{"input":10,"output":30},"limit":{"context":128000,"output":4096},"display_name":"GPT-4 Turbo"},{"id":"gpt-3.5-turbo-0613","name":"GPT-3.5 Turbo 0613","attachment":false,"reasoning":false,"temperature":true,"tool_call":false,"knowledge":"2021-08","release_date":"2023-06-13","last_updated":"2023-06-13","modalities":{"input":["text"],"output":["text"]},"open_weights":false,"cost":{"input":3,"output":4},"limit":{"context":16384,"output":16384},"display_name":"GPT-3.5 Turbo 0613"},{"id":"o1-preview","name":"o1-preview","attachment":false,"reasoning":true,"temperature":false,"tool_call":true,"knowledge":"2023-09","release_date":"2024-09-12","last_updated":"2024-09-12","modalities":{"input":["text"],"output":["text"]},"open_weights":false,"cost":{"input":16.5,"output":66,"cache_read":8.25},"limit":{"context":128000,"output":32768},"display_name":"o1-preview"},{"id":"o3-mini","name":"o3-mini","attachment":false,"reasoning":true,"temperature":false,"tool_call":true,"knowledge":"2024-05","release_date":"2024-12-20","last_updated":"2025-01-29","modalities":{"input":["text"],"output":["text"]},"open_weights":false,"cost":{"input":1.1,"output":4.4,"cache_read":0.55},"limit":{"context":200000,"output":100000},"display_name":"o3-mini"},{"id":"gpt-5-nano","name":"GPT-5 Nano","attachment":true,"reasoning":true,"temperature":false,"tool_call":true,"knowledge":"2024-05-30","release_date":"2025-08-07","last_updated":"2025-08-07","modalities":{"input":["text","image"],"output":["text"]},"open_weights":false,"cost":{"input":0.05,"output":0.4,"cache_read":0.01},"limit":{"context":272000,"output":128000},"display_name":"GPT-5 Nano"},{"id":"gpt-5-codex","name":"GPT-5-Codex","attachment":false,"reasoning":true,"temperature":false,"tool_call":true,"knowledge":"2024-09-30","release_date":"2025-09-15","last_updated":"2025-09-15","modalities":{"input":["text","image"],"output":["text"]},"open_weights":false,"limit":{"context":400000,"output":128000},"display_name":"GPT-5-Codex"},{"id":"gpt-4o","name":"GPT-4o","attachment":true,"reasoning":false,"temperature":true,"tool_call":true,"knowledge":"2023-09","release_date":"2024-05-13","last_updated":"2024-05-13","modalities":{"input":["text","image"],"output":["text"]},"open_weights":false,"cost":{"input":2.5,"output":10,"cache_read":1.25},"limit":{"context":128000,"output":16384},"display_name":"GPT-4o"},{"id":"gpt-3.5-turbo-0301","name":"GPT-3.5 Turbo 0301","attachment":false,"reasoning":false,"temperature":true,"tool_call":false,"knowledge":"2021-08","release_date":"2023-03-01","last_updated":"2023-03-01","modalities":{"input":["text"],"output":["text"]},"open_weights":false,"cost":{"input":1.5,"output":2},"limit":{"context":4096,"output":4096},"display_name":"GPT-3.5 Turbo 0301"},{"id":"gpt-4.1","name":"GPT-4.1","attachment":true,"reasoning":false,"temperature":true,"tool_call":true,"knowledge":"2024-05","release_date":"2025-04-14","last_updated":"2025-04-14","modalities":{"input":["text","image"],"output":["text"]},"open_weights":false,"cost":{"input":2,"output":8,"cache_read":0.5},"limit":{"context":1047576,"output":32768},"display_name":"GPT-4.1"},{"id":"o4-mini","name":"o4-mini","attachment":true,"reasoning":true,"temperature":false,"tool_call":true,"knowledge":"2024-05","release_date":"2025-04-16","last_updated":"2025-04-16","modalities":{"input":["text","image"],"output":["text"]},"open_weights":false,"cost":{"input":1.1,"output":4.4,"cache_read":0.28},"limit":{"context":200000,"output":100000},"display_name":"o4-mini"},{"id":"o1","name":"o1","attachment":false,"reasoning":true,"temperature":false,"tool_call":true,"knowledge":"2023-09","release_date":"2024-12-05","last_updated":"2024-12-05","modalities":{"input":["text","image"],"output":["text"]},"open_weights":false,"cost":{"input":15,"output":60,"cache_read":7.5},"limit":{"context":200000,"output":100000},"display_name":"o1"},{"id":"gpt-5-mini","name":"GPT-5 Mini","attachment":true,"reasoning":true,"temperature":false,"tool_call":true,"knowledge":"2024-05-30","release_date":"2025-08-07","last_updated":"2025-08-07","modalities":{"input":["text","image"],"output":["text"]},"open_weights":false,"cost":{"input":0.25,"output":2,"cache_read":0.03},"limit":{"context":272000,"output":128000},"display_name":"GPT-5 Mini"},{"id":"o1-mini","name":"o1-mini","attachment":false,"reasoning":true,"temperature":false,"tool_call":true,"knowledge":"2023-09","release_date":"2024-09-12","last_updated":"2024-09-12","modalities":{"input":["text"],"output":["text"]},"open_weights":false,"cost":{"input":1.1,"output":4.4,"cache_read":0.55},"limit":{"context":128000,"output":65536},"display_name":"o1-mini"},{"id":"gpt-3.5-turbo-instruct","name":"GPT-3.5 Turbo Instruct","attachment":false,"reasoning":false,"temperature":true,"tool_call":false,"knowledge":"2021-08","release_date":"2023-09-21","last_updated":"2023-09-21","modalities":{"input":["text"],"output":["text"]},"open_weights":false,"cost":{"input":1.5,"output":2},"limit":{"context":4096,"output":4096},"display_name":"GPT-3.5 Turbo Instruct"},{"id":"o3","name":"o3","attachment":true,"reasoning":true,"temperature":false,"tool_call":true,"knowledge":"2024-05","release_date":"2025-04-16","last_updated":"2025-04-16","modalities":{"input":["text","image"],"output":["text"]},"open_weights":false,"cost":{"input":2,"output":8,"cache_read":0.5},"limit":{"context":200000,"output":100000},"display_name":"o3"},{"id":"codex-mini","name":"Codex Mini","attachment":true,"reasoning":true,"temperature":false,"tool_call":true,"knowledge":"2024-04","release_date":"2025-05-16","last_updated":"2025-05-16","modalities":{"input":["text"],"output":["text"]},"open_weights":false,"cost":{"input":1.5,"output":6,"cache_read":0.375},"limit":{"context":200000,"output":100000},"display_name":"Codex Mini"},{"id":"gpt-4-turbo-vision","name":"GPT-4 Turbo Vision","attachment":true,"reasoning":false,"temperature":true,"tool_call":true,"knowledge":"2023-11","release_date":"2023-11-06","last_updated":"2024-04-09","modalities":{"input":["text","image"],"output":["text"]},"open_weights":false,"cost":{"input":10,"output":30},"limit":{"context":128000,"output":4096},"display_name":"GPT-4 Turbo Vision"},{"id":"gpt-4o-mini","name":"GPT-4o mini","attachment":true,"reasoning":false,"temperature":true,"tool_call":true,"knowledge":"2023-09","release_date":"2024-07-18","last_updated":"2024-07-18","modalities":{"input":["text","image"],"output":["text"]},"open_weights":false,"cost":{"input":0.15,"output":0.6,"cache_read":0.08},"limit":{"context":128000,"output":16384},"display_name":"GPT-4o mini"},{"id":"gpt-5","name":"GPT-5","attachment":true,"reasoning":true,"temperature":false,"tool_call":true,"knowledge":"2024-09-30","release_date":"2025-08-07","last_updated":"2025-08-07","modalities":{"input":["text","image"],"output":["text"]},"open_weights":false,"cost":{"input":1.25,"output":10,"cache_read":0.13},"limit":{"context":272000,"output":128000},"display_name":"GPT-5"},{"id":"gpt-3.5-turbo-1106","name":"GPT-3.5 Turbo 1106","attachment":false,"reasoning":false,"temperature":true,"tool_call":false,"knowledge":"2021-08","release_date":"2023-11-06","last_updated":"2023-11-06","modalities":{"input":["text"],"output":["text"]},"open_weights":false,"cost":{"input":1,"output":2},"limit":{"context":16384,"output":16384},"display_name":"GPT-3.5 Turbo 1106"}]},"baseten":{"id":"baseten","api":"https://inference.baseten.co/v1","name":"Baseten","doc":"https://docs.baseten.co/development/model-apis/overview","display_name":"Baseten","models":[{"id":"moonshotai/Kimi-K2-Instruct-0905","name":"Kimi K2 Instruct 0905","attachment":false,"reasoning":false,"temperature":true,"tool_call":true,"knowledge":"2025-08","release_date":"2025-09-05","last_updated":"2025-09-05","modalities":{"input":["text"],"output":["text"]},"open_weights":true,"cost":{"input":0.6,"output":2.5},"limit":{"context":262144,"output":262144},"display_name":"Kimi K2 Instruct 0905"},{"id":"Qwen3/Qwen3-Coder-480B-A35B-Instruct","name":"Qwen3 Coder 480B A35B Instruct","attachment":false,"reasoning":false,"temperature":true,"tool_call":true,"knowledge":"2025-04","release_date":"2025-07-23","last_updated":"2025-07-23","modalities":{"input":["text"],"output":["text"]},"open_weights":true,"cost":{"input":0.38,"output":1.53},"limit":{"context":262144,"output":66536},"display_name":"Qwen3 Coder 480B A35B Instruct"}]},"huggingface":{"id":"huggingface","api":"https://router.huggingface.co/v1","name":"Hugging Face","doc":"https://huggingface.co/docs/inference-providers","display_name":"Hugging Face","models":[{"id":"moonshotai/Kimi-K2-Instruct","name":"Kimi-K2-Instruct","attachment":false,"reasoning":false,"temperature":true,"tool_call":true,"knowledge":"2024-10","release_date":"2025-07-14","last_updated":"2025-07-14","modalities":{"input":["text"],"output":["text"]},"open_weights":true,"cost":{"input":1,"output":3},"limit":{"context":131072,"output":16384},"display_name":"Kimi-K2-Instruct"},{"id":"moonshotai/Kimi-K2-Instruct-0905","name":"Kimi-K2-Instruct-0905","attachment":false,"reasoning":false,"temperature":true,"tool_call":true,"knowledge":"2024-10","release_date":"2025-09-04","last_updated":"2025-09-04","modalities":{"input":["text"],"output":["text"]},"open_weights":true,"cost":{"input":1,"output":3},"limit":{"context":262144,"output":16384},"display_name":"Kimi-K2-Instruct-0905"},{"id":"Qwen/Qwen3-Coder-480B-A35B-Instruct","name":"Qwen3-Coder-480B-A35B-Instruct","attachment":false,"reasoning":false,"temperature":true,"tool_call":true,"knowledge":"2025-04","release_date":"2025-07-23","last_updated":"2025-07-23","modalities":{"input":["text"],"output":["text"]},"open_weights":true,"cost":{"input":2,"output":2},"limit":{"context":262144,"output":66536},"display_name":"Qwen3-Coder-480B-A35B-Instruct"},{"id":"Qwen/Qwen3-235B-A22B-Thinking-2507","name":"Qwen3-235B-A22B-Thinking-2507","attachment":false,"reasoning":true,"temperature":true,"tool_call":true,"knowledge":"2025-04","release_date":"2025-07-25","last_updated":"2025-07-25","modalities":{"input":["text"],"output":["text"]},"open_weights":true,"cost":{"input":0.3,"output":3},"limit":{"context":262144,"output":131072},"display_name":"Qwen3-235B-A22B-Thinking-2507"},{"id":"Qwen/Qwen3-Next-80B-A3B-Instruct","name":"Qwen3-Next-80B-A3B-Instruct","attachment":false,"reasoning":false,"temperature":true,"tool_call":true,"knowledge":"2025-04","release_date":"2025-09-11","last_updated":"2025-09-11","modalities":{"input":["text"],"output":["text"]},"open_weights":true,"cost":{"input":0.25,"output":1},"limit":{"context":262144,"output":66536},"display_name":"Qwen3-Next-80B-A3B-Instruct"},{"id":"Qwen/Qwen3-Next-80B-A3B-Thinking","name":"Qwen3-Next-80B-A3B-Thinking","attachment":false,"reasoning":false,"temperature":true,"tool_call":true,"knowledge":"2025-04","release_date":"2025-09-11","last_updated":"2025-09-11","modalities":{"input":["text"],"output":["text"]},"open_weights":true,"cost":{"input":0.3,"output":2},"limit":{"context":262144,"output":131072},"display_name":"Qwen3-Next-80B-A3B-Thinking"},{"id":"zai-org/GLM-4.5","name":"GLM-4.5","attachment":false,"reasoning":true,"temperature":true,"tool_call":true,"knowledge":"2025-04","release_date":"2025-07-28","last_updated":"2025-07-28","modalities":{"input":["text"],"output":["text"]},"open_weights":true,"cost":{"input":0.6,"output":2.2},"limit":{"context":131072,"output":98304},"display_name":"GLM-4.5"},{"id":"zai-org/GLM-4.6","name":"GLM-4.6","attachment":false,"reasoning":true,"temperature":true,"tool_call":true,"knowledge":"2025-04","release_date":"2025-09-30","last_updated":"2025-09-30","modalities":{"input":["text"],"output":["text"]},"open_weights":true,"cost":{"input":0.6,"output":2.2,"cache_read":0.11},"limit":{"context":200000,"output":128000},"display_name":"GLM-4.6"},{"id":"zai-org/GLM-4.5-Air","name":"GLM-4.5-Air","attachment":false,"reasoning":true,"temperature":true,"tool_call":true,"knowledge":"2025-04","release_date":"2025-07-28","last_updated":"2025-07-28","modalities":{"input":["text"],"output":["text"]},"open_weights":true,"cost":{"input":0.2,"output":1.1},"limit":{"context":128000,"output":96000},"display_name":"GLM-4.5-Air"},{"id":"deepseek-ai/Deepseek-V3-0324","name":"DeepSeek-V3-0324","attachment":false,"reasoning":false,"temperature":true,"tool_call":true,"knowledge":"2024-10","release_date":"2025-03-24","last_updated":"2025-03-24","modalities":{"input":["text"],"output":["text"]},"open_weights":true,"cost":{"input":1.25,"output":1.25},"limit":{"context":16384,"output":8192},"display_name":"DeepSeek-V3-0324"},{"id":"deepseek-ai/DeepSeek-R1-0528","name":"DeepSeek-R1-0528","attachment":false,"reasoning":true,"temperature":true,"tool_call":true,"knowledge":"2025-05","release_date":"2025-05-28","last_updated":"2025-05-28","modalities":{"input":["text"],"output":["text"]},"open_weights":true,"cost":{"input":3,"output":5},"limit":{"context":163840,"output":163840},"display_name":"DeepSeek-R1-0528"}]},"opencode":{"id":"opencode","api":"https://opencode.ai/zen/v1","name":"opencode zen","doc":"https://opencode.ai/docs","display_name":"opencode zen","models":[{"id":"qwen3-coder","name":"Qwen3 Coder","attachment":false,"reasoning":false,"temperature":true,"tool_call":true,"knowledge":"2025-04","release_date":"2025-07-23","last_updated":"2025-07-23","modalities":{"input":["text"],"output":["text"]},"open_weights":true,"cost":{"input":0.45,"output":1.8},"limit":{"context":262144,"output":65536},"display_name":"Qwen3 Coder"},{"id":"claude-opus-4-1","name":"Claude Opus 4.1","attachment":true,"reasoning":true,"temperature":true,"tool_call":true,"knowledge":"2025-03-31","release_date":"2025-08-05","last_updated":"2025-08-05","modalities":{"input":["text","image"],"output":["text"]},"open_weights":false,"cost":{"input":15,"output":75,"reasoning":75,"cache_read":1.5,"cache_write":18.75},"limit":{"context":200000,"output":32000},"provider":{"npm":"@ai-sdk/anthropic"},"display_name":"Claude Opus 4.1"},{"id":"kimi-k2","name":"Kimi K2","attachment":false,"reasoning":false,"temperature":true,"tool_call":true,"knowledge":"2024-10","release_date":"2025-09-05","last_updated":"2025-09-05","modalities":{"input":["text"],"output":["text"]},"open_weights":true,"cost":{"input":0.6,"output":2.5,"cache_read":0.36},"limit":{"context":262144,"output":262144},"display_name":"Kimi K2"},{"id":"claude-sonnet-4-5","name":"Claude Sonnet 4.5","attachment":true,"reasoning":true,"temperature":true,"tool_call":true,"knowledge":"2025-07-31","release_date":"2025-09-29","last_updated":"2025-09-29","modalities":{"input":["text","image"],"output":["text"]},"open_weights":false,"cost":{"input":3,"output":15,"cache_read":0.3,"cache_write":3.75},"limit":{"context":1000000,"output":64000},"provider":{"npm":"@ai-sdk/anthropic"},"display_name":"Claude Sonnet 4.5"},{"id":"gpt-5-codex","name":"GPT-5-Codex","attachment":true,"reasoning":true,"temperature":false,"tool_call":true,"knowledge":"2024-09-30","release_date":"2025-08-07","last_updated":"2025-08-07","modalities":{"input":["text","image"],"output":["text"]},"open_weights":false,"cost":{"input":1.25,"output":10,"reasoning":10,"cache_read":0.125},"limit":{"context":400000,"output":128000},"provider":{"npm":"@ai-sdk/openai"},"display_name":"GPT-5-Codex"},{"id":"claude-3-5-haiku","name":"Claude Haiku 3.5","attachment":true,"reasoning":false,"temperature":true,"tool_call":true,"knowledge":"2024-07-31","release_date":"2024-10-22","last_updated":"2024-10-22","modalities":{"input":["text","image"],"output":["text"]},"open_weights":false,"cost":{"input":0.8,"output":4,"cache_read":0.08,"cache_write":1},"limit":{"context":200000,"output":8192},"provider":{"npm":"@ai-sdk/anthropic"},"display_name":"Claude Haiku 3.5"},{"id":"glm-4.6","name":"GLM-4.6","attachment":false,"reasoning":true,"temperature":true,"tool_call":true,"knowledge":"2025-04","release_date":"2025-09-30","last_updated":"2025-09-30","modalities":{"input":["text"],"output":["text"]},"open_weights":true,"cost":{"input":0.6,"output":2.2,"cache_read":0.11,"cache_write":0},"limit":{"context":204800,"output":131072},"experimental":true,"display_name":"GLM-4.6"},{"id":"grok-code","name":"Grok Code Fast 1","attachment":true,"reasoning":true,"temperature":true,"tool_call":true,"release_date":"2025-08-20","last_updated":"2025-08-20","modalities":{"input":["text"],"output":["text"]},"open_weights":false,"cost":{"input":0,"output":0,"cache_read":0,"cache_write":0},"limit":{"context":256000,"output":256000},"display_name":"Grok Code Fast 1"},{"id":"code-supernova","name":"Code Supernova 1M","attachment":true,"reasoning":true,"temperature":true,"tool_call":true,"release_date":"2025-09-19","last_updated":"2025-09-19","modalities":{"input":["text","image"],"output":["text"]},"open_weights":false,"cost":{"input":0,"output":0,"cache_read":0,"cache_write":0},"limit":{"context":1000000,"output":1000000},"display_name":"Code Supernova 1M"},{"id":"qwen3-max","name":"Qwen3 Max","attachment":false,"reasoning":true,"temperature":true,"tool_call":true,"knowledge":"2025-04","release_date":"2025-09-05","last_updated":"2025-09-05","modalities":{"input":["text"],"output":["text"]},"open_weights":true,"cost":{"input":1.6,"output":6.4},"limit":{"context":262144,"output":65536},"experimental":true,"display_name":"Qwen3 Max"},{"id":"claude-sonnet-4","name":"Claude Sonnet 4","attachment":true,"reasoning":true,"temperature":true,"tool_call":true,"knowledge":"2025-03-31","release_date":"2025-05-22","last_updated":"2025-05-22","modalities":{"input":["text","image"],"output":["text"]},"open_weights":false,"cost":{"input":3,"output":15,"cache_read":0.3,"cache_write":3.75},"limit":{"context":1000000,"output":64000},"provider":{"npm":"@ai-sdk/anthropic"},"display_name":"Claude Sonnet 4"},{"id":"gpt-5","name":"GPT-5","attachment":true,"reasoning":true,"temperature":false,"tool_call":true,"knowledge":"2024-09-30","release_date":"2025-08-07","last_updated":"2025-08-07","modalities":{"input":["text","image"],"output":["text"]},"open_weights":false,"cost":{"input":1.25,"output":10,"reasoning":10,"cache_read":0.125},"limit":{"context":400000,"output":128000},"provider":{"npm":"@ai-sdk/openai"},"display_name":"GPT-5"}]},"fastrouter":{"id":"fastrouter","api":"https://go.fastrouter.ai/api/v1","name":"FastRouter","doc":"https://fastrouter.ai/models","display_name":"FastRouter","models":[{"id":"moonshotai/kimi-k2","name":"Kimi K2","attachment":false,"reasoning":false,"temperature":true,"tool_call":true,"knowledge":"2024-10","release_date":"2025-07-11","last_updated":"2025-07-11","modalities":{"input":["text"],"output":["text"]},"open_weights":true,"cost":{"input":0.55,"output":2.2},"limit":{"context":131072,"output":32768},"display_name":"Kimi K2"},{"id":"x-ai/grok-4","name":"Grok 4","attachment":false,"reasoning":true,"temperature":true,"tool_call":true,"knowledge":"2025-07","release_date":"2025-07-09","last_updated":"2025-07-09","modalities":{"input":["text"],"output":["text"]},"open_weights":false,"cost":{"input":3,"output":15,"cache_read":0.75,"cache_write":15},"limit":{"context":256000,"output":64000},"display_name":"Grok 4"},{"id":"google/gemini-2.5-flash","name":"Gemini 2.5 Flash","attachment":true,"reasoning":true,"temperature":true,"tool_call":true,"knowledge":"2025-01","release_date":"2025-06-17","last_updated":"2025-06-17","modalities":{"input":["text","image","pdf"],"output":["text"]},"open_weights":false,"cost":{"input":0.3,"output":2.5,"cache_read":0.0375},"limit":{"context":1048576,"output":65536},"display_name":"Gemini 2.5 Flash"},{"id":"google/gemini-2.5-pro","name":"Gemini 2.5 Pro","attachment":true,"reasoning":true,"temperature":true,"tool_call":true,"knowledge":"2025-01","release_date":"2025-06-17","last_updated":"2025-06-17","modalities":{"input":["text","image","pdf"],"output":["text"]},"open_weights":false,"cost":{"input":1.25,"output":10,"cache_read":0.31},"limit":{"context":1048576,"output":65536},"display_name":"Gemini 2.5 Pro"},{"id":"openai/gpt-5-nano","name":"GPT-5 Nano","attachment":true,"reasoning":true,"temperature":true,"tool_call":true,"knowledge":"2024-10-01","release_date":"2025-08-07","last_updated":"2025-08-07","modalities":{"input":["text","image"],"output":["text"]},"open_weights":false,"cost":{"input":0.05,"output":0.4,"cache_read":0.005},"limit":{"context":400000,"output":128000},"display_name":"GPT-5 Nano"},{"id":"openai/gpt-4.1","name":"GPT-4.1","attachment":true,"reasoning":false,"temperature":true,"tool_call":true,"knowledge":"2024-04","release_date":"2025-04-14","last_updated":"2025-04-14","modalities":{"input":["text","image"],"output":["text"]},"open_weights":false,"cost":{"input":2,"output":8,"cache_read":0.5},"limit":{"context":1047576,"output":32768},"display_name":"GPT-4.1"},{"id":"openai/gpt-5-mini","name":"GPT-5 Mini","attachment":true,"reasoning":true,"temperature":true,"tool_call":true,"knowledge":"2024-10-01","release_date":"2025-08-07","last_updated":"2025-08-07","modalities":{"input":["text","image"],"output":["text"]},"open_weights":false,"cost":{"input":0.25,"output":2,"cache_read":0.025},"limit":{"context":400000,"output":128000},"display_name":"GPT-5 Mini"},{"id":"openai/gpt-oss-20b","name":"GPT OSS 20B","attachment":false,"reasoning":true,"temperature":true,"tool_call":true,"release_date":"2025-08-05","last_updated":"2025-08-05","modalities":{"input":["text"],"output":["text"]},"open_weights":true,"cost":{"input":0.05,"output":0.2},"limit":{"context":131072,"output":65536},"display_name":"GPT OSS 20B"},{"id":"openai/gpt-oss-120b","name":"GPT OSS 120B","attachment":false,"reasoning":true,"temperature":true,"tool_call":true,"release_date":"2025-08-05","last_updated":"2025-08-05","modalities":{"input":["text"],"output":["text"]},"open_weights":true,"cost":{"input":0.15,"output":0.6},"limit":{"context":131072,"output":32768},"display_name":"GPT OSS 120B"},{"id":"openai/gpt-5","name":"GPT-5","attachment":true,"reasoning":true,"temperature":true,"tool_call":true,"knowledge":"2024-10-01","release_date":"2025-08-07","last_updated":"2025-08-07","modalities":{"input":["text","image"],"output":["text"]},"open_weights":false,"cost":{"input":1.25,"output":10,"cache_read":0.125},"limit":{"context":400000,"output":128000},"display_name":"GPT-5"},{"id":"qwen/qwen3-coder","name":"Qwen3 Coder","attachment":false,"reasoning":false,"temperature":true,"tool_call":true,"knowledge":"2025-04","release_date":"2025-07-23","last_updated":"2025-07-23","modalities":{"input":["text"],"output":["text"]},"open_weights":true,"cost":{"input":0.3,"output":1.2},"limit":{"context":262144,"output":66536},"display_name":"Qwen3 Coder"},{"id":"anthropic/claude-opus-4.1","name":"Claude Opus 4.1","attachment":true,"reasoning":true,"temperature":true,"tool_call":true,"knowledge":"2025-03-31","release_date":"2025-08-05","last_updated":"2025-08-05","modalities":{"input":["text","image"],"output":["text"]},"open_weights":false,"cost":{"input":15,"output":75,"cache_read":1.5,"cache_write":18.75},"limit":{"context":200000,"output":32000},"display_name":"Claude Opus 4.1"},{"id":"anthropic/claude-sonnet-4","name":"Claude Sonnet 4","attachment":true,"reasoning":true,"temperature":true,"tool_call":true,"knowledge":"2025-03-31","release_date":"2025-05-22","last_updated":"2025-05-22","modalities":{"input":["text","image"],"output":["text"]},"open_weights":false,"cost":{"input":3,"output":15,"cache_read":0.3,"cache_write":3.75},"limit":{"context":200000,"output":64000},"display_name":"Claude Sonnet 4"},{"id":"deepseek-ai/deepseek-r1-distill-llama-70b","name":"DeepSeek R1 Distill Llama 70B","attachment":false,"reasoning":true,"temperature":true,"tool_call":false,"knowledge":"2024-10","release_date":"2025-01-23","last_updated":"2025-01-23","modalities":{"input":["text"],"output":["text"]},"open_weights":true,"cost":{"input":0.03,"output":0.14},"limit":{"context":131072,"output":131072},"display_name":"DeepSeek R1 Distill Llama 70B"}]},"google":{"id":"google","name":"Google","doc":"https://ai.google.dev/gemini-api/docs/pricing","display_name":"Google","models":[{"id":"gemini-2.5-flash-preview-05-20","name":"Gemini 2.5 Flash Preview 05-20","attachment":true,"reasoning":true,"temperature":true,"tool_call":true,"knowledge":"2025-01","release_date":"2025-05-20","last_updated":"2025-05-20","modalities":{"input":["text","image","audio","video","pdf"],"output":["text"]},"open_weights":false,"cost":{"input":0.15,"output":0.6,"cache_read":0.0375},"limit":{"context":1048576,"output":65536},"display_name":"Gemini 2.5 Flash Preview 05-20"},{"id":"gemini-flash-lite-latest","name":"Gemini Flash-Lite Latest","attachment":true,"reasoning":true,"temperature":true,"tool_call":true,"knowledge":"2025-01","release_date":"2025-09-25","last_updated":"2025-09-25","modalities":{"input":["text","image","audio","video","pdf"],"output":["text"]},"open_weights":false,"cost":{"input":0.1,"output":0.4,"cache_read":0.025},"limit":{"context":1048576,"output":65536},"display_name":"Gemini Flash-Lite Latest"},{"id":"gemini-2.5-flash","name":"Gemini 2.5 Flash","attachment":true,"reasoning":true,"temperature":true,"tool_call":true,"knowledge":"2025-01","release_date":"2025-03-20","last_updated":"2025-06-05","modalities":{"input":["text","image","audio","video","pdf"],"output":["text"]},"open_weights":false,"cost":{"input":0.3,"output":2.5,"cache_read":0.075,"input_audio":1},"limit":{"context":1048576,"output":65536},"display_name":"Gemini 2.5 Flash"},{"id":"gemini-flash-latest","name":"Gemini Flash Latest","attachment":true,"reasoning":true,"temperature":true,"tool_call":true,"knowledge":"2025-01","release_date":"2025-09-25","last_updated":"2025-09-25","modalities":{"input":["text","image","audio","video","pdf"],"output":["text"]},"open_weights":false,"cost":{"input":0.15,"output":0.6,"cache_read":0.0375},"limit":{"context":1048576,"output":65536},"display_name":"Gemini Flash Latest"},{"id":"gemini-2.5-pro-preview-05-06","name":"Gemini 2.5 Pro Preview 05-06","attachment":true,"reasoning":true,"temperature":true,"tool_call":true,"knowledge":"2025-01","release_date":"2025-05-06","last_updated":"2025-05-06","modalities":{"input":["text","image","audio","video","pdf"],"output":["text"]},"open_weights":false,"cost":{"input":1.25,"output":10,"cache_read":0.31},"limit":{"context":1048576,"output":65536},"display_name":"Gemini 2.5 Pro Preview 05-06"},{"id":"gemini-2.0-flash-lite","name":"Gemini 2.0 Flash Lite","attachment":true,"reasoning":false,"temperature":true,"tool_call":true,"knowledge":"2024-06","release_date":"2024-12-11","last_updated":"2024-12-11","modalities":{"input":["text","image","audio","video","pdf"],"output":["text"]},"open_weights":false,"cost":{"input":0.075,"output":0.3},"limit":{"context":1048576,"output":8192},"display_name":"Gemini 2.0 Flash Lite"},{"id":"gemini-live-2.5-flash-preview-native-audio","name":"Gemini Live 2.5 Flash Preview Native Audio","attachment":false,"reasoning":true,"temperature":false,"tool_call":true,"knowledge":"2025-01","release_date":"2025-06-17","last_updated":"2025-09-18","modalities":{"input":["text","audio","video"],"output":["text","audio"]},"open_weights":false,"cost":{"input":0.5,"output":2,"input_audio":3,"output_audio":12},"limit":{"context":131072,"output":65536},"experimental":true,"display_name":"Gemini Live 2.5 Flash Preview Native Audio"},{"id":"gemini-2.0-flash","name":"Gemini 2.0 Flash","attachment":true,"reasoning":false,"temperature":true,"tool_call":true,"knowledge":"2024-06","release_date":"2024-12-11","last_updated":"2024-12-11","modalities":{"input":["text","image","audio","video","pdf"],"output":["text"]},"open_weights":false,"cost":{"input":0.1,"output":0.4,"cache_read":0.025},"limit":{"context":1048576,"output":8192},"display_name":"Gemini 2.0 Flash"},{"id":"gemini-2.5-flash-lite","name":"Gemini 2.5 Flash Lite","attachment":true,"reasoning":true,"temperature":true,"tool_call":true,"knowledge":"2025-01","release_date":"2025-06-17","last_updated":"2025-06-17","modalities":{"input":["text","image","audio","video","pdf"],"output":["text"]},"open_weights":false,"cost":{"input":0.1,"output":0.4,"cache_read":0.025},"limit":{"context":1048576,"output":65536},"display_name":"Gemini 2.5 Flash Lite"},{"id":"gemini-2.5-pro-preview-06-05","name":"Gemini 2.5 Pro Preview 06-05","attachment":true,"reasoning":true,"temperature":true,"tool_call":true,"knowledge":"2025-01","release_date":"2025-06-05","last_updated":"2025-06-05","modalities":{"input":["text","image","audio","video","pdf"],"output":["text"]},"open_weights":false,"cost":{"input":1.25,"output":10,"cache_read":0.31},"limit":{"context":1048576,"output":65536},"display_name":"Gemini 2.5 Pro Preview 06-05"},{"id":"gemini-2.5-flash-lite-preview-06-17","name":"Gemini 2.5 Flash Lite Preview 06-17","attachment":true,"reasoning":true,"temperature":true,"tool_call":true,"knowledge":"2025-01","release_date":"2025-06-17","last_updated":"2025-06-17","modalities":{"input":["text","image","audio","video","pdf"],"output":["text"]},"open_weights":false,"cost":{"input":0.1,"output":0.4,"cache_read":0.025,"input_audio":0.3},"limit":{"context":1048576,"output":65536},"display_name":"Gemini 2.5 Flash Lite Preview 06-17"},{"id":"gemini-2.5-flash-preview-09-2025","name":"Gemini 2.5 Flash Preview 09-25","attachment":true,"reasoning":true,"temperature":true,"tool_call":true,"knowledge":"2025-01","release_date":"2025-09-25","last_updated":"2025-09-25","modalities":{"input":["text","image","audio","video","pdf"],"output":["text"]},"open_weights":false,"cost":{"input":0.15,"output":0.6,"cache_read":0.0375},"limit":{"context":1048576,"output":65536},"display_name":"Gemini 2.5 Flash Preview 09-25"},{"id":"gemini-2.5-flash-preview-04-17","name":"Gemini 2.5 Flash Preview 04-17","attachment":true,"reasoning":true,"temperature":true,"tool_call":true,"knowledge":"2025-01","release_date":"2025-04-17","last_updated":"2025-04-17","modalities":{"input":["text","image","audio","video","pdf"],"output":["text"]},"open_weights":false,"cost":{"input":0.15,"output":0.6,"cache_read":0.0375},"limit":{"context":1048576,"output":65536},"display_name":"Gemini 2.5 Flash Preview 04-17"},{"id":"gemini-2.5-pro","name":"Gemini 2.5 Pro","attachment":true,"reasoning":true,"temperature":true,"tool_call":true,"knowledge":"2025-01","release_date":"2025-03-20","last_updated":"2025-06-05","modalities":{"input":["text","image","audio","video","pdf"],"output":["text"]},"open_weights":false,"cost":{"input":1.25,"output":10,"cache_read":0.31},"limit":{"context":1048576,"output":65536},"display_name":"Gemini 2.5 Pro"},{"id":"gemini-1.5-flash","name":"Gemini 1.5 Flash","attachment":true,"reasoning":false,"temperature":true,"tool_call":true,"knowledge":"2024-04","release_date":"2024-05-14","last_updated":"2024-05-14","modalities":{"input":["text","image","audio","video"],"output":["text"]},"open_weights":false,"cost":{"input":0.075,"output":0.3,"cache_read":0.01875},"limit":{"context":1000000,"output":8192},"display_name":"Gemini 1.5 Flash"},{"id":"gemini-1.5-flash-8b","name":"Gemini 1.5 Flash-8B","attachment":true,"reasoning":false,"temperature":true,"tool_call":true,"knowledge":"2024-04","release_date":"2024-10-03","last_updated":"2024-10-03","modalities":{"input":["text","image","audio","video"],"output":["text"]},"open_weights":false,"cost":{"input":0.0375,"output":0.15,"cache_read":0.01},"limit":{"context":1000000,"output":8192},"display_name":"Gemini 1.5 Flash-8B"},{"id":"gemini-2.5-flash-lite-preview-09-2025","name":"Gemini 2.5 Flash Lite Preview 09-25","attachment":true,"reasoning":true,"temperature":true,"tool_call":true,"knowledge":"2025-01","release_date":"2025-09-25","last_updated":"2025-09-25","modalities":{"input":["text","image","audio","video","pdf"],"output":["text"]},"open_weights":false,"cost":{"input":0.1,"output":0.4,"cache_read":0.025},"limit":{"context":1048576,"output":65536},"display_name":"Gemini 2.5 Flash Lite Preview 09-25"},{"id":"gemini-1.5-pro","name":"Gemini 1.5 Pro","attachment":true,"reasoning":false,"temperature":true,"tool_call":true,"knowledge":"2024-04","release_date":"2024-02-15","last_updated":"2024-02-15","modalities":{"input":["text","image","audio","video"],"output":["text"]},"open_weights":false,"cost":{"input":1.25,"output":5,"cache_read":0.3125},"limit":{"context":1000000,"output":8192},"display_name":"Gemini 1.5 Pro"}]},"google-vertex":{"id":"google-vertex","name":"Vertex","doc":"https://cloud.google.com/vertex-ai/generative-ai/docs/models","display_name":"Vertex","models":[{"id":"gemini-2.5-flash-preview-05-20","name":"Gemini 2.5 Flash Preview 05-20","attachment":true,"reasoning":true,"temperature":true,"tool_call":true,"knowledge":"2025-01","release_date":"2025-05-20","last_updated":"2025-05-20","modalities":{"input":["text","image","audio","video","pdf"],"output":["text"]},"open_weights":false,"cost":{"input":0.15,"output":0.6,"cache_read":0.0375},"limit":{"context":1048576,"output":65536},"display_name":"Gemini 2.5 Flash Preview 05-20"},{"id":"gemini-2.5-flash","name":"Gemini 2.5 Flash","attachment":true,"reasoning":true,"temperature":true,"tool_call":true,"knowledge":"2025-01","release_date":"2025-06-17","last_updated":"2025-06-17","modalities":{"input":["text","image","audio","video","pdf"],"output":["text"]},"open_weights":false,"cost":{"input":0.3,"output":2.5,"cache_read":0.075,"cache_write":0.383},"limit":{"context":1048576,"output":65536},"display_name":"Gemini 2.5 Flash"},{"id":"gemini-2.5-pro-preview-05-06","name":"Gemini 2.5 Pro Preview 05-06","attachment":true,"reasoning":true,"temperature":true,"tool_call":true,"knowledge":"2025-01","release_date":"2025-05-06","last_updated":"2025-05-06","modalities":{"input":["text","image","audio","video","pdf"],"output":["text"]},"open_weights":false,"cost":{"input":1.25,"output":10,"cache_read":0.31},"limit":{"context":1048576,"output":65536},"display_name":"Gemini 2.5 Pro Preview 05-06"},{"id":"gemini-2.0-flash-lite","name":"Gemini 2.0 Flash Lite","attachment":true,"reasoning":false,"temperature":true,"tool_call":true,"knowledge":"2024-06","release_date":"2024-12-11","last_updated":"2024-12-11","modalities":{"input":["text","image","audio","video","pdf"],"output":["text"]},"open_weights":false,"cost":{"input":0.075,"output":0.3},"limit":{"context":1048576,"output":8192},"display_name":"Gemini 2.0 Flash Lite"},{"id":"gemini-2.0-flash","name":"Gemini 2.0 Flash","attachment":true,"reasoning":false,"temperature":true,"tool_call":true,"knowledge":"2024-06","release_date":"2024-12-11","last_updated":"2024-12-11","modalities":{"input":["text","image","audio","video","pdf"],"output":["text"]},"open_weights":false,"cost":{"input":0.1,"output":0.4,"cache_read":0.025},"limit":{"context":1048576,"output":8192},"display_name":"Gemini 2.0 Flash"},{"id":"gemini-2.5-pro-preview-06-05","name":"Gemini 2.5 Pro Preview 06-05","attachment":true,"reasoning":true,"temperature":true,"tool_call":true,"knowledge":"2025-01","release_date":"2025-06-05","last_updated":"2025-06-05","modalities":{"input":["text","image","audio","video","pdf"],"output":["text"]},"open_weights":false,"cost":{"input":1.25,"output":10,"cache_read":0.31},"limit":{"context":1048576,"output":65536},"display_name":"Gemini 2.5 Pro Preview 06-05"},{"id":"gemini-2.5-flash-lite-preview-06-17","name":"Gemini 2.5 Flash Lite Preview 06-17","attachment":true,"reasoning":true,"temperature":true,"tool_call":true,"knowledge":"2025-01","release_date":"2025-06-17","last_updated":"2025-06-17","modalities":{"input":["text","image","audio","video","pdf"],"output":["text"]},"open_weights":false,"cost":{"input":0.1,"output":0.4,"cache_read":0.025},"limit":{"context":65536,"output":65536},"display_name":"Gemini 2.5 Flash Lite Preview 06-17"},{"id":"gemini-2.5-flash-preview-04-17","name":"Gemini 2.5 Flash Preview 04-17","attachment":true,"reasoning":true,"temperature":true,"tool_call":true,"knowledge":"2025-01","release_date":"2025-04-17","last_updated":"2025-04-17","modalities":{"input":["text","image","audio","video","pdf"],"output":["text"]},"open_weights":false,"cost":{"input":0.15,"output":0.6,"cache_read":0.0375},"limit":{"context":1048576,"output":65536},"display_name":"Gemini 2.5 Flash Preview 04-17"},{"id":"gemini-2.5-pro","name":"Gemini 2.5 Pro","attachment":true,"reasoning":true,"temperature":true,"tool_call":true,"knowledge":"2025-01","release_date":"2025-03-20","last_updated":"2025-06-05","modalities":{"input":["text","image","audio","video","pdf"],"output":["text"]},"open_weights":false,"cost":{"input":1.25,"output":10,"cache_read":0.31},"limit":{"context":1048576,"output":65536},"display_name":"Gemini 2.5 Pro"}]},"cloudflare-workers-ai":{"id":"cloudflare-workers-ai","name":"Cloudflare Workers AI","doc":"https://developers.cloudflare.com/workers-ai/models/","display_name":"Cloudflare Workers AI","models":[{"id":"mistral-7b-instruct-v0.1-awq","name":"@hf/thebloke/mistral-7b-instruct-v0.1-awq","attachment":false,"reasoning":false,"temperature":true,"tool_call":true,"release_date":"2023-09-27","last_updated":"2023-11-09","modalities":{"input":["text"],"output":["text"]},"open_weights":true,"cost":{"input":0,"output":0},"limit":{"context":4096,"output":4096},"display_name":"@hf/thebloke/mistral-7b-instruct-v0.1-awq"},{"id":"aura-1","name":"@cf/deepgram/aura-1","attachment":false,"reasoning":false,"temperature":false,"tool_call":false,"release_date":"2025-08-27","last_updated":"2025-07-07","modalities":{"input":["text"],"output":["audio"]},"open_weights":true,"cost":{"input":0.015,"output":0.015},"limit":{"context":0,"output":0},"display_name":"@cf/deepgram/aura-1"},{"id":"mistral-7b-instruct-v0.2","name":"@hf/mistral/mistral-7b-instruct-v0.2","attachment":false,"reasoning":false,"temperature":true,"tool_call":true,"release_date":"2023-12-11","last_updated":"2025-07-24","modalities":{"input":["text"],"output":["text"]},"open_weights":true,"cost":{"input":0,"output":0},"limit":{"context":3072,"output":3072},"display_name":"@hf/mistral/mistral-7b-instruct-v0.2"},{"id":"tinyllama-1.1b-chat-v1.0","name":"@cf/tinyllama/tinyllama-1.1b-chat-v1.0","attachment":false,"reasoning":false,"temperature":true,"tool_call":true,"release_date":"2023-12-30","last_updated":"2024-03-17","modalities":{"input":["text"],"output":["text"]},"open_weights":true,"cost":{"input":0,"output":0},"limit":{"context":2048,"output":2048},"display_name":"@cf/tinyllama/tinyllama-1.1b-chat-v1.0"},{"id":"qwen1.5-0.5b-chat","name":"@cf/qwen/qwen1.5-0.5b-chat","attachment":false,"reasoning":false,"temperature":true,"tool_call":true,"release_date":"2024-01-31","last_updated":"2024-04-30","modalities":{"input":["text"],"output":["text"]},"open_weights":true,"cost":{"input":0,"output":0},"limit":{"context":32000,"output":32000},"display_name":"@cf/qwen/qwen1.5-0.5b-chat"},{"id":"llama-3.2-11b-vision-instruct","name":"@cf/meta/llama-3.2-11b-vision-instruct","attachment":false,"reasoning":false,"temperature":true,"tool_call":true,"release_date":"2024-09-18","last_updated":"2024-12-04","modalities":{"input":["text"],"output":["text"]},"open_weights":true,"cost":{"input":0.049,"output":0.68},"limit":{"context":128000,"output":128000},"display_name":"@cf/meta/llama-3.2-11b-vision-instruct"},{"id":"llama-2-13b-chat-awq","name":"@hf/thebloke/llama-2-13b-chat-awq","attachment":false,"reasoning":false,"temperature":true,"tool_call":true,"release_date":"2023-09-19","last_updated":"2023-11-09","modalities":{"input":["text"],"output":["text"]},"open_weights":true,"cost":{"input":0,"output":0},"limit":{"context":4096,"output":4096},"display_name":"@hf/thebloke/llama-2-13b-chat-awq"},{"id":"llama-3.1-8b-instruct-fp8","name":"@cf/meta/llama-3.1-8b-instruct-fp8","attachment":false,"reasoning":false,"temperature":true,"tool_call":true,"release_date":"2024-07-25","last_updated":"2024-07-25","modalities":{"input":["text"],"output":["text"]},"open_weights":true,"cost":{"input":0.15,"output":0.29},"limit":{"context":32000,"output":32000},"display_name":"@cf/meta/llama-3.1-8b-instruct-fp8"},{"id":"whisper","name":"@cf/openai/whisper","attachment":false,"reasoning":false,"temperature":false,"tool_call":false,"release_date":"2023-11-07","last_updated":"2024-08-12","modalities":{"input":["audio"],"output":["text"]},"open_weights":true,"cost":{"input":0.00045,"output":0.00045},"limit":{"context":0,"output":0},"display_name":"@cf/openai/whisper"},{"id":"stable-diffusion-xl-base-1.0","name":"@cf/stabilityai/stable-diffusion-xl-base-1.0","attachment":false,"reasoning":false,"temperature":false,"tool_call":false,"release_date":"2023-07-25","last_updated":"2023-10-30","modalities":{"input":["text"],"output":["image"]},"open_weights":true,"cost":{"input":0,"output":0},"limit":{"context":0,"output":0},"display_name":"@cf/stabilityai/stable-diffusion-xl-base-1.0"},{"id":"llama-2-7b-chat-fp16","name":"@cf/meta/llama-2-7b-chat-fp16","attachment":false,"reasoning":false,"temperature":true,"tool_call":true,"release_date":"2023-07-26","last_updated":"2023-07-26","modalities":{"input":["text"],"output":["text"]},"open_weights":true,"cost":{"input":0.56,"output":6.67},"limit":{"context":4096,"output":4096},"display_name":"@cf/meta/llama-2-7b-chat-fp16"},{"id":"resnet-50","name":"@cf/microsoft/resnet-50","attachment":false,"reasoning":false,"temperature":false,"tool_call":false,"release_date":"2022-03-16","last_updated":"2024-02-13","modalities":{"input":["image"],"output":["text"]},"open_weights":true,"cost":{"input":0.0000025,"output":0},"limit":{"context":0,"output":0},"display_name":"@cf/microsoft/resnet-50"},{"id":"stable-diffusion-v1-5-inpainting","name":"@cf/runwayml/stable-diffusion-v1-5-inpainting","attachment":false,"reasoning":false,"temperature":false,"tool_call":false,"release_date":"2024-02-27","last_updated":"2024-02-27","modalities":{"input":["text"],"output":["image"]},"open_weights":true,"cost":{"input":0,"output":0},"limit":{"context":0,"output":0},"display_name":"@cf/runwayml/stable-diffusion-v1-5-inpainting"},{"id":"sqlcoder-7b-2","name":"@cf/defog/sqlcoder-7b-2","attachment":false,"reasoning":false,"temperature":true,"tool_call":true,"release_date":"2024-02-05","last_updated":"2024-02-12","modalities":{"input":["text"],"output":["text"]},"open_weights":true,"cost":{"input":0,"output":0},"limit":{"context":10000,"output":10000},"display_name":"@cf/defog/sqlcoder-7b-2"},{"id":"llama-3-8b-instruct","name":"@cf/meta/llama-3-8b-instruct","attachment":false,"reasoning":false,"temperature":true,"tool_call":true,"release_date":"2024-04-17","last_updated":"2025-06-19","modalities":{"input":["text"],"output":["text"]},"open_weights":true,"cost":{"input":0.28,"output":0.83},"limit":{"context":7968,"output":7968},"display_name":"@cf/meta/llama-3-8b-instruct"},{"id":"llama-2-7b-chat-hf-lora","name":"@cf/meta-llama/llama-2-7b-chat-hf-lora","attachment":false,"reasoning":false,"temperature":true,"tool_call":true,"release_date":"2023-07-13","last_updated":"2024-04-17","modalities":{"input":["text"],"output":["text"]},"open_weights":true,"cost":{"input":0,"output":0},"limit":{"context":8192,"output":8192},"display_name":"@cf/meta-llama/llama-2-7b-chat-hf-lora"},{"id":"llama-3.1-8b-instruct","name":"@cf/meta/llama-3.1-8b-instruct","attachment":false,"reasoning":false,"temperature":true,"tool_call":true,"release_date":"2024-07-18","last_updated":"2024-09-25","modalities":{"input":["text"],"output":["text"]},"open_weights":true,"cost":{"input":0.28,"output":0.83},"limit":{"context":7968,"output":7968},"display_name":"@cf/meta/llama-3.1-8b-instruct"},{"id":"openchat-3.5-0106","name":"@cf/openchat/openchat-3.5-0106","attachment":false,"reasoning":false,"temperature":true,"tool_call":true,"release_date":"2024-01-07","last_updated":"2024-05-18","modalities":{"input":["text"],"output":["text"]},"open_weights":true,"cost":{"input":0,"output":0},"limit":{"context":8192,"output":8192},"display_name":"@cf/openchat/openchat-3.5-0106"},{"id":"openhermes-2.5-mistral-7b-awq","name":"@hf/thebloke/openhermes-2.5-mistral-7b-awq","attachment":false,"reasoning":false,"temperature":true,"tool_call":true,"release_date":"2023-11-02","last_updated":"2023-11-09","modalities":{"input":["text"],"output":["text"]},"open_weights":true,"cost":{"input":0,"output":0},"limit":{"context":4096,"output":4096},"display_name":"@hf/thebloke/openhermes-2.5-mistral-7b-awq"},{"id":"lucid-origin","name":"@cf/leonardo/lucid-origin","attachment":false,"reasoning":false,"temperature":false,"tool_call":false,"release_date":"2025-08-25","last_updated":"2025-08-05","modalities":{"input":["text"],"output":["image"]},"open_weights":false,"cost":{"input":0.007,"output":0.007},"limit":{"context":0,"output":0},"display_name":"@cf/leonardo/lucid-origin"},{"id":"bart-large-cnn","name":"@cf/facebook/bart-large-cnn","attachment":false,"reasoning":false,"temperature":false,"tool_call":false,"release_date":"2022-03-02","last_updated":"2024-02-13","modalities":{"input":["text"],"output":["text"]},"open_weights":true,"cost":{"input":0,"output":0},"limit":{"context":0,"output":0},"display_name":"@cf/facebook/bart-large-cnn"},{"id":"flux-1-schnell","name":"@cf/black-forest-labs/flux-1-schnell","attachment":false,"reasoning":false,"temperature":false,"tool_call":false,"release_date":"2024-07-31","last_updated":"2024-08-16","modalities":{"input":["text"],"output":["image"]},"open_weights":true,"cost":{"input":0.000053,"output":0.00011},"limit":{"context":2048,"output":0},"display_name":"@cf/black-forest-labs/flux-1-schnell"},{"id":"deepseek-r1-distill-qwen-32b","name":"@cf/deepseek-ai/deepseek-r1-distill-qwen-32b","attachment":false,"reasoning":true,"temperature":true,"tool_call":true,"release_date":"2025-01-20","last_updated":"2025-02-24","modalities":{"input":["text"],"output":["text"]},"open_weights":true,"cost":{"input":0.5,"output":4.88},"limit":{"context":80000,"output":80000},"display_name":"@cf/deepseek-ai/deepseek-r1-distill-qwen-32b"},{"id":"gemma-2b-it-lora","name":"@cf/google/gemma-2b-it-lora","attachment":false,"reasoning":false,"temperature":true,"tool_call":true,"release_date":"2024-04-02","last_updated":"2024-04-02","modalities":{"input":["text"],"output":["text"]},"open_weights":true,"cost":{"input":0,"output":0},"limit":{"context":8192,"output":8192},"display_name":"@cf/google/gemma-2b-it-lora"},{"id":"una-cybertron-7b-v2-bf16","name":"@cf/fblgit/una-cybertron-7b-v2-bf16","attachment":false,"reasoning":false,"temperature":true,"tool_call":true,"release_date":"2023-12-02","last_updated":"2024-03-08","modalities":{"input":["text"],"output":["text"]},"open_weights":true,"cost":{"input":0,"output":0},"limit":{"context":15000,"output":15000},"display_name":"@cf/fblgit/una-cybertron-7b-v2-bf16"},{"id":"m2m100-1.2b","name":"@cf/meta/m2m100-1.2b","attachment":false,"reasoning":false,"temperature":false,"tool_call":false,"release_date":"2022-03-02","last_updated":"2023-11-16","modalities":{"input":["text"],"output":["text"]},"open_weights":true,"cost":{"input":0.34,"output":0.34},"limit":{"context":0,"output":0},"display_name":"@cf/meta/m2m100-1.2b"},{"id":"llama-3.2-3b-instruct","name":"@cf/meta/llama-3.2-3b-instruct","attachment":false,"reasoning":false,"temperature":true,"tool_call":true,"release_date":"2024-09-18","last_updated":"2024-10-24","modalities":{"input":["text"],"output":["text"]},"open_weights":true,"cost":{"input":0.051,"output":0.34},"limit":{"context":128000,"output":128000},"display_name":"@cf/meta/llama-3.2-3b-instruct"},{"id":"qwen2.5-coder-32b-instruct","name":"@cf/qwen/qwen2.5-coder-32b-instruct","attachment":false,"reasoning":false,"temperature":true,"tool_call":true,"release_date":"2024-11-06","last_updated":"2025-01-12","modalities":{"input":["text"],"output":["text"]},"open_weights":true,"cost":{"input":0.66,"output":1},"limit":{"context":32768,"output":32768},"display_name":"@cf/qwen/qwen2.5-coder-32b-instruct"},{"id":"stable-diffusion-v1-5-img2img","name":"@cf/runwayml/stable-diffusion-v1-5-img2img","attachment":false,"reasoning":false,"temperature":false,"tool_call":false,"release_date":"2024-02-27","last_updated":"2024-02-27","modalities":{"input":["text"],"output":["image"]},"open_weights":true,"cost":{"input":0,"output":0},"limit":{"context":0,"output":0},"display_name":"@cf/runwayml/stable-diffusion-v1-5-img2img"},{"id":"gemma-7b-it-lora","name":"@cf/google/gemma-7b-it-lora","attachment":false,"reasoning":false,"temperature":true,"tool_call":true,"release_date":"2024-04-02","last_updated":"2024-04-02","modalities":{"input":["text"],"output":["text"]},"open_weights":true,"cost":{"input":0,"output":0},"limit":{"context":3500,"output":3500},"display_name":"@cf/google/gemma-7b-it-lora"},{"id":"qwen1.5-14b-chat-awq","name":"@cf/qwen/qwen1.5-14b-chat-awq","attachment":false,"reasoning":false,"temperature":true,"tool_call":true,"release_date":"2024-02-03","last_updated":"2024-04-30","modalities":{"input":["text"],"output":["text"]},"open_weights":true,"cost":{"input":0,"output":0},"limit":{"context":7500,"output":7500},"display_name":"@cf/qwen/qwen1.5-14b-chat-awq"},{"id":"qwen1.5-1.8b-chat","name":"@cf/qwen/qwen1.5-1.8b-chat","attachment":false,"reasoning":false,"temperature":true,"tool_call":true,"release_date":"2024-01-30","last_updated":"2024-04-30","modalities":{"input":["text"],"output":["text"]},"open_weights":true,"cost":{"input":0,"output":0},"limit":{"context":32000,"output":32000},"display_name":"@cf/qwen/qwen1.5-1.8b-chat"},{"id":"mistral-small-3.1-24b-instruct","name":"@cf/mistralai/mistral-small-3.1-24b-instruct","attachment":false,"reasoning":false,"temperature":true,"tool_call":true,"release_date":"2025-03-11","last_updated":"2025-07-28","modalities":{"input":["text"],"output":["text"]},"open_weights":true,"cost":{"input":0.35,"output":0.56},"limit":{"context":128000,"output":128000},"display_name":"@cf/mistralai/mistral-small-3.1-24b-instruct"},{"id":"gemma-7b-it","name":"@hf/google/gemma-7b-it","attachment":false,"reasoning":false,"temperature":true,"tool_call":true,"release_date":"2024-02-13","last_updated":"2024-08-14","modalities":{"input":["text"],"output":["text"]},"open_weights":true,"cost":{"input":0,"output":0},"limit":{"context":8192,"output":8192},"display_name":"@hf/google/gemma-7b-it"},{"id":"llamaguard-7b-awq","name":"@hf/thebloke/llamaguard-7b-awq","attachment":false,"reasoning":false,"temperature":true,"tool_call":true,"release_date":"2023-12-11","last_updated":"2023-12-11","modalities":{"input":["text"],"output":["text"]},"open_weights":true,"cost":{"input":0,"output":0},"limit":{"context":4096,"output":4096},"display_name":"@hf/thebloke/llamaguard-7b-awq"},{"id":"hermes-2-pro-mistral-7b","name":"@hf/nousresearch/hermes-2-pro-mistral-7b","attachment":false,"reasoning":false,"temperature":true,"tool_call":true,"release_date":"2024-03-11","last_updated":"2024-09-08","modalities":{"input":["text"],"output":["text"]},"open_weights":true,"cost":{"input":0,"output":0},"limit":{"context":24000,"output":24000},"display_name":"@hf/nousresearch/hermes-2-pro-mistral-7b"},{"id":"falcon-7b-instruct","name":"@cf/tiiuae/falcon-7b-instruct","attachment":false,"reasoning":false,"temperature":true,"tool_call":true,"release_date":"2023-04-25","last_updated":"2024-10-12","modalities":{"input":["text"],"output":["text"]},"open_weights":true,"cost":{"input":0,"output":0},"limit":{"context":4096,"output":4096},"display_name":"@cf/tiiuae/falcon-7b-instruct"},{"id":"llama-3.3-70b-instruct-fp8-fast","name":"@cf/meta/llama-3.3-70b-instruct-fp8-fast","attachment":false,"reasoning":false,"temperature":true,"tool_call":true,"release_date":"2024-12-06","last_updated":"2024-12-06","modalities":{"input":["text"],"output":["text"]},"open_weights":true,"cost":{"input":0.29,"output":2.25},"limit":{"context":24000,"output":24000},"display_name":"@cf/meta/llama-3.3-70b-instruct-fp8-fast"},{"id":"llama-3-8b-instruct-awq","name":"@cf/meta/llama-3-8b-instruct-awq","attachment":false,"reasoning":false,"temperature":true,"tool_call":true,"release_date":"2024-05-09","last_updated":"2024-05-09","modalities":{"input":["text"],"output":["text"]},"open_weights":true,"cost":{"input":0.12,"output":0.27},"limit":{"context":8192,"output":8192},"display_name":"@cf/meta/llama-3-8b-instruct-awq"},{"id":"phoenix-1.0","name":"@cf/leonardo/phoenix-1.0","attachment":false,"reasoning":false,"temperature":false,"tool_call":false,"release_date":"2025-08-25","last_updated":"2025-08-25","modalities":{"input":["text"],"output":["image"]},"open_weights":false,"cost":{"input":0.0058,"output":0.0058},"limit":{"context":0,"output":0},"display_name":"@cf/leonardo/phoenix-1.0"},{"id":"phi-2","name":"@cf/microsoft/phi-2","attachment":false,"reasoning":false,"temperature":true,"tool_call":true,"release_date":"2023-12-13","last_updated":"2024-04-29","modalities":{"input":["text"],"output":["text"]},"open_weights":true,"cost":{"input":0,"output":0},"limit":{"context":2048,"output":2048},"display_name":"@cf/microsoft/phi-2"},{"id":"dreamshaper-8-lcm","name":"@cf/lykon/dreamshaper-8-lcm","attachment":true,"reasoning":false,"temperature":false,"tool_call":false,"release_date":"2023-12-06","last_updated":"2023-12-07","modalities":{"input":["text"],"output":["image"]},"open_weights":true,"cost":{"input":0,"output":0},"limit":{"context":0,"output":0},"display_name":"@cf/lykon/dreamshaper-8-lcm"},{"id":"discolm-german-7b-v1-awq","name":"@cf/thebloke/discolm-german-7b-v1-awq","attachment":false,"reasoning":false,"temperature":true,"tool_call":true,"release_date":"2024-01-18","last_updated":"2024-01-24","modalities":{"input":["text"],"output":["text"]},"open_weights":true,"cost":{"input":0,"output":0},"limit":{"context":4096,"output":4096},"display_name":"@cf/thebloke/discolm-german-7b-v1-awq"},{"id":"llama-2-7b-chat-int8","name":"@cf/meta/llama-2-7b-chat-int8","attachment":false,"reasoning":false,"temperature":true,"tool_call":true,"release_date":"2023-09-25","last_updated":"2023-09-25","modalities":{"input":["text"],"output":["text"]},"open_weights":true,"limit":{"context":8192,"output":8192},"display_name":"@cf/meta/llama-2-7b-chat-int8"},{"id":"llama-3.2-1b-instruct","name":"@cf/meta/llama-3.2-1b-instruct","attachment":false,"reasoning":false,"temperature":true,"tool_call":true,"release_date":"2024-09-18","last_updated":"2024-10-24","modalities":{"input":["text"],"output":["text"]},"open_weights":true,"cost":{"input":0.027,"output":0.2},"limit":{"context":60000,"output":60000},"display_name":"@cf/meta/llama-3.2-1b-instruct"},{"id":"whisper-large-v3-turbo","name":"@cf/openai/whisper-large-v3-turbo","attachment":false,"reasoning":false,"temperature":false,"tool_call":false,"release_date":"2024-10-01","last_updated":"2024-10-04","modalities":{"input":["audio"],"output":["text"]},"open_weights":true,"cost":{"input":0.00051,"output":0.00051},"limit":{"context":0,"output":0},"display_name":"@cf/openai/whisper-large-v3-turbo"},{"id":"llama-4-scout-17b-16e-instruct","name":"@cf/meta/llama-4-scout-17b-16e-instruct","attachment":false,"reasoning":false,"temperature":true,"tool_call":true,"release_date":"2025-04-02","last_updated":"2025-05-23","modalities":{"input":["text"],"output":["text"]},"open_weights":true,"cost":{"input":0.27,"output":0.85},"limit":{"context":131000,"output":131000},"display_name":"@cf/meta/llama-4-scout-17b-16e-instruct"},{"id":"starling-lm-7b-beta","name":"@hf/nexusflow/starling-lm-7b-beta","attachment":false,"reasoning":false,"temperature":true,"tool_call":true,"release_date":"2024-03-19","last_updated":"2024-04-03","modalities":{"input":["text"],"output":["text"]},"open_weights":true,"cost":{"input":0,"output":0},"limit":{"context":4096,"output":4096},"display_name":"@hf/nexusflow/starling-lm-7b-beta"},{"id":"deepseek-coder-6.7b-base-awq","name":"@hf/thebloke/deepseek-coder-6.7b-base-awq","attachment":false,"reasoning":false,"temperature":true,"tool_call":true,"release_date":"2023-11-05","last_updated":"2023-11-09","modalities":{"input":["text"],"output":["text"]},"open_weights":true,"cost":{"input":0,"output":0},"limit":{"context":4096,"output":4096},"display_name":"@hf/thebloke/deepseek-coder-6.7b-base-awq"},{"id":"gemma-3-12b-it","name":"@cf/google/gemma-3-12b-it","attachment":false,"reasoning":false,"temperature":true,"tool_call":true,"release_date":"2025-03-01","last_updated":"2025-03-21","modalities":{"input":["text"],"output":["text"]},"open_weights":true,"cost":{"input":0.35,"output":0.56},"limit":{"context":80000,"output":80000},"display_name":"@cf/google/gemma-3-12b-it"},{"id":"llama-guard-3-8b","name":"@cf/meta/llama-guard-3-8b","attachment":false,"reasoning":false,"temperature":true,"tool_call":false,"release_date":"2024-07-22","last_updated":"2024-10-11","modalities":{"input":["text"],"output":["text"]},"open_weights":true,"cost":{"input":0.48,"output":0.03},"limit":{"context":0,"output":0},"display_name":"@cf/meta/llama-guard-3-8b"},{"id":"neural-chat-7b-v3-1-awq","name":"@hf/thebloke/neural-chat-7b-v3-1-awq","attachment":false,"reasoning":false,"temperature":true,"tool_call":true,"release_date":"2023-11-15","last_updated":"2023-11-17","modalities":{"input":["text"],"output":["text"]},"open_weights":true,"cost":{"input":0,"output":0},"limit":{"context":4096,"output":4096},"display_name":"@hf/thebloke/neural-chat-7b-v3-1-awq"},{"id":"whisper-tiny-en","name":"@cf/openai/whisper-tiny-en","attachment":false,"reasoning":false,"temperature":false,"tool_call":false,"release_date":"2022-09-26","last_updated":"2024-01-22","modalities":{"input":["audio"],"output":["text"]},"open_weights":true,"cost":{"input":0,"output":0},"limit":{"context":0,"output":0},"display_name":"@cf/openai/whisper-tiny-en"},{"id":"stable-diffusion-xl-lightning","name":"@cf/bytedance/stable-diffusion-xl-lightning","attachment":false,"reasoning":false,"temperature":false,"tool_call":false,"release_date":"2024-02-20","last_updated":"2024-04-03","modalities":{"input":["text"],"output":["image"]},"open_weights":true,"cost":{"input":0,"output":0},"limit":{"context":0,"output":0},"display_name":"@cf/bytedance/stable-diffusion-xl-lightning"},{"id":"mistral-7b-instruct-v0.1","name":"@cf/mistral/mistral-7b-instruct-v0.1","attachment":false,"reasoning":false,"temperature":true,"tool_call":true,"release_date":"2023-09-27","last_updated":"2025-07-24","modalities":{"input":["text"],"output":["text"]},"open_weights":true,"cost":{"input":0.11,"output":0.19},"limit":{"context":2824,"output":2824},"display_name":"@cf/mistral/mistral-7b-instruct-v0.1"},{"id":"llava-1.5-7b-hf","name":"@cf/llava-hf/llava-1.5-7b-hf","attachment":true,"reasoning":false,"temperature":true,"tool_call":false,"release_date":"2023-12-05","last_updated":"2025-06-06","modalities":{"input":["image","text"],"output":["text"]},"open_weights":true,"cost":{"input":0,"output":0},"limit":{"context":0,"output":0},"display_name":"@cf/llava-hf/llava-1.5-7b-hf"},{"id":"gpt-oss-20b","name":"@cf/openai/gpt-oss-20b","attachment":false,"reasoning":false,"temperature":false,"tool_call":false,"release_date":"2025-08-04","last_updated":"2025-08-14","modalities":{"input":["text"],"output":["text"]},"open_weights":true,"cost":{"input":0.2,"output":0.3},"limit":{"context":128000,"output":128000},"display_name":"@cf/openai/gpt-oss-20b"},{"id":"deepseek-math-7b-instruct","name":"@cf/deepseek-ai/deepseek-math-7b-instruct","attachment":false,"reasoning":false,"temperature":true,"tool_call":true,"release_date":"2024-02-05","last_updated":"2024-02-06","modalities":{"input":["text"],"output":["text"]},"open_weights":true,"cost":{"input":0,"output":0},"limit":{"context":4096,"output":4096},"display_name":"@cf/deepseek-ai/deepseek-math-7b-instruct"},{"id":"gpt-oss-120b","name":"@cf/openai/gpt-oss-120b","attachment":false,"reasoning":false,"temperature":false,"tool_call":false,"release_date":"2025-08-04","last_updated":"2025-08-14","modalities":{"input":["text"],"output":["text"]},"open_weights":true,"cost":{"input":0.35,"output":0.75},"limit":{"context":128000,"output":128000},"display_name":"@cf/openai/gpt-oss-120b"},{"id":"melotts","name":"@cf/myshell-ai/melotts","attachment":true,"reasoning":false,"temperature":false,"tool_call":false,"release_date":"2024-07-19","last_updated":"2024-07-19","modalities":{"input":["text"],"output":["audio"]},"open_weights":true,"cost":{"input":0.0002,"output":0},"limit":{"context":0,"output":0},"display_name":"@cf/myshell-ai/melotts"},{"id":"qwen1.5-7b-chat-awq","name":"@cf/qwen/qwen1.5-7b-chat-awq","attachment":false,"reasoning":false,"temperature":true,"tool_call":true,"release_date":"2024-02-03","last_updated":"2024-04-30","modalities":{"input":["text"],"output":["text"]},"open_weights":true,"cost":{"input":0,"output":0},"limit":{"context":20000,"output":20000},"display_name":"@cf/qwen/qwen1.5-7b-chat-awq"},{"id":"llama-3.1-8b-instruct-fast","name":"@cf/meta/llama-3.1-8b-instruct-fast","attachment":false,"reasoning":false,"temperature":true,"tool_call":true,"release_date":"2024-07-18","last_updated":"2024-09-25","modalities":{"input":["text"],"output":["text"]},"open_weights":true,"limit":{"context":128000,"output":128000},"display_name":"@cf/meta/llama-3.1-8b-instruct-fast"},{"id":"nova-3","name":"@cf/deepgram/nova-3","attachment":false,"reasoning":false,"temperature":false,"tool_call":false,"release_date":"2025-06-05","last_updated":"2025-07-08","modalities":{"input":["audio"],"output":["text"]},"open_weights":true,"cost":{"input":0.0052,"output":0.0052},"limit":{"context":0,"output":0},"display_name":"@cf/deepgram/nova-3"},{"id":"llama-3.1-70b-instruct","name":"@cf/meta/llama-3.1-70b-instruct","attachment":false,"reasoning":false,"temperature":true,"tool_call":true,"release_date":"2024-07-16","last_updated":"2024-12-15","modalities":{"input":["text"],"output":["text"]},"open_weights":true,"limit":{"context":24000,"output":24000},"display_name":"@cf/meta/llama-3.1-70b-instruct"},{"id":"qwq-32b","name":"@cf/qwen/qwq-32b","attachment":false,"reasoning":false,"temperature":true,"tool_call":true,"release_date":"2025-03-05","last_updated":"2025-03-11","modalities":{"input":["text"],"output":["text"]},"open_weights":true,"cost":{"input":0.66,"output":1},"limit":{"context":24000,"output":24000},"display_name":"@cf/qwen/qwq-32b"},{"id":"zephyr-7b-beta-awq","name":"@hf/thebloke/zephyr-7b-beta-awq","attachment":false,"reasoning":false,"temperature":true,"tool_call":true,"release_date":"2023-10-27","last_updated":"2023-11-09","modalities":{"input":["text"],"output":["text"]},"open_weights":true,"cost":{"input":0,"output":0},"limit":{"context":4096,"output":4096},"display_name":"@hf/thebloke/zephyr-7b-beta-awq"},{"id":"deepseek-coder-6.7b-instruct-awq","name":"@hf/thebloke/deepseek-coder-6.7b-instruct-awq","attachment":false,"reasoning":false,"temperature":true,"tool_call":true,"release_date":"2023-11-05","last_updated":"2023-11-13","modalities":{"input":["text"],"output":["text"]},"open_weights":true,"cost":{"input":0,"output":0},"limit":{"context":4096,"output":4096},"display_name":"@hf/thebloke/deepseek-coder-6.7b-instruct-awq"},{"id":"llama-3.1-8b-instruct-awq","name":"@cf/meta/llama-3.1-8b-instruct-awq","attachment":false,"reasoning":false,"temperature":true,"tool_call":true,"release_date":"2024-07-25","last_updated":"2024-07-25","modalities":{"input":["text"],"output":["text"]},"open_weights":true,"cost":{"input":0.12,"output":0.27},"limit":{"context":8192,"output":8192},"display_name":"@cf/meta/llama-3.1-8b-instruct-awq"},{"id":"mistral-7b-instruct-v0.2-lora","name":"@cf/mistral/mistral-7b-instruct-v0.2-lora","attachment":false,"reasoning":false,"temperature":true,"tool_call":true,"release_date":"2024-04-01","last_updated":"2024-04-01","modalities":{"input":["text"],"output":["text"]},"open_weights":true,"cost":{"input":0,"output":0},"limit":{"context":15000,"output":15000},"display_name":"@cf/mistral/mistral-7b-instruct-v0.2-lora"},{"id":"uform-gen2-qwen-500m","name":"@cf/unum/uform-gen2-qwen-500m","attachment":false,"reasoning":false,"temperature":false,"tool_call":false,"release_date":"2024-02-15","last_updated":"2024-04-24","modalities":{"input":["image","text"],"output":["text"]},"open_weights":true,"cost":{"input":0,"output":0},"limit":{"context":0,"output":0},"display_name":"@cf/unum/uform-gen2-qwen-500m"}]},"inception":{"id":"inception","api":"https://api.inceptionlabs.ai/v1/","name":"Inception","doc":"https://platform.inceptionlabs.ai/docs","display_name":"Inception","models":[{"id":"mercury-coder","name":"Mercury Coder","attachment":false,"reasoning":false,"temperature":true,"tool_call":true,"knowledge":"2023-10","release_date":"2025-02-26","last_updated":"2025-07-31","modalities":{"input":["text"],"output":["text"]},"open_weights":false,"cost":{"input":0.25,"output":1,"cache_read":0.25,"cache_write":1},"limit":{"context":128000,"output":16384},"display_name":"Mercury Coder"},{"id":"mercury","name":"Mercury","attachment":false,"reasoning":false,"temperature":true,"tool_call":true,"knowledge":"2023-10","release_date":"2025-06-26","last_updated":"2025-07-31","modalities":{"input":["text"],"output":["text"]},"open_weights":false,"cost":{"input":0.25,"output":1,"cache_read":0.25,"cache_write":1},"limit":{"context":128000,"output":16384},"display_name":"Mercury"}]},"wandb":{"id":"wandb","api":"https://api.inference.wandb.ai/v1","name":"Weights & Biases","doc":"https://weave-docs.wandb.ai/guides/integrations/inference/","display_name":"Weights & Biases","models":[{"id":"moonshotai/Kimi-K2-Instruct","name":"Kimi-K2-Instruct","attachment":false,"reasoning":false,"temperature":true,"tool_call":true,"knowledge":"2024-10","release_date":"2025-07-14","last_updated":"2025-07-14","modalities":{"input":["text"],"output":["text"]},"open_weights":true,"cost":{"input":1.35,"output":4},"limit":{"context":128000,"output":16384},"display_name":"Kimi-K2-Instruct"},{"id":"microsoft/Phi-4-mini-instruct","name":"Phi-4-mini-instruct","attachment":false,"reasoning":true,"temperature":true,"tool_call":true,"knowledge":"2023-10","release_date":"2024-12-11","last_updated":"2024-12-11","modalities":{"input":["text"],"output":["text"]},"open_weights":true,"cost":{"input":0.08,"output":0.35},"limit":{"context":128000,"output":4096},"display_name":"Phi-4-mini-instruct"},{"id":"meta-llama/Llama-3.1-8B-Instruct","name":"Meta-Llama-3.1-8B-Instruct","attachment":false,"reasoning":true,"temperature":true,"tool_call":true,"knowledge":"2023-12","release_date":"2024-07-23","last_updated":"2024-07-23","modalities":{"input":["text"],"output":["text"]},"open_weights":true,"cost":{"input":0.22,"output":0.22},"limit":{"context":128000,"output":32768},"display_name":"Meta-Llama-3.1-8B-Instruct"},{"id":"meta-llama/Llama-3.3-70B-Instruct","name":"Llama-3.3-70B-Instruct","attachment":false,"reasoning":true,"temperature":true,"tool_call":true,"knowledge":"2023-12","release_date":"2024-12-06","last_updated":"2024-12-06","modalities":{"input":["text"],"output":["text"]},"open_weights":true,"cost":{"input":0.71,"output":0.71},"limit":{"context":128000,"output":32768},"display_name":"Llama-3.3-70B-Instruct"},{"id":"meta-llama/Llama-4-Scout-17B-16E-Instruct","name":"Llama 4 Scout 17B 16E Instruct","attachment":false,"reasoning":true,"temperature":true,"tool_call":true,"knowledge":"2024-12","release_date":"2025-01-31","last_updated":"2025-01-31","modalities":{"input":["text","image"],"output":["text"]},"open_weights":true,"cost":{"input":0.17,"output":0.66},"limit":{"context":64000,"output":8192},"display_name":"Llama 4 Scout 17B 16E Instruct"},{"id":"Qwen/Qwen3-235B-A22B-Instruct-2507","name":"Qwen3 235B A22B Instruct 2507","attachment":false,"reasoning":false,"temperature":true,"tool_call":true,"knowledge":"2025-04","release_date":"2025-04-28","last_updated":"2025-07-21","modalities":{"input":["text"],"output":["text"]},"open_weights":true,"cost":{"input":0.1,"output":0.1},"limit":{"context":262144,"output":131072},"display_name":"Qwen3 235B A22B Instruct 2507"},{"id":"Qwen/Qwen3-Coder-480B-A35B-Instruct","name":"Qwen3-Coder-480B-A35B-Instruct","attachment":false,"reasoning":false,"temperature":true,"tool_call":true,"knowledge":"2025-04","release_date":"2025-07-23","last_updated":"2025-07-23","modalities":{"input":["text"],"output":["text"]},"open_weights":true,"cost":{"input":1,"output":1.5},"limit":{"context":262144,"output":66536},"display_name":"Qwen3-Coder-480B-A35B-Instruct"},{"id":"Qwen/Qwen3-235B-A22B-Thinking-2507","name":"Qwen3-235B-A22B-Thinking-2507","attachment":false,"reasoning":true,"temperature":true,"tool_call":true,"knowledge":"2025-04","release_date":"2025-07-25","last_updated":"2025-07-25","modalities":{"input":["text"],"output":["text"]},"open_weights":true,"cost":{"input":0.1,"output":0.1},"limit":{"context":262144,"output":131072},"display_name":"Qwen3-235B-A22B-Thinking-2507"},{"id":"deepseek-ai/DeepSeek-R1-0528","name":"DeepSeek-R1-0528","attachment":false,"reasoning":true,"temperature":true,"tool_call":true,"knowledge":"2025-05","release_date":"2025-05-28","last_updated":"2025-05-28","modalities":{"input":["text"],"output":["text"]},"open_weights":true,"cost":{"input":1.35,"output":5.4},"limit":{"context":161000,"output":163840},"display_name":"DeepSeek-R1-0528"},{"id":"deepseek-ai/DeepSeek-V3-0324","name":"DeepSeek-V3-0324","attachment":false,"reasoning":false,"temperature":true,"tool_call":true,"knowledge":"2024-10","release_date":"2025-03-24","last_updated":"2025-03-24","modalities":{"input":["text"],"output":["text"]},"open_weights":true,"cost":{"input":1.14,"output":2.75},"limit":{"context":161000,"output":8192},"display_name":"DeepSeek-V3-0324"}]},"openai":{"id":"openai","name":"openai","doc":"https://platform.openai.com/docs/models","display_name":"openai","models":[{"id":"gpt-4.1-nano","name":"GPT-4.1 nano","attachment":true,"reasoning":false,"temperature":true,"tool_call":true,"knowledge":"2024-04","release_date":"2025-04-14","last_updated":"2025-04-14","modalities":{"input":["text","image"],"output":["text"]},"open_weights":false,"cost":{"input":0.1,"output":0.4,"cache_read":0.03},"limit":{"context":1047576,"output":32768},"display_name":"GPT-4.1 nano"},{"id":"gpt-4","name":"GPT-4","attachment":true,"reasoning":false,"temperature":true,"tool_call":true,"knowledge":"2023-11","release_date":"2023-11-06","last_updated":"2024-04-09","modalities":{"input":["text"],"output":["text"]},"open_weights":false,"cost":{"input":30,"output":60},"limit":{"context":8192,"output":8192},"display_name":"GPT-4"},{"id":"o1-pro","name":"o1-pro","attachment":true,"reasoning":true,"temperature":false,"tool_call":true,"knowledge":"2023-09","release_date":"2025-03-19","last_updated":"2025-03-19","modalities":{"input":["text","image"],"output":["text"]},"open_weights":false,"cost":{"input":150,"output":600},"limit":{"context":200000,"output":100000},"display_name":"o1-pro"},{"id":"gpt-4o-2024-05-13","name":"GPT-4o (2024-05-13)","attachment":true,"reasoning":false,"temperature":true,"tool_call":true,"knowledge":"2023-09","release_date":"2024-05-13","last_updated":"2024-05-13","modalities":{"input":["text","image"],"output":["text"]},"open_weights":false,"cost":{"input":5,"output":15},"limit":{"context":128000,"output":4096},"display_name":"GPT-4o (2024-05-13)"},{"id":"gpt-4o-2024-08-06","name":"GPT-4o (2024-08-06)","attachment":true,"reasoning":false,"temperature":true,"tool_call":true,"knowledge":"2023-09","release_date":"2024-08-06","last_updated":"2024-08-06","modalities":{"input":["text","image"],"output":["text"]},"open_weights":false,"cost":{"input":2.5,"output":10,"cache_read":1.25},"limit":{"context":128000,"output":16384},"display_name":"GPT-4o (2024-08-06)"},{"id":"gpt-4.1-mini","name":"GPT-4.1 mini","attachment":true,"reasoning":false,"temperature":true,"tool_call":true,"knowledge":"2024-04","release_date":"2025-04-14","last_updated":"2025-04-14","modalities":{"input":["text","image"],"output":["text"]},"open_weights":false,"cost":{"input":0.4,"output":1.6,"cache_read":0.1},"limit":{"context":1047576,"output":32768},"display_name":"GPT-4.1 mini"},{"id":"o3-deep-research","name":"o3-deep-research","attachment":true,"reasoning":true,"temperature":false,"tool_call":true,"knowledge":"2024-05","release_date":"2024-06-26","last_updated":"2024-06-26","modalities":{"input":["text","image"],"output":["text"]},"open_weights":false,"cost":{"input":10,"output":40,"cache_read":2.5},"limit":{"context":200000,"output":100000},"display_name":"o3-deep-research"},{"id":"gpt-3.5-turbo","name":"GPT-3.5-turbo","attachment":false,"reasoning":false,"temperature":true,"tool_call":false,"knowledge":"2021-09-01","release_date":"2023-03-01","last_updated":"2023-11-06","modalities":{"input":["text"],"output":["text"]},"open_weights":false,"cost":{"input":0.5,"output":1.5,"cache_read":1.25},"limit":{"context":16385,"output":4096},"display_name":"GPT-3.5-turbo"},{"id":"gpt-4-turbo","name":"GPT-4 Turbo","attachment":true,"reasoning":false,"temperature":true,"tool_call":true,"knowledge":"2023-12","release_date":"2023-11-06","last_updated":"2024-04-09","modalities":{"input":["text","image"],"output":["text"]},"open_weights":false,"cost":{"input":10,"output":30},"limit":{"context":128000,"output":4096},"display_name":"GPT-4 Turbo"},{"id":"o1-preview","name":"o1-preview","attachment":false,"reasoning":true,"temperature":true,"tool_call":false,"knowledge":"2023-09","release_date":"2024-09-12","last_updated":"2024-09-12","modalities":{"input":["text"],"output":["text"]},"open_weights":false,"cost":{"input":15,"output":60,"cache_read":7.5},"limit":{"context":128000,"output":32768},"display_name":"o1-preview"},{"id":"o3-mini","name":"o3-mini","attachment":false,"reasoning":true,"temperature":false,"tool_call":true,"knowledge":"2024-05","release_date":"2024-12-20","last_updated":"2025-01-29","modalities":{"input":["text"],"output":["text"]},"open_weights":false,"cost":{"input":1.1,"output":4.4,"cache_read":0.55},"limit":{"context":200000,"output":100000},"display_name":"o3-mini"},{"id":"codex-mini-latest","name":"Codex Mini","attachment":true,"reasoning":true,"temperature":false,"tool_call":true,"knowledge":"2024-04","release_date":"2025-05-16","last_updated":"2025-05-16","modalities":{"input":["text"],"output":["text"]},"open_weights":false,"cost":{"input":1.5,"output":6,"cache_read":0.375},"limit":{"context":200000,"output":100000},"display_name":"Codex Mini"},{"id":"gpt-5-nano","name":"gpt-5-nano","attachment":true,"reasoning":true,"temperature":false,"tool_call":true,"knowledge":"2024-05-30","release_date":"2025-08-07","last_updated":"2025-08-07","modalities":{"input":["text","image"],"output":["text"]},"open_weights":false,"cost":{"input":0.05,"output":0.4,"cache_read":0.01},"limit":{"context":400000,"output":128000},"display_name":"gpt-5-nano","type":"chat","context_length":272000,"reasoning_effort":"medium"},{"id":"gpt-5-codex","name":"GPT-5-Codex","attachment":false,"reasoning":true,"temperature":false,"tool_call":true,"knowledge":"2024-09-30","release_date":"2025-09-15","last_updated":"2025-09-15","modalities":{"input":["text","image"],"output":["text"]},"open_weights":false,"limit":{"context":400000,"output":128000},"display_name":"GPT-5-Codex"},{"id":"gpt-4o","name":"GPT-4o","attachment":true,"reasoning":false,"temperature":true,"tool_call":true,"knowledge":"2023-09","release_date":"2024-05-13","last_updated":"2024-08-06","modalities":{"input":["text","image"],"output":["text"]},"open_weights":false,"cost":{"input":2.5,"output":10,"cache_read":1.25},"limit":{"context":128000,"output":16384},"display_name":"GPT-4o"},{"id":"gpt-4.1","name":"GPT-4.1","attachment":true,"reasoning":false,"temperature":true,"tool_call":true,"knowledge":"2024-04","release_date":"2025-04-14","last_updated":"2025-04-14","modalities":{"input":["text","image"],"output":["text"]},"open_weights":false,"cost":{"input":2,"output":8,"cache_read":0.5},"limit":{"context":1047576,"output":32768},"display_name":"GPT-4.1"},{"id":"o4-mini","name":"o4-mini","attachment":true,"reasoning":true,"temperature":false,"tool_call":true,"knowledge":"2024-05","release_date":"2025-04-16","last_updated":"2025-04-16","modalities":{"input":["text","image"],"output":["text"]},"open_weights":false,"cost":{"input":1.1,"output":4.4,"cache_read":0.28},"limit":{"context":200000,"output":100000},"display_name":"o4-mini"},{"id":"o1","name":"o1","attachment":true,"reasoning":true,"temperature":false,"tool_call":true,"knowledge":"2023-09","release_date":"2024-12-05","last_updated":"2024-12-05","modalities":{"input":["text","image"],"output":["text"]},"open_weights":false,"cost":{"input":15,"output":60,"cache_read":7.5},"limit":{"context":200000,"output":100000},"display_name":"o1"},{"id":"gpt-5-mini","name":"gpt-5-mini","attachment":true,"reasoning":true,"temperature":false,"tool_call":true,"knowledge":"2024-05-30","release_date":"2025-08-07","last_updated":"2025-08-07","modalities":{"input":["text","image"],"output":["text"]},"open_weights":false,"cost":{"input":0.25,"output":2,"cache_read":0.03},"limit":{"context":400000,"output":128000},"display_name":"gpt-5-mini","type":"chat","context_length":272000,"reasoning_effort":"medium"},{"id":"o1-mini","name":"o1-mini","attachment":false,"reasoning":true,"temperature":false,"tool_call":false,"knowledge":"2023-09","release_date":"2024-09-12","last_updated":"2024-09-12","modalities":{"input":["text"],"output":["text"]},"open_weights":false,"cost":{"input":1.1,"output":4.4,"cache_read":0.55},"limit":{"context":128000,"output":65536},"display_name":"o1-mini"},{"id":"o3-pro","name":"o3-pro","attachment":true,"reasoning":true,"temperature":false,"tool_call":true,"knowledge":"2024-05","release_date":"2025-06-10","last_updated":"2025-06-10","modalities":{"input":["text","image"],"output":["text"]},"open_weights":false,"cost":{"input":20,"output":80},"limit":{"context":200000,"output":100000},"display_name":"o3-pro"},{"id":"gpt-4o-2024-11-20","name":"GPT-4o (2024-11-20)","attachment":true,"reasoning":false,"temperature":true,"tool_call":true,"knowledge":"2023-09","release_date":"2024-11-20","last_updated":"2024-11-20","modalities":{"input":["text","image"],"output":["text"]},"open_weights":false,"cost":{"input":2.5,"output":10,"cache_read":1.25},"limit":{"context":128000,"output":16384},"display_name":"GPT-4o (2024-11-20)"},{"id":"o3","name":"o3","attachment":true,"reasoning":true,"temperature":false,"tool_call":true,"knowledge":"2024-05","release_date":"2025-04-16","last_updated":"2025-04-16","modalities":{"input":["text","image"],"output":["text"]},"open_weights":false,"cost":{"input":2,"output":8,"cache_read":0.5},"limit":{"context":200000,"output":100000},"display_name":"o3"},{"id":"o4-mini-deep-research","name":"o4-mini-deep-research","attachment":true,"reasoning":true,"temperature":false,"tool_call":true,"knowledge":"2024-05","release_date":"2024-06-26","last_updated":"2024-06-26","modalities":{"input":["text","image"],"output":["text"]},"open_weights":false,"cost":{"input":2,"output":8,"cache_read":0.5},"limit":{"context":200000,"output":100000},"display_name":"o4-mini-deep-research"},{"id":"gpt-5-chat-latest","name":"gpt-5-chat-latest","attachment":true,"reasoning":true,"temperature":true,"tool_call":false,"knowledge":"2024-09-30","release_date":"2025-08-07","last_updated":"2025-08-07","modalities":{"input":["text","image"],"output":["text"]},"open_weights":false,"cost":{"input":1.25,"output":10},"limit":{"context":400000,"output":128000},"display_name":"gpt-5-chat-latest","type":"chat","context_length":272000,"max_output_tokens":16384,"reasoning_effort":"medium"},{"id":"gpt-4o-mini","name":"GPT-4o mini","attachment":true,"reasoning":false,"temperature":true,"tool_call":true,"knowledge":"2023-09","release_date":"2024-07-18","last_updated":"2024-07-18","modalities":{"input":["text","image"],"output":["text"]},"open_weights":false,"cost":{"input":0.15,"output":0.6,"cache_read":0.08},"limit":{"context":128000,"output":16384},"display_name":"GPT-4o mini"},{"id":"gpt-5","name":"gpt-5","attachment":true,"reasoning":true,"temperature":false,"tool_call":true,"knowledge":"2024-09-30","release_date":"2025-08-07","last_updated":"2025-08-07","modalities":{"input":["text","image"],"output":["text"]},"open_weights":false,"cost":{"input":1.25,"output":10,"cache_read":0.13},"limit":{"context":400000,"output":128000},"display_name":"gpt-5","type":"chat","context_length":272000,"reasoning_effort":"medium"},{"id":"gpt-5-chat","type":"chat","context_length":272000,"max_output_tokens":16384,"reasoning_effort":"medium","name":"gpt-5-chat","display_name":"gpt-5-chat"}]},"zhipuai-coding-plan":{"id":"zhipuai-coding-plan","api":"https://open.bigmodel.cn/api/coding/paas/v4","name":"Zhipu AI Coding Plan","doc":"https://docs.bigmodel.cn/cn/coding-plan/overview","display_name":"Zhipu AI Coding Plan","models":[{"id":"glm-4.6","name":"GLM-4.6","attachment":false,"reasoning":true,"temperature":true,"tool_call":true,"knowledge":"2025-04","release_date":"2025-09-30","last_updated":"2025-09-30","modalities":{"input":["text"],"output":["text"]},"open_weights":true,"cost":{"input":0,"output":0,"cache_read":0,"cache_write":0},"limit":{"context":204800,"output":131072},"display_name":"GLM-4.6"},{"id":"glm-4.5v","name":"GLM 4.5V","attachment":true,"reasoning":true,"temperature":true,"tool_call":true,"knowledge":"2025-04","release_date":"2025-08-11","last_updated":"2025-08-11","modalities":{"input":["text","image","video"],"output":["text"]},"open_weights":true,"cost":{"input":0,"output":0},"limit":{"context":64000,"output":16384},"display_name":"GLM 4.5V"},{"id":"glm-4.5-air","name":"GLM-4.5-Air","attachment":false,"reasoning":true,"temperature":true,"tool_call":true,"knowledge":"2025-04","release_date":"2025-07-28","last_updated":"2025-07-28","modalities":{"input":["text"],"output":["text"]},"open_weights":true,"cost":{"input":0,"output":0,"cache_read":0,"cache_write":0},"limit":{"context":131072,"output":98304},"display_name":"GLM-4.5-Air"},{"id":"glm-4.5","name":"GLM-4.5","attachment":false,"reasoning":true,"temperature":true,"tool_call":true,"knowledge":"2025-04","release_date":"2025-07-28","last_updated":"2025-07-28","modalities":{"input":["text"],"output":["text"]},"open_weights":true,"cost":{"input":0,"output":0,"cache_read":0,"cache_write":0},"limit":{"context":131072,"output":98304},"display_name":"GLM-4.5"},{"id":"glm-4.5-flash","name":"GLM-4.5-Flash","attachment":false,"reasoning":true,"temperature":true,"tool_call":true,"knowledge":"2025-04","release_date":"2025-07-28","last_updated":"2025-07-28","modalities":{"input":["text"],"output":["text"]},"open_weights":true,"cost":{"input":0,"output":0,"cache_read":0,"cache_write":0},"limit":{"context":131072,"output":98304},"display_name":"GLM-4.5-Flash"}]},"perplexity":{"id":"perplexity","name":"Perplexity","doc":"https://docs.perplexity.ai","display_name":"Perplexity","models":[{"id":"sonar-reasoning","name":"Sonar Reasoning","attachment":false,"reasoning":true,"temperature":true,"tool_call":false,"knowledge":"2025-09-01","release_date":"2024-01-01","last_updated":"2025-09-01","modalities":{"input":["text"],"output":["text"]},"open_weights":false,"cost":{"input":1,"output":5},"limit":{"context":128000,"output":4096},"display_name":"Sonar Reasoning"},{"id":"sonar","name":"Sonar","attachment":false,"reasoning":false,"temperature":true,"tool_call":false,"knowledge":"2025-09-01","release_date":"2024-01-01","last_updated":"2025-09-01","modalities":{"input":["text"],"output":["text"]},"open_weights":false,"cost":{"input":1,"output":1},"limit":{"context":128000,"output":4096},"display_name":"Sonar"},{"id":"sonar-pro","name":"Sonar Pro","attachment":true,"reasoning":false,"temperature":true,"tool_call":false,"knowledge":"2025-09-01","release_date":"2024-01-01","last_updated":"2025-09-01","modalities":{"input":["text","image"],"output":["text"]},"open_weights":false,"cost":{"input":3,"output":15},"limit":{"context":200000,"output":8192},"display_name":"Sonar Pro"},{"id":"sonar-reasoning-pro","name":"Sonar Reasoning Pro","attachment":true,"reasoning":true,"temperature":true,"tool_call":false,"knowledge":"2025-09-01","release_date":"2024-01-01","last_updated":"2025-09-01","modalities":{"input":["text","image"],"output":["text"]},"open_weights":false,"cost":{"input":2,"output":8},"limit":{"context":128000,"output":4096},"display_name":"Sonar Reasoning Pro"}]},"openrouter":{"id":"openrouter","api":"https://openrouter.ai/api/v1","name":"openrouter","doc":"https://openrouter.ai/models","display_name":"openrouter","models":[{"id":"moonshotai/kimi-k2","name":"Kimi K2","attachment":false,"reasoning":false,"temperature":true,"tool_call":true,"knowledge":"2024-10","release_date":"2025-07-11","last_updated":"2025-07-11","modalities":{"input":["text"],"output":["text"]},"open_weights":true,"cost":{"input":0.55,"output":2.2},"limit":{"context":131072,"output":32768},"display_name":"Kimi K2"},{"id":"moonshotai/kimi-k2-0905","name":"Kimi K2 Instruct 0905","attachment":false,"reasoning":false,"temperature":true,"tool_call":true,"knowledge":"2024-10","release_date":"2025-09-05","last_updated":"2025-09-05","modalities":{"input":["text"],"output":["text"]},"open_weights":true,"cost":{"input":0.6,"output":2.5},"limit":{"context":262144,"output":16384},"display_name":"Kimi K2 Instruct 0905"},{"id":"moonshotai/kimi-dev-72b:free","name":"Kimi Dev 72b (free)","attachment":false,"reasoning":false,"temperature":true,"tool_call":true,"knowledge":"2025-06","release_date":"2025-06-16","last_updated":"2025-06-16","modalities":{"input":["text"],"output":["text"]},"open_weights":true,"cost":{"input":0,"output":0},"limit":{"context":131072,"output":131072},"display_name":"Kimi Dev 72b (free)"},{"id":"moonshotai/kimi-k2:free","name":"Kimi K2 (free)","attachment":false,"reasoning":false,"temperature":true,"tool_call":true,"knowledge":"2025-04","release_date":"2025-07-11","last_updated":"2025-07-11","modalities":{"input":["text"],"output":["text"]},"open_weights":true,"cost":{"input":0,"output":0},"limit":{"context":32800,"output":32800},"display_name":"Kimi K2 (free)"},{"id":"thudm/glm-z1-32b:free","name":"GLM Z1 32B (free)","attachment":false,"reasoning":true,"temperature":true,"tool_call":true,"knowledge":"2025-04","release_date":"2025-04-17","last_updated":"2025-04-17","modalities":{"input":["text"],"output":["text"]},"open_weights":true,"cost":{"input":0,"output":0},"limit":{"context":32768,"output":32768},"display_name":"GLM Z1 32B (free)"},{"id":"nousresearch/hermes-4-70b","name":"Hermes 4 70B","attachment":false,"reasoning":true,"temperature":true,"tool_call":true,"knowledge":"2023-12","release_date":"2025-08-25","last_updated":"2025-08-25","modalities":{"input":["text"],"output":["text"]},"open_weights":true,"cost":{"input":0.13,"output":0.4},"limit":{"context":131072,"output":131072},"display_name":"Hermes 4 70B"},{"id":"nousresearch/hermes-4-405b","name":"Hermes 4 405B","attachment":false,"reasoning":true,"temperature":true,"tool_call":true,"knowledge":"2023-12","release_date":"2025-08-25","last_updated":"2025-08-25","modalities":{"input":["text"],"output":["text"]},"open_weights":true,"cost":{"input":1,"output":3},"limit":{"context":131072,"output":131072},"display_name":"Hermes 4 405B"},{"id":"nousresearch/deephermes-3-llama-3-8b-preview","name":"DeepHermes 3 Llama 3 8B Preview","attachment":false,"reasoning":true,"temperature":true,"tool_call":true,"knowledge":"2024-04","release_date":"2025-02-28","last_updated":"2025-02-28","modalities":{"input":["text"],"output":["text"]},"open_weights":true,"cost":{"input":0,"output":0},"limit":{"context":131072,"output":8192},"display_name":"DeepHermes 3 Llama 3 8B Preview"},{"id":"x-ai/grok-4","name":"Grok 4","attachment":false,"reasoning":true,"temperature":true,"tool_call":true,"knowledge":"2025-07","release_date":"2025-07-09","last_updated":"2025-07-09","modalities":{"input":["text"],"output":["text"]},"open_weights":false,"cost":{"input":3,"output":15,"cache_read":0.75,"cache_write":15},"limit":{"context":256000,"output":64000},"display_name":"Grok 4"},{"id":"x-ai/grok-code-fast-1","name":"Grok Code Fast 1","attachment":false,"reasoning":true,"temperature":true,"tool_call":true,"knowledge":"2025-08","release_date":"2025-08-26","last_updated":"2025-08-26","modalities":{"input":["text"],"output":["text"]},"open_weights":false,"cost":{"input":0.2,"output":1.5,"cache_read":0.02},"limit":{"context":256000,"output":10000},"display_name":"Grok Code Fast 1"},{"id":"x-ai/grok-4-fast:free","name":"Grok 4 Fast (free)","attachment":false,"reasoning":true,"temperature":true,"tool_call":true,"knowledge":"2024-11","release_date":"2025-08-19","last_updated":"2025-08-19","modalities":{"input":["text","image"],"output":["text"]},"open_weights":false,"cost":{"input":0,"output":0,"cache_read":0,"cache_write":0},"limit":{"context":2000000,"output":2000000},"display_name":"Grok 4 Fast (free)"},{"id":"x-ai/grok-3","name":"Grok 3","attachment":false,"reasoning":false,"temperature":true,"tool_call":true,"knowledge":"2024-11","release_date":"2025-02-17","last_updated":"2025-02-17","modalities":{"input":["text"],"output":["text"]},"open_weights":false,"cost":{"input":3,"output":15,"cache_read":0.75,"cache_write":15},"limit":{"context":131072,"output":8192},"display_name":"Grok 3"},{"id":"x-ai/grok-4-fast","name":"Grok 4 Fast","attachment":false,"reasoning":true,"temperature":true,"tool_call":true,"knowledge":"2024-11","release_date":"2025-08-19","last_updated":"2025-08-19","modalities":{"input":["text","image"],"output":["text"]},"open_weights":false,"cost":{"input":0.2,"output":0.5,"cache_read":0.05,"cache_write":0.05},"limit":{"context":2000000,"output":30000},"display_name":"Grok 4 Fast"},{"id":"x-ai/grok-3-beta","name":"Grok 3 Beta","attachment":false,"reasoning":false,"temperature":true,"tool_call":true,"knowledge":"2024-11","release_date":"2025-02-17","last_updated":"2025-02-17","modalities":{"input":["text"],"output":["text"]},"open_weights":false,"cost":{"input":3,"output":15,"cache_read":0.75,"cache_write":15},"limit":{"context":131072,"output":8192},"display_name":"Grok 3 Beta"},{"id":"x-ai/grok-3-mini-beta","name":"Grok 3 Mini Beta","attachment":false,"reasoning":true,"temperature":true,"tool_call":true,"knowledge":"2024-11","release_date":"2025-02-17","last_updated":"2025-02-17","modalities":{"input":["text"],"output":["text"]},"open_weights":false,"cost":{"input":0.3,"output":0.5,"cache_read":0.075,"cache_write":0.5},"limit":{"context":131072,"output":8192},"display_name":"Grok 3 Mini Beta"},{"id":"x-ai/grok-3-mini","name":"Grok 3 Mini","attachment":false,"reasoning":true,"temperature":true,"tool_call":true,"knowledge":"2024-11","release_date":"2025-02-17","last_updated":"2025-02-17","modalities":{"input":["text"],"output":["text"]},"open_weights":false,"cost":{"input":0.3,"output":0.5,"cache_read":0.075,"cache_write":0.5},"limit":{"context":131072,"output":8192},"display_name":"Grok 3 Mini"},{"id":"cognitivecomputations/dolphin3.0-mistral-24b","name":"Dolphin3.0 Mistral 24B","attachment":false,"reasoning":false,"temperature":true,"tool_call":true,"knowledge":"2024-10","release_date":"2025-02-13","last_updated":"2025-02-13","modalities":{"input":["text"],"output":["text"]},"open_weights":true,"cost":{"input":0,"output":0},"limit":{"context":32768,"output":8192},"display_name":"Dolphin3.0 Mistral 24B"},{"id":"cognitivecomputations/dolphin3.0-r1-mistral-24b","name":"Dolphin3.0 R1 Mistral 24B","attachment":false,"reasoning":true,"temperature":true,"tool_call":true,"knowledge":"2024-10","release_date":"2025-02-13","last_updated":"2025-02-13","modalities":{"input":["text"],"output":["text"]},"open_weights":true,"cost":{"input":0,"output":0},"limit":{"context":32768,"output":8192},"display_name":"Dolphin3.0 R1 Mistral 24B"},{"id":"deepseek/deepseek-chat-v3.1","name":"DeepSeek-V3.1","attachment":false,"reasoning":true,"temperature":true,"tool_call":true,"knowledge":"2025-07","release_date":"2025-08-21","last_updated":"2025-08-21","modalities":{"input":["text"],"output":["text"]},"open_weights":true,"cost":{"input":0.2,"output":0.8},"limit":{"context":163840,"output":163840},"display_name":"DeepSeek-V3.1"},{"id":"deepseek/deepseek-r1:free","name":"R1 (free)","attachment":false,"reasoning":true,"temperature":true,"tool_call":true,"knowledge":"2025-01","release_date":"2025-01-20","last_updated":"2025-01-20","modalities":{"input":["text"],"output":["text"]},"open_weights":true,"cost":{"input":0,"output":0},"limit":{"context":163840,"output":163840},"display_name":"R1 (free)"},{"id":"deepseek/deepseek-v3-base:free","name":"DeepSeek V3 Base (free)","attachment":false,"reasoning":false,"temperature":true,"tool_call":false,"knowledge":"2025-03","release_date":"2025-03-29","last_updated":"2025-03-29","modalities":{"input":["text"],"output":["text"]},"open_weights":true,"cost":{"input":0,"output":0},"limit":{"context":163840,"output":163840},"display_name":"DeepSeek V3 Base (free)"},{"id":"deepseek/deepseek-v3.1-terminus","name":"DeepSeek V3.1 Terminus","attachment":false,"reasoning":true,"temperature":true,"tool_call":true,"knowledge":"2025-07","release_date":"2025-09-22","last_updated":"2025-09-22","modalities":{"input":["text"],"output":["text"]},"open_weights":true,"cost":{"input":0.27,"output":1},"limit":{"context":131072,"output":65536},"display_name":"DeepSeek V3.1 Terminus"},{"id":"deepseek/deepseek-r1-0528-qwen3-8b:free","name":"Deepseek R1 0528 Qwen3 8B (free)","attachment":false,"reasoning":true,"temperature":true,"tool_call":true,"knowledge":"2025-05","release_date":"2025-05-29","last_updated":"2025-05-29","modalities":{"input":["text"],"output":["text"]},"open_weights":true,"cost":{"input":0,"output":0},"limit":{"context":131072,"output":131072},"display_name":"Deepseek R1 0528 Qwen3 8B (free)"},{"id":"deepseek/deepseek-chat-v3-0324","name":"DeepSeek V3 0324","attachment":false,"reasoning":false,"temperature":true,"tool_call":false,"knowledge":"2024-10","release_date":"2025-03-24","last_updated":"2025-03-24","modalities":{"input":["text"],"output":["text"]},"open_weights":true,"cost":{"input":0,"output":0},"limit":{"context":16384,"output":8192},"display_name":"DeepSeek V3 0324"},{"id":"deepseek/deepseek-r1-0528:free","name":"R1 0528 (free)","attachment":false,"reasoning":true,"temperature":true,"tool_call":true,"knowledge":"2025-05","release_date":"2025-05-28","last_updated":"2025-05-28","modalities":{"input":["text"],"output":["text"]},"open_weights":true,"cost":{"input":0,"output":0},"limit":{"context":163840,"output":163840},"display_name":"R1 0528 (free)"},{"id":"deepseek/deepseek-r1-distill-llama-70b","name":"DeepSeek R1 Distill Llama 70B","attachment":false,"reasoning":true,"temperature":true,"tool_call":false,"knowledge":"2024-10","release_date":"2025-01-23","last_updated":"2025-01-23","modalities":{"input":["text"],"output":["text"]},"open_weights":true,"cost":{"input":0,"output":0},"limit":{"context":8192,"output":8192},"display_name":"DeepSeek R1 Distill Llama 70B"},{"id":"deepseek/deepseek-r1-distill-qwen-14b","name":"DeepSeek R1 Distill Qwen 14B","attachment":false,"reasoning":true,"temperature":true,"tool_call":false,"knowledge":"2024-10","release_date":"2025-01-29","last_updated":"2025-01-29","modalities":{"input":["text"],"output":["text"]},"open_weights":true,"cost":{"input":0,"output":0},"limit":{"context":64000,"output":8192},"display_name":"DeepSeek R1 Distill Qwen 14B"},{"id":"featherless/qwerky-72b","name":"Qwerky 72B","attachment":false,"reasoning":false,"temperature":true,"tool_call":false,"knowledge":"2024-10","release_date":"2025-03-20","last_updated":"2025-03-20","modalities":{"input":["text"],"output":["text"]},"open_weights":true,"cost":{"input":0,"output":0},"limit":{"context":32768,"output":8192},"display_name":"Qwerky 72B"},{"id":"tngtech/deepseek-r1t2-chimera:free","name":"DeepSeek R1T2 Chimera (free)","attachment":false,"reasoning":true,"temperature":true,"tool_call":false,"knowledge":"2025-07","release_date":"2025-07-08","last_updated":"2025-07-08","modalities":{"input":["text"],"output":["text"]},"open_weights":true,"cost":{"input":0,"output":0},"limit":{"context":163840,"output":163840},"display_name":"DeepSeek R1T2 Chimera (free)"},{"id":"google/gemini-2.0-flash-001","name":"Gemini 2.0 Flash","attachment":true,"reasoning":false,"temperature":true,"tool_call":true,"knowledge":"2024-06","release_date":"2024-12-11","last_updated":"2024-12-11","modalities":{"input":["text","image","audio","video","pdf"],"output":["text"]},"open_weights":false,"cost":{"input":0.1,"output":0.4,"cache_read":0.025},"limit":{"context":1048576,"output":8192},"display_name":"Gemini 2.0 Flash"},{"id":"google/gemma-2-9b-it:free","name":"Gemma 2 9B (free)","attachment":false,"reasoning":false,"temperature":true,"tool_call":true,"knowledge":"2024-06","release_date":"2024-06-28","last_updated":"2024-06-28","modalities":{"input":["text"],"output":["text"]},"open_weights":true,"cost":{"input":0,"output":0},"limit":{"context":8192,"output":8192},"display_name":"Gemma 2 9B (free)"},{"id":"google/gemini-2.5-flash","name":"Gemini 2.5 Flash","attachment":true,"reasoning":true,"temperature":true,"tool_call":true,"knowledge":"2025-01","release_date":"2025-07-17","last_updated":"2025-07-17","modalities":{"input":["text","image","audio","video","pdf"],"output":["text"]},"open_weights":false,"cost":{"input":0.3,"output":2.5,"cache_read":0.0375},"limit":{"context":1048576,"output":65536},"display_name":"Gemini 2.5 Flash"},{"id":"google/gemini-2.5-pro-preview-05-06","name":"Gemini 2.5 Pro Preview 05-06","attachment":true,"reasoning":true,"temperature":true,"tool_call":true,"knowledge":"2025-01","release_date":"2025-05-06","last_updated":"2025-05-06","modalities":{"input":["text","image","audio","video","pdf"],"output":["text"]},"open_weights":false,"cost":{"input":1.25,"output":10,"cache_read":0.31},"limit":{"context":1048576,"output":65536},"display_name":"Gemini 2.5 Pro Preview 05-06"},{"id":"google/gemma-3n-e4b-it","name":"Gemma 3n E4B IT","attachment":true,"reasoning":false,"temperature":true,"tool_call":false,"knowledge":"2024-10","release_date":"2025-05-20","last_updated":"2025-05-20","modalities":{"input":["text","image","audio"],"output":["text"]},"open_weights":true,"cost":{"input":0,"output":0},"limit":{"context":8192,"output":8192},"display_name":"Gemma 3n E4B IT"},{"id":"google/gemini-2.5-pro-preview-06-05","name":"Gemini 2.5 Pro Preview 06-05","attachment":true,"reasoning":true,"temperature":true,"tool_call":true,"knowledge":"2025-01","release_date":"2025-06-05","last_updated":"2025-06-05","modalities":{"input":["text","image","audio","video","pdf"],"output":["text"]},"open_weights":false,"cost":{"input":1.25,"output":10,"cache_read":0.31},"limit":{"context":1048576,"output":65536},"display_name":"Gemini 2.5 Pro Preview 06-05"},{"id":"google/gemini-2.5-pro","name":"Gemini 2.5 Pro","attachment":true,"reasoning":true,"temperature":true,"tool_call":true,"knowledge":"2025-01","release_date":"2025-03-20","last_updated":"2025-06-05","modalities":{"input":["text","image","audio","video","pdf"],"output":["text"]},"open_weights":false,"cost":{"input":1.25,"output":10,"cache_read":0.31},"limit":{"context":1048576,"output":65536},"display_name":"Gemini 2.5 Pro"},{"id":"google/gemma-3-12b-it","name":"Gemma 3 12B IT","attachment":true,"reasoning":false,"temperature":true,"tool_call":true,"knowledge":"2024-10","release_date":"2025-03-13","last_updated":"2025-03-13","modalities":{"input":["text","image"],"output":["text"]},"open_weights":true,"cost":{"input":0,"output":0},"limit":{"context":96000,"output":8192},"display_name":"Gemma 3 12B IT"},{"id":"google/gemma-3n-e4b-it:free","name":"Gemma 3n 4B (free)","attachment":true,"reasoning":false,"temperature":true,"tool_call":true,"knowledge":"2025-05","release_date":"2025-05-20","last_updated":"2025-05-20","modalities":{"input":["text","image","audio"],"output":["text"]},"open_weights":true,"cost":{"input":0,"output":0},"limit":{"context":8192,"output":8192},"display_name":"Gemma 3n 4B (free)"},{"id":"google/gemini-2.0-flash-exp:free","name":"Gemini 2.0 Flash Experimental (free)","attachment":true,"reasoning":false,"temperature":true,"tool_call":true,"knowledge":"2024-12","release_date":"2024-12-11","last_updated":"2024-12-11","modalities":{"input":["text","image"],"output":["text"]},"open_weights":false,"cost":{"input":0,"output":0},"limit":{"context":1048576,"output":1048576},"display_name":"Gemini 2.0 Flash Experimental (free)"},{"id":"google/gemma-3-27b-it","name":"Gemma 3 27B IT","attachment":true,"reasoning":false,"temperature":true,"tool_call":true,"knowledge":"2024-10","release_date":"2025-03-12","last_updated":"2025-03-12","modalities":{"input":["text","image"],"output":["text"]},"open_weights":true,"cost":{"input":0,"output":0},"limit":{"context":96000,"output":8192},"display_name":"Gemma 3 27B IT"},{"id":"microsoft/mai-ds-r1:free","name":"MAI DS R1 (free)","attachment":false,"reasoning":true,"temperature":true,"tool_call":true,"knowledge":"2025-04","release_date":"2025-04-21","last_updated":"2025-04-21","modalities":{"input":["text"],"output":["text"]},"open_weights":true,"cost":{"input":0,"output":0},"limit":{"context":163840,"output":163840},"display_name":"MAI DS R1 (free)"},{"id":"openai/gpt-4.1-mini","name":"GPT-4.1 Mini","attachment":true,"reasoning":false,"temperature":true,"tool_call":true,"knowledge":"2024-04","release_date":"2025-04-14","last_updated":"2025-04-14","modalities":{"input":["text","image"],"output":["text"]},"open_weights":false,"cost":{"input":0.4,"output":1.6,"cache_read":0.1},"limit":{"context":1047576,"output":32768},"display_name":"GPT-4.1 Mini"},{"id":"openai/gpt-5-chat","name":"GPT-5 Chat (latest)","attachment":true,"reasoning":true,"temperature":true,"tool_call":false,"knowledge":"2024-09-30","release_date":"2025-08-07","last_updated":"2025-08-07","modalities":{"input":["text","image"],"output":["text"]},"open_weights":false,"cost":{"input":1.25,"output":10},"limit":{"context":400000,"output":128000},"display_name":"GPT-5 Chat (latest)"},{"id":"openai/gpt-5-nano","name":"GPT-5 Nano","attachment":true,"reasoning":true,"temperature":true,"tool_call":true,"knowledge":"2024-10-01","release_date":"2025-08-07","last_updated":"2025-08-07","modalities":{"input":["text","image"],"output":["text"]},"open_weights":false,"cost":{"input":0.05,"output":0.4},"limit":{"context":400000,"output":128000},"display_name":"GPT-5 Nano"},{"id":"openai/gpt-5-codex","name":"GPT-5 Codex","attachment":true,"reasoning":true,"temperature":true,"tool_call":true,"knowledge":"2024-10-01","release_date":"2025-09-15","last_updated":"2025-09-15","modalities":{"input":["text","image"],"output":["text"]},"open_weights":false,"cost":{"input":1.25,"output":10,"cache_read":0.125},"limit":{"context":400000,"output":128000},"display_name":"GPT-5 Codex"},{"id":"openai/gpt-4.1","name":"GPT-4.1","attachment":true,"reasoning":false,"temperature":true,"tool_call":true,"knowledge":"2024-04","release_date":"2025-04-14","last_updated":"2025-04-14","modalities":{"input":["text","image"],"output":["text"]},"open_weights":false,"cost":{"input":2,"output":8,"cache_read":0.5},"limit":{"context":1047576,"output":32768},"display_name":"GPT-4.1"},{"id":"openai/o4-mini","name":"o4 Mini","attachment":true,"reasoning":true,"temperature":true,"tool_call":true,"knowledge":"2024-06","release_date":"2025-04-16","last_updated":"2025-04-16","modalities":{"input":["text","image"],"output":["text"]},"open_weights":false,"cost":{"input":1.1,"output":4.4,"cache_read":0.28},"limit":{"context":200000,"output":100000},"display_name":"o4 Mini"},{"id":"openai/gpt-5-mini","name":"GPT-5 Mini","attachment":true,"reasoning":true,"temperature":true,"tool_call":true,"knowledge":"2024-10-01","release_date":"2025-08-07","last_updated":"2025-08-07","modalities":{"input":["text","image"],"output":["text"]},"open_weights":false,"cost":{"input":0.25,"output":2},"limit":{"context":400000,"output":128000},"display_name":"GPT-5 Mini"},{"id":"openai/gpt-oss-20b","name":"GPT OSS 20B","attachment":false,"reasoning":true,"temperature":true,"tool_call":true,"release_date":"2025-08-05","last_updated":"2025-08-05","modalities":{"input":["text"],"output":["text"]},"open_weights":true,"cost":{"input":0.05,"output":0.2},"limit":{"context":131072,"output":32768},"display_name":"GPT OSS 20B"},{"id":"openai/gpt-oss-120b","name":"GPT OSS 120B","attachment":false,"reasoning":true,"temperature":true,"tool_call":true,"release_date":"2025-08-05","last_updated":"2025-08-05","modalities":{"input":["text"],"output":["text"]},"open_weights":true,"cost":{"input":0.072,"output":0.28},"limit":{"context":131072,"output":32768},"display_name":"GPT OSS 120B"},{"id":"openai/gpt-4o-mini","name":"GPT-4o-mini","attachment":true,"reasoning":false,"temperature":true,"tool_call":true,"knowledge":"2024-10","release_date":"2024-07-18","last_updated":"2024-07-18","modalities":{"input":["text","image"],"output":["text"]},"open_weights":false,"cost":{"input":0.15,"output":0.6,"cache_read":0.08},"limit":{"context":128000,"output":16384},"display_name":"GPT-4o-mini"},{"id":"openai/gpt-5","name":"GPT-5","attachment":true,"reasoning":true,"temperature":true,"tool_call":true,"knowledge":"2024-10-01","release_date":"2025-08-07","last_updated":"2025-08-07","modalities":{"input":["text","image"],"output":["text"]},"open_weights":false,"cost":{"input":1.25,"output":10},"limit":{"context":400000,"output":128000},"display_name":"GPT-5"},{"id":"openrouter/horizon-alpha","name":"Horizon Alpha","attachment":true,"reasoning":false,"temperature":false,"tool_call":true,"knowledge":"2025-07","release_date":"2025-07-30","last_updated":"2025-07-30","modalities":{"input":["text","image"],"output":["text"]},"open_weights":false,"cost":{"input":0,"output":0},"limit":{"context":256000,"output":128000},"display_name":"Horizon Alpha"},{"id":"openrouter/sonoma-sky-alpha","name":"Sonoma Sky Alpha","attachment":true,"reasoning":false,"temperature":false,"tool_call":true,"release_date":"2024-09-05","last_updated":"2024-09-05","modalities":{"input":["text","image"],"output":["text"]},"open_weights":false,"cost":{"input":0,"output":0},"limit":{"context":2000000,"output":2000000},"display_name":"Sonoma Sky Alpha"},{"id":"openrouter/cypher-alpha:free","name":"Cypher Alpha (free)","attachment":false,"reasoning":false,"temperature":true,"tool_call":true,"knowledge":"2025-07","release_date":"2025-07-01","last_updated":"2025-07-01","modalities":{"input":["text"],"output":["text"]},"open_weights":false,"cost":{"input":0,"output":0},"limit":{"context":1000000,"output":1000000},"display_name":"Cypher Alpha (free)"},{"id":"openrouter/sonoma-dusk-alpha","name":"Sonoma Dusk Alpha","attachment":true,"reasoning":false,"temperature":false,"tool_call":true,"release_date":"2024-09-05","last_updated":"2024-09-05","modalities":{"input":["text","image"],"output":["text"]},"open_weights":false,"cost":{"input":0,"output":0},"limit":{"context":2000000,"output":2000000},"display_name":"Sonoma Dusk Alpha"},{"id":"openrouter/horizon-beta","name":"Horizon Beta","attachment":true,"reasoning":false,"temperature":false,"tool_call":true,"knowledge":"2025-07","release_date":"2025-08-01","last_updated":"2025-08-01","modalities":{"input":["text","image"],"output":["text"]},"open_weights":false,"cost":{"input":0,"output":0},"limit":{"context":256000,"output":128000},"display_name":"Horizon Beta"},{"id":"z-ai/glm-4.5","name":"GLM 4.5","attachment":false,"reasoning":true,"temperature":true,"tool_call":true,"knowledge":"2025-04","release_date":"2025-07-28","last_updated":"2025-07-28","modalities":{"input":["text"],"output":["text"]},"open_weights":true,"cost":{"input":0.6,"output":2.2},"limit":{"context":128000,"output":96000},"display_name":"GLM 4.5"},{"id":"z-ai/glm-4.5-air","name":"GLM 4.5 Air","attachment":false,"reasoning":true,"temperature":true,"tool_call":true,"knowledge":"2025-04","release_date":"2025-07-28","last_updated":"2025-07-28","modalities":{"input":["text"],"output":["text"]},"open_weights":true,"cost":{"input":0.2,"output":1.1},"limit":{"context":128000,"output":96000},"display_name":"GLM 4.5 Air"},{"id":"z-ai/glm-4.5v","name":"GLM 4.5V","attachment":true,"reasoning":true,"temperature":true,"tool_call":true,"knowledge":"2025-04","release_date":"2025-08-11","last_updated":"2025-08-11","modalities":{"input":["text","image","video"],"output":["text"]},"open_weights":true,"cost":{"input":0.6,"output":1.8},"limit":{"context":64000,"output":16384},"display_name":"GLM 4.5V"},{"id":"z-ai/glm-4.6","name":"GLM 4.6","attachment":false,"reasoning":true,"temperature":true,"tool_call":true,"knowledge":"2025-09","release_date":"2025-09-30","last_updated":"2025-09-30","modalities":{"input":["text"],"output":["text"]},"open_weights":true,"cost":{"input":0.6,"output":2.2,"cache_read":0.11},"limit":{"context":200000,"output":128000},"display_name":"GLM 4.6"},{"id":"z-ai/glm-4.5-air:free","name":"GLM 4.5 Air (free)","attachment":false,"reasoning":true,"temperature":true,"tool_call":false,"knowledge":"2025-04","release_date":"2025-07-28","last_updated":"2025-07-28","modalities":{"input":["text"],"output":["text"]},"open_weights":true,"cost":{"input":0,"output":0},"limit":{"context":128000,"output":96000},"display_name":"GLM 4.5 Air (free)"},{"id":"qwen/qwen3-coder","name":"Qwen3 Coder","attachment":false,"reasoning":false,"temperature":true,"tool_call":true,"knowledge":"2025-04","release_date":"2025-07-23","last_updated":"2025-07-23","modalities":{"input":["text"],"output":["text"]},"open_weights":true,"cost":{"input":0.3,"output":1.2},"limit":{"context":262144,"output":66536},"display_name":"Qwen3 Coder"},{"id":"qwen/qwen3-32b:free","name":"Qwen3 32B (free)","attachment":false,"reasoning":true,"temperature":true,"tool_call":true,"knowledge":"2025-04","release_date":"2025-04-28","last_updated":"2025-04-28","modalities":{"input":["text"],"output":["text"]},"open_weights":true,"cost":{"input":0,"output":0},"limit":{"context":40960,"output":40960},"display_name":"Qwen3 32B (free)"},{"id":"qwen/qwen3-next-80b-a3b-instruct","name":"Qwen3 Next 80B A3B Instruct","attachment":false,"reasoning":false,"temperature":true,"tool_call":true,"knowledge":"2025-04","release_date":"2025-09-11","last_updated":"2025-09-11","modalities":{"input":["text"],"output":["text"]},"open_weights":true,"cost":{"input":0.14,"output":1.4},"limit":{"context":262144,"output":262144},"display_name":"Qwen3 Next 80B A3B Instruct"},{"id":"qwen/qwen-2.5-coder-32b-instruct","name":"Qwen2.5 Coder 32B Instruct","attachment":false,"reasoning":false,"temperature":true,"tool_call":false,"knowledge":"2024-10","release_date":"2024-11-11","last_updated":"2024-11-11","modalities":{"input":["text"],"output":["text"]},"open_weights":true,"cost":{"input":0,"output":0},"limit":{"context":32768,"output":8192},"display_name":"Qwen2.5 Coder 32B Instruct"},{"id":"qwen/qwen3-235b-a22b:free","name":"Qwen3 235B A22B (free)","attachment":false,"reasoning":true,"temperature":true,"tool_call":true,"knowledge":"2025-04","release_date":"2025-04-28","last_updated":"2025-04-28","modalities":{"input":["text"],"output":["text"]},"open_weights":true,"cost":{"input":0,"output":0},"limit":{"context":131072,"output":131072},"display_name":"Qwen3 235B A22B (free)"},{"id":"qwen/qwq-32b:free","name":"QwQ 32B (free)","attachment":false,"reasoning":true,"temperature":true,"tool_call":true,"knowledge":"2025-03","release_date":"2025-03-05","last_updated":"2025-03-05","modalities":{"input":["text"],"output":["text"]},"open_weights":true,"cost":{"input":0,"output":0},"limit":{"context":32768,"output":32768},"display_name":"QwQ 32B (free)"},{"id":"qwen/qwen3-30b-a3b:free","name":"Qwen3 30B A3B (free)","attachment":false,"reasoning":true,"temperature":true,"tool_call":true,"knowledge":"2025-04","release_date":"2025-04-28","last_updated":"2025-04-28","modalities":{"input":["text"],"output":["text"]},"open_weights":true,"cost":{"input":0,"output":0},"limit":{"context":40960,"output":40960},"display_name":"Qwen3 30B A3B (free)"},{"id":"qwen/qwen2.5-vl-72b-instruct","name":"Qwen2.5 VL 72B Instruct","attachment":true,"reasoning":false,"temperature":true,"tool_call":false,"knowledge":"2024-10","release_date":"2025-02-01","last_updated":"2025-02-01","modalities":{"input":["text","image"],"output":["text"]},"open_weights":true,"cost":{"input":0,"output":0},"limit":{"context":32768,"output":8192},"display_name":"Qwen2.5 VL 72B Instruct"},{"id":"qwen/qwen3-14b:free","name":"Qwen3 14B (free)","attachment":false,"reasoning":true,"temperature":true,"tool_call":true,"knowledge":"2025-04","release_date":"2025-04-28","last_updated":"2025-04-28","modalities":{"input":["text"],"output":["text"]},"open_weights":true,"cost":{"input":0,"output":0},"limit":{"context":40960,"output":40960},"display_name":"Qwen3 14B (free)"},{"id":"qwen/qwen3-30b-a3b-instruct-2507","name":"Qwen3 30B A3B Instruct 2507","attachment":false,"reasoning":false,"temperature":true,"tool_call":false,"knowledge":"2025-04","release_date":"2025-07-29","last_updated":"2025-07-29","modalities":{"input":["text"],"output":["text"]},"open_weights":true,"cost":{"input":0.2,"output":0.8},"limit":{"context":131072,"output":33000},"display_name":"Qwen3 30B A3B Instruct 2507"},{"id":"qwen/qwen3-235b-a22b-thinking-2507","name":"Qwen3 235B A22B Thinking 2507","attachment":false,"reasoning":true,"temperature":true,"tool_call":true,"knowledge":"2025-04","release_date":"2025-07-25","last_updated":"2025-07-25","modalities":{"input":["text"],"output":["text"]},"open_weights":true,"cost":{"input":0.078,"output":0.312},"limit":{"context":262144,"output":81920},"display_name":"Qwen3 235B A22B Thinking 2507"},{"id":"qwen/qwen2.5-vl-32b-instruct:free","name":"Qwen2.5 VL 32B Instruct (free)","attachment":true,"reasoning":false,"temperature":true,"tool_call":true,"knowledge":"2025-03","release_date":"2025-03-24","last_updated":"2025-03-24","modalities":{"input":["text","image","video"],"output":["text"]},"open_weights":true,"cost":{"input":0,"output":0},"limit":{"context":8192,"output":8192},"display_name":"Qwen2.5 VL 32B Instruct (free)"},{"id":"qwen/qwen2.5-vl-72b-instruct:free","name":"Qwen2.5 VL 72B Instruct (free)","attachment":true,"reasoning":false,"temperature":true,"tool_call":true,"knowledge":"2025-02","release_date":"2025-02-01","last_updated":"2025-02-01","modalities":{"input":["text","image"],"output":["text"]},"open_weights":true,"cost":{"input":0,"output":0},"limit":{"context":32768,"output":32768},"display_name":"Qwen2.5 VL 72B Instruct (free)"},{"id":"qwen/qwen3-235b-a22b-07-25:free","name":"Qwen3 235B A22B Instruct 2507 (free)","attachment":false,"reasoning":false,"temperature":true,"tool_call":true,"knowledge":"2025-04","release_date":"2025-04-28","last_updated":"2025-07-21","modalities":{"input":["text"],"output":["text"]},"open_weights":true,"cost":{"input":0,"output":0},"limit":{"context":262144,"output":131072},"display_name":"Qwen3 235B A22B Instruct 2507 (free)"},{"id":"qwen/qwen3-coder:free","name":"Qwen3 Coder 480B A35B Instruct (free)","attachment":false,"reasoning":false,"temperature":true,"tool_call":true,"knowledge":"2025-04","release_date":"2025-07-23","last_updated":"2025-07-23","modalities":{"input":["text"],"output":["text"]},"open_weights":true,"cost":{"input":0,"output":0},"limit":{"context":262144,"output":66536},"display_name":"Qwen3 Coder 480B A35B Instruct (free)"},{"id":"qwen/qwen3-235b-a22b-07-25","name":"Qwen3 235B A22B Instruct 2507","attachment":false,"reasoning":false,"temperature":true,"tool_call":true,"knowledge":"2025-04","release_date":"2025-04-28","last_updated":"2025-07-21","modalities":{"input":["text"],"output":["text"]},"open_weights":true,"cost":{"input":0.15,"output":0.85},"limit":{"context":262144,"output":131072},"display_name":"Qwen3 235B A22B Instruct 2507"},{"id":"qwen/qwen3-8b:free","name":"Qwen3 8B (free)","attachment":false,"reasoning":true,"temperature":true,"tool_call":true,"knowledge":"2025-04","release_date":"2025-04-28","last_updated":"2025-04-28","modalities":{"input":["text"],"output":["text"]},"open_weights":true,"cost":{"input":0,"output":0},"limit":{"context":40960,"output":40960},"display_name":"Qwen3 8B (free)"},{"id":"qwen/qwen3-max","name":"Qwen3 Max","attachment":false,"reasoning":true,"temperature":true,"tool_call":true,"release_date":"2025-09-05","last_updated":"2025-09-05","modalities":{"input":["text"],"output":["text"]},"open_weights":false,"cost":{"input":1.2,"output":6},"limit":{"context":262144,"output":32768},"display_name":"Qwen3 Max"},{"id":"mistralai/devstral-medium-2507","name":"Devstral Medium","attachment":false,"reasoning":false,"temperature":true,"tool_call":true,"knowledge":"2025-05","release_date":"2025-07-10","last_updated":"2025-07-10","modalities":{"input":["text"],"output":["text"]},"open_weights":true,"cost":{"input":0.4,"output":2},"limit":{"context":131072,"output":131072},"display_name":"Devstral Medium"},{"id":"mistralai/codestral-2508","name":"Codestral 2508","attachment":false,"reasoning":false,"temperature":true,"tool_call":true,"knowledge":"2025-05","release_date":"2025-08-01","last_updated":"2025-08-01","modalities":{"input":["text"],"output":["text"]},"open_weights":true,"cost":{"input":0.3,"output":0.9},"limit":{"context":256000,"output":256000},"display_name":"Codestral 2508"},{"id":"mistralai/mistral-7b-instruct:free","name":"Mistral 7B Instruct (free)","attachment":false,"reasoning":false,"temperature":true,"tool_call":true,"knowledge":"2024-05","release_date":"2024-05-27","last_updated":"2024-05-27","modalities":{"input":["text"],"output":["text"]},"open_weights":true,"cost":{"input":0,"output":0},"limit":{"context":32768,"output":32768},"display_name":"Mistral 7B Instruct (free)"},{"id":"mistralai/devstral-small-2505","name":"Devstral Small","attachment":false,"reasoning":false,"temperature":true,"tool_call":true,"knowledge":"2025-05","release_date":"2025-05-07","last_updated":"2025-05-07","modalities":{"input":["text"],"output":["text"]},"open_weights":true,"cost":{"input":0.06,"output":0.12},"limit":{"context":128000,"output":128000},"display_name":"Devstral Small"},{"id":"mistralai/mistral-small-3.2-24b-instruct","name":"Mistral Small 3.2 24B Instruct","attachment":true,"reasoning":false,"temperature":true,"tool_call":true,"knowledge":"2024-10","release_date":"2025-06-20","last_updated":"2025-06-20","modalities":{"input":["text","image"],"output":["text"]},"open_weights":true,"cost":{"input":0,"output":0},"limit":{"context":96000,"output":8192},"display_name":"Mistral Small 3.2 24B Instruct"},{"id":"mistralai/devstral-small-2505:free","name":"Devstral Small 2505 (free)","attachment":false,"reasoning":false,"temperature":true,"tool_call":true,"knowledge":"2025-05","release_date":"2025-05-21","last_updated":"2025-05-21","modalities":{"input":["text"],"output":["text"]},"open_weights":true,"cost":{"input":0,"output":0},"limit":{"context":32768,"output":32768},"display_name":"Devstral Small 2505 (free)"},{"id":"mistralai/mistral-small-3.2-24b-instruct:free","name":"Mistral Small 3.2 24B (free)","attachment":true,"reasoning":false,"temperature":true,"tool_call":true,"knowledge":"2025-06","release_date":"2025-06-20","last_updated":"2025-06-20","modalities":{"input":["text","image"],"output":["text"]},"open_weights":true,"cost":{"input":0,"output":0},"limit":{"context":96000,"output":96000},"display_name":"Mistral Small 3.2 24B (free)"},{"id":"mistralai/mistral-medium-3","name":"Mistral Medium 3","attachment":true,"reasoning":false,"temperature":true,"tool_call":true,"knowledge":"2025-05","release_date":"2025-05-07","last_updated":"2025-05-07","modalities":{"input":["text","image"],"output":["text"]},"open_weights":false,"cost":{"input":0.4,"output":2},"limit":{"context":131072,"output":131072},"display_name":"Mistral Medium 3"},{"id":"mistralai/mistral-small-3.1-24b-instruct","name":"Mistral Small 3.1 24B Instruct","attachment":true,"reasoning":false,"temperature":true,"tool_call":true,"knowledge":"2024-10","release_date":"2025-03-17","last_updated":"2025-03-17","modalities":{"input":["text","image"],"output":["text"]},"open_weights":true,"cost":{"input":0,"output":0},"limit":{"context":128000,"output":8192},"display_name":"Mistral Small 3.1 24B Instruct"},{"id":"mistralai/devstral-small-2507","name":"Devstral Small 1.1","attachment":false,"reasoning":false,"temperature":true,"tool_call":true,"knowledge":"2025-05","release_date":"2025-07-10","last_updated":"2025-07-10","modalities":{"input":["text"],"output":["text"]},"open_weights":true,"cost":{"input":0.1,"output":0.3},"limit":{"context":131072,"output":131072},"display_name":"Devstral Small 1.1"},{"id":"mistralai/mistral-medium-3.1","name":"Mistral Medium 3.1","attachment":true,"reasoning":false,"temperature":true,"tool_call":true,"knowledge":"2025-05","release_date":"2025-08-12","last_updated":"2025-08-12","modalities":{"input":["text","image"],"output":["text"]},"open_weights":false,"cost":{"input":0.4,"output":2},"limit":{"context":262144,"output":262144},"display_name":"Mistral Medium 3.1"},{"id":"mistralai/mistral-nemo:free","name":"Mistral Nemo (free)","attachment":false,"reasoning":false,"temperature":true,"tool_call":true,"knowledge":"2024-07","release_date":"2024-07-19","last_updated":"2024-07-19","modalities":{"input":["text"],"output":["text"]},"open_weights":true,"cost":{"input":0,"output":0},"limit":{"context":131072,"output":131072},"display_name":"Mistral Nemo (free)"},{"id":"rekaai/reka-flash-3","name":"Reka Flash 3","attachment":false,"reasoning":true,"temperature":true,"tool_call":true,"knowledge":"2024-10","release_date":"2025-03-12","last_updated":"2025-03-12","modalities":{"input":["text"],"output":["text"]},"open_weights":true,"cost":{"input":0,"output":0},"limit":{"context":32768,"output":8192},"display_name":"Reka Flash 3"},{"id":"meta-llama/llama-3.2-11b-vision-instruct","name":"Llama 3.2 11B Vision Instruct","attachment":true,"reasoning":false,"temperature":true,"tool_call":false,"knowledge":"2023-12","release_date":"2024-09-25","last_updated":"2024-09-25","modalities":{"input":["text","image"],"output":["text"]},"open_weights":true,"cost":{"input":0,"output":0},"limit":{"context":131072,"output":8192},"display_name":"Llama 3.2 11B Vision Instruct"},{"id":"meta-llama/llama-3.3-70b-instruct:free","name":"Llama 3.3 70B Instruct (free)","attachment":false,"reasoning":false,"temperature":true,"tool_call":true,"knowledge":"2024-12","release_date":"2024-12-06","last_updated":"2024-12-06","modalities":{"input":["text"],"output":["text"]},"open_weights":true,"cost":{"input":0,"output":0},"limit":{"context":65536,"output":65536},"display_name":"Llama 3.3 70B Instruct (free)"},{"id":"meta-llama/llama-4-scout:free","name":"Llama 4 Scout (free)","attachment":true,"reasoning":false,"temperature":true,"tool_call":true,"knowledge":"2024-08","release_date":"2025-04-05","last_updated":"2025-04-05","modalities":{"input":["text","image"],"output":["text"]},"open_weights":true,"cost":{"input":0,"output":0},"limit":{"context":64000,"output":64000},"display_name":"Llama 4 Scout (free)"},{"id":"anthropic/claude-opus-4","name":"Claude Opus 4","attachment":true,"reasoning":true,"temperature":true,"tool_call":true,"knowledge":"2025-03-31","release_date":"2025-05-22","last_updated":"2025-05-22","modalities":{"input":["text","image"],"output":["text"]},"open_weights":false,"cost":{"input":15,"output":75,"cache_read":1.5,"cache_write":18.75},"limit":{"context":200000,"output":32000},"display_name":"Claude Opus 4"},{"id":"anthropic/claude-opus-4.1","name":"Claude Opus 4.1","attachment":true,"reasoning":true,"temperature":true,"tool_call":true,"knowledge":"2025-03-31","release_date":"2025-08-05","last_updated":"2025-08-05","modalities":{"input":["text","image"],"output":["text"]},"open_weights":false,"cost":{"input":15,"output":75,"cache_read":1.5,"cache_write":18.75},"limit":{"context":200000,"output":32000},"display_name":"Claude Opus 4.1"},{"id":"anthropic/claude-3.7-sonnet","name":"Claude Sonnet 3.7","attachment":true,"reasoning":true,"temperature":true,"tool_call":true,"knowledge":"2024-01","release_date":"2025-02-19","last_updated":"2025-02-19","modalities":{"input":["text","image"],"output":["text"]},"open_weights":false,"cost":{"input":15,"output":75,"cache_read":1.5,"cache_write":18.75},"limit":{"context":200000,"output":128000},"display_name":"Claude Sonnet 3.7"},{"id":"anthropic/claude-3.5-haiku","name":"Claude Haiku 3.5","attachment":true,"reasoning":false,"temperature":true,"tool_call":true,"knowledge":"2024-07-31","release_date":"2024-10-22","last_updated":"2024-10-22","modalities":{"input":["text","image"],"output":["text"]},"open_weights":false,"cost":{"input":0.8,"output":4,"cache_read":0.08,"cache_write":1},"limit":{"context":200000,"output":8192},"display_name":"Claude Haiku 3.5"},{"id":"anthropic/claude-sonnet-4","name":"Claude Sonnet 4","attachment":true,"reasoning":true,"temperature":true,"tool_call":true,"knowledge":"2025-03-31","release_date":"2025-05-22","last_updated":"2025-05-22","modalities":{"input":["text","image"],"output":["text"]},"open_weights":false,"cost":{"input":3,"output":15,"cache_read":0.3,"cache_write":3.75},"limit":{"context":200000,"output":64000},"display_name":"Claude Sonnet 4"},{"id":"anthropic/claude-sonnet-4.5","name":"Claude Sonnet 4.5","attachment":true,"reasoning":true,"temperature":true,"tool_call":true,"knowledge":"2025-07-31","release_date":"2025-09-29","last_updated":"2025-09-29","modalities":{"input":["text","image"],"output":["text"]},"open_weights":false,"cost":{"input":3,"output":15,"cache_read":0.3,"cache_write":3.75},"limit":{"context":1000000,"output":64000},"display_name":"Claude Sonnet 4.5"},{"id":"sarvamai/sarvam-m:free","name":"Sarvam-M (free)","attachment":false,"reasoning":true,"temperature":true,"tool_call":true,"knowledge":"2025-05","release_date":"2025-05-25","last_updated":"2025-05-25","modalities":{"input":["text"],"output":["text"]},"open_weights":true,"cost":{"input":0,"output":0},"limit":{"context":32768,"output":32768},"display_name":"Sarvam-M (free)"},{"id":"deepseek-chat-v3-0324:free","type":"chat","context_length":131072,"max_output_tokens":65536,"name":"deepseek-chat-v3-0324:free","display_name":"deepseek-chat-v3-0324:free"},{"id":"deepseek-r1-0528:free","type":"chat","context_length":131072,"max_output_tokens":65536,"name":"deepseek-r1-0528:free","display_name":"deepseek-r1-0528:free"},{"id":"google/gemini-2.5-flash-image-preview","type":"image-generation","context_length":32768,"max_output_tokens":32768,"name":"google/gemini-2.5-flash-image-preview","display_name":"google/gemini-2.5-flash-image-preview"},{"id":"gpt-5","type":"chat","reasoning_effort":"medium","name":"gpt-5","display_name":"gpt-5"},{"id":"gpt-5-chat","type":"chat","reasoning_effort":"medium","name":"gpt-5-chat","display_name":"gpt-5-chat"},{"id":"gpt-5-mini","type":"chat","reasoning_effort":"medium","name":"gpt-5-mini","display_name":"gpt-5-mini"},{"id":"gpt-5-nano","type":"chat","reasoning_effort":"medium","name":"gpt-5-nano","display_name":"gpt-5-nano"},{"id":"o1","type":"chat","context_length":200000,"max_output_tokens":100000,"reasoning_effort":"medium","name":"o1","display_name":"o1"},{"id":"o1-mini","type":"chat","context_length":128000,"max_output_tokens":65536,"reasoning_effort":"medium","name":"o1-mini","display_name":"o1-mini"},{"id":"o1-preview","type":"chat","context_length":128000,"max_output_tokens":32768,"reasoning_effort":"medium","name":"o1-preview","display_name":"o1-preview"},{"id":"o1-pro","type":"chat","context_length":200000,"max_output_tokens":100000,"reasoning_effort":"medium","name":"o1-pro","display_name":"o1-pro"},{"id":"o3","type":"chat","context_length":200000,"max_output_tokens":100000,"reasoning_effort":"medium","name":"o3","display_name":"o3"},{"id":"o3-mini","type":"chat","context_length":128000,"max_output_tokens":65536,"reasoning_effort":"medium","name":"o3-mini","display_name":"o3-mini"},{"id":"o3-mini-high","type":"chat","context_length":128000,"max_output_tokens":65536,"reasoning_effort":"high","name":"o3-mini-high","display_name":"o3-mini-high"},{"id":"o3-pro","type":"chat","context_length":200000,"max_output_tokens":100000,"reasoning_effort":"medium","name":"o3-pro","display_name":"o3-pro"}]},"v0":{"id":"v0","name":"v0","doc":"https://sdk.vercel.ai/providers/ai-sdk-providers/vercel","display_name":"v0","models":[{"id":"v0-1.5-lg","name":"v0-1.5-lg","attachment":true,"reasoning":true,"temperature":true,"tool_call":true,"release_date":"2025-06-09","last_updated":"2025-06-09","modalities":{"input":["text","image"],"output":["text"]},"open_weights":false,"cost":{"input":15,"output":75},"limit":{"context":512000,"output":32000},"display_name":"v0-1.5-lg"},{"id":"v0-1.5-md","name":"v0-1.5-md","attachment":true,"reasoning":true,"temperature":true,"tool_call":true,"release_date":"2025-06-09","last_updated":"2025-06-09","modalities":{"input":["text","image"],"output":["text"]},"open_weights":false,"cost":{"input":3,"output":15},"limit":{"context":128000,"output":32000},"display_name":"v0-1.5-md"},{"id":"v0-1.0-md","name":"v0-1.0-md","attachment":true,"reasoning":true,"temperature":true,"tool_call":true,"release_date":"2025-05-22","last_updated":"2025-05-22","modalities":{"input":["text","image"],"output":["text"]},"open_weights":false,"cost":{"input":3,"output":15},"limit":{"context":128000,"output":32000},"display_name":"v0-1.0-md"}]},"synthetic":{"id":"synthetic","api":"https://api.synthetic.new/v1","name":"Synthetic","doc":"https://synthetic.new/pricing","display_name":"Synthetic","models":[{"id":"hf:Qwen/Qwen3-235B-A22B-Instruct-2507","name":"Qwen 3 235B Instruct","attachment":false,"reasoning":false,"temperature":true,"tool_call":true,"knowledge":"2025-04","release_date":"2025-04-28","last_updated":"2025-07-21","modalities":{"input":["text"],"output":["text"]},"open_weights":true,"cost":{"input":0.2,"output":0.6},"limit":{"context":256000,"output":32000},"display_name":"Qwen 3 235B Instruct"},{"id":"hf:Qwen/Qwen2.5-Coder-32B-Instruct","name":"Qwen2.5-Coder-32B-Instruct","attachment":false,"reasoning":false,"temperature":true,"tool_call":false,"knowledge":"2024-10","release_date":"2024-11-11","last_updated":"2024-11-11","modalities":{"input":["text"],"output":["text"]},"open_weights":true,"cost":{"input":0.8,"output":0.8},"limit":{"context":32768,"output":32768},"display_name":"Qwen2.5-Coder-32B-Instruct"},{"id":"hf:Qwen/Qwen3-Coder-480B-A35B-Instruct","name":"Qwen 3 Coder 480B","attachment":false,"reasoning":false,"temperature":true,"tool_call":true,"knowledge":"2025-04","release_date":"2025-07-23","last_updated":"2025-07-23","modalities":{"input":["text"],"output":["text"]},"open_weights":true,"cost":{"input":2,"output":2},"limit":{"context":256000,"output":32000},"display_name":"Qwen 3 Coder 480B"},{"id":"hf:Qwen/Qwen3-235B-A22B-Thinking-2507","name":"Qwen3 235B A22B Thinking 2507","attachment":false,"reasoning":true,"temperature":true,"tool_call":true,"knowledge":"2025-04","release_date":"2025-07-25","last_updated":"2025-07-25","modalities":{"input":["text"],"output":["text"]},"open_weights":true,"cost":{"input":0.65,"output":3},"limit":{"context":256000,"output":32000},"display_name":"Qwen3 235B A22B Thinking 2507"},{"id":"hf:meta-llama/Llama-3.1-70B-Instruct","name":"Llama-3.1-70B-Instruct","attachment":false,"reasoning":true,"temperature":true,"tool_call":true,"knowledge":"2023-12","release_date":"2024-07-23","last_updated":"2024-07-23","modalities":{"input":["text"],"output":["text"]},"open_weights":true,"cost":{"input":0.9,"output":0.9},"limit":{"context":128000,"output":32768},"display_name":"Llama-3.1-70B-Instruct"},{"id":"hf:meta-llama/Llama-3.1-8B-Instruct","name":"Llama-3.1-8B-Instruct","attachment":false,"reasoning":true,"temperature":true,"tool_call":true,"knowledge":"2023-12","release_date":"2024-07-23","last_updated":"2024-07-23","modalities":{"input":["text"],"output":["text"]},"open_weights":true,"cost":{"input":0.2,"output":0.2},"limit":{"context":128000,"output":32768},"display_name":"Llama-3.1-8B-Instruct"},{"id":"hf:meta-llama/Llama-3.3-70B-Instruct","name":"Llama-3.3-70B-Instruct","attachment":false,"reasoning":true,"temperature":true,"tool_call":true,"knowledge":"2023-12","release_date":"2024-12-06","last_updated":"2024-12-06","modalities":{"input":["text"],"output":["text"]},"open_weights":true,"cost":{"input":0.9,"output":0.9},"limit":{"context":128000,"output":32768},"display_name":"Llama-3.3-70B-Instruct"},{"id":"hf:meta-llama/Llama-4-Scout-17B-16E-Instruct","name":"Llama-4-Scout-17B-16E-Instruct","attachment":true,"reasoning":false,"temperature":true,"tool_call":true,"knowledge":"2024-08","release_date":"2025-04-05","last_updated":"2025-04-05","modalities":{"input":["text","image"],"output":["text"]},"open_weights":true,"cost":{"input":0.15,"output":0.6},"limit":{"context":328000,"output":4096},"display_name":"Llama-4-Scout-17B-16E-Instruct"},{"id":"hf:meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8","name":"Llama-4-Maverick-17B-128E-Instruct-FP8","attachment":true,"reasoning":false,"temperature":true,"tool_call":true,"knowledge":"2024-08","release_date":"2025-04-05","last_updated":"2025-04-05","modalities":{"input":["text","image"],"output":["text"]},"open_weights":true,"cost":{"input":0.22,"output":0.88},"limit":{"context":524000,"output":4096},"display_name":"Llama-4-Maverick-17B-128E-Instruct-FP8"},{"id":"hf:meta-llama/Llama-3.1-405B-Instruct","name":"Llama-3.1-405B-Instruct","attachment":false,"reasoning":true,"temperature":true,"tool_call":true,"knowledge":"2023-12","release_date":"2024-07-23","last_updated":"2024-07-23","modalities":{"input":["text"],"output":["text"]},"open_weights":true,"cost":{"input":3,"output":3},"limit":{"context":128000,"output":32768},"display_name":"Llama-3.1-405B-Instruct"},{"id":"hf:moonshotai/Kimi-K2-Instruct","name":"Kimi K2","attachment":false,"reasoning":false,"temperature":true,"tool_call":true,"knowledge":"2024-10","release_date":"2025-07-11","last_updated":"2025-07-11","modalities":{"input":["text"],"output":["text"]},"open_weights":true,"cost":{"input":0.6,"output":2.5},"limit":{"context":128000,"output":32768},"display_name":"Kimi K2"},{"id":"hf:moonshotai/Kimi-K2-Instruct-0905","name":"Kimi K2 0905","attachment":false,"reasoning":false,"temperature":true,"tool_call":true,"knowledge":"2024-10","release_date":"2025-09-05","last_updated":"2025-09-05","modalities":{"input":["text"],"output":["text"]},"open_weights":true,"cost":{"input":1.2,"output":1.2},"limit":{"context":262144,"output":32768},"display_name":"Kimi K2 0905"},{"id":"hf:zai-org/GLM-4.5","name":"GLM 4.5","attachment":false,"reasoning":true,"temperature":true,"tool_call":true,"knowledge":"2025-04","release_date":"2025-07-28","last_updated":"2025-07-28","modalities":{"input":["text"],"output":["text"]},"open_weights":true,"cost":{"input":0.55,"output":2.19},"limit":{"context":128000,"output":96000},"display_name":"GLM 4.5"},{"id":"hf:zai-org/GLM-4.6","name":"GLM 4.6","attachment":false,"reasoning":true,"temperature":true,"tool_call":true,"knowledge":"2025-04","release_date":"2025-09-30","last_updated":"2025-09-30","modalities":{"input":["text"],"output":["text"]},"open_weights":true,"cost":{"input":0.55,"output":2.19},"limit":{"context":200000,"output":96000},"display_name":"GLM 4.6"},{"id":"hf:deepseek-ai/DeepSeek-R1","name":"DeepSeek R1","attachment":false,"reasoning":true,"temperature":true,"tool_call":true,"knowledge":"2025-01","release_date":"2025-01-20","last_updated":"2025-01-20","modalities":{"input":["text"],"output":["text"]},"open_weights":true,"cost":{"input":0.55,"output":2.19},"limit":{"context":128000,"output":128000},"display_name":"DeepSeek R1"},{"id":"hf:deepseek-ai/DeepSeek-R1-0528","name":"DeepSeek R1 (0528)","attachment":false,"reasoning":true,"temperature":true,"tool_call":true,"release_date":"2025-08-01","last_updated":"2025-08-01","modalities":{"input":["text"],"output":["text"]},"open_weights":false,"cost":{"input":3,"output":8},"limit":{"context":128000,"output":128000},"display_name":"DeepSeek R1 (0528)"},{"id":"hf:deepseek-ai/DeepSeek-V3.1-Terminus","name":"DeepSeek V3.1 Terminus","attachment":false,"reasoning":true,"temperature":true,"tool_call":true,"release_date":"2025-09-22","last_updated":"2025-09-25","modalities":{"input":["text"],"output":["text"]},"open_weights":false,"cost":{"input":1.2,"output":1.2},"limit":{"context":128000,"output":128000},"display_name":"DeepSeek V3.1 Terminus"},{"id":"hf:deepseek-ai/DeepSeek-V3","name":"DeepSeek V3","attachment":false,"reasoning":true,"temperature":true,"tool_call":true,"knowledge":"2024-07","release_date":"2025-01-20","last_updated":"2025-05-29","modalities":{"input":["text"],"output":["text"]},"open_weights":true,"cost":{"input":1.25,"output":1.25},"limit":{"context":128000,"output":128000},"display_name":"DeepSeek V3"},{"id":"hf:deepseek-ai/DeepSeek-V3.1","name":"DeepSeek V3.1","attachment":false,"reasoning":true,"temperature":true,"tool_call":true,"release_date":"2025-08-21","last_updated":"2025-08-21","modalities":{"input":["text"],"output":["text"]},"open_weights":false,"cost":{"input":0.56,"output":1.68},"limit":{"context":128000,"output":128000},"display_name":"DeepSeek V3.1"},{"id":"hf:deepseek-ai/DeepSeek-V3-0324","name":"DeepSeek V3 (0324)","attachment":false,"reasoning":false,"temperature":true,"tool_call":true,"release_date":"2025-08-01","last_updated":"2025-08-01","modalities":{"input":["text"],"output":["text"]},"open_weights":false,"cost":{"input":1.2,"output":1.2},"limit":{"context":128000,"output":128000},"display_name":"DeepSeek V3 (0324)"},{"id":"hf:openai/gpt-oss-120b","name":"GPT OSS 120B","attachment":false,"reasoning":true,"temperature":true,"tool_call":true,"release_date":"2025-08-05","last_updated":"2025-08-05","modalities":{"input":["text"],"output":["text"]},"open_weights":true,"cost":{"input":0.1,"output":0.1},"limit":{"context":128000,"output":32768},"display_name":"GPT OSS 120B"}]},"deepinfra":{"id":"deepinfra","name":"Deep Infra","doc":"https://deepinfra.com/models","display_name":"Deep Infra","models":[{"id":"moonshotai/Kimi-K2-Instruct","name":"Kimi K2","attachment":false,"reasoning":false,"temperature":true,"tool_call":true,"knowledge":"2024-10","release_date":"2025-07-11","last_updated":"2025-07-11","modalities":{"input":["text"],"output":["text"]},"open_weights":true,"cost":{"input":0.5,"output":2},"limit":{"context":131072,"output":32768},"display_name":"Kimi K2"},{"id":"Qwen/Qwen3-Coder-480B-A35B-Instruct","name":"Qwen3 Coder 480B A35B Instruct","attachment":false,"reasoning":false,"temperature":true,"tool_call":true,"knowledge":"2025-04","release_date":"2025-07-23","last_updated":"2025-07-23","modalities":{"input":["text"],"output":["text"]},"open_weights":true,"cost":{"input":0.4,"output":1.6},"limit":{"context":262144,"output":66536},"display_name":"Qwen3 Coder 480B A35B Instruct"},{"id":"Qwen/Qwen3-Coder-480B-A35B-Instruct-Turbo","name":"Qwen3 Coder 480B A35B Instruct Turbo","attachment":false,"reasoning":false,"temperature":true,"tool_call":true,"knowledge":"2025-04","release_date":"2025-07-23","last_updated":"2025-07-23","modalities":{"input":["text"],"output":["text"]},"open_weights":true,"cost":{"input":0.3,"output":1.2},"limit":{"context":262144,"output":66536},"display_name":"Qwen3 Coder 480B A35B Instruct Turbo"},{"id":"zai-org/GLM-4.5","name":"GLM-4.5","attachment":false,"reasoning":false,"temperature":true,"tool_call":true,"knowledge":"2025-04","release_date":"2025-07-28","last_updated":"2025-07-28","modalities":{"input":["text"],"output":["text"]},"open_weights":true,"cost":{"input":0.6,"output":2.2},"limit":{"context":131072,"output":98304},"display_name":"GLM-4.5"}]},"zhipuai":{"id":"zhipuai","api":"https://open.bigmodel.cn/api/paas/v4","name":"Zhipu AI","doc":"https://docs.z.ai/guides/overview/pricing","display_name":"Zhipu AI","models":[{"id":"glm-4.6","name":"GLM-4.6","attachment":false,"reasoning":true,"temperature":true,"tool_call":true,"knowledge":"2025-04","release_date":"2025-09-30","last_updated":"2025-09-30","modalities":{"input":["text"],"output":["text"]},"open_weights":true,"cost":{"input":0.6,"output":2.2,"cache_read":0.11,"cache_write":0},"limit":{"context":204800,"output":131072},"display_name":"GLM-4.6"},{"id":"glm-4.5v","name":"GLM 4.5V","attachment":true,"reasoning":true,"temperature":true,"tool_call":true,"knowledge":"2025-04","release_date":"2025-08-11","last_updated":"2025-08-11","modalities":{"input":["text","image","video"],"output":["text"]},"open_weights":true,"cost":{"input":0.6,"output":1.8},"limit":{"context":64000,"output":16384},"display_name":"GLM 4.5V"},{"id":"glm-4.5-air","name":"GLM-4.5-Air","attachment":false,"reasoning":true,"temperature":true,"tool_call":true,"knowledge":"2025-04","release_date":"2025-07-28","last_updated":"2025-07-28","modalities":{"input":["text"],"output":["text"]},"open_weights":true,"cost":{"input":0.2,"output":1.1,"cache_read":0.03,"cache_write":0},"limit":{"context":131072,"output":98304},"display_name":"GLM-4.5-Air"},{"id":"glm-4.5","name":"GLM-4.5","attachment":false,"reasoning":true,"temperature":true,"tool_call":true,"knowledge":"2025-04","release_date":"2025-07-28","last_updated":"2025-07-28","modalities":{"input":["text"],"output":["text"]},"open_weights":true,"cost":{"input":0.6,"output":2.2,"cache_read":0.11,"cache_write":0},"limit":{"context":131072,"output":98304},"display_name":"GLM-4.5"},{"id":"glm-4.5-flash","name":"GLM-4.5-Flash","attachment":false,"reasoning":true,"temperature":true,"tool_call":true,"knowledge":"2025-04","release_date":"2025-07-28","last_updated":"2025-07-28","modalities":{"input":["text"],"output":["text"]},"open_weights":true,"cost":{"input":0,"output":0,"cache_read":0,"cache_write":0},"limit":{"context":131072,"output":98304},"display_name":"GLM-4.5-Flash"}]},"submodel":{"id":"submodel","api":"https://llm.submodel.ai/v1","name":"submodel","doc":"https://submodel.gitbook.io","display_name":"submodel","models":[{"id":"openai/gpt-oss-120b","name":"GPT OSS 120B","attachment":false,"reasoning":true,"temperature":true,"tool_call":true,"release_date":"2025-08-23","last_updated":"2025-08-23","modalities":{"input":["text"],"output":["text"]},"open_weights":true,"cost":{"input":0.1,"output":0.5},"limit":{"context":131072,"output":32768},"display_name":"GPT OSS 120B"},{"id":"Qwen/Qwen3-235B-A22B-Instruct-2507","name":"Qwen3 235B A22B Instruct 2507","attachment":false,"reasoning":false,"temperature":true,"tool_call":true,"release_date":"2025-08-23","last_updated":"2025-08-23","modalities":{"input":["text"],"output":["text"]},"open_weights":true,"cost":{"input":0.2,"output":0.3},"limit":{"context":262144,"output":131072},"display_name":"Qwen3 235B A22B Instruct 2507"},{"id":"Qwen/Qwen3-Coder-480B-A35B-Instruct-FP8","name":"Qwen3 Coder 480B A35B Instruct","attachment":false,"reasoning":false,"temperature":true,"tool_call":true,"release_date":"2025-08-23","last_updated":"2025-08-23","modalities":{"input":["text"],"output":["text"]},"open_weights":false,"cost":{"input":0.2,"output":0.8},"limit":{"context":262144,"output":262144},"display_name":"Qwen3 Coder 480B A35B Instruct"},{"id":"Qwen/Qwen3-235B-A22B-Thinking-2507","name":"Qwen3 235B A22B Thinking 2507","attachment":false,"reasoning":true,"temperature":true,"tool_call":true,"release_date":"2025-08-23","last_updated":"2025-08-23","modalities":{"input":["text"],"output":["text"]},"open_weights":true,"cost":{"input":0.2,"output":0.6},"limit":{"context":262144,"output":131072},"display_name":"Qwen3 235B A22B Thinking 2507"},{"id":"zai-org/GLM-4.5-FP8","name":"GLM 4.5 FP8","attachment":false,"reasoning":true,"temperature":true,"tool_call":true,"release_date":"2025-07-28","last_updated":"2025-07-28","modalities":{"input":["text"],"output":["text"]},"open_weights":true,"cost":{"input":0.2,"output":0.8},"limit":{"context":131072,"output":131072},"display_name":"GLM 4.5 FP8"},{"id":"zai-org/GLM-4.5-Air","name":"GLM 4.5 Air","attachment":false,"reasoning":false,"temperature":true,"tool_call":true,"release_date":"2025-07-28","last_updated":"2025-07-28","modalities":{"input":["text"],"output":["text"]},"open_weights":true,"cost":{"input":0.1,"output":0.5},"limit":{"context":131072,"output":131072},"display_name":"GLM 4.5 Air"},{"id":"deepseek-ai/DeepSeek-R1-0528","name":"DeepSeek R1 0528","attachment":false,"reasoning":true,"temperature":true,"tool_call":true,"release_date":"2025-08-23","last_updated":"2025-08-23","modalities":{"input":["text"],"output":["text"]},"open_weights":false,"cost":{"input":0.5,"output":2.15},"limit":{"context":75000,"output":163840},"display_name":"DeepSeek R1 0528"},{"id":"deepseek-ai/DeepSeek-V3.1","name":"DeepSeek V3.1","attachment":false,"reasoning":true,"temperature":true,"tool_call":true,"release_date":"2025-08-23","last_updated":"2025-08-23","modalities":{"input":["text"],"output":["text"]},"open_weights":false,"cost":{"input":0.2,"output":0.8},"limit":{"context":75000,"output":163840},"display_name":"DeepSeek V3.1"},{"id":"deepseek-ai/DeepSeek-V3-0324","name":"DeepSeek V3 0324","attachment":false,"reasoning":false,"temperature":true,"tool_call":true,"release_date":"2025-08-23","last_updated":"2025-08-23","modalities":{"input":["text"],"output":["text"]},"open_weights":false,"cost":{"input":0.2,"output":0.8},"limit":{"context":75000,"output":163840},"display_name":"DeepSeek V3 0324"}]},"zai":{"id":"zai","api":"https://api.z.ai/api/paas/v4","name":"Z.AI","doc":"https://docs.z.ai/guides/overview/pricing","display_name":"Z.AI","models":[{"id":"glm-4.5-flash","name":"GLM-4.5-Flash","attachment":false,"reasoning":true,"temperature":true,"tool_call":true,"knowledge":"2025-04","release_date":"2025-07-28","last_updated":"2025-07-28","modalities":{"input":["text"],"output":["text"]},"open_weights":true,"cost":{"input":0,"output":0,"cache_read":0,"cache_write":0},"limit":{"context":131072,"output":98304},"display_name":"GLM-4.5-Flash"},{"id":"glm-4.5","name":"GLM-4.5","attachment":false,"reasoning":true,"temperature":true,"tool_call":true,"knowledge":"2025-04","release_date":"2025-07-28","last_updated":"2025-07-28","modalities":{"input":["text"],"output":["text"]},"open_weights":true,"cost":{"input":0.6,"output":2.2,"cache_read":0.11,"cache_write":0},"limit":{"context":131072,"output":98304},"display_name":"GLM-4.5"},{"id":"glm-4.5-air","name":"GLM-4.5-Air","attachment":false,"reasoning":true,"temperature":true,"tool_call":true,"knowledge":"2025-04","release_date":"2025-07-28","last_updated":"2025-07-28","modalities":{"input":["text"],"output":["text"]},"open_weights":true,"cost":{"input":0.2,"output":1.1,"cache_read":0.03,"cache_write":0},"limit":{"context":131072,"output":98304},"display_name":"GLM-4.5-Air"},{"id":"glm-4.5v","name":"GLM 4.5V","attachment":true,"reasoning":true,"temperature":true,"tool_call":true,"knowledge":"2025-04","release_date":"2025-08-11","last_updated":"2025-08-11","modalities":{"input":["text","image","video"],"output":["text"]},"open_weights":true,"cost":{"input":0.6,"output":1.8},"limit":{"context":64000,"output":16384},"display_name":"GLM 4.5V"},{"id":"glm-4.6","name":"GLM-4.6","attachment":false,"reasoning":true,"temperature":true,"tool_call":true,"knowledge":"2025-04","release_date":"2025-09-30","last_updated":"2025-09-30","modalities":{"input":["text"],"output":["text"]},"open_weights":true,"cost":{"input":0.6,"output":2.2,"cache_read":0.11,"cache_write":0},"limit":{"context":204800,"output":131072},"display_name":"GLM-4.6"}]},"inference":{"id":"inference","api":"https://inference.net/v1","name":"Inference","doc":"https://inference.net/models","display_name":"Inference","models":[{"id":"mistral/mistral-nemo-12b-instruct","name":"Mistral Nemo 12B Instruct","attachment":false,"reasoning":false,"temperature":true,"tool_call":true,"knowledge":"2024-12","release_date":"2025-01-01","last_updated":"2025-01-01","modalities":{"input":["text"],"output":["text"]},"open_weights":true,"cost":{"input":0.038,"output":0.1},"limit":{"context":16000,"output":4096},"display_name":"Mistral Nemo 12B Instruct"},{"id":"google/gemma-3","name":"Google Gemma 3","attachment":true,"reasoning":false,"temperature":true,"tool_call":true,"knowledge":"2024-12","release_date":"2025-01-01","last_updated":"2025-01-01","modalities":{"input":["text","image"],"output":["text"]},"open_weights":true,"cost":{"input":0.15,"output":0.3},"limit":{"context":125000,"output":4096},"display_name":"Google Gemma 3"},{"id":"osmosis/osmosis-structure-0.6b","name":"Osmosis Structure 0.6B","attachment":false,"reasoning":false,"temperature":true,"tool_call":true,"knowledge":"2024-12","release_date":"2025-01-01","last_updated":"2025-01-01","modalities":{"input":["text"],"output":["text"]},"open_weights":true,"cost":{"input":0.1,"output":0.5},"limit":{"context":4000,"output":2048},"display_name":"Osmosis Structure 0.6B"},{"id":"qwen/qwen3-embedding-4b","name":"Qwen 3 Embedding 4B","attachment":false,"reasoning":false,"temperature":false,"tool_call":false,"knowledge":"2024-12","release_date":"2025-01-01","last_updated":"2025-01-01","modalities":{"input":["text"],"output":["text"]},"open_weights":true,"cost":{"input":0.01,"output":0},"limit":{"context":32000,"output":2048},"display_name":"Qwen 3 Embedding 4B"},{"id":"qwen/qwen-2.5-7b-vision-instruct","name":"Qwen 2.5 7B Vision Instruct","attachment":true,"reasoning":false,"temperature":true,"tool_call":true,"knowledge":"2024-12","release_date":"2025-01-01","last_updated":"2025-01-01","modalities":{"input":["text","image"],"output":["text"]},"open_weights":true,"cost":{"input":0.2,"output":0.2},"limit":{"context":125000,"output":4096},"display_name":"Qwen 2.5 7B Vision Instruct"},{"id":"meta/llama-3.2-11b-vision-instruct","name":"Llama 3.2 11B Vision Instruct","attachment":true,"reasoning":false,"temperature":true,"tool_call":true,"knowledge":"2023-12","release_date":"2025-01-01","last_updated":"2025-01-01","modalities":{"input":["text","image"],"output":["text"]},"open_weights":true,"cost":{"input":0.055,"output":0.055},"limit":{"context":16000,"output":4096},"display_name":"Llama 3.2 11B Vision Instruct"},{"id":"meta/llama-3.1-8b-instruct","name":"Llama 3.1 8B Instruct","attachment":false,"reasoning":false,"temperature":true,"tool_call":true,"knowledge":"2023-12","release_date":"2025-01-01","last_updated":"2025-01-01","modalities":{"input":["text"],"output":["text"]},"open_weights":true,"cost":{"input":0.025,"output":0.025},"limit":{"context":16000,"output":4096},"display_name":"Llama 3.1 8B Instruct"},{"id":"meta/llama-3.2-3b-instruct","name":"Llama 3.2 3B Instruct","attachment":false,"reasoning":false,"temperature":true,"tool_call":true,"knowledge":"2023-12","release_date":"2025-01-01","last_updated":"2025-01-01","modalities":{"input":["text"],"output":["text"]},"open_weights":true,"cost":{"input":0.02,"output":0.02},"limit":{"context":16000,"output":4096},"display_name":"Llama 3.2 3B Instruct"},{"id":"meta/llama-3.2-1b-instruct","name":"Llama 3.2 1B Instruct","attachment":false,"reasoning":false,"temperature":true,"tool_call":true,"knowledge":"2023-12","release_date":"2025-01-01","last_updated":"2025-01-01","modalities":{"input":["text"],"output":["text"]},"open_weights":true,"cost":{"input":0.01,"output":0.01},"limit":{"context":16000,"output":4096},"display_name":"Llama 3.2 1B Instruct"}]},"requesty":{"id":"requesty","api":"https://router.requesty.ai/v1","name":"Requesty","doc":"https://requesty.ai/solution/llm-routing/models","display_name":"Requesty","models":[{"id":"google/gemini-2.5-flash","name":"Gemini 2.5 Flash","attachment":true,"reasoning":true,"temperature":true,"tool_call":true,"knowledge":"2025-01","release_date":"2025-06-17","last_updated":"2025-06-17","modalities":{"input":["text","image","audio","video","pdf"],"output":["text"]},"open_weights":false,"cost":{"input":0.3,"output":2.5,"cache_read":0.075,"cache_write":0.55},"limit":{"context":1048576,"output":65536},"display_name":"Gemini 2.5 Flash"},{"id":"google/gemini-2.5-pro","name":"Gemini 2.5 Pro","attachment":true,"reasoning":true,"temperature":true,"tool_call":true,"knowledge":"2025-01","release_date":"2025-06-17","last_updated":"2025-06-17","modalities":{"input":["text","image","audio","video","pdf"],"output":["text"]},"open_weights":false,"cost":{"input":1.25,"output":10,"cache_read":0.31,"cache_write":2.375},"limit":{"context":1048576,"output":65536},"display_name":"Gemini 2.5 Pro"},{"id":"openai/gpt-4.1-mini","name":"GPT-4.1 Mini","attachment":true,"reasoning":false,"temperature":true,"tool_call":true,"knowledge":"2024-04","release_date":"2025-04-14","last_updated":"2025-04-14","modalities":{"input":["text","image"],"output":["text"]},"open_weights":false,"cost":{"input":0.4,"output":1.6,"cache_read":0.1},"limit":{"context":1047576,"output":32768},"display_name":"GPT-4.1 Mini"},{"id":"openai/gpt-5-nano","name":"GPT-5 Nano","attachment":true,"reasoning":true,"temperature":false,"tool_call":true,"knowledge":"2024-05-30","release_date":"2025-08-07","last_updated":"2025-08-07","modalities":{"input":["text"],"output":["text"]},"open_weights":false,"cost":{"input":0.05,"output":0.4,"cache_read":0.01},"limit":{"context":16000,"output":4000},"display_name":"GPT-5 Nano"},{"id":"openai/gpt-4.1","name":"GPT-4.1","attachment":true,"reasoning":false,"temperature":true,"tool_call":true,"knowledge":"2024-04","release_date":"2025-04-14","last_updated":"2025-04-14","modalities":{"input":["text","image"],"output":["text"]},"open_weights":false,"cost":{"input":2,"output":8,"cache_read":0.5},"limit":{"context":1047576,"output":32768},"display_name":"GPT-4.1"},{"id":"openai/o4-mini","name":"o4 Mini","attachment":true,"reasoning":true,"temperature":true,"tool_call":true,"knowledge":"2024-06","release_date":"2025-04-16","last_updated":"2025-04-16","modalities":{"input":["text","image"],"output":["text"]},"open_weights":false,"cost":{"input":1.1,"output":4.4,"cache_read":0.28},"limit":{"context":200000,"output":100000},"display_name":"o4 Mini"},{"id":"openai/gpt-5-mini","name":"GPT-5 Mini","attachment":true,"reasoning":true,"temperature":false,"tool_call":true,"knowledge":"2024-05-30","release_date":"2025-08-07","last_updated":"2025-08-07","modalities":{"input":["text","image"],"output":["text"]},"open_weights":false,"cost":{"input":0.25,"output":2,"cache_read":0.03},"limit":{"context":128000,"output":32000},"display_name":"GPT-5 Mini"},{"id":"openai/gpt-4o-mini","name":"GPT-4o Mini","attachment":true,"reasoning":false,"temperature":true,"tool_call":true,"knowledge":"2024-10","release_date":"2024-07-18","last_updated":"2024-07-18","modalities":{"input":["text","image"],"output":["text"]},"open_weights":false,"cost":{"input":0.15,"output":0.6,"cache_read":0.08},"limit":{"context":128000,"output":16384},"display_name":"GPT-4o Mini"},{"id":"openai/gpt-5","name":"GPT-5","attachment":true,"reasoning":true,"temperature":false,"tool_call":true,"knowledge":"2024-09-30","release_date":"2025-08-07","last_updated":"2025-08-07","modalities":{"input":["text","audio","image","video"],"output":["text","audio","image"]},"open_weights":false,"cost":{"input":1.25,"output":10,"cache_read":0.13},"limit":{"context":400000,"output":128000},"display_name":"GPT-5"},{"id":"anthropic/claude-opus-4","name":"Claude Opus 4","attachment":true,"reasoning":true,"temperature":true,"tool_call":true,"knowledge":"2025-03-31","release_date":"2025-05-22","last_updated":"2025-05-22","modalities":{"input":["text","image"],"output":["text"]},"open_weights":false,"cost":{"input":15,"output":75,"cache_read":1.5,"cache_write":18.75},"limit":{"context":200000,"output":32000},"display_name":"Claude Opus 4"},{"id":"anthropic/claude-3-7-sonnet","name":"Claude Sonnet 3.7","attachment":true,"reasoning":true,"temperature":true,"tool_call":true,"knowledge":"2024-01","release_date":"2025-02-19","last_updated":"2025-02-19","modalities":{"input":["text","image"],"output":["text"]},"open_weights":false,"cost":{"input":3,"output":15,"cache_read":0.3,"cache_write":3.75},"limit":{"context":200000,"output":64000},"display_name":"Claude Sonnet 3.7"},{"id":"anthropic/claude-4-sonnet-20250522","name":"Claude Sonnet 4","attachment":true,"reasoning":true,"temperature":true,"tool_call":true,"knowledge":"2025-03-31","release_date":"2025-05-22","last_updated":"2025-05-22","modalities":{"input":["text","image"],"output":["text"]},"open_weights":false,"cost":{"input":3,"output":15,"cache_read":0.3,"cache_write":3.75},"limit":{"context":200000,"output":64000},"display_name":"Claude Sonnet 4"},{"id":"anthropic/claude-opus-4-1-20250805","name":"Claude Opus 4.1","attachment":true,"reasoning":true,"temperature":true,"tool_call":true,"knowledge":"2025-03-31","release_date":"2025-08-05","last_updated":"2025-08-05","modalities":{"input":["text","image"],"output":["text"]},"open_weights":false,"cost":{"input":15,"output":75,"cache_read":1.5,"cache_write":18.75},"limit":{"context":200000,"output":32000},"display_name":"Claude Opus 4.1"}]},"morph":{"id":"morph","api":"https://api.morphllm.com/v1","name":"Morph","doc":"https://docs.morphllm.com/api-reference/introduction","display_name":"Morph","models":[{"id":"morph-v3-large","name":"Morph v3 Large","attachment":false,"reasoning":false,"temperature":false,"tool_call":false,"release_date":"2024-08-15","last_updated":"2024-08-15","modalities":{"input":["text"],"output":["text"]},"open_weights":false,"cost":{"input":0.9,"output":1.9},"limit":{"context":32000,"output":32000},"display_name":"Morph v3 Large"},{"id":"auto","name":"Auto","attachment":false,"reasoning":false,"temperature":false,"tool_call":false,"release_date":"2024-06-01","last_updated":"2024-06-01","modalities":{"input":["text"],"output":["text"]},"open_weights":false,"cost":{"input":0.85,"output":1.55},"limit":{"context":32000,"output":32000},"display_name":"Auto"},{"id":"morph-v3-fast","name":"Morph v3 Fast","attachment":false,"reasoning":false,"temperature":false,"tool_call":false,"release_date":"2024-08-15","last_updated":"2024-08-15","modalities":{"input":["text"],"output":["text"]},"open_weights":false,"cost":{"input":0.8,"output":1.2},"limit":{"context":16000,"output":16000},"display_name":"Morph v3 Fast"}]},"lmstudio":{"id":"lmstudio","api":"http://127.0.0.1:1234/v1","name":"LMStudio","doc":"https://lmstudio.ai/models","display_name":"LMStudio","models":[{"id":"openai/gpt-oss-20b","name":"GPT OSS 20B","attachment":false,"reasoning":true,"temperature":true,"tool_call":true,"release_date":"2025-08-05","last_updated":"2025-08-05","modalities":{"input":["text"],"output":["text"]},"open_weights":true,"cost":{"input":0,"output":0},"limit":{"context":131072,"output":32768},"display_name":"GPT OSS 20B"},{"id":"qwen/qwen3-30b-a3b-2507","name":"Qwen3 30B A3B 2507","attachment":false,"reasoning":false,"temperature":true,"tool_call":true,"knowledge":"2025-04","release_date":"2025-07-30","last_updated":"2025-07-30","modalities":{"input":["text"],"output":["text"]},"open_weights":true,"cost":{"input":0,"output":0},"limit":{"context":262144,"output":16384},"display_name":"Qwen3 30B A3B 2507"},{"id":"qwen/qwen3-coder-30b","name":"Qwen3 Coder 30B","attachment":false,"reasoning":false,"temperature":true,"tool_call":true,"knowledge":"2025-04","release_date":"2025-07-23","last_updated":"2025-07-23","modalities":{"input":["text"],"output":["text"]},"open_weights":true,"cost":{"input":0,"output":0},"limit":{"context":262144,"output":65536},"display_name":"Qwen3 Coder 30B"}]},"anthropic":{"id":"anthropic","name":"Anthropic","doc":"https://docs.anthropic.com/en/docs/about-claude/models","display_name":"Anthropic","models":[{"id":"claude-3-5-sonnet-20241022","name":"Claude Sonnet 3.5 v2","attachment":true,"reasoning":false,"temperature":true,"tool_call":true,"knowledge":"2024-04-30","release_date":"2024-10-22","last_updated":"2024-10-22","modalities":{"input":["text","image"],"output":["text"]},"open_weights":false,"cost":{"input":3,"output":15,"cache_read":0.3,"cache_write":3.75},"limit":{"context":200000,"output":8192},"display_name":"Claude Sonnet 3.5 v2"},{"id":"claude-3-5-sonnet-20240620","name":"Claude Sonnet 3.5","attachment":true,"reasoning":false,"temperature":true,"tool_call":true,"knowledge":"2024-04-30","release_date":"2024-06-20","last_updated":"2024-06-20","modalities":{"input":["text","image"],"output":["text"]},"open_weights":false,"cost":{"input":3,"output":15,"cache_read":0.3,"cache_write":3.75},"limit":{"context":200000,"output":8192},"display_name":"Claude Sonnet 3.5"},{"id":"claude-3-opus-20240229","name":"Claude Opus 3","attachment":true,"reasoning":false,"temperature":true,"tool_call":true,"knowledge":"2023-08-31","release_date":"2024-02-29","last_updated":"2024-02-29","modalities":{"input":["text","image"],"output":["text"]},"open_weights":false,"cost":{"input":15,"output":75,"cache_read":1.5,"cache_write":18.75},"limit":{"context":200000,"output":4096},"display_name":"Claude Opus 3"},{"id":"claude-sonnet-4-5-20250929","name":"Claude Sonnet 4.5","attachment":true,"reasoning":true,"temperature":true,"tool_call":true,"knowledge":"2025-07-31","release_date":"2025-09-29","last_updated":"2025-09-29","modalities":{"input":["text","image"],"output":["text"]},"open_weights":false,"cost":{"input":3,"output":15,"cache_read":0.3,"cache_write":3.75},"limit":{"context":200000,"output":64000},"display_name":"Claude Sonnet 4.5"},{"id":"claude-sonnet-4-20250514","name":"Claude Sonnet 4","attachment":true,"reasoning":true,"temperature":true,"tool_call":true,"knowledge":"2025-03-31","release_date":"2025-05-22","last_updated":"2025-05-22","modalities":{"input":["text","image"],"output":["text"]},"open_weights":false,"cost":{"input":3,"output":15,"cache_read":0.3,"cache_write":3.75},"limit":{"context":200000,"output":64000},"display_name":"Claude Sonnet 4"},{"id":"claude-opus-4-20250514","name":"Claude Opus 4","attachment":true,"reasoning":true,"temperature":true,"tool_call":true,"knowledge":"2025-03-31","release_date":"2025-05-22","last_updated":"2025-05-22","modalities":{"input":["text","image"],"output":["text"]},"open_weights":false,"cost":{"input":15,"output":75,"cache_read":1.5,"cache_write":18.75},"limit":{"context":200000,"output":32000},"display_name":"Claude Opus 4"},{"id":"claude-3-5-haiku-20241022","name":"Claude Haiku 3.5","attachment":true,"reasoning":false,"temperature":true,"tool_call":true,"knowledge":"2024-07-31","release_date":"2024-10-22","last_updated":"2024-10-22","modalities":{"input":["text","image"],"output":["text"]},"open_weights":false,"cost":{"input":0.8,"output":4,"cache_read":0.08,"cache_write":1},"limit":{"context":200000,"output":8192},"display_name":"Claude Haiku 3.5"},{"id":"claude-3-haiku-20240307","name":"Claude Haiku 3","attachment":true,"reasoning":false,"temperature":true,"tool_call":true,"knowledge":"2023-08-31","release_date":"2024-03-13","last_updated":"2024-03-13","modalities":{"input":["text","image"],"output":["text"]},"open_weights":false,"cost":{"input":0.25,"output":1.25,"cache_read":0.03,"cache_write":0.3},"limit":{"context":200000,"output":4096},"display_name":"Claude Haiku 3"},{"id":"claude-3-7-sonnet-20250219","name":"Claude Sonnet 3.7","attachment":true,"reasoning":true,"temperature":true,"tool_call":true,"knowledge":"2024-10-31","release_date":"2025-02-19","last_updated":"2025-02-19","modalities":{"input":["text","image"],"output":["text"]},"open_weights":false,"cost":{"input":3,"output":15,"cache_read":0.3,"cache_write":3.75},"limit":{"context":200000,"output":64000},"display_name":"Claude Sonnet 3.7"},{"id":"claude-opus-4-1-20250805","name":"Claude Opus 4.1","attachment":true,"reasoning":true,"temperature":true,"tool_call":true,"knowledge":"2025-03-31","release_date":"2025-08-05","last_updated":"2025-08-05","modalities":{"input":["text","image"],"output":["text"]},"open_weights":false,"cost":{"input":15,"output":75,"cache_read":1.5,"cache_write":18.75},"limit":{"context":200000,"output":32000},"display_name":"Claude Opus 4.1"},{"id":"claude-3-sonnet-20240229","name":"Claude Sonnet 3","attachment":true,"reasoning":false,"temperature":true,"tool_call":true,"knowledge":"2023-08-31","release_date":"2024-03-04","last_updated":"2024-03-04","modalities":{"input":["text","image"],"output":["text"]},"open_weights":false,"cost":{"input":3,"output":15,"cache_read":0.3,"cache_write":0.3},"limit":{"context":200000,"output":4096},"display_name":"Claude Sonnet 3"}]},"fireworks-ai":{"id":"fireworks-ai","api":"https://api.fireworks.ai/inference/v1/","name":"Fireworks AI","doc":"https://fireworks.ai/docs/","display_name":"Fireworks AI","models":[{"id":"accounts/fireworks/models/deepseek-r1-0528","name":"Deepseek R1 05/28","attachment":false,"reasoning":true,"temperature":true,"tool_call":true,"knowledge":"2025-05","release_date":"2025-05-28","last_updated":"2025-05-28","modalities":{"input":["text"],"output":["text"]},"open_weights":true,"cost":{"input":3,"output":8},"limit":{"context":160000,"output":16384},"display_name":"Deepseek R1 05/28"},{"id":"accounts/fireworks/models/deepseek-v3p1","name":"DeepSeek V3.1","attachment":false,"reasoning":true,"temperature":true,"tool_call":true,"knowledge":"2025-07","release_date":"2025-08-21","last_updated":"2025-08-21","modalities":{"input":["text"],"output":["text"]},"open_weights":true,"cost":{"input":0.56,"output":1.68},"limit":{"context":163840,"output":163840},"display_name":"DeepSeek V3.1"},{"id":"accounts/fireworks/models/deepseek-v3-0324","name":"Deepseek V3 03-24","attachment":false,"reasoning":false,"temperature":true,"tool_call":true,"knowledge":"2024-10","release_date":"2025-03-24","last_updated":"2025-03-24","modalities":{"input":["text"],"output":["text"]},"open_weights":true,"cost":{"input":0.9,"output":0.9},"limit":{"context":160000,"output":16384},"display_name":"Deepseek V3 03-24"},{"id":"accounts/fireworks/models/kimi-k2-instruct","name":"Kimi K2 Instruct","attachment":false,"reasoning":false,"temperature":true,"tool_call":true,"knowledge":"2024-10","release_date":"2025-07-11","last_updated":"2025-07-11","modalities":{"input":["text"],"output":["text"]},"open_weights":true,"cost":{"input":1,"output":3},"limit":{"context":128000,"output":16384},"display_name":"Kimi K2 Instruct"},{"id":"accounts/fireworks/models/qwen3-235b-a22b","name":"Qwen3 235B-A22B","attachment":false,"reasoning":true,"temperature":true,"tool_call":true,"knowledge":"2025-04","release_date":"2025-04-29","last_updated":"2025-04-29","modalities":{"input":["text"],"output":["text"]},"open_weights":true,"cost":{"input":0.22,"output":0.88},"limit":{"context":128000,"output":16384},"display_name":"Qwen3 235B-A22B"},{"id":"accounts/fireworks/models/gpt-oss-20b","name":"GPT OSS 20B","attachment":false,"reasoning":true,"temperature":true,"tool_call":true,"release_date":"2025-08-05","last_updated":"2025-08-05","modalities":{"input":["text"],"output":["text"]},"open_weights":true,"cost":{"input":0.05,"output":0.2},"limit":{"context":131072,"output":32768},"display_name":"GPT OSS 20B"},{"id":"accounts/fireworks/models/gpt-oss-120b","name":"GPT OSS 120B","attachment":false,"reasoning":true,"temperature":true,"tool_call":true,"release_date":"2025-08-05","last_updated":"2025-08-05","modalities":{"input":["text"],"output":["text"]},"open_weights":true,"cost":{"input":0.15,"output":0.6},"limit":{"context":131072,"output":32768},"display_name":"GPT OSS 120B"},{"id":"accounts/fireworks/models/glm-4p5-air","name":"GLM 4.5 Air","attachment":false,"reasoning":true,"temperature":true,"tool_call":true,"knowledge":"2025-04","release_date":"2025-08-01","last_updated":"2025-08-01","modalities":{"input":["text"],"output":["text"]},"open_weights":true,"cost":{"input":0.22,"output":0.88},"limit":{"context":131072,"output":131072},"display_name":"GLM 4.5 Air"},{"id":"accounts/fireworks/models/qwen3-coder-480b-a35b-instruct","name":"Qwen3 Coder 480B A35B Instruct","attachment":false,"reasoning":false,"temperature":true,"tool_call":true,"release_date":"2025-07-22","last_updated":"2025-07-22","modalities":{"input":["text"],"output":["text"]},"open_weights":true,"cost":{"input":0.45,"output":1.8},"limit":{"context":256000,"output":32768},"display_name":"Qwen3 Coder 480B A35B Instruct"},{"id":"accounts/fireworks/models/glm-4p5","name":"GLM 4.5","attachment":false,"reasoning":true,"temperature":true,"tool_call":true,"knowledge":"2025-04","release_date":"2025-07-29","last_updated":"2025-07-29","modalities":{"input":["text"],"output":["text"]},"open_weights":true,"cost":{"input":0.55,"output":2.19},"limit":{"context":131072,"output":131072},"display_name":"GLM 4.5"}]},"modelscope":{"id":"modelscope","api":"https://api-inference.modelscope.cn/v1","name":"ModelScope","doc":"https://modelscope.cn/docs/model-service/API-Inference/intro","display_name":"ModelScope","models":[{"id":"ZhipuAI/GLM-4.5","name":"GLM-4.5","attachment":false,"reasoning":true,"temperature":true,"tool_call":true,"knowledge":"2025-04","release_date":"2025-07-28","last_updated":"2025-07-28","modalities":{"input":["text"],"output":["text"]},"open_weights":true,"cost":{"input":0,"output":0},"limit":{"context":131072,"output":98304},"display_name":"GLM-4.5"},{"id":"Qwen/Qwen3-30B-A3B-Thinking-2507","name":"Qwen3 30B A3B Thinking 2507","attachment":false,"reasoning":true,"temperature":true,"tool_call":true,"knowledge":"2025-04","release_date":"2025-07-30","last_updated":"2025-07-30","modalities":{"input":["text"],"output":["text"]},"open_weights":true,"cost":{"input":0,"output":0},"limit":{"context":262144,"output":32768},"display_name":"Qwen3 30B A3B Thinking 2507"},{"id":"Qwen/Qwen3-235B-A22B-Instruct-2507","name":"Qwen3 235B A22B Instruct 2507","attachment":false,"reasoning":false,"temperature":true,"tool_call":true,"knowledge":"2025-04","release_date":"2025-04-28","last_updated":"2025-07-21","modalities":{"input":["text"],"output":["text"]},"open_weights":true,"cost":{"input":0,"output":0},"limit":{"context":262144,"output":131072},"display_name":"Qwen3 235B A22B Instruct 2507"},{"id":"Qwen/Qwen3-Coder-30B-A3B-Instruct","name":"Qwen3 Coder 30B A3B Instruct","attachment":false,"reasoning":false,"temperature":true,"tool_call":true,"knowledge":"2025-04","release_date":"2025-07-31","last_updated":"2025-07-31","modalities":{"input":["text"],"output":["text"]},"open_weights":true,"cost":{"input":0,"output":0},"limit":{"context":262144,"output":65536},"display_name":"Qwen3 Coder 30B A3B Instruct"},{"id":"Qwen/Qwen3-Coder-480B-A35B-Instruct","name":"Qwen3-Coder-480B-A35B-Instruct","attachment":false,"reasoning":false,"temperature":true,"tool_call":true,"knowledge":"2025-04","release_date":"2025-07-23","last_updated":"2025-07-23","modalities":{"input":["text"],"output":["text"]},"open_weights":true,"cost":{"input":0,"output":0},"limit":{"context":262144,"output":66536},"display_name":"Qwen3-Coder-480B-A35B-Instruct"},{"id":"Qwen/Qwen3-30B-A3B-Instruct-2507","name":"Qwen3 30B A3B Instruct 2507","attachment":false,"reasoning":false,"temperature":true,"tool_call":true,"knowledge":"2025-04","release_date":"2025-07-30","last_updated":"2025-07-30","modalities":{"input":["text"],"output":["text"]},"open_weights":true,"cost":{"input":0,"output":0},"limit":{"context":262144,"output":16384},"display_name":"Qwen3 30B A3B Instruct 2507"},{"id":"Qwen/Qwen3-235B-A22B-Thinking-2507","name":"Qwen3-235B-A22B-Thinking-2507","attachment":false,"reasoning":true,"temperature":true,"tool_call":true,"knowledge":"2025-04","release_date":"2025-07-25","last_updated":"2025-07-25","modalities":{"input":["text"],"output":["text"]},"open_weights":true,"cost":{"input":0,"output":0},"limit":{"context":262144,"output":131072},"display_name":"Qwen3-235B-A22B-Thinking-2507"}]},"llama":{"id":"llama","api":"https://api.llama.com/compat/v1/","name":"Llama","doc":"https://llama.developer.meta.com/docs/models","display_name":"Llama","models":[{"id":"llama-3.3-8b-instruct","name":"Llama-3.3-8B-Instruct","attachment":true,"reasoning":false,"temperature":true,"tool_call":true,"knowledge":"2023-12","release_date":"2024-12-06","last_updated":"2024-12-06","modalities":{"input":["text"],"output":["text"]},"open_weights":true,"cost":{"input":0,"output":0},"limit":{"context":128000,"output":4096},"display_name":"Llama-3.3-8B-Instruct"},{"id":"llama-4-maverick-17b-128e-instruct-fp8","name":"Llama-4-Maverick-17B-128E-Instruct-FP8","attachment":true,"reasoning":false,"temperature":true,"tool_call":true,"knowledge":"2024-08","release_date":"2025-04-05","last_updated":"2025-04-05","modalities":{"input":["text","image"],"output":["text"]},"open_weights":true,"cost":{"input":0,"output":0},"limit":{"context":128000,"output":4096},"display_name":"Llama-4-Maverick-17B-128E-Instruct-FP8"},{"id":"llama-3.3-70b-instruct","name":"Llama-3.3-70B-Instruct","attachment":true,"reasoning":false,"temperature":true,"tool_call":true,"knowledge":"2023-12","release_date":"2024-12-06","last_updated":"2024-12-06","modalities":{"input":["text"],"output":["text"]},"open_weights":true,"cost":{"input":0,"output":0},"limit":{"context":128000,"output":4096},"display_name":"Llama-3.3-70B-Instruct"},{"id":"llama-4-scout-17b-16e-instruct-fp8","name":"Llama-4-Scout-17B-16E-Instruct-FP8","attachment":true,"reasoning":false,"temperature":true,"tool_call":true,"knowledge":"2024-08","release_date":"2025-04-05","last_updated":"2025-04-05","modalities":{"input":["text","image"],"output":["text"]},"open_weights":true,"cost":{"input":0,"output":0},"limit":{"context":128000,"output":4096},"display_name":"Llama-4-Scout-17B-16E-Instruct-FP8"},{"id":"groq-llama-4-maverick-17b-128e-instruct","name":"Groq-Llama-4-Maverick-17B-128E-Instruct","attachment":true,"reasoning":false,"temperature":true,"tool_call":true,"knowledge":"2025-01","release_date":"2025-04-05","last_updated":"2025-04-05","modalities":{"input":["text"],"output":["text"]},"open_weights":true,"cost":{"input":0,"output":0},"limit":{"context":128000,"output":4096},"display_name":"Groq-Llama-4-Maverick-17B-128E-Instruct"},{"id":"cerebras-llama-4-scout-17b-16e-instruct","name":"Cerebras-Llama-4-Scout-17B-16E-Instruct","attachment":true,"reasoning":false,"temperature":true,"tool_call":true,"knowledge":"2025-01","release_date":"2025-04-05","last_updated":"2025-04-05","modalities":{"input":["text"],"output":["text"]},"open_weights":true,"cost":{"input":0,"output":0},"limit":{"context":128000,"output":4096},"display_name":"Cerebras-Llama-4-Scout-17B-16E-Instruct"},{"id":"cerebras-llama-4-maverick-17b-128e-instruct","name":"Cerebras-Llama-4-Maverick-17B-128E-Instruct","attachment":true,"reasoning":false,"temperature":true,"tool_call":true,"knowledge":"2025-01","release_date":"2025-04-05","last_updated":"2025-04-05","modalities":{"input":["text"],"output":["text"]},"open_weights":true,"cost":{"input":0,"output":0},"limit":{"context":128000,"output":4096},"display_name":"Cerebras-Llama-4-Maverick-17B-128E-Instruct"}]},"amazon-bedrock":{"id":"amazon-bedrock","name":"Amazon Bedrock","doc":"https://docs.aws.amazon.com/bedrock/latest/userguide/models-supported.html","display_name":"Amazon Bedrock","models":[{"id":"cohere.command-r-plus-v1:0","name":"Command R+","attachment":false,"reasoning":false,"temperature":true,"tool_call":true,"knowledge":"2024-04","release_date":"2024-04-04","last_updated":"2024-04-04","modalities":{"input":["text"],"output":["text"]},"open_weights":true,"cost":{"input":3,"output":15},"limit":{"context":128000,"output":4096},"display_name":"Command R+"},{"id":"anthropic.claude-v2","name":"Claude 2","attachment":false,"reasoning":false,"temperature":true,"tool_call":false,"knowledge":"2023-08","release_date":"2023-07-11","last_updated":"2023-07-11","modalities":{"input":["text"],"output":["text"]},"open_weights":false,"cost":{"input":8,"output":24},"limit":{"context":100000,"output":4096},"display_name":"Claude 2"},{"id":"anthropic.claude-3-7-sonnet-20250219-v1:0","name":"Claude Sonnet 3.7","attachment":true,"reasoning":false,"temperature":true,"tool_call":true,"knowledge":"2024-04","release_date":"2025-02-19","last_updated":"2025-02-19","modalities":{"input":["text","image"],"output":["text"]},"open_weights":false,"cost":{"input":3,"output":15,"cache_read":0.3,"cache_write":3.75},"limit":{"context":200000,"output":8192},"display_name":"Claude Sonnet 3.7"},{"id":"anthropic.claude-sonnet-4-20250514-v1:0","name":"Claude Sonnet 4","attachment":true,"reasoning":true,"temperature":true,"tool_call":true,"knowledge":"2024-04","release_date":"2025-05-22","last_updated":"2025-05-22","modalities":{"input":["text","image"],"output":["text"]},"open_weights":false,"cost":{"input":3,"output":15,"cache_read":0.3,"cache_write":3.75},"limit":{"context":200000,"output":64000},"display_name":"Claude Sonnet 4"},{"id":"meta.llama3-2-11b-instruct-v1:0","name":"Llama 3.2 11B Instruct","attachment":true,"reasoning":false,"temperature":true,"tool_call":true,"knowledge":"2023-12","release_date":"2024-09-25","last_updated":"2024-09-25","modalities":{"input":["text","image"],"output":["text"]},"open_weights":true,"cost":{"input":0.16,"output":0.16},"limit":{"context":128000,"output":4096},"display_name":"Llama 3.2 11B Instruct"},{"id":"anthropic.claude-3-haiku-20240307-v1:0","name":"Claude Haiku 3","attachment":true,"reasoning":false,"temperature":true,"tool_call":true,"knowledge":"2024-02","release_date":"2024-03-13","last_updated":"2024-03-13","modalities":{"input":["text","image"],"output":["text"]},"open_weights":false,"cost":{"input":0.25,"output":1.25},"limit":{"context":200000,"output":4096},"display_name":"Claude Haiku 3"},{"id":"meta.llama3-2-90b-instruct-v1:0","name":"Llama 3.2 90B Instruct","attachment":true,"reasoning":false,"temperature":true,"tool_call":true,"knowledge":"2023-12","release_date":"2024-09-25","last_updated":"2024-09-25","modalities":{"input":["text","image"],"output":["text"]},"open_weights":true,"cost":{"input":0.72,"output":0.72},"limit":{"context":128000,"output":4096},"display_name":"Llama 3.2 90B Instruct"},{"id":"meta.llama3-2-1b-instruct-v1:0","name":"Llama 3.2 1B Instruct","attachment":false,"reasoning":false,"temperature":true,"tool_call":true,"knowledge":"2023-12","release_date":"2024-09-25","last_updated":"2024-09-25","modalities":{"input":["text"],"output":["text"]},"open_weights":true,"cost":{"input":0.1,"output":0.1},"limit":{"context":131000,"output":4096},"display_name":"Llama 3.2 1B Instruct"},{"id":"anthropic.claude-v2:1","name":"Claude 2.1","attachment":false,"reasoning":false,"temperature":true,"tool_call":false,"knowledge":"2023-08","release_date":"2023-11-21","last_updated":"2023-11-21","modalities":{"input":["text"],"output":["text"]},"open_weights":false,"cost":{"input":8,"output":24},"limit":{"context":200000,"output":4096},"display_name":"Claude 2.1"},{"id":"cohere.command-light-text-v14","name":"Command Light","attachment":false,"reasoning":false,"temperature":true,"tool_call":false,"knowledge":"2023-08","release_date":"2023-11-01","last_updated":"2023-11-01","modalities":{"input":["text"],"output":["text"]},"open_weights":true,"cost":{"input":0.3,"output":0.6},"limit":{"context":4096,"output":4096},"display_name":"Command Light"},{"id":"ai21.jamba-1-5-large-v1:0","name":"Jamba 1.5 Large","attachment":false,"reasoning":false,"temperature":true,"tool_call":true,"knowledge":"2024-08","release_date":"2024-08-15","last_updated":"2024-08-15","modalities":{"input":["text"],"output":["text"]},"open_weights":true,"cost":{"input":2,"output":8},"limit":{"context":256000,"output":4096},"display_name":"Jamba 1.5 Large"},{"id":"meta.llama3-3-70b-instruct-v1:0","name":"Llama 3.3 70B Instruct","attachment":false,"reasoning":false,"temperature":true,"tool_call":true,"knowledge":"2023-12","release_date":"2024-12-06","last_updated":"2024-12-06","modalities":{"input":["text"],"output":["text"]},"open_weights":true,"cost":{"input":0.72,"output":0.72},"limit":{"context":128000,"output":4096},"display_name":"Llama 3.3 70B Instruct"},{"id":"anthropic.claude-3-opus-20240229-v1:0","name":"Claude Opus 3","attachment":true,"reasoning":false,"temperature":true,"tool_call":true,"knowledge":"2023-08","release_date":"2024-02-29","last_updated":"2024-02-29","modalities":{"input":["text","image"],"output":["text"]},"open_weights":false,"cost":{"input":15,"output":75},"limit":{"context":200000,"output":4096},"display_name":"Claude Opus 3"},{"id":"amazon.nova-pro-v1:0","name":"Nova Pro","attachment":true,"reasoning":false,"temperature":true,"tool_call":true,"knowledge":"2024-10","release_date":"2024-12-03","last_updated":"2024-12-03","modalities":{"input":["text","image","video"],"output":["text"]},"open_weights":false,"cost":{"input":0.8,"output":3.2,"cache_read":0.2},"limit":{"context":300000,"output":8192},"display_name":"Nova Pro"},{"id":"meta.llama3-1-8b-instruct-v1:0","name":"Llama 3.1 8B Instruct","attachment":false,"reasoning":false,"temperature":true,"tool_call":true,"knowledge":"2023-12","release_date":"2024-07-23","last_updated":"2024-07-23","modalities":{"input":["text"],"output":["text"]},"open_weights":true,"cost":{"input":0.22,"output":0.22},"limit":{"context":128000,"output":4096},"display_name":"Llama 3.1 8B Instruct"},{"id":"anthropic.claude-3-5-sonnet-20240620-v1:0","name":"Claude Sonnet 3.5","attachment":true,"reasoning":false,"temperature":true,"tool_call":true,"knowledge":"2024-04","release_date":"2024-06-20","last_updated":"2024-06-20","modalities":{"input":["text","image"],"output":["text"]},"open_weights":false,"cost":{"input":3,"output":15,"cache_read":0.3,"cache_write":3.75},"limit":{"context":200000,"output":8192},"display_name":"Claude Sonnet 3.5"},{"id":"cohere.command-r-v1:0","name":"Command R","attachment":false,"reasoning":false,"temperature":true,"tool_call":true,"knowledge":"2024-04","release_date":"2024-03-11","last_updated":"2024-03-11","modalities":{"input":["text"],"output":["text"]},"open_weights":true,"cost":{"input":0.5,"output":1.5},"limit":{"context":128000,"output":4096},"display_name":"Command R"},{"id":"amazon.nova-micro-v1:0","name":"Nova Micro","attachment":false,"reasoning":false,"temperature":true,"tool_call":true,"knowledge":"2024-10","release_date":"2024-12-03","last_updated":"2024-12-03","modalities":{"input":["text"],"output":["text"]},"open_weights":false,"cost":{"input":0.035,"output":0.14,"cache_read":0.00875},"limit":{"context":128000,"output":8192},"display_name":"Nova Micro"},{"id":"meta.llama3-1-70b-instruct-v1:0","name":"Llama 3.1 70B Instruct","attachment":false,"reasoning":false,"temperature":true,"tool_call":true,"knowledge":"2023-12","release_date":"2024-07-23","last_updated":"2024-07-23","modalities":{"input":["text"],"output":["text"]},"open_weights":true,"cost":{"input":0.72,"output":0.72},"limit":{"context":128000,"output":4096},"display_name":"Llama 3.1 70B Instruct"},{"id":"meta.llama3-70b-instruct-v1:0","name":"Llama 3 70B Instruct","attachment":false,"reasoning":false,"temperature":true,"tool_call":false,"knowledge":"2023-12","release_date":"2024-07-23","last_updated":"2024-07-23","modalities":{"input":["text"],"output":["text"]},"open_weights":true,"cost":{"input":2.65,"output":3.5},"limit":{"context":8192,"output":2048},"display_name":"Llama 3 70B Instruct"},{"id":"deepseek.r1-v1:0","name":"DeepSeek-R1","attachment":false,"reasoning":true,"temperature":true,"tool_call":true,"knowledge":"2024-07","release_date":"2025-01-20","last_updated":"2025-05-29","modalities":{"input":["text"],"output":["text"]},"open_weights":false,"cost":{"input":1.35,"output":5.4},"limit":{"context":128000,"output":32768},"display_name":"DeepSeek-R1"},{"id":"anthropic.claude-3-5-sonnet-20241022-v2:0","name":"Claude Sonnet 3.5 v2","attachment":true,"reasoning":false,"temperature":true,"tool_call":true,"knowledge":"2024-04","release_date":"2024-10-22","last_updated":"2024-10-22","modalities":{"input":["text","image"],"output":["text"]},"open_weights":false,"cost":{"input":3,"output":15,"cache_read":0.3,"cache_write":3.75},"limit":{"context":200000,"output":8192},"display_name":"Claude Sonnet 3.5 v2"},{"id":"cohere.command-text-v14","name":"Command","attachment":false,"reasoning":false,"temperature":true,"tool_call":false,"knowledge":"2023-08","release_date":"2023-11-01","last_updated":"2023-11-01","modalities":{"input":["text"],"output":["text"]},"open_weights":true,"cost":{"input":1.5,"output":2},"limit":{"context":4096,"output":4096},"display_name":"Command"},{"id":"anthropic.claude-opus-4-20250514-v1:0","name":"Claude Opus 4","attachment":true,"reasoning":true,"temperature":true,"tool_call":true,"knowledge":"2024-04","release_date":"2025-05-22","last_updated":"2025-05-22","modalities":{"input":["text","image"],"output":["text"]},"open_weights":false,"cost":{"input":15,"output":75,"cache_read":1.5,"cache_write":18.75},"limit":{"context":200000,"output":32000},"display_name":"Claude Opus 4"},{"id":"anthropic.claude-sonnet-4-5-20250929-v1:0","name":"Claude Sonnet 4.5","attachment":true,"reasoning":true,"temperature":true,"tool_call":true,"knowledge":"2025-07-31","release_date":"2025-09-29","last_updated":"2025-09-29","modalities":{"input":["text","image"],"output":["text"]},"open_weights":false,"cost":{"input":3,"output":15,"cache_read":0.3,"cache_write":3.75},"limit":{"context":200000,"output":64000},"display_name":"Claude Sonnet 4.5"},{"id":"meta.llama3-2-3b-instruct-v1:0","name":"Llama 3.2 3B Instruct","attachment":false,"reasoning":false,"temperature":true,"tool_call":true,"knowledge":"2023-12","release_date":"2024-09-25","last_updated":"2024-09-25","modalities":{"input":["text"],"output":["text"]},"open_weights":true,"cost":{"input":0.15,"output":0.15},"limit":{"context":131000,"output":4096},"display_name":"Llama 3.2 3B Instruct"},{"id":"anthropic.claude-instant-v1","name":"Claude Instant","attachment":false,"reasoning":false,"temperature":true,"tool_call":false,"knowledge":"2023-08","release_date":"2023-03-01","last_updated":"2023-03-01","modalities":{"input":["text"],"output":["text"]},"open_weights":false,"cost":{"input":0.8,"output":2.4},"limit":{"context":100000,"output":4096},"display_name":"Claude Instant"},{"id":"amazon.nova-premier-v1:0","name":"Nova Premier","attachment":true,"reasoning":true,"temperature":true,"tool_call":true,"knowledge":"2024-10","release_date":"2024-12-03","last_updated":"2024-12-03","modalities":{"input":["text","image","video"],"output":["text"]},"open_weights":false,"cost":{"input":2.5,"output":12.5},"limit":{"context":1000000,"output":16384},"display_name":"Nova Premier"},{"id":"anthropic.claude-opus-4-1-20250805-v1:0","name":"Claude Opus 4.1","attachment":true,"reasoning":true,"temperature":true,"tool_call":true,"knowledge":"2025-03-31","release_date":"2025-08-05","last_updated":"2025-08-05","modalities":{"input":["text","image"],"output":["text"]},"open_weights":false,"cost":{"input":15,"output":75,"cache_read":1.5,"cache_write":18.75},"limit":{"context":200000,"output":32000},"display_name":"Claude Opus 4.1"},{"id":"meta.llama4-scout-17b-instruct-v1:0","name":"Llama 4 Scout 17B Instruct","attachment":true,"reasoning":false,"temperature":true,"tool_call":true,"knowledge":"2024-08","release_date":"2025-04-05","last_updated":"2025-04-05","modalities":{"input":["text","image"],"output":["text"]},"open_weights":true,"cost":{"input":0.17,"output":0.66},"limit":{"context":3500000,"output":16384},"display_name":"Llama 4 Scout 17B Instruct"},{"id":"ai21.jamba-1-5-mini-v1:0","name":"Jamba 1.5 Mini","attachment":false,"reasoning":false,"temperature":true,"tool_call":true,"knowledge":"2024-08","release_date":"2024-08-15","last_updated":"2024-08-15","modalities":{"input":["text"],"output":["text"]},"open_weights":true,"cost":{"input":0.2,"output":0.4},"limit":{"context":256000,"output":4096},"display_name":"Jamba 1.5 Mini"},{"id":"meta.llama3-8b-instruct-v1:0","name":"Llama 3 8B Instruct","attachment":false,"reasoning":false,"temperature":true,"tool_call":false,"knowledge":"2023-03","release_date":"2024-07-23","last_updated":"2024-07-23","modalities":{"input":["text"],"output":["text"]},"open_weights":true,"cost":{"input":0.3,"output":0.6},"limit":{"context":8192,"output":2048},"display_name":"Llama 3 8B Instruct"},{"id":"anthropic.claude-3-sonnet-20240229-v1:0","name":"Claude Sonnet 3","attachment":true,"reasoning":false,"temperature":true,"tool_call":true,"knowledge":"2023-08","release_date":"2024-03-04","last_updated":"2024-03-04","modalities":{"input":["text","image"],"output":["text"]},"open_weights":false,"cost":{"input":3,"output":15},"limit":{"context":200000,"output":4096},"display_name":"Claude Sonnet 3"},{"id":"meta.llama4-maverick-17b-instruct-v1:0","name":"Llama 4 Maverick 17B Instruct","attachment":true,"reasoning":false,"temperature":true,"tool_call":true,"knowledge":"2024-08","release_date":"2025-04-05","last_updated":"2025-04-05","modalities":{"input":["text","image"],"output":["text"]},"open_weights":true,"cost":{"input":0.24,"output":0.97},"limit":{"context":1000000,"output":16384},"display_name":"Llama 4 Maverick 17B Instruct"},{"id":"amazon.nova-lite-v1:0","name":"Nova Lite","attachment":true,"reasoning":false,"temperature":true,"tool_call":true,"knowledge":"2024-10","release_date":"2024-12-03","last_updated":"2024-12-03","modalities":{"input":["text","image","video"],"output":["text"]},"open_weights":false,"cost":{"input":0.06,"output":0.24,"cache_read":0.015},"limit":{"context":300000,"output":8192},"display_name":"Nova Lite"},{"id":"anthropic.claude-3-5-haiku-20241022-v1:0","name":"Claude Haiku 3.5","attachment":true,"reasoning":false,"temperature":true,"tool_call":true,"knowledge":"2024-07","release_date":"2024-10-22","last_updated":"2024-10-22","modalities":{"input":["text"],"output":["text"]},"open_weights":false,"cost":{"input":0.8,"output":4,"cache_read":0.08,"cache_write":1},"limit":{"context":200000,"output":8192},"display_name":"Claude Haiku 3.5"}]},"cerebras":{"id":"cerebras","name":"Cerebras","doc":"https://inference-docs.cerebras.ai/models/overview","display_name":"Cerebras","models":[{"id":"qwen-3-235b-a22b-instruct-2507","name":"Qwen 3 235B Instruct","attachment":false,"reasoning":false,"temperature":true,"tool_call":true,"knowledge":"2025-04","release_date":"2025-07-22","last_updated":"2025-07-22","modalities":{"input":["text"],"output":["text"]},"open_weights":true,"cost":{"input":0.6,"output":1.2},"limit":{"context":131000,"output":32000},"display_name":"Qwen 3 235B Instruct"},{"id":"qwen-3-coder-480b","name":"Qwen 3 Coder 480B","attachment":false,"reasoning":false,"temperature":true,"tool_call":true,"knowledge":"2025-04","release_date":"2025-07-23","last_updated":"2025-07-23","modalities":{"input":["text"],"output":["text"]},"open_weights":true,"cost":{"input":2,"output":2},"limit":{"context":131000,"output":32000},"display_name":"Qwen 3 Coder 480B"},{"id":"gpt-oss-120b","name":"GPT OSS 120B","attachment":false,"reasoning":true,"temperature":true,"tool_call":true,"release_date":"2025-08-05","last_updated":"2025-08-05","modalities":{"input":["text"],"output":["text"]},"open_weights":true,"cost":{"input":0.25,"output":0.69},"limit":{"context":131072,"output":32768},"display_name":"GPT OSS 120B"}]},"aihubmix":{"id":"aihubmix","name":"aihubmix","display_name":"aihubmix","updated_at":"2025-10-03T14:35:02.904Z","api":"https://aihubmix.com/call/mdl_info","models":[{"id":"AiHubmix-Phi-4-mini-reasoning","name":"Phi-4-mini-reasoning","display_name":"Phi-4-mini-reasoning","type":"chat","context_length":0,"max_output_tokens":0,"capabilities":{"vision":false,"function_calling":false,"reasoning":true,"tool_calling":false},"reasoning":true,"tool_call":false,"metadata":{"developer":"Microsoft","developerId":3,"providerId":45,"modelRatio":0.06,"cacheRatio":1,"completionRatio":1,"description":"Phi-4-mini-reasoning 是一种轻量级开源模型，旨在进行高级数学推理和逻辑密集型问题解决。它特别适用于形式证明、符号计算以及多步骤文字题的解答。凭借高效的架构，该模型在保持高质量推理性能的同时，实现了成本效益的部署，非常适合教育应用、嵌入式辅导以及轻量级边缘或移动系统。\n\nPhi-4-mini-reasoning 支持128K令牌上下文长度，能够处理和推理长篇数学题目与证明。该模型基于合成和高质量数学数据集，通过监督微调和偏好建模等先进微调技术提升推理能力。其训练过程中融入了安全性与对齐协议，确保在支持的用例中表现稳健可靠。","descriptionEn":"Phi-4-mini-reasoning is a lightweight open model designed for advanced mathematical reasoning and logic-intensive problem-solving. It is particularly well-suited for tasks such as formal proofs, symbolic computation, and solving multi-step word problems. With its efficient architecture, the model balances high-quality reasoning performance with cost-effective deployment, making it ideal for educational applications, embedded tutoring, and lightweight edge or mobile systems.\n\nPhi-4-mini-reasoning supports a 128K token context length, enabling it to process and reason over long mathematical problems and proofs. Built on synthetic and high-quality math datasets, the model leverages advanced fine-tuning techniques such as supervised fine-tuning and preference modeling to enhance reasoning capabilities. Its training incorporates safety and alignment protocols, ensuring robust and reliable performance across supported use cases.","order":49,"flag":1,"features":["thinking"],"typeHints":["t2t"],"source":"public-provider-conf"},"vision":false},{"id":"AiHubmix-Phi-4-reasoning","name":"Phi-4-reasoning","display_name":"Phi-4-reasoning","type":"chat","context_length":0,"max_output_tokens":0,"capabilities":{"vision":false,"function_calling":false,"reasoning":true,"tool_calling":false},"reasoning":true,"tool_call":false,"metadata":{"developer":"Microsoft","developerId":3,"providerId":8,"modelRatio":0.1,"cacheRatio":1,"completionRatio":1,"description":"Phi-4-Reasoning 是一种最先进的开源推理模型，基于 Phi-4 经过监督微调而成，使用链式思维轨迹数据集和强化学习进行微调。监督微调的数据集包括合成提示和来自公共网站的高质量过滤数据，重点涉及数学、科学、编码技能以及安全与负责任人工智能的对齐数据。这种方法的目标是确保训练出具有较强能力的小型模型，其数据专注于高质量和高级推理能力。","descriptionEn":"Phi-4-Reasoning is a state-of-the-art open-weight reasoning model finetuned from Phi-4 using supervised fine-tuning on a dataset of chain-of-thought traces and reinforcement learning. The supervised fine-tuning dataset includes a blend of synthetic prompts and high-quality filtered data from public domain websites, focused on math, science, and coding skills as well as alignment data for safety and Responsible AI. The goal of this approach was to ensure that small capable models were trained with data focused on high quality and advanced reasoning.","order":50,"flag":1,"features":["thinking"],"typeHints":["t2t"],"source":"public-provider-conf"},"vision":false},{"id":"ByteDance-Seed/Seed-OSS-36B-Instruct","name":"ByteDance-Seed/Seed-OSS-36B-Instruct","display_name":"ByteDance-Seed/Seed-OSS-36B-Instruct","type":"chat","context_length":0,"max_output_tokens":0,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"developer":"Doubao","developerId":4,"providerId":44,"modelRatio":0.1,"cacheRatio":1,"completionRatio":2.67,"description":"Seed-OSS 是由字节跳动 Seed 团队开发的一系列开源大型语言模型，专为强大的长上下文处理、推理、智能体（agent）和通用能力而设计。该系列中的 Seed-OSS-36B-Instruct 是一个拥有 360 亿参数的指令微调模型，它原生支持超长上下文长度，使其能够一次性处理海量文档或复杂的代码库。该模型在推理、代码生成和智能体任务（如工具使用）方面进行了特别优化，同时保持了平衡且出色的通用能力。此模型的一大特色是“思考预算”（Thinking Budget）功能，允许用户根据需要灵活调整推理长度，从而在实际应用中有效提升推理效率。","descriptionEn":"Seed-OSS is a series of open-source large language models developed by ByteDance's Seed team, designed specifically for powerful long-context processing, reasoning, agents, and general capabilities. Among this series, Seed-OSS-36B-Instruct is an instruction-tuned model with 36 billion parameters that natively supports ultra-long context lengths, enabling it to process massive documents or complex codebases in a single pass. This model is specially optimized for reasoning, code generation, and agent tasks (such as tool usage), while maintaining balanced and excellent general capabilities. A notable feature of this model is the \"Thinking Budget\" functionality, which allows users to flexibly adjust the inference length as needed, thereby effectively improving inference efficiency in practical applications.","order":220,"flag":1,"source":"public-provider-conf"},"vision":false},{"id":"DESCRIBE","name":"describe","display_name":"describe","type":"image-generation","context_length":0,"max_output_tokens":0,"capabilities":{"vision":true,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"modalities":{"input":["text","image"],"output":["text","image"]},"metadata":{"developer":"Ideogram","developerId":21,"providerId":8,"modelRatio":1,"cacheRatio":0,"completionRatio":1,"description":"单张图处理费用为 US $0.01。Ideogram AI 绘图模型的提示词反推（describe）接口，描述大模型看到的画面。\n\n调用示例和计价以文档为准，见 https://docs.aihubmix.com/cn/api/IdeogramAI","descriptionEn":"This endpoint is used to describe an image.\nSupported image formats include JPEG, PNG, and WebP.\nUS $0.01/ IMG.\nFor usage examples and pricing details, refer to the documentation at https://docs.aihubmix.com/cn/api/IdeogramAI.","order":1,"flag":0,"usage":"大陆用户暂时需要开代理，后续支持直连，敬请期待。","displayInput":"-","displayOutput":"$0.01 / IMG","tags":["best"],"modalities":["text","image"],"typeHints":["t2i"],"source":"public-provider-conf"},"vision":true},{"id":"DeepSeek-R1","name":"DeepSeek-R1","display_name":"DeepSeek-R1","type":"chat","context_length":64000,"max_output_tokens":64000,"capabilities":{"vision":false,"function_calling":false,"reasoning":true,"tool_calling":false},"reasoning":true,"tool_call":false,"modalities":{"input":["text"],"output":["text"]},"metadata":{"developer":"DeepSeek","developerId":7,"providerId":36,"modelRatio":0.273,"cacheRatio":1,"completionRatio":4,"description":"已升级至最新版本250528；字节火山云开源部署的满血 R1，总参数量 671B，输入最高 64k。目前最稳定，推荐用这个。","descriptionEn":"DeepSeek-R1 has been automatically upgraded to the latest version 250528;Open-source deployment R1, with a total parameter count of 671B and a maximum input of 64k; currently the most stable, recommended to use this one.","order":820,"flag":2,"features":["thinking"],"tags":["best","economical"],"modalities":["text"],"typeHints":["t2t"],"source":"public-provider-conf"},"vision":false},{"id":"DeepSeek-R1-0528","name":"DeepSeek-R1-0528","display_name":"DeepSeek-R1-0528","type":"chat","context_length":0,"max_output_tokens":0,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"developer":"DeepSeek","developerId":7,"providerId":8,"modelRatio":0.27,"cacheRatio":1,"completionRatio":4,"description":"模型供应商为：sophnet平台。DeepSeek R1 0528 模型在多个方面实现了性能提升，在编程能力、审美设计和代码补全等方面表现出色，尤其在复杂指令处理和前端页面生成上展现了高精度和高效能。\nDeepSeek R1是首个通过纯强化学习（无监督微调）训练的大规模语言模型。\n在强化学习过程中自然形成了多种强大的推理能力。\n通过在强化学习前引入冷启动数据，解决了无限重复、可读性差和语言混杂等问题。\nDeepSeek R1 0528作为DeepSeek R1的升级版，综合能力可与OpenAI-o3 相媲美。","descriptionEn":"The model provider is the Sophnet platform. The DeepSeek R1 0528 model has achieved performance improvements in multiple areas, excelling in programming skills, aesthetic design, and code completion, particularly demonstrating high accuracy and efficiency in handling complex instructions and front-end page generation.\nDeepSeek R1 is the first large-scale language model trained purely through reinforcement learning (without supervised fine-tuning).\nDuring the reinforcement learning process, it naturally developed various powerful reasoning capabilities.\nBy introducing cold-start data before reinforcement learning, it addresses issues such as infinite repetition, poor readability, and language mixing.\nDeepSeek R1 0528, as an upgraded version of DeepSeek R1, has comprehensive capabilities comparable to OpenAI-o3.","order":400,"flag":0,"source":"public-provider-conf"},"vision":false},{"id":"DeepSeek-R1-Distill-Qwen-32B","name":"DeepSeek-R1-Distill-Qwen-32B","display_name":"DeepSeek-R1-Distill-Qwen-32B","type":"chat","context_length":0,"max_output_tokens":0,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"developer":"DeepSeek","developerId":7,"providerId":8,"modelRatio":0.14,"cacheRatio":1,"completionRatio":3,"description":"模型供应商为：sophnet平台。Deepseek-R1-Distill-Qwen-32B 是一个基于 Qwen 2.5 32B 的知识蒸馏大语言模型，使用 DeepSeek R1 的输出进行训练。\nDeepSeek-R1 通过在强化学习前引入冷启动数据，解决了无限重复、可读性差和语言混杂等问题。\nDeepSeek-R1 在数学、编程和推理任务上的表现可与 OpenAI-o1 相媲美。\n为支持研究社区，我们开源了 DeepSeek-R1-Zero、DeepSeek-R1 以及基于 Llama 和 Qwen 的六个密集模型。\nDeepSeek-R1-Distill-Qwen-32B 在多个基准测试中的表现优于 OpenAI-o1-mini，为密集模型创造了新的最佳成绩。\n","descriptionEn":"The model provider is the Sophnet platform. Deepseek-R1-Distill-Qwen-32B is a knowledge-distilled large language model based on Qwen 2.5 32B and trained using outputs from DeepSeek R1.\nDeepSeek-R1 addresses issues such as infinite repetition, poor readability, and language mixing by introducing cold-start data before reinforcement learning.\nDeepSeek-R1’s performance in mathematics, programming, and reasoning tasks is comparable to OpenAI-o1.\nTo support the research community, we have open-sourced DeepSeek-R1-Zero, DeepSeek-R1, and six dense models based on Llama and Qwen.\nDeepSeek-R1-Distill-Qwen-32B outperforms OpenAI-o1-mini on multiple benchmark tests, setting new state-of-the-art results for dense models.","order":400,"flag":0,"source":"public-provider-conf"},"vision":false},{"id":"DeepSeek-R1-Distill-Qwen-7B","name":"DeepSeek-R1-Distill-Qwen-7B","display_name":"DeepSeek-R1-Distill-Qwen-7B","type":"chat","context_length":0,"max_output_tokens":0,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"developer":"DeepSeek","developerId":7,"providerId":8,"modelRatio":0.03,"cacheRatio":1,"completionRatio":2,"description":"模型供应商为：sophnet平台。DeepSeek-R1-Distill-Qwen-7B 是一个基于 Qwen 架构的蒸馏模型，专为高推理速度和低成本优化。在 7B 规模下实现接近原版 70% 的性能，但响应延迟降低40%，适合实时交互场景。\nAPI 调用成本仅为原版 Qwen-7B 的 1/4。\n支持流式输出，适合聊天机器人等应用。\n在 GSM8K 数学任务上准确率超过 65%。","descriptionEn":"The model provider is the Sophnet platform. DeepSeek-R1-Distill-Qwen-7B is a distilled model based on the Qwen architecture, optimized for high reasoning speed and low cost. It achieves approximately 70% of the performance of the original model at the 7B scale, while reducing response latency by 40%, making it suitable for real-time interactive scenarios.\nThe API call cost is only one-quarter of the original Qwen-7B.\nIt supports streaming output, making it suitable for applications like chatbots.\nIt achieves an accuracy of over 65% on the GSM8K math task.","order":400,"flag":0,"source":"public-provider-conf"},"vision":false},{"id":"DeepSeek-V3","name":"DeepSeek-V3","display_name":"DeepSeek-V3","type":"chat","context_length":0,"max_output_tokens":0,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"modalities":{"input":["text"],"output":["text"]},"metadata":{"developer":"DeepSeek","developerId":7,"providerId":36,"modelRatio":0.136,"cacheRatio":1,"completionRatio":4,"description":"字节火山云开源部署目前最稳定，推荐用这个。已经自动升级为最新发布的版本 250324。","descriptionEn":"The open-source deployment is currently the most stable, recommended to use this.\nAutomatically upgraded to the latest released version 250324.","order":700,"flag":2,"tags":["best","economical"],"modalities":["text"],"typeHints":["t2t"],"source":"public-provider-conf"},"vision":false},{"id":"DeepSeek-V3-Fast","name":"DeepSeek-V3-Fast","display_name":"DeepSeek-V3-Fast","type":"chat","context_length":0,"max_output_tokens":0,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"developer":"DeepSeek","developerId":7,"providerId":8,"modelRatio":0.28,"cacheRatio":1,"completionRatio":4,"description":"V3超快版本，当前价格为限时五折，7月31号恢复原价，原价为输入：0.55美元/M，输出：2.2美元/M。模型供应商为：sophnet平台。DeepSeek V3 Fast 是 DeepSeek V3 0324 版本的高TPS极速版，满血非量化，代码与数学能力更强，响应更快！\nDeepSeek V3 0324 是一个强大的专家混合模型(MoE)，总参数量达671B，每个token激活37B参数。\n采用多头潜在注意力(MLA)和DeepSeekMoE架构，实现高效推理和经济的训练成本。\n创新性地采用无辅助损失的负载均衡策略，并设置多token预测训练目标以提升性能。\n在14.8万亿多样化、高质量的token上进行预训练，并通过监督微调和强化学习阶段充分发挥其能力。\n全面评估显示，DeepSeek-V3超越其他开源模型，性能可与领先的闭源模型相媲美。\n仅需2.788M H800 GPU小时即可完成全部训练，且训练过程极其稳定，无不可恢复的损失峰值或回滚。","descriptionEn":"V3 Ultra-Fast Version,The current price is a limited-time 50% discount and will return to the original price on July 31st. The original price is: input: $0.55/M, output: $2.2/M. The model provider is the Sophnet platform. DeepSeek V3 Fast is a high-TPS, ultra-fast version of DeepSeek V3 0324, featuring full-precision (non-quantized) performance, enhanced code and math capabilities, and faster responses!\n\nDeepSeek V3 0324 is a powerful Mixture-of-Experts (MoE) model with a total parameter count of 671B, activating 37B parameters per token.\nIt adopts Multi-Head Latent Attention (MLA) and the DeepSeekMoE architecture to achieve efficient inference and economical training costs.\nIt innovatively implements a load balancing strategy without auxiliary loss and sets multi-token prediction training targets to enhance performance.\nThe model is pre-trained on 14.8 trillion diverse, high-quality tokens and further optimized through supervised fine-tuning and reinforcement learning stages to fully realize its capabilities.\nComprehensive evaluations show that DeepSeek V3 outperforms other open-source models and rivals leading closed-source models in performance.\nThe entire training process only requires 2.788M H800 GPU hours and remains highly stable, with no irrecoverable loss spikes or rollbacks.","order":821,"flag":1,"source":"public-provider-conf"},"vision":false},{"id":"DeepSeek-V3.1","name":"DeepSeek-V3.1","display_name":"DeepSeek-V3.1","type":"chat","context_length":0,"max_output_tokens":0,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"developer":"DeepSeek","developerId":7,"providerId":8,"modelRatio":0.28,"cacheRatio":1,"completionRatio":3,"description":"DeepSeek-V3.1-非思考模式；\nDeepSeek V3.1是深度求索提供的文本生成类模型，拥有混合推理架构，实现了思考模式和非思考模式的有效融合。","descriptionEn":"DeepSeek-V3.1 - Non-Thinking Mode;  \nDeepSeek V3.1 is a text generation model provided by Deep Seek, featuring a hybrid reasoning architecture that effectively integrates thinking and non-thinking modes.","order":972,"flag":1,"source":"public-provider-conf"},"vision":false},{"id":"DeepSeek-V3.1-Fast","name":"DeepSeek-V3.1-Fast","display_name":"DeepSeek-V3.1-Fast","type":"chat","context_length":0,"max_output_tokens":0,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"developer":"DeepSeek","developerId":7,"providerId":8,"modelRatio":0.548,"cacheRatio":1,"completionRatio":3,"description":"模型供应商为：sophnet平台。DeepSeek V3.1 Fast 是 DeepSeek V3.1版本的高TPS极速版。\n混合思考模式：通过更改聊天模板，一个模型可以同时支持思考模式和非思考模式。\n更智能的工具调用：通过后训练优化，模型在工具使用和代理任务中的表现显著提升。","descriptionEn":"The model provider is the Sophon platform. DeepSeek V3.1 Fast is the high-TPS speed version of DeepSeek V3.1.\nHybrid thinking mode: By modifying the chat template, a single model can simultaneously support both thinking and non-thinking modes.\nSmarter tool usage: Through post-training optimization, the model’s performance in tool utilization and agent tasks has improved significantly.\n","order":862,"flag":1,"source":"public-provider-conf"},"vision":false},{"id":"DeepSeek-V3.1-Think","name":"DeepSeek-V3.1-Think","display_name":"DeepSeek-V3.1-Think","type":"chat","context_length":0,"max_output_tokens":0,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"developer":"DeepSeek","developerId":7,"providerId":15,"modelRatio":0.28,"cacheRatio":1,"completionRatio":3,"description":"DeepSeek-V3.1的思考模式；\nDeepSeek V3.1是深度求索提供的文本生成类模型，拥有混合推理架构，实现了思考模式和非思考模式的有效融合。","descriptionEn":"Thinking mode of DeepSeek-V3.1;  \nDeepSeek V3.1 is a text generation model provided by DeepSeek, featuring a hybrid reasoning architecture that achieves an effective integration of thinking and non-thinking modes.","order":971,"flag":1,"source":"public-provider-conf"},"vision":false},{"id":"DeepSeek-V3.2-Exp","name":"DeepSeek-V3.2-Exp","display_name":"DeepSeek-V3.2-Exp","type":"chat","context_length":0,"max_output_tokens":0,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"developer":"DeepSeek","developerId":7,"providerId":36,"modelRatio":0.14,"cacheRatio":0.1,"completionRatio":1.5,"description":" DeepSeek-V3.2-Exp 模型官网名字为deepseek-chat，这是一个实验性（Experimental）的版本。作为迈向新一代架构的中间步骤，V3.2-Exp 在 V3.1-Terminus 的基础上引入了 DeepSeek Sparse Attention（一种稀疏注意力机制），针对长文本的训练和推理效率进行了探索性的优化和验证。","descriptionEn":"The model DeepSeek-V3.2-Exp is officially named deepseek-chat on the website. It is an experimental version. As an intermediate step towards the next-generation architecture, V3.2-Exp introduces DeepSeek Sparse Attention (a sparse attention mechanism) based on V3.1-Terminus, exploring and validating exploratory optimizations for training and inference efficiency on long texts.","order":973,"flag":1,"source":"public-provider-conf"},"vision":false},{"id":"DeepSeek-V3.2-Exp-Think","name":"DeepSeek-V3.2-Exp-Think","display_name":"DeepSeek-V3.2-Exp-Think","type":"chat","context_length":0,"max_output_tokens":0,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"developer":"DeepSeek","developerId":7,"providerId":36,"modelRatio":0.14,"cacheRatio":0.1,"completionRatio":1.5,"description":"DeepSeek-V3.2-Exp-Think 模型官方名字为deepseek-reasoner，这是一个实验性（Experimental）的版本。作为迈向新一代架构的中间步骤，V3.2-Exp 在 V3.1-Terminus 的基础上引入了 DeepSeek Sparse Attention（一种稀疏注意力机制），针对长文本的训练和推理效率进行了探索性的优化和验证。","descriptionEn":"The model DeepSeek-V3.2-Exp-Think is officially named deepseek-reasoner. It is an experimental version. As an intermediate step towards the next-generation architecture, V3.2-Exp introduces DeepSeek Sparse Attention (a sparse attention mechanism) based on V3.1-Terminus, exploring and validating exploratory optimizations for training and inference efficiency on long texts.","order":973,"flag":1,"source":"public-provider-conf"},"vision":false},{"id":"DeepSeek-v3","name":"DeepSeek-v3","display_name":"DeepSeek-v3","type":"chat","context_length":0,"max_output_tokens":0,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"developer":"DeepSeek","developerId":7,"providerId":8,"modelRatio":0.136,"cacheRatio":1,"completionRatio":4,"order":0,"flag":0,"source":"public-provider-conf"},"vision":false},{"id":"Doubao-1.5-lite-32k","name":"Doubao-1.5-lite-32k","display_name":"Doubao-1.5-lite-32k","type":"chat","context_length":0,"max_output_tokens":0,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"developer":"Doubao","developerId":4,"providerId":47,"modelRatio":0.025,"cacheRatio":1,"completionRatio":2,"description":"Doubao-1.5-lite，全新一代轻量版模型，极致响应速度，效果与时延均达到全球一流水平。支持32k上下文窗口，输出长度支持最大12k tokens。","descriptionEn":"Doubao-1.5-lite, a brand-new generation of lightweight model, offers exceptional response speed with both performance and latency reaching world-class levels. It supports a 32k context window and an output length of up to 12k tokens.","order":0,"flag":0,"billingConfig":"{\n  \"model_name\": \"Doubao-1.5-lite-32k\",\n  \"default_tier\": \"tier1\",\n  \"token_based_tier_configs\": {\n    \"tier1\": {\n      \"tier_condition\": {\n        \"min_tokens\": 0,\n        \"max_tokens\": -1\n      },\n      \"model_ratio\": 0.020548,\n      \"prompt_tokens_ratio\": 1.0,\n      \"completion_tokens_ratio\": 2.0,\n      \"cached_tokens_ratio\": 0.2\n    }\n  },\n  \"per_unit_price_config\": {\n    \"cache_storage_price\": 0.002329\n  },\n  \"enabled_billing_items\": [\n    \"prompt_tokens\",\n    \"completion_tokens\",\n    \"cached_tokens\",\n    \"cache_storage_hours\"\n  ]\n}","source":"public-provider-conf"},"vision":false},{"id":"Doubao-1.5-pro-256k","name":"Doubao-1.5-pro-256k","display_name":"Doubao-1.5-pro-256k","type":"chat","context_length":0,"max_output_tokens":0,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"developer":"Doubao","developerId":4,"providerId":47,"modelRatio":0.4,"cacheRatio":1,"completionRatio":1.8,"description":"Doubao-1.5-pro-256k，基于Doubao-1.5-Pro全面升级版，整体效果大幅提升10%。支持256k上下文窗口的推理，输出长度支持最大12k tokens。更高性能、更大窗口、超高性价比，适用于更广泛的应用场景。","descriptionEn":"Doubao-1.5-pro-256k, a fully upgraded version based on Doubao-1.5-Pro, delivers an overall performance improvement of 10%. It supports inference with a 256k context window and an output length of up to 12k tokens. With higher performance, larger window size, and exceptional cost-effectiveness, it is suitable for a wider range of application scenarios.","order":0,"flag":0,"billingConfig":"{\n  \"model_name\": \"Doubao-1.5-pro-256k\",\n  \"default_tier\": \"tier1\",\n  \"token_based_tier_configs\": {\n    \"tier1\": {\n      \"tier_condition\": {\n        \"min_tokens\": 0,\n        \"max_tokens\": -1\n      },\n      \"model_ratio\": 0.342466,\n      \"prompt_tokens_ratio\": 1.0,\n      \"completion_tokens_ratio\": 1.8\n    }\n  },\n  \"per_unit_price_config\": {},\n  \"enabled_billing_items\": [\n    \"prompt_tokens\",\n    \"completion_tokens\"\n  ]\n}","source":"public-provider-conf"},"vision":false},{"id":"Doubao-1.5-pro-32k","name":"Doubao-1.5-pro-32k","display_name":"Doubao-1.5-pro-32k","type":"chat","context_length":0,"max_output_tokens":0,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"developer":"Doubao","developerId":4,"providerId":47,"modelRatio":0.067,"cacheRatio":1,"completionRatio":2.5,"description":"Doubao-1.5-pro，全新一代主力模型，性能全面升级，在知识、代码、推理、等方面表现卓越。支持32k上下文窗口，输出长度支持最大12k tokens。","descriptionEn":"Doubao-1.5-pro, a brand-new generation of flagship model, features comprehensive performance upgrades and excels in knowledge, coding, reasoning, and other aspects. It supports a 32k context window and an output length of up to 12k tokens.","order":0,"flag":0,"billingConfig":"{\n  \"model_name\": \"Doubao-1.5-pro-32k\",\n  \"default_tier\": \"tier1\",\n  \"token_based_tier_configs\": {\n    \"tier1\": {\n      \"tier_condition\": {\n        \"min_tokens\": 0,\n        \"max_tokens\": -1\n      },\n      \"model_ratio\": 0.054795,\n      \"prompt_tokens_ratio\": 1.0,\n      \"completion_tokens_ratio\": 2.5,\n      \"cached_tokens_ratio\": 0.2\n    }\n  },\n  \"per_unit_price_config\": {\n    \"cache_storage_price\": 0.002329\n  },\n  \"enabled_billing_items\": [\n    \"prompt_tokens\",\n    \"completion_tokens\",\n    \"cached_tokens\",\n    \"cache_storage_hours\"\n  ]\n}","source":"public-provider-conf"},"vision":false},{"id":"Doubao-1.5-thinking-pro","name":"Doubao-1.5-thinking-pro","display_name":"Doubao-1.5-thinking-pro","type":"chat","context_length":0,"max_output_tokens":0,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"developer":"Doubao","developerId":4,"providerId":47,"modelRatio":0.31,"cacheRatio":1,"completionRatio":4,"description":"Doubao-1.5全新深度思考模型，在数学、编程、科学推理等专业领域及创意写作等通用任务中表现突出，在AIME 2024、Codeforces、GPQA等多项权威基准上达到或接近业界第一梯队水平。支持128k上下文窗口，16k输出。","descriptionEn":"Doubao-1.5 is a brand-new deep thinking model that excels in specialized fields such as mathematics, programming, scientific reasoning, and general tasks like creative writing. It achieves or approaches the top-tier industry level on multiple authoritative benchmarks including AIME 2024, Codeforces, and GPQA. It supports a 128k context window and 16k output.","order":200,"flag":1,"billingConfig":"{\n  \"model_name\": \"Doubao-1.5-thinking-pro\",\n  \"default_tier\": \"tier1\",\n  \"token_based_tier_configs\": {\n    \"tier1\": {\n      \"tier_condition\": {\n        \"min_tokens\": 0,\n        \"max_tokens\": -1\n      },\n      \"model_ratio\": 0.273973,\n      \"prompt_tokens_ratio\": 1.0,\n      \"completion_tokens_ratio\": 4.0\n    }\n  },\n  \"per_unit_price_config\": {},\n  \"enabled_billing_items\": [\n    \"prompt_tokens\",\n    \"completion_tokens\"\n  ]\n}","source":"public-provider-conf"},"vision":false},{"id":"Doubao-1.5-vision-pro-32k","name":"Doubao-1.5-vision-pro-32k","display_name":"Doubao-1.5-vision-pro-32k","type":"chat","context_length":0,"max_output_tokens":0,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"developer":"Doubao","developerId":4,"providerId":47,"modelRatio":0.23,"cacheRatio":1,"completionRatio":3,"description":"Doubao-1.5-vision-pro，全新升级的多模态大模型，支持任意分辨率和极端长宽比图像识别，增强视觉推理、文档识别、细节信息理解和指令遵循能力。支持32k上下文窗口，输出长度支持最大12k tokens。","descriptionEn":"Doubao-1.5-vision-pro is a newly upgraded multimodal large model that supports image recognition at any resolution and extreme aspect ratios. It enhances visual reasoning, document recognition, detailed information understanding, and instruction-following capabilities. It supports a 32k context window and an output length of up to 12k tokens.","order":0,"flag":0,"source":"public-provider-conf"},"vision":false},{"id":"Doubao-lite-128k","name":"Doubao-lite-128k","display_name":"Doubao-lite-128k","type":"chat","context_length":0,"max_output_tokens":0,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"developer":"字节跳动","developerId":4,"providerId":47,"modelRatio":0.07,"cacheRatio":1,"completionRatio":2,"order":0,"flag":0,"billingConfig":"{\n  \"model_name\": \"Doubao-lite-128k\",\n  \"default_tier\": \"tier1\",\n  \"token_based_tier_configs\": {\n    \"tier1\": {\n      \"tier_condition\": {\n        \"min_tokens\": 0,\n        \"max_tokens\": -1\n      },\n      \"model_ratio\": 0.054795,\n      \"prompt_tokens_ratio\": 1.0,\n      \"completion_tokens_ratio\": 1.25\n    }\n  },\n  \"per_unit_price_config\": {},\n  \"enabled_billing_items\": [\n    \"prompt_tokens\",\n    \"completion_tokens\"\n  ]\n}","source":"public-provider-conf"},"vision":false},{"id":"Doubao-lite-32k","name":"Doubao-lite-32k","display_name":"Doubao-lite-32k","type":"chat","context_length":0,"max_output_tokens":0,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"developer":"字节跳动","developerId":4,"providerId":47,"modelRatio":0.03,"cacheRatio":1,"completionRatio":2,"order":0,"flag":0,"billingConfig":"{\n  \"model_name\": \"Doubao-lite-32k\",\n  \"default_tier\": \"tier1\",\n  \"token_based_tier_configs\": {\n    \"tier1\": {\n      \"tier_condition\": {\n        \"min_tokens\": 0,\n        \"max_tokens\": -1\n      },\n      \"model_ratio\": 0.020548,\n      \"prompt_tokens_ratio\": 1.0,\n      \"completion_tokens_ratio\": 2.0,\n      \"cached_tokens_ratio\": 0.2\n    }\n  },\n  \"per_unit_price_config\": {\n    \"cache_storage_price\": 0.002329\n  },\n  \"enabled_billing_items\": [\n    \"prompt_tokens\",\n    \"completion_tokens\",\n    \"cached_tokens\",\n    \"cache_storage_hours\"\n  ]\n}","source":"public-provider-conf"},"vision":false},{"id":"Doubao-lite-4k","name":"Doubao-lite-4k","display_name":"Doubao-lite-4k","type":"chat","context_length":0,"max_output_tokens":0,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"developer":"字节跳动","developerId":4,"providerId":47,"modelRatio":0.03,"cacheRatio":1,"completionRatio":2,"order":0,"flag":0,"billingConfig":"{\n  \"model_name\": \"Doubao-lite-4k\",\n  \"default_tier\": \"tier1\",\n  \"token_based_tier_configs\": {\n    \"tier1\": {\n      \"tier_condition\": {\n        \"min_tokens\": 0,\n        \"max_tokens\": -1\n      },\n      \"model_ratio\": 0.020548,\n      \"prompt_tokens_ratio\": 1.0,\n      \"completion_tokens_ratio\": 2.0\n    }\n  },\n  \"per_unit_price_config\": {},\n  \"enabled_billing_items\": [\n    \"prompt_tokens\",\n    \"completion_tokens\"\n  ]\n}","source":"public-provider-conf"},"vision":false},{"id":"Doubao-pro-128k","name":"Doubao-pro-128k","display_name":"Doubao-pro-128k","type":"chat","context_length":0,"max_output_tokens":0,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"developer":"字节跳动","developerId":4,"providerId":47,"modelRatio":0.4,"cacheRatio":1,"completionRatio":1.8,"order":0,"flag":0,"source":"public-provider-conf"},"vision":false},{"id":"Doubao-pro-256k","name":"Doubao-pro-256k","display_name":"Doubao-pro-256k","type":"chat","context_length":0,"max_output_tokens":0,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"developer":"字节跳动","developerId":4,"providerId":47,"modelRatio":0.4,"cacheRatio":1,"completionRatio":1.8,"order":0,"flag":0,"billingConfig":"{\n  \"model_name\": \"Doubao-pro-256k\",\n  \"default_tier\": \"tier1\",\n  \"token_based_tier_configs\": {\n    \"tier1\": {\n      \"tier_condition\": {\n        \"min_tokens\": 0,\n        \"max_tokens\": -1\n      },\n      \"model_ratio\": 0.342466,\n      \"prompt_tokens_ratio\": 1.0,\n      \"completion_tokens_ratio\": 1.8\n    }\n  },\n  \"per_unit_price_config\": {},\n  \"enabled_billing_items\": [\n    \"prompt_tokens\",\n    \"completion_tokens\"\n  ]\n}","source":"public-provider-conf"},"vision":false},{"id":"Doubao-pro-32k","name":"Doubao-pro-32k","display_name":"Doubao-pro-32k","type":"chat","context_length":0,"max_output_tokens":0,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"developer":"字节跳动","developerId":4,"providerId":47,"modelRatio":0.07,"cacheRatio":1,"completionRatio":2.5,"order":0,"flag":0,"billingConfig":"{\n  \"model_name\": \"Doubao-pro-32k\",\n  \"default_tier\": \"tier1\",\n  \"token_based_tier_configs\": {\n    \"tier1\": {\n      \"tier_condition\": {\n        \"min_tokens\": 0,\n        \"max_tokens\": -1\n      },\n      \"model_ratio\": 0.054795,\n      \"prompt_tokens_ratio\": 1.0,\n      \"completion_tokens_ratio\": 2.5,\n      \"cached_tokens_ratio\": 0.2\n    }\n  },\n  \"per_unit_price_config\": {\n    \"cache_storage_price\": 0.002329\n  },\n  \"enabled_billing_items\": [\n    \"prompt_tokens\",\n    \"completion_tokens\",\n    \"cached_tokens\",\n    \"cache_storage_hours\"\n  ]\n}","source":"public-provider-conf"},"vision":false},{"id":"Doubao-pro-4k","name":"Doubao-pro-4k","display_name":"Doubao-pro-4k","type":"chat","context_length":0,"max_output_tokens":0,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"developer":"字节跳动","developerId":4,"providerId":47,"modelRatio":0.07,"cacheRatio":1,"completionRatio":2.5,"order":0,"flag":0,"source":"public-provider-conf"},"vision":false},{"id":"FLUX-1.1-pro","name":"FLUX-1.1-pro","display_name":"FLUX-1.1-pro","type":"image-generation","context_length":0,"max_output_tokens":0,"capabilities":{"vision":true,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"modalities":{"input":["text","image"],"output":["text","image"]},"metadata":{"developer":"Flux","developerId":27,"providerId":3,"modelRatio":20,"cacheRatio":0,"completionRatio":1,"order":499,"flag":0,"displayInput":"-","displayOutput":" $0.04 / IMG","modalities":["text","image"],"typeHints":["t2i"],"source":"public-provider-conf"},"vision":true},{"id":"FLUX.1-Kontext-pro","name":"FLUX.1-Kontext-pro","display_name":"FLUX.1-Kontext-pro","type":"image-generation","context_length":0,"max_output_tokens":0,"capabilities":{"vision":true,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"modalities":{"input":["text","image"],"output":["text","image"]},"metadata":{"developer":"Flux","developerId":27,"providerId":45,"modelRatio":20,"cacheRatio":1,"completionRatio":1,"description":"通过文本与图像提示生成并编辑图片。Flux.1 Kontext 是一种多模态流匹配模型，既支持文本到图像的生成，又支持在上下文中进行图像编辑。它能在保持角色一致性的前提下对图像进行修改，并且在局部编辑方面比其他领先模型快 8 倍。","descriptionEn":"Generate and edit images through both text and image prompts. Flux.1 Kontext is a multimodal flow matching model that enables both text-to-image generation and in-context image editing. Modify images while maintaining character consistency and performing local edits up to 8x faster than other leading models.","order":500,"flag":1,"displayInput":"-","displayOutput":"$0.04/ IMG","tags":["best"],"modalities":["text","image"],"typeHints":["t2i"],"source":"public-provider-conf"},"vision":true},{"id":"GLM-4.5","name":"GLM-4.5","display_name":"GLM-4.5","type":"chat","context_length":0,"max_output_tokens":0,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"developer":"ChatGLM","developerId":5,"providerId":8,"modelRatio":0.2,"cacheRatio":1,"completionRatio":4,"description":"GLM-4.5","descriptionEn":"GLM-4.5","order":800,"flag":1,"source":"public-provider-conf"},"vision":false},{"id":"GLM-4.5V","name":"GLM-4.5V","display_name":"GLM-4.5V","type":"chat","context_length":0,"max_output_tokens":0,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"developer":"ChatGLM","developerId":5,"providerId":8,"modelRatio":0.14,"cacheRatio":1,"completionRatio":3,"description":"算能提供","order":851,"flag":1,"source":"public-provider-conf"},"vision":false},{"id":"GPT-OSS-20B","name":"GPT-OSS-20B","display_name":"GPT-OSS-20B","type":"chat","context_length":0,"max_output_tokens":0,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"developer":"OpenAI","developerId":12,"providerId":8,"modelRatio":0.055,"cacheRatio":1,"completionRatio":5,"order":0,"flag":1,"source":"public-provider-conf"},"vision":false},{"id":"Kimi-K2","name":"Kimi-K2","display_name":"Kimi-K2","type":"chat","context_length":0,"max_output_tokens":0,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"developer":"Moonshot AI","developerId":15,"providerId":8,"modelRatio":0.27,"cacheRatio":1,"completionRatio":4,"description":"模型供应商为：sophnet平台。Kimi-K2 是一款具备超强代码和 Agent 能力的 MoE 架构基础模型，总参数 1T，激活参数 32B。在通用知识推理、编程、数学、Agent 等主要类别的基准性能测试中，K2 模型的性能超过其他主流开源模型\nKimi-K2 模型上下文长度为 128k\n不支持视觉功能","descriptionEn":"The model provider is the Sophnet platform. Kimi-K2 is a MoE architecture foundational model with extremely powerful coding and agent capabilities, featuring a total of 1 trillion parameters and activating 32 billion parameters. In benchmark performance tests across major categories such as general knowledge reasoning, programming, mathematics, and agents, the K2 model outperforms other mainstream open-source models.\nThe Kimi-K2 model supports a context length of 128k tokens.\nIt does not support visual capabilities.","order":400,"flag":1,"source":"public-provider-conf"},"vision":false},{"id":"Kimi-K2-0905","name":"Kimi-K2-0905","display_name":"Kimi-K2-0905","type":"chat","context_length":0,"max_output_tokens":0,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"developer":"Moonshot AI","developerId":15,"providerId":8,"modelRatio":0.274,"cacheRatio":1,"completionRatio":4,"description":"模型供应商为：sophnet平台。Kimi-K2-0905 是 Moonshot AI 开发的大规模混合专家 (MoE) 语言模型，总参数量达 1 万亿，每次前向传播有 320 亿个活跃参数。它支持高达 256k 个 token 的长上下文推理，比之前的 128k 有所扩展。","descriptionEn":"The model provider is the Sophnet platform. Kimi-K2-0905 is a large-scale Mixture of Experts (MoE) language model developed by Moonshot AI, with a total of 1 trillion parameters and 32 billion active parameters per forward pass. It supports long-context inference of up to 256k tokens, an expansion from the previous 128k.","order":863,"flag":1,"source":"public-provider-conf"},"vision":false},{"id":"Llama-4-Maverick-17B-128E-Instruct-FP8","name":"Llama-4-Maverick-17B-128E-Instruct-FP8","display_name":"Llama-4-Maverick-17B-128E-Instruct-FP8","type":"chat","context_length":0,"max_output_tokens":0,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"developer":"Llama","developerId":11,"providerId":3,"modelRatio":0.15,"cacheRatio":1,"completionRatio":4,"description":"azure 部署","descriptionEn":"Azure deployment","order":703,"flag":1,"source":"public-provider-conf"},"vision":false},{"id":"LongCat-Flash-Chat","name":"LongCat-Flash-Chat","display_name":"LongCat-Flash-Chat","type":"chat","context_length":0,"max_output_tokens":0,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"developer":"Meituan","developerId":28,"providerId":8,"modelRatio":0.07,"cacheRatio":1,"completionRatio":5,"description":"美团正式发布并开源LongCat-Flash-Chat，通过创新MoE与“零计算专家”机制，实现总参560B但单token仅按需激活约27B参数。与此同时，面向Agent全流程的优化（含自建评测集与多智能体轨迹数据）显著提升其在工具使用与复杂任务编排中的表现。","descriptionEn":"Meituan has officially released and open-sourced LongCat-Flash-Chat, which utilizes an innovative Mixture of Experts (MoE) and \"zero-computation expert\" mechanism to achieve a total of 560B parameters, while only activating around 27B parameters per token as needed. At the same time, end-to-end optimization for agents (including a self-built evaluation set and multi-agent trajectory data) significantly enhances its performance in tool usage and complex task orchestration.","order":700,"flag":1,"source":"public-provider-conf"},"vision":false},{"id":"MiniMax-Text-01","name":"MiniMax-Text-01","display_name":"MiniMax-Text-01","type":"chat","context_length":1000000,"max_output_tokens":1000000,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"modalities":{"input":["text"],"output":["text"]},"metadata":{"developer":"Minimax","developerId":18,"providerId":27,"modelRatio":0.07,"cacheRatio":1,"completionRatio":8,"order":0,"flag":0,"features":["long_context"],"modalities":["text"],"typeHints":["t2t"],"source":"public-provider-conf"},"vision":false},{"id":"MiniMaxAI/MiniMax-M1-80k","name":"MiniMaxAI/MiniMax-M1-80k","display_name":"MiniMaxAI/MiniMax-M1-80k","type":"chat","context_length":0,"max_output_tokens":0,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"developer":"Minimax","developerId":18,"providerId":8,"modelRatio":0.3,"cacheRatio":1,"completionRatio":4,"description":"MiniMax-M1 是一个开源的混合注意力大模型，参数量达 4560 亿（每次推理激活 459 亿）。它原生支持 100 万 Token 的超长上下文，并通过闪电注意力机制，在 10 万 Token 生成任务中比 DeepSeek R1 节省 75% 计算量。采用 MoE 架构和 CISPO 算法优化训练，在长文本推理与软件工程场景中性能领先。","descriptionEn":"MiniMax-M1 is an open-source large-scale hybrid attention model with 456B total parameters (45.9B activated per token). It natively supports 1M-token context and reduces FLOPs by 75% versus DeepSeek R1 in 100K-token generation tasks via lightning attention. Built on MoE architecture and optimized by CISPO algorithm, it achieves state-of-the-art performance in long-context reasoning and real-world software engineering scenarios.","order":100,"flag":1,"source":"public-provider-conf"},"vision":false},{"id":"Pro/THUDM/GLM-4.1V-9B-Thinking","name":"Pro/THUDM/GLM-4.1V-9B-Thinking","display_name":"Pro/THUDM/GLM-4.1V-9B-Thinking","type":"chat","context_length":0,"max_output_tokens":0,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"developer":"ChatGLM","developerId":5,"providerId":16,"modelRatio":0.02,"cacheRatio":0,"completionRatio":4,"description":"GLM-4.1V-9B-Thinking 是由智谱 AI 和清华大学 KEG 实验室联合发布的一款开源视觉语言模型（VLM），专为处理复杂的多模态认知任务而设计。该模型基于 GLM-4-9B-0414 基础模型，通过引入“思维链”（Chain-of-Thought）推理机制和采用强化学习策略，显著提升了其跨模态的推理能力和稳定性。作为一个 9B 参数规模的轻量级模型，它在部署效率和性能之间取得了平衡，在 28 项权威评测基准中，有 18 项的表现持平甚至超越了 72B 参数规模的 Qwen-2.5-VL-72B。该模型不仅在图文理解、数学科学推理、视频理解等任务上表现卓越，还支持高达 4K 分辨率的图像和任意宽高比输入","descriptionEn":"GLM-4.1V-9B-Thinking is an open-source Vision Language Model (VLM) jointly released by Zhipu AI and the KEG Laboratory at Tsinghua University, designed specifically for handling complex multimodal cognitive tasks. Based on the GLM-4-9B-0414 foundation model, it significantly enhances cross-modal reasoning ability and stability by introducing the “Chain-of-Thought” reasoning mechanism and using reinforcement learning strategies. As a lightweight model with 9 billion parameters, it strikes a balance between deployment efficiency and performance. In 28 authoritative benchmark evaluations, it matched or even outperformed the 72-billion-parameter Qwen-2.5-VL-72B model in 18 tasks. The model excels not only in image-text understanding, mathematical and scientific reasoning, and video understanding, but also supports images up to 4K resolution and inputs of arbitrary aspect ratios.","order":34,"flag":1,"source":"public-provider-conf"},"vision":false},{"id":"QwQ-32B","name":"QwQ-32B","display_name":"QwQ-32B","type":"chat","context_length":0,"max_output_tokens":0,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"developer":"Qwen","developerId":13,"providerId":8,"modelRatio":0.14,"cacheRatio":1,"completionRatio":3,"description":"模型供应商为：sophnet平台。QwQ 是千问系列的推理模型，具有出色的思考和推理能力。\n与传统的指令调优模型相比，QwQ 可以在下游任务中实现显著增强的性能，特别是在困难问题上。\nQwQ-32B 是中型推理模型，能够与最先进的推理模型（如 DeepSeek-R1、o1-mini）相比，实现有竞争力的性能。\n支持长上下文，最多可达 128K tokens，并能生成最多 128K tokens 文本。\n","descriptionEn":"The model provider is the Sophnet platform. QwQ is an inference model from the Qianwen series, featuring outstanding thinking and reasoning capabilities.\nCompared to traditional instruction-finetuned models, QwQ can achieve significantly enhanced performance on downstream tasks, especially on difficult problems.\nQwQ-32B is a medium-sized inference model capable of delivering competitive performance compared to state-of-the-art inference models such as DeepSeek-R1 and o1-mini.\nIt supports long context lengths of up to 128K tokens and can generate text up to 128K tokens.","order":400,"flag":0,"source":"public-provider-conf"},"vision":false},{"id":"Qwen/QVQ-72B-Preview","name":"Qwen/QVQ-72B","display_name":"Qwen/QVQ-72B","type":"chat","context_length":0,"max_output_tokens":0,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"developer":"Qwen","developerId":13,"providerId":44,"modelRatio":0.6,"cacheRatio":1,"completionRatio":1,"order":9,"flag":0,"source":"public-provider-conf"},"vision":false},{"id":"Qwen/QwQ-32B","name":"Qwen/QwQ-32B","display_name":"Qwen/QwQ-32B","type":"chat","context_length":0,"max_output_tokens":0,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"developer":"Qwen","developerId":13,"providerId":17,"modelRatio":0.07,"cacheRatio":1,"completionRatio":4,"description":"硅基流动提供","descriptionEn":"Silicon-based flow provision","order":101,"flag":1,"source":"public-provider-conf"},"vision":false},{"id":"Qwen/QwQ-32B-Preview","name":"QwQ-32B-Preview","display_name":"QwQ-32B-Preview","type":"chat","context_length":0,"max_output_tokens":0,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"developer":"Qwen","developerId":13,"providerId":44,"modelRatio":0.08,"cacheRatio":1,"completionRatio":1,"order":8,"flag":0,"source":"public-provider-conf"},"vision":false},{"id":"Qwen/Qwen2-7B-Instruct","name":"Qwen2-7B","display_name":"Qwen2-7B","type":"chat","context_length":0,"max_output_tokens":0,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"developer":"Qwen","developerId":13,"providerId":8,"modelRatio":0.04,"cacheRatio":1,"completionRatio":1,"order":0,"flag":0,"source":"public-provider-conf"},"vision":false},{"id":"Qwen/Qwen2.5-32B-Instruct","name":"Qwen2.5-32B","display_name":"Qwen2.5-32B","type":"chat","context_length":0,"max_output_tokens":0,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"developer":"Qwen","developerId":13,"providerId":8,"modelRatio":0.3,"cacheRatio":1,"completionRatio":1,"order":0,"flag":0,"source":"public-provider-conf"},"vision":false},{"id":"Qwen/Qwen2.5-72B-Instruct","name":"Qwen2.5-72B","display_name":"Qwen2.5-72B","type":"chat","context_length":0,"max_output_tokens":0,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"developer":"Qwen","developerId":13,"providerId":8,"modelRatio":0.4,"cacheRatio":1,"completionRatio":1,"order":0,"flag":0,"source":"public-provider-conf"},"vision":false},{"id":"Qwen/Qwen2.5-72B-Instruct-128K","name":"Qwen2.5-72B","display_name":"Qwen2.5-72B","type":"chat","context_length":0,"max_output_tokens":0,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"developer":"Qwen","developerId":13,"providerId":44,"modelRatio":0.4,"cacheRatio":1,"completionRatio":1,"order":0,"flag":0,"source":"public-provider-conf"},"vision":false},{"id":"Qwen/Qwen2.5-7B-Instruct","name":"Qwen2.5-7B","display_name":"Qwen2.5-7B","type":"chat","context_length":0,"max_output_tokens":0,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"developer":"Qwen","developerId":13,"providerId":8,"modelRatio":0.2,"cacheRatio":1,"completionRatio":1,"order":0,"flag":0,"source":"public-provider-conf"},"vision":false},{"id":"Qwen/Qwen2.5-Coder-32B-Instruct","name":"Qwen2.5-Coder-32B-Instruct","display_name":"Qwen2.5-Coder-32B-Instruct","type":"chat","context_length":0,"max_output_tokens":0,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"developer":"Qwen","developerId":13,"providerId":44,"modelRatio":0.08,"cacheRatio":1,"completionRatio":1,"order":0,"flag":0,"source":"public-provider-conf"},"vision":false},{"id":"Qwen/Qwen2.5-VL-32B-Instruct","name":"Qwen2.5-vl-32b","display_name":"Qwen2.5-vl-32b","type":"chat","context_length":0,"max_output_tokens":0,"capabilities":{"vision":true,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"modalities":{"input":["text","image"],"output":["text","image"]},"metadata":{"developer":"Qwen","developerId":13,"providerId":44,"modelRatio":0.12,"cacheRatio":1,"completionRatio":1,"description":"通义千问团队的Qwen2.5-VL-32B-Instruct是一款先进多模态模型，能识别物体、分析图像文本和图表、操作工具、定位图像对象并生成结构化输出。它通过强化学习改进了数学和问题解决能力，回复风格更简洁自然。","descriptionEn":"Qwen2.5-VL-32B-Instruct is an advanced multimodal model from the Tongyi Qianwen team that can recognize objects, analyze text and graphics in images, operate tools, locate objects in images, and generate structured outputs. Through reinforcement learning, it has improved mathematics and problem-solving capabilities, with a more concise and natural response style.","order":100,"flag":1,"tags":["multi_modal"],"modalities":["text","image"],"typeHints":["t2t"],"source":"public-provider-conf"},"vision":true},{"id":"Qwen/Qwen2.5-VL-72B-Instruct","name":"Qwen2.5-VL-72B","display_name":"Qwen2.5-VL-72B","type":"chat","context_length":128000,"max_output_tokens":128000,"capabilities":{"vision":true,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"modalities":{"input":["text","image"],"output":["text","image"]},"metadata":{"developer":"Qwen","developerId":13,"providerId":44,"modelRatio":0.25,"cacheRatio":0,"completionRatio":1,"description":"来自硅基流动部署；Qwen2.5-VL 是 Qwen2.5 系列的视觉语言模型，具备强大视觉理解和推理能力。它能识别物体、分析文本与图表、理解长视频关键事件，并准确定位图像中的目标。模型支持结构化输出，适用于发票、表格等数据，在多项基准测试中表现优异。","descriptionEn":"Qwen2.5-VL is a visual language model from the Qwen2.5 series, equipped with strong visual understanding and reasoning capabilities. It can recognize objects, analyze text and charts, understand key events in long videos, and accurately locate targets within images. The model supports structured output, making it suitable for data such as invoices and forms, and performs excellently in multiple benchmark tests.","order":290,"flag":0,"tags":["multi_modal"],"modalities":["text","image"],"typeHints":["t2t"],"source":"public-provider-conf"},"vision":true},{"id":"Qwen/Qwen3-14B","name":"Qwen/Qwen3-14B","display_name":"Qwen/Qwen3-14B","type":"chat","context_length":0,"max_output_tokens":0,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"developer":"Qwen","developerId":13,"providerId":8,"modelRatio":0.25,"cacheRatio":1,"completionRatio":1,"description":"由chutes.ai提供","descriptionEn":"Provided by chutes.ai","order":377,"flag":1,"source":"public-provider-conf"},"vision":false},{"id":"Qwen/Qwen3-235B-A22B","name":"Qwen/Qwen3-235B-A22B","display_name":"Qwen/Qwen3-235B-A22B","type":"chat","context_length":0,"max_output_tokens":0,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"developer":"Qwen","developerId":13,"providerId":8,"modelRatio":0.14,"cacheRatio":0,"completionRatio":4,"description":"由chutes.ai提供","descriptionEn":"Provided by chutes.ai","order":500,"flag":1,"source":"public-provider-conf"},"vision":false},{"id":"Qwen/Qwen3-235B-A22B-Instruct-2507","name":"Qwen/Qwen3-235B-A22B-Instruct-2507","display_name":"Qwen/Qwen3-235B-A22B-Instruct-2507","type":"chat","context_length":0,"max_output_tokens":0,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"developer":"Qwen","developerId":13,"providerId":8,"modelRatio":0.2,"cacheRatio":1,"completionRatio":4,"description":"Qwen3-235B-A22B-Instruct-2507 是一个具有 22 亿活跃参数的 235B 参数稀疏 MoE 模型，擅长推理、编码和多语言能力等一般任务，同时支持非常长的 256K 上下文窗口。","descriptionEn":"Qwen3-235B-A22B-Instruct-2507 is a 235B parameter sparse MoE model (with 22B active parameters) that excels at general tasks like reasoning, coding, and multilingual capabilities while supporting a very long 256K context window.","order":600,"flag":1,"source":"public-provider-conf"},"vision":false},{"id":"Qwen/Qwen3-235B-A22B-Thinking-2507","name":"Qwen/Qwen3-235B-A22B-Thinking-2507","display_name":"Qwen/Qwen3-235B-A22B-Thinking-2507","type":"chat","context_length":0,"max_output_tokens":0,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"developer":"Qwen","developerId":13,"providerId":8,"modelRatio":0.14,"cacheRatio":1,"completionRatio":10,"description":"Qwen3-235B-A22B-Thinking-2507 是 Qwen3 的新型号，通过提升 Qwen3-235B-A22B 的思考能力，实现了推理质量和深度的双重提升。","descriptionEn":"Qwen3-235B-A22B-Thinking-2507 is the Qwen3's new model with scaling the thinking capability of Qwen3-235B-A22B, improving both the quality and depth of reasoning.","order":400,"flag":0,"source":"public-provider-conf"},"vision":false},{"id":"Qwen/Qwen3-30B-A3B","name":"Qwen/Qwen3-30B-A3B","display_name":"Qwen/Qwen3-30B-A3B","type":"chat","context_length":0,"max_output_tokens":0,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"developer":"Qwen","developerId":13,"providerId":8,"modelRatio":0.5,"cacheRatio":1,"completionRatio":1,"description":"由chutes.ai提供","descriptionEn":"Provided by chutes.ai","order":399,"flag":1,"source":"public-provider-conf"},"vision":false},{"id":"Qwen/Qwen3-32B","name":"Qwen/Qwen3-32B","display_name":"Qwen/Qwen3-32B","type":"chat","context_length":0,"max_output_tokens":0,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"developer":"Qwen","developerId":13,"providerId":8,"modelRatio":0.25,"cacheRatio":1,"completionRatio":1,"description":"由chutes.ai提供","descriptionEn":"Provided by chutes.ai","order":388,"flag":1,"source":"public-provider-conf"},"vision":false},{"id":"Qwen/Qwen3-8B","name":"Qwen/Qwen3-8B","display_name":"Qwen/Qwen3-8B","type":"chat","context_length":0,"max_output_tokens":0,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"developer":"Qwen","developerId":13,"providerId":8,"modelRatio":0.1,"cacheRatio":1,"completionRatio":1,"description":"由chutes.ai提供","descriptionEn":"Provided by chutes.ai","order":375,"flag":1,"source":"public-provider-conf"},"vision":false},{"id":"Qwen/Qwen3-Coder-30B-A3B-Instruct","name":"Qwen/Qwen3-Coder-30B-A3B-Instruct","display_name":"Qwen/Qwen3-Coder-30B-A3B-Instruct","type":"chat","context_length":0,"max_output_tokens":0,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"developer":"Qwen","developerId":13,"providerId":44,"modelRatio":0.05,"cacheRatio":1,"completionRatio":4,"description":"Qwen3-Coder 是阿里通义千问团队发布的一款高效的代码模型。它体积更小，但性能依然很强。\n\n这个模型在处理 Agentic Coding (智能体编码) 这类复杂任务时，表现很突出，常常优于其他开源模型。\n\n它还能一次性读取大量代码（支持256K文本，可扩展至1M），方便理解整个项目代码。同时，它也为 Qwen Code 和 CLINE 这类智能体平台提供了很好的支持。","descriptionEn":"Qwen3-Coder is an efficient code model from Alibaba's Qwen team. It's built to be smaller but still powerful.\n\nThe model is very good at complex jobs like agentic coding and browser tasks. It often does better than other open-source models on these.\n\nIt can also read a lot of code at once—256K tokens, which can be expanded to 1M. This helps it understand whole code projects. It's designed to work with agent platforms like Qwen Code and CLINE.","order":200,"flag":1,"source":"public-provider-conf"},"vision":false},{"id":"Qwen/Qwen3-Embedding-0.6B","name":"Qwen/Qwen3-Embedding-0.6B","display_name":"Qwen/Qwen3-Embedding-0.6B","type":"embedding","context_length":0,"max_output_tokens":0,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"developer":"Qwen","developerId":13,"providerId":17,"modelRatio":0.0053,"cacheRatio":0,"completionRatio":0,"description":"Qwen3-Embedding-0.6B 是 Qwen3 系列最新的专有嵌入模型，专为文本嵌入与排序设计，拥有 6 亿参数，支持最长 32K 上下文和 1024 维嵌入向量。模型具备卓越的多语言能力（支持 100 多种语言）、长文本理解与推理能力，并在 MTEB 榜单上取得 64.33 的优异成绩。适用于文本/代码检索、分类、聚类等任务，支持自定义输出维度（32-1024）及指令感知，能灵活适配不同应用场景，兼顾效率与效果。","descriptionEn":"Qwen3-Embedding-0.6B is the latest proprietary embedding model in the Qwen3 series, specifically designed for text embedding and ranking. It has 600 million parameters, supports a maximum context length of 32K, and generates embeddings with up to 1024 dimensions. The model boasts excellent multilingual capabilities (supporting over 100 languages), strong long-text understanding and reasoning abilities, and achieved an impressive score of 64.33 on the MTEB leaderboard. It is suitable for tasks such as text/code retrieval, classification, and clustering. The model supports customizable output dimensions (ranging from 32 to 1024) and instruction-awareness, allowing flexible adaptation to different application scenarios, balancing efficiency and effectiveness.","order":60,"flag":1,"typeHints":["embedding"],"source":"public-provider-conf"},"vision":false},{"id":"Qwen2-VL-72B-Instruct","name":"Qwen2-VL-72B-Instruct","display_name":"Qwen2-VL-72B-Instruct","type":"chat","context_length":0,"max_output_tokens":0,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"developer":"Qwen","developerId":13,"providerId":8,"modelRatio":1.09,"cacheRatio":1,"completionRatio":3,"description":"模型供应商为：sophnet平台。Qwen2-VL-72B-Instruct\nQwen2-VL-72B-Instruct是阿里云推出的Qwen2-VL系列最新迭代版本，代表了近一年的创新成果。该模型拥有720亿参数量，能够理解各种分辨率和比例的图像。此外，它还支持超过20分钟的视频理解，可进行高质量的视频问答、对话和内容创建，并具备复杂推理和决策能力。\n\n最先进的图像理解能力：可处理各种分辨率和比例的图像，在多项视觉理解基准测试中表现卓越\n长视频理解：支持超过20分钟的视频理解，可进行高质量的视频问答、对话和内容创建\n代理操作能力：具备复杂推理和决策能力，可与手机、机器人等设备集成，基于视觉环境和文本指令进行自动操作\n多语言支持：除英语和中文外，还支持理解图像中的多种语言文本，包括大多数欧洲语言、日语、韩语、阿拉伯语、越南语等\n支持最大128K上下文长度，处理能力强大\n","descriptionEn":"The model provider is the Sophnet platform. Qwen2-VL-72B-Instruct is the latest iteration in the Qwen2-VL series launched by Alibaba Cloud, representing nearly a year of innovative achievements. This model has 72 billion parameters and can understand images of various resolutions and aspect ratios. Additionally, it supports video understanding of over 20 minutes, enabling high-quality video question answering, dialogue, and content creation, along with complex reasoning and decision-making capabilities.\n\n- State-of-the-art image understanding: capable of processing images of various resolutions and aspect ratios, performing excellently across multiple visual understanding benchmarks.\n- Long video understanding: supports video comprehension exceeding 20 minutes, enabling high-quality video Q&A, dialogues, and content creation.\n- Agent operation capability: equipped with complex reasoning and decision-making abilities, it can integrate with devices such as phones and robots to perform automated operations based on visual environments and textual instructions.\n- Multilingual support: in addition to English and Chinese, it supports understanding text in images in multiple languages, including most European languages, Japanese, Korean, Arabic, Vietnamese, and more.\n- Supports a maximum context length of 128K tokens, offering powerful processing capabilities.","order":400,"flag":0,"source":"public-provider-conf"},"vision":false},{"id":"Qwen2.5-VL-72B-Instruct","name":"Qwen2.5-VL-72B-Instruct","display_name":"Qwen2.5-VL-72B-Instruct","type":"chat","context_length":0,"max_output_tokens":0,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"developer":"Qwen","developerId":13,"providerId":8,"modelRatio":0.31,"cacheRatio":1,"completionRatio":1,"description":"模型供应商为：sophnet平台。Qwen2.5-VL-72B-Instruct是Qwen团队推出的最新视觉语言模型。该模型不仅精通识别花卉、鸟类、鱼类和昆虫等常见物体，还能高效分析图像中的文本、图表、图标、图形和布局。作为视觉代理，它能够推理并动态指导工具使用，支持计算机和手机操作。此外，它还能理解超过1小时的长视频并精确定位相关视频片段。","descriptionEn":"The model provider is the Sophon platform. Qwen2.5-VL-72B-Instruct is the latest vision-language model released by the Qwen team. This model excels not only at recognizing common objects such as flowers, birds, fish, and insects, but also at efficiently analyzing text, charts, icons, graphics, and layouts within images. As a visual agent, it is capable of reasoning and dynamically guiding tool usage, supporting both computer and mobile operations. Moreover, it can understand videos longer than one hour and accurately locate relevant video segments.","order":400,"flag":0,"source":"public-provider-conf"},"vision":false},{"id":"Qwen3-235B-A22B-Instruct-2507","name":"Qwen3-235B-A22B-Instruct-2507","display_name":"Qwen3-235B-A22B-Instruct-2507","type":"chat","context_length":0,"max_output_tokens":0,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"developer":"Qwen","developerId":13,"providerId":8,"modelRatio":0.14,"cacheRatio":1,"completionRatio":4,"description":"Qwen3-235B-A22B-Instruct-2507","descriptionEn":"Qwen3-235B-A22B-Instruct-2507","order":700,"flag":1,"source":"public-provider-conf"},"vision":false},{"id":"Qwen3-235B-A22B-Thinking-2507","name":"Qwen3-235B-A22B-Thinking-2507","display_name":"Qwen3-235B-A22B-Thinking-2507","type":"chat","context_length":0,"max_output_tokens":0,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"developer":"Qwen","developerId":13,"providerId":8,"modelRatio":0.14,"cacheRatio":1,"completionRatio":10,"description":"算能提供","order":0,"flag":1,"source":"public-provider-conf"},"vision":false},{"id":"Qwen3-Coder","name":"Qwen3-Coder","display_name":"Qwen3-Coder","type":"chat","context_length":0,"max_output_tokens":0,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"developer":"Qwen","developerId":13,"providerId":8,"modelRatio":0.27,"cacheRatio":1,"completionRatio":4,"description":"模型供应商为：sophnet平台。Qwen3-Coder-480B-A35B-Instruct 是由 Qwen 团队开发的混合专家 (MoE) 代码生成模型。该模型针对函数调用、工具使用以及基于存储库的长上下文推理等代理编码任务进行了优化。该模型总共包含 4800 亿个参数，每次前向传递有 350 亿个活跃参数（160 位专家中的 8 位）。\n\n在Agentic Coding、Agentic Browser-Use和其他基础编码任务的开放模型中，取得了与 Claude Sonnet 相当的结果；\n原生支持256K 个令牌，使用 Yarn 可扩展至1M 个令牌，并针对存储库规模的理解进行了优化；\n支持Qwen Code、CLINE等大多数平台，具有专门设计的函数调用格式；\n支持 358 种编码语言；","descriptionEn":"The model provider is the Sophnet platform. Qwen3-Coder-480B-A35B-Instruct is a mixture-of-experts (MoE) code generation model developed by the Qwen team. This model is optimized for agent coding tasks such as function calls, tool usage, and repository-based long-context reasoning. It contains a total of 48 billion parameters, with 3.5 billion active parameters per forward pass (8 out of 160 experts).\n\nIt achieves results comparable to Claude Sonnet in open models for Agentic Coding, Agentic Browser-Use, and other fundamental coding tasks.\nIt natively supports 256K tokens and can be scaled up to 1 million tokens using Yarn, with optimizations for understanding repository-scale contexts.\nThe model supports most platforms including Qwen Code and CLINE, featuring specially designed function call formats.\nIt also supports 358 programming languages.","order":703,"flag":0,"source":"public-provider-conf"},"vision":false},{"id":"Qwen3-Next-80B-A3B-Instruct","name":"Qwen3-Next-80B-A3B-Instruct","display_name":"Qwen3-Next-80B-A3B-Instruct","type":"chat","context_length":0,"max_output_tokens":0,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"developer":"Qwen","developerId":13,"providerId":8,"modelRatio":0.069,"cacheRatio":1,"completionRatio":4,"description":"模型供应商为：sophnet平台。Qwen3-Next-80B-A3B-Instruct 是 Qwen3-Next 系列中一个指令调优的聊天模型，经过优化，可实现快速、稳定的响应，且不留“思考”痕迹。它针对推理、代码生成、知识问答和多语言应用等复杂任务，同时在对齐和格式化方面保持稳健。","descriptionEn":"The model provider is the Sophnet platform. Qwen3-Next-80B-A3B-Instruct is an instruction-tuned chat model in the Qwen3-Next series, optimized for fast and stable responses without leaving any \"thinking\" traces. It is designed for complex tasks such as reasoning, code generation, knowledge Q&A, and multilingual applications, while maintaining robustness in alignment and formatting.","order":705,"flag":0,"source":"public-provider-conf"},"vision":false},{"id":"Qwen3-Next-80B-A3B-Thinking","name":"Qwen3-Next-80B-A3B-Thinking","display_name":"Qwen3-Next-80B-A3B-Thinking","type":"chat","context_length":0,"max_output_tokens":0,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"developer":"Qwen","developerId":13,"providerId":8,"modelRatio":0.069,"cacheRatio":1,"completionRatio":10,"description":"模型供应商为：sophnet平台。Qwen3-Next-80B-A3B-Thinking 是 Qwen3-Next 系列中推理优先的聊天模型，默认输出结构化的“思考”轨迹。它专为解决复杂的多步骤问题而设计，例如数学证明、代码合成/调试、逻辑和代理规划，并在知识、推理、编码、对齐和多语言评估方面均取得了优异的成果。","descriptionEn":"The model provider is the Sophnet platform. Qwen3-Next-80B-A3B-Thinking is a reasoning-prioritized chat model in the Qwen3-Next series, which by default outputs structured \"thinking\" trajectories. It is specifically designed to solve complex multi-step problems, such as mathematical proofs, code synthesis/debugging, logic, and agent planning, and has achieved excellent results in knowledge, reasoning, coding, alignment, and multilingual evaluations.","order":705,"flag":0,"source":"public-provider-conf"},"vision":false},{"id":"THUDM/GLM-4-32B-0414","name":"THUDM/GLM-4-32B-0414","display_name":"THUDM/GLM-4-32B-0414","type":"chat","context_length":0,"max_output_tokens":0,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"developer":"ChatGLM","developerId":5,"providerId":44,"modelRatio":0.04,"cacheRatio":1,"completionRatio":1,"description":"GLM-4-32B-0414 是新一代开源大模型，拥有 320 亿参数，性能接近 OpenAI 的 GPT 系列和 DeepSeek V3/R1 系列，并支持本地部署。其基础模型在 15T 高质量数据上预训练，涵盖大量推理类合成数据，为后续强化学习打下基础。\n\n在后训练阶段，团队通过人类反馈对齐、拒绝采样和强化学习等方法，提升了模型在指令理解、代码生成和函数调用等方面的能力，强化了执行复杂任务所需的核心技能。\n\n该模型在工程代码、自动生成 Artifact、函数调用、搜索问答和报告生成等任务上表现优异，在部分评测中甚至接近或超越 GPT-4o 和 DeepSeek-V3（671B 参数）的水平。","descriptionEn":"GLM-4-32B-0414 is a next-generation open-source model with 32 billion parameters, delivering performance comparable to OpenAI’s GPT series and DeepSeek V3/R1. It supports smooth local deployment.\n\nThe base model was pre-trained on 15T of high-quality data, including a large amount of reasoning-focused synthetic content, setting the stage for advanced reinforcement learning.\n\nIn the post-training phase, techniques like human preference alignment, rejection sampling, and reinforcement learning were used to improve the model’s ability to follow instructions, generate code, and handle function calls—core skills needed for agent-style tasks.\n\nGLM-4-32B-0414 has shown strong results in engineering code, artifact generation, function calling, search-based QA, and report writing—sometimes matching or even surpassing larger models like GPT-4o and DeepSeek-V3 (671B) on specific benchmarks.","order":33,"flag":1,"source":"public-provider-conf"},"vision":false},{"id":"THUDM/GLM-4-9B-0414","name":"THUDM/GLM-4-9B-0414","display_name":"THUDM/GLM-4-9B-0414","type":"chat","context_length":0,"max_output_tokens":0,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"developer":"ChatGLM","developerId":5,"providerId":44,"modelRatio":0.025,"cacheRatio":1,"completionRatio":1,"description":"GLM-4-9B-0414 是 GLM 系列的小型模型，拥有 90 亿参数，继承了 GLM-4-32B 的核心技术，适合轻量部署。尽管模型较小，但在代码生成、网页设计、SVG 图形生成和搜索辅助写作等任务上表现出色。\n\n它支持函数调用，可连接外部工具扩展能力，非常适合计算资源有限的场景。在多个基准测试中，GLM-4-9B-0414 展示了强劲的竞争力，是高效且实用的 AI 解决方案。","descriptionEn":"GLM-4-9B-0414 is a lightweight model in the GLM family, with 9 billion parameters. It inherits the core tech from GLM-4-32B and offers an efficient option for deployment on limited resources.\n\nDespite its smaller size, it performs well in tasks like code generation, web design, SVG graphics creation, and search-based writing. It also supports function calling to interact with external tools, enhancing its versatility.\n\nGLM-4-9B-0414 strikes a solid balance between efficiency and performance, making it a strong choice for low-resource environments—while remaining competitive on various benchmarks.","order":30,"flag":1,"source":"public-provider-conf"},"vision":false},{"id":"THUDM/GLM-4.1V-9B-Thinking","name":"THUDM/GLM-4.1V-9B-Thinking","display_name":"THUDM/GLM-4.1V-9B-Thinking","type":"chat","context_length":0,"max_output_tokens":0,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"developer":"ChatGLM","developerId":5,"providerId":16,"modelRatio":0.05,"cacheRatio":0,"completionRatio":1,"description":"GLM-4.1V-9B-Thinking 是由智谱 AI 和清华大学 KEG 实验室联合发布的一款开源视觉语言模型（VLM），专为处理复杂的多模态认知任务而设计。该模型基于 GLM-4-9B-0414 基础模型，通过引入“思维链”（Chain-of-Thought）推理机制和采用强化学习策略，显著提升了其跨模态的推理能力和稳定性。作为一个 9B 参数规模的轻量级模型，它在部署效率和性能之间取得了平衡，在 28 项权威评测基准中，有 18 项的表现持平甚至超越了 72B 参数规模的 Qwen-2.5-VL-72B。该模型不仅在图文理解、数学科学推理、视频理解等任务上表现卓越，还支持高达 4K 分辨率的图像和任意宽高比输入","descriptionEn":"GLM-4.1V-9B-Thinking is an open-source Vision Language Model (VLM) jointly released by Zhipu AI and the KEG Laboratory at Tsinghua University, designed specifically for handling complex multimodal cognitive tasks. Based on the GLM-4-9B-0414 foundation model, it significantly enhances cross-modal reasoning ability and stability by introducing the “Chain-of-Thought” reasoning mechanism and using reinforcement learning strategies. As a lightweight model with 9 billion parameters, it strikes a balance between deployment efficiency and performance. In 28 authoritative benchmark evaluations, it matched or even outperformed the 72-billion-parameter Qwen-2.5-VL-72B model in 18 tasks. The model excels not only in image-text understanding, mathematical and scientific reasoning, and video understanding, but also supports images up to 4K resolution and inputs of arbitrary aspect ratios.","order":34,"flag":1,"source":"public-provider-conf"},"vision":false},{"id":"THUDM/GLM-Z1-32B-0414","name":"THUDM/GLM-Z1-32B-0414","display_name":"THUDM/GLM-Z1-32B-0414","type":"chat","context_length":0,"max_output_tokens":0,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"developer":"ChatGLM","developerId":5,"providerId":16,"modelRatio":0.04,"cacheRatio":1,"completionRatio":1,"description":"GLM-Z1-32B-0414 是一个专注于深度推理的 AI 模型。它基于 GLM-4-32B-0414 开发，通过冷启动和强化学习优化，特别加强了数学、编程和逻辑能力。虽然只有 32B 参数，但在一些任务上已接近 DeepSeek-R1（671B 参数）的表现。它在 AIME 24/25、LiveCodeBench、GPQA 等基准中表现出色，适合处理复杂的数理任务。","descriptionEn":"GLM-Z1-32B-0414 is a reasoning-focused AI model built on GLM-4-32B-0414. It has been enhanced through cold-start methods and reinforcement learning, with a strong emphasis on math, coding, and logic tasks. Despite having only 32B parameters, it performs comparably to the 671B DeepSeek-R1 on some benchmarks. It excels in complex reasoning tasks, as shown in evaluations like AIME 24/25, LiveCodeBench, and GPQA.","order":35,"flag":1,"source":"public-provider-conf"},"vision":false},{"id":"THUDM/GLM-Z1-9B-0414","name":"THUDM/GLM-Z1-9B-0414","display_name":"THUDM/GLM-Z1-9B-0414","type":"chat","context_length":0,"max_output_tokens":0,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"developer":"ChatGLM","developerId":5,"providerId":44,"modelRatio":0.025,"cacheRatio":1,"completionRatio":1,"description":"GLM-Z1-9B-0414 是 GLM 系列的小型模型，参数量为 90 亿，虽小但性能强大。它在数学推理和通用任务中表现优异，在同规模开源模型中处于领先地位。\n\n该模型采用与大模型相同的训练技术，具备良好的泛化能力，尤其适合资源受限的环境。它在保持高性能的同时兼顾运行效率，是轻量部署的理想选择。","descriptionEn":"GLM-Z1-9B-0414 is a small but powerful model in the GLM series, with only 9 billion parameters. Despite its size, it delivers strong performance in math reasoning and general tasks, ranking among the best in its class of open-source models.\n\nTrained with the same techniques as larger models, it strikes an excellent balance between performance and efficiency—making it a great option for low-resource or lightweight deployment scenarios.","order":32,"flag":1,"source":"public-provider-conf"},"vision":false},{"id":"UPSCALE","name":"upscale","display_name":"upscale","type":"image-generation","context_length":0,"max_output_tokens":0,"capabilities":{"vision":true,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"modalities":{"input":["text","image"],"output":["text","image"]},"metadata":{"developer":"Ideogram","developerId":21,"providerId":8,"modelRatio":1,"cacheRatio":0,"completionRatio":1,"description":"单张图处理费用为 US $0.06。Ideogram AI 绘图模型的超分辨率放大接口（upscale），功能是将低分辨率的图片放大至高分辨率，会重绘细节（相似度和细节比例可控制）。\n\n调用示例和计价以文档为准，见 https://docs.aihubmix.com/cn/api/IdeogramAI","descriptionEn":"The super-resolution upscale interface of the Ideogram AI drawing model is designed to enlarge low-resolution images into high-resolution ones, redrawing details (with controllable similarity and detail proportions).\nUS $0.06/ IMG.\nFor usage examples and pricing details, refer to the documentation at https://docs.aihubmix.com/cn/api/IdeogramAI.","order":1,"flag":0,"usage":"大陆用户暂时需要开代理，后续支持直连，敬请期待。","displayInput":"-","displayOutput":"$0.06 / IMG","tags":["best"],"modalities":["text","image"],"typeHints":["t2i"],"source":"public-provider-conf"},"vision":true},{"id":"V3","name":"generate","display_name":"generate","type":"image-generation","context_length":0,"max_output_tokens":0,"capabilities":{"vision":true,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"modalities":{"input":["text","image"],"output":["text","image"]},"metadata":{"developer":"Ideogram","developerId":21,"providerId":8,"modelRatio":1,"cacheRatio":0,"completionRatio":1,"description":"Ideogram AI 最强模型上线。\n快速高质 — 最高画质平均 11 秒/张，批量生成几乎不额外耗时。\n比例灵活 — 支持 3:1、2:1 等超宽或超高画幅，视角多样丰富。\n独特优势 — 设计能力突出，文字绘制表现强劲。\n局部编辑 — 精准遮罩控制重绘区域（edit），背景替换更随心（replace-background）。","descriptionEn":"Fast and high-quality — top image quality in just 11 seconds per piece, with almost no extra time for batch generation.\nFlexible ratios — supports ultra-wide and tall formats like 3:1, 2:1, offering diverse perspectives.\nUnique strengths — outstanding design capabilities in the V3 and V2 series, with powerful text rendering (Chinese support coming soon).\nPrecise local editing — fine-tuned mask control for area redrawing (edit) and easy background replacement (replace-background).","order":70,"flag":1,"displayInput":"-","displayOutput":"$ 0.09 / IMG (Quality) ","tags":["best"],"modalities":["text","image"],"typeHints":["t2i"],"source":"public-provider-conf"},"vision":true},{"id":"V_1","name":"generate","display_name":"generate","type":"image-generation","context_length":0,"max_output_tokens":0,"capabilities":{"vision":true,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"modalities":{"input":["text","image"],"output":["text","image"]},"metadata":{"developer":"Ideogram","developerId":21,"providerId":8,"modelRatio":1,"cacheRatio":0,"completionRatio":1,"description":"单张图费用为 US $0.06。Ideogram AI 绘图接口上线，该模型文字绘制能力强劲，支持端口：生图 /generate、混合 /remix。\n该模型为初代的 V_1 版本，\n调用示例和计价以文档为准，见 https://docs.aihubmix.com/cn/api/IdeogramAI","descriptionEn":"The Ideogram AI drawing interface is now live. This model boasts powerful text-to-image capabilities, supporting endpoints are: /generate, /remix.\nThis model is the original V_1 version.\nUS $0.06/ IMG.\nFor usage examples and pricing details, refer to the documentation at https://docs.aihubmix.com/cn/api/IdeogramAI.","order":63,"flag":0,"usage":"大陆用户暂时需要开代理，后续支持直连，敬请期待。","displayInput":"-","displayOutput":"$0.06 / IMG","tags":["best"],"modalities":["text","image"],"typeHints":["t2i"],"source":"public-provider-conf"},"vision":true},{"id":"V_1_TURBO","name":"generate","display_name":"generate","type":"image-generation","context_length":0,"max_output_tokens":0,"capabilities":{"vision":true,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"modalities":{"input":["text","image"],"output":["text","image"]},"metadata":{"developer":"Ideogram","developerId":21,"providerId":8,"modelRatio":1,"cacheRatio":0,"completionRatio":1,"description":"单张图费用为 US $0.02。Ideogram AI 绘图接口上线，该模型文字绘制能力强劲，支持端口：生图 /generate、混合 /remix。\n该模型为初代 V_1 的极速版本，速度更快但会稍微降低品质，\n调用示例和计价以文档为准，见 https://docs.aihubmix.com/cn/api/IdeogramAI","descriptionEn":"The Ideogram AI drawing interface is now live. This model boasts powerful text-to-image capabilities, supporting endpoints are: /generate, /remix.\nThis model is the ultra-fast version of the original V_1, offering increased speed at the slight expense of quality.\nUS $0.02/ IMG.\nFor usage examples and pricing details, refer to the documentation at https://docs.aihubmix.com/cn/api/IdeogramAI.","order":62,"flag":0,"usage":"大陆用户暂时需要开代理，后续支持直连，敬请期待。","displayInput":"-","displayOutput":"$0.02 / IMG","tags":["best"],"modalities":["text","image"],"typeHints":["t2i"],"source":"public-provider-conf"},"vision":true},{"id":"V_2","name":"generate","display_name":"generate","type":"image-generation","context_length":0,"max_output_tokens":0,"capabilities":{"vision":true,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"modalities":{"input":["text","image"],"output":["text","image"]},"metadata":{"developer":"Ideogram","developerId":21,"providerId":8,"modelRatio":1,"cacheRatio":0,"completionRatio":1,"description":"单张图费用为 US $0.08。Ideogram AI 绘图接口上线，该模型文字绘制能力强劲，支持端口：生图 /generate、混合 /remix、局部编辑 /edit。\n💡 该模型为稳定的 V_2 版本，编辑特别推荐。\n单张图费用为 US $0.08。\n调用示例和计价以文档为准，见 https://docs.aihubmix.com/cn/api/IdeogramAI","descriptionEn":" The Ideogram AI drawing interface is now live. This model boasts powerful text-to-image capabilities, supporting endpoints are: /generate, /remix, /edit.\nThis model is the stable V_2 version, highly recommended for editing.\nUS $0.08/ 1 IMG.\nFor usage examples and pricing details, refer to the documentation at https://docs.aihubmix.com/cn/api/IdeogramAI.\n","order":69,"flag":2,"usage":"大陆用户暂时需要开代理，后续支持直连，敬请期待。","displayInput":"-","displayOutput":"$0.08 / IMG","tags":["best"],"modalities":["text","image"],"typeHints":["t2i"],"source":"public-provider-conf"},"vision":true},{"id":"V_2A","name":"generate","display_name":"generate","type":"image-generation","context_length":0,"max_output_tokens":0,"capabilities":{"vision":true,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"modalities":{"input":["text","image"],"output":["text","image"]},"metadata":{"developer":"Ideogram","developerId":21,"providerId":8,"modelRatio":1,"cacheRatio":0,"completionRatio":1,"description":"单张图费用为 US $0.04。Ideogram AI 绘图接口上线，该模型文字绘制能力强劲，支持端口：生图 /generate、混合 /remix。\n该模型为 V_2 的快速版本，速度更快，费用更低。\n调用示例和计价以文档为准，见 https://docs.aihubmix.com/cn/api/IdeogramAI","descriptionEn":"The Ideogram AI drawing interface is now live. This model boasts powerful text-to-image capabilities, supporting endpoints are: /generate, /remix.\nThis model is the fast version of V_2, faster and cheaper.\nUS $0.04/ IMG.\nFor usage examples and pricing details, refer to the documentation at https://docs.aihubmix.com/cn/api/IdeogramAI.","order":67,"flag":0,"usage":"大陆用户暂时需要开代理，后续支持直连，敬请期待。","displayInput":"-","displayOutput":"$0.04 / IMG","tags":["best"],"modalities":["text","image"],"typeHints":["t2i"],"source":"public-provider-conf"},"vision":true},{"id":"V_2A_TURBO","name":"generate","display_name":"generate","type":"image-generation","context_length":0,"max_output_tokens":0,"capabilities":{"vision":true,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"modalities":{"input":["text","image"],"output":["text","image"]},"metadata":{"developer":"Ideogram","developerId":21,"providerId":8,"modelRatio":1,"cacheRatio":0,"completionRatio":1,"description":"单张图费用为 US $0.025。Ideogram AI 绘图接口上线，该模型文字绘制能力强劲，支持端口：生图 /generate、混合 /remix。\n该模型为 V_2 的极速版本，速度最快但会稍微降低品质。\n\n调用示例和计价以文档为准，见 https://docs.aihubmix.com/cn/api/IdeogramAI","descriptionEn":"The Ideogram AI drawing interface is now live. This model boasts powerful text-to-image capabilities, supporting endpoints are: /generate, /remix.\nThis model is the ultra-fast version of V_2, delivering the highest speed while slightly reducing quality.\nUS $0.025/ IMG.\nFor usage examples and pricing details, refer to the documentation at https://docs.aihubmix.com/cn/api/IdeogramAI.","order":66,"flag":0,"usage":"大陆用户暂时需要开代理，后续支持直连，敬请期待。","displayInput":"-","displayOutput":"$0.0025 / IMG","tags":["best"],"modalities":["text","image"],"typeHints":["t2i"],"source":"public-provider-conf"},"vision":true},{"id":"V_2_TURBO","name":"generate","display_name":"generate","type":"image-generation","context_length":0,"max_output_tokens":0,"capabilities":{"vision":true,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"modalities":{"input":["text","image"],"output":["text","image"]},"metadata":{"developer":"Ideogram","developerId":21,"providerId":8,"modelRatio":1,"cacheRatio":0,"completionRatio":1,"description":"单张图费用为 US $0.05。Ideogram AI 绘图接口上线，该模型文字绘制能力强劲，支持端口：生图 /generate、混合 /remix、局部编辑 /edit。\n该模型为 V_2 的快速版本，速度更快但会稍微降低品质。\n\n调用示例和计价以文档为准，见 https://docs.aihubmix.com/cn/api/IdeogramAI","descriptionEn":"The Ideogram AI drawing interface is now live. This model boasts powerful text-to-image capabilities, supporting endpoints are: /generate, /remix, /edit.\nThis model is the fast version of V_2, offering increased speed at the slight expense of quality.\nUS $0.05/ IMG.\nFor usage examples and pricing details, refer to the documentation at https://docs.aihubmix.com/cn/api/IdeogramAI.","order":68,"flag":0,"usage":"大陆用户暂时需要开代理，后续支持直连，敬请期待。","displayInput":"-","displayOutput":"$0.05 / IMG","tags":["best"],"modalities":["text","image"],"typeHints":["t2i"],"source":"public-provider-conf"},"vision":true},{"id":"Z/glm-4.5","name":"Z/glm-4.5","display_name":"Z/glm-4.5","type":"chat","context_length":0,"max_output_tokens":0,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"developer":"ChatGLM","developerId":5,"providerId":16,"modelRatio":0.25,"cacheRatio":1,"completionRatio":4,"description":"Z/glm-4.5","descriptionEn":"Z/glm-4.5","order":850,"flag":1,"source":"public-provider-conf"},"vision":false},{"id":"Z/glm-4.5-air","name":"Z/glm-4.5-air","display_name":"Z/glm-4.5-air","type":"chat","context_length":0,"max_output_tokens":0,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"developer":"ChatGLM","developerId":5,"providerId":16,"modelRatio":0.07,"cacheRatio":1,"completionRatio":6,"description":"Z/glm-4.5-air","descriptionEn":"Z/glm-4.5-air","order":849,"flag":1,"source":"public-provider-conf"},"vision":false},{"id":"ahm-Phi-3-5-MoE-instruct","name":"Phi-3-5-MoE-instruct","display_name":"Phi-3-5-MoE-instruct","type":"chat","context_length":0,"max_output_tokens":0,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"developer":"Microsoft","developerId":3,"providerId":45,"modelRatio":0.2,"cacheRatio":1,"completionRatio":4,"description":"Phi-3.5-MoE 是一个轻量级的最先进开放模型，基于用于 Phi-3 的数据集构建——合成数据和经过筛选的公开可用文档，重点关注高质量、推理密集的数据。该模型支持多语言，并具有 128K 的上下文长度（以标记为单位）。","order":0,"flag":0,"source":"public-provider-conf"},"vision":false},{"id":"ahm-Phi-3-5-mini-instruct","name":"Phi-3-5-mini-instruct","display_name":"Phi-3-5-mini-instruct","type":"chat","context_length":0,"max_output_tokens":0,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"developer":"Microsoft","developerId":3,"providerId":45,"modelRatio":0.5,"cacheRatio":1,"completionRatio":3,"description":"Phi-3.5-mini 是一个轻量级的最先进开放模型，基于用于 Phi-3 的数据集构建——合成数据和经过筛选的公开可用网站——重点关注非常高质量、推理密集的数据。该模型属于 Phi-3 模型家族，支持 128K 令牌上下文长度。","descriptionEn":"Phi-3.5-mini is a lightweight, state-of-the-art open model built upon the dataset used for Phi-3—which includes synthetic data and carefully curated publicly available websites—focusing on very high-quality, reasoning-intensive data. This model is part of the Phi-3 model family and supports a context length of 128K tokens.","order":0,"flag":0,"source":"public-provider-conf"},"vision":false},{"id":"ahm-Phi-3-5-vision-instruct","name":"Phi-3-5-vision-instruct","display_name":"Phi-3-5-vision-instruct","type":"chat","context_length":0,"max_output_tokens":0,"capabilities":{"vision":true,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"modalities":{"input":["text","image"],"output":["text","image"]},"metadata":{"developer":"Microsoft","developerId":3,"providerId":45,"modelRatio":0.2,"cacheRatio":1,"completionRatio":4,"order":0,"flag":0,"tags":["multi_modal"],"modalities":["text","image"],"typeHints":["t2t"],"source":"public-provider-conf"},"vision":true},{"id":"ahm-Phi-3-medium-128k","name":"Phi-3-medium-128k","display_name":"Phi-3-medium-128k","type":"chat","context_length":0,"max_output_tokens":0,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"developer":"Microsoft","developerId":3,"providerId":45,"modelRatio":3,"cacheRatio":1,"completionRatio":3,"order":0,"flag":0,"source":"public-provider-conf"},"vision":false},{"id":"ahm-Phi-3-medium-4k","name":"Phi-3-medium-4k","display_name":"Phi-3-medium-4k","type":"chat","context_length":0,"max_output_tokens":0,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"developer":"Microsoft","developerId":3,"providerId":45,"modelRatio":0.5,"cacheRatio":1,"completionRatio":3,"order":0,"flag":0,"source":"public-provider-conf"},"vision":false},{"id":"ahm-Phi-3-small-128k","name":"Phi-3-small-128k","display_name":"Phi-3-small-128k","type":"chat","context_length":0,"max_output_tokens":0,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"developer":"Microsoft","developerId":3,"providerId":45,"modelRatio":0.5,"cacheRatio":1,"completionRatio":3,"order":0,"flag":0,"source":"public-provider-conf"},"vision":false},{"id":"aihub-Phi-4","name":"Phi-4","display_name":"Phi-4","type":"chat","context_length":0,"max_output_tokens":0,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"developer":"Microsoft","developerId":3,"providerId":45,"modelRatio":0.06,"cacheRatio":1,"completionRatio":4,"description":"Phi-4 是一个最先进的开放模型，基于合成数据集、经过筛选的公共领域网站数据以及获取的学术书籍和问答数据集的结合。该方法的目标是确保小型高效模型使用专注于高质量和高级推理的数据进行训练。","descriptionEn":"Phi-4 is a state-of-the-art open model based on a combination of synthetic datasets, curated public domain website data, and acquired academic books and QA datasets. The approach aims to ensure that small, efficient models are trained using data focused on high quality and advanced reasoning.","order":45,"flag":0,"source":"public-provider-conf"},"vision":false},{"id":"aihub-Phi-4-mini-instruct","name":"Phi-4-mini-instruct","display_name":"Phi-4-mini-instruct","type":"chat","context_length":0,"max_output_tokens":0,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"developer":"Microsoft","developerId":3,"providerId":45,"modelRatio":0.06,"cacheRatio":1,"completionRatio":4,"description":"微软最新模型","descriptionEn":"Microsoft's latest model","order":46,"flag":0,"source":"public-provider-conf"},"vision":false},{"id":"aihub-Phi-4-multimodal-instruct","name":"Phi-4-multimodal-instruct","display_name":"Phi-4-multimodal-instruct","type":"chat","context_length":0,"max_output_tokens":0,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"developer":"Microsoft","developerId":3,"providerId":45,"modelRatio":0.06,"cacheRatio":1,"completionRatio":4,"description":"微软最新模型","descriptionEn":"Microsoft's latest model","order":48,"flag":0,"source":"public-provider-conf"},"vision":false},{"id":"aihubmix-DeepSeek-R1","name":"DeepSeek-R1","display_name":"DeepSeek-R1","type":"chat","context_length":128000,"max_output_tokens":128000,"capabilities":{"vision":false,"function_calling":false,"reasoning":true,"tool_calling":false},"reasoning":true,"tool_call":false,"modalities":{"input":["text"],"output":["text"]},"metadata":{"developer":"DeepSeek","developerId":7,"providerId":36,"modelRatio":0.7,"cacheRatio":1,"completionRatio":4,"description":"Azure 开源部署的满血 R1，参数 671B，输入最高 128k，如果不输出思考，可以增加提示来强制开启思考， Prompt 参考：\"先思考再输出答案\"","descriptionEn":"The fully activated R1 deployed on Azure open source has 671 billion parameters and supports input lengths up to 128k. If the model does not output the reasoning process, you can add a prompt to force it to think first. Suggested prompt: \"Think first, then provide the answer.\"","order":240,"flag":0,"features":["thinking"],"tags":["best"],"modalities":["text"],"typeHints":["t2t"],"source":"public-provider-conf"},"vision":false},{"id":"aihubmix-Llama-3-1-8B-Instruct","name":"Llama-3.1-8B","display_name":"Llama-3.1-8B","type":"chat","context_length":0,"max_output_tokens":0,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"developer":"Meta","developerId":11,"providerId":45,"modelRatio":0.15,"cacheRatio":1,"completionRatio":2,"order":0,"flag":0,"source":"public-provider-conf"},"vision":false},{"id":"aihubmix-Llama-3-3-70B-Instruct","name":"llama-3.3-70b","display_name":"llama-3.3-70b","type":"chat","context_length":0,"max_output_tokens":0,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"developer":"Llama","developerId":11,"providerId":45,"modelRatio":0.4,"cacheRatio":1,"completionRatio":1,"description":"llama最新模型，这个模型部署在微软azure","descriptionEn":"The latest llama model is deployed on Microsoft Azure.","order":98,"flag":0,"source":"public-provider-conf"},"vision":false},{"id":"aihubmix-command-r-plus","name":"command-r-plus","display_name":"command-r-plus","type":"chat","context_length":0,"max_output_tokens":0,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"modalities":{"input":["text"],"output":["text"]},"metadata":{"developer":"Cohere","developerId":6,"providerId":45,"modelRatio":1.92,"cacheRatio":1,"completionRatio":5,"order":0,"flag":0,"modalities":["text"],"typeHints":["t2t"],"source":"public-provider-conf"},"vision":false},{"id":"aihubmix-router","name":"aihubmix-router","display_name":"aihubmix-router","type":"chat","context_length":0,"max_output_tokens":0,"capabilities":{"vision":true,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"modalities":{"input":["text","image"],"output":["text","image"]},"metadata":{"developer":"OpenAI","developerId":12,"providerId":1,"modelRatio":0.2,"cacheRatio":0.25,"completionRatio":4,"description":"新增模型路由能力；请求aihubmix-router 自动模型自动根据问题复杂度进行路由到合适的模型，大家再也不用手动切换模型了；在我们比较使用模型路由器与仅使用GPT-4.1的测试中，我们看到最高可节省60%的成本，同时保持相似的准确性。\n模型路由器的上下文长度取决于每个 prompt所使用的基础模型。输入大小为200,000，输出大小为32,768。\n目前路由模型由以下四个：gpt-4.1、gpt-4.1-mini、gpt-4.1-nano、o4-mini\n价格：由于本身我们系统计费的结构现在，aihubmix-router 的请求无论最后请求到哪个模型我们都以 gpt-4.1-mini 价格计算；后续我们会根据实际命中的模型计费；\n欢迎大家体验；再接口中会返回实际调用的模型名字；","descriptionEn":"New model routing capability; request aihubmix-router to automatically route models based on question complexity, so everyone no longer needs to manually switch models; in our tests comparing the use of the model router versus only using GPT-4.1, we observed up to 60% cost savings while maintaining similar accuracy.  \nThe context length of the model router depends on the base model used for each prompt. Input size is 200,000, output size is 32,768.  \nCurrently, there are four routing models: gpt-4.1, gpt-4.1-mini, gpt-4.1-nano, o4-mini.  \nPricing: Due to our current billing structure system, requests through aihubmix-router are billed at the price of gpt-4.1-mini regardless of which final model is used; future billing will be based on the actual model invoked.  \nEveryone is welcome to try it out; the interface will return the name of the actual called model.","order":799,"flag":1,"tags":["best","economical"],"modalities":["text","image"],"typeHints":["t2t"],"source":"public-provider-conf"},"vision":true},{"id":"anthropic-3-5-sonnet-20240620","name":"Claude 3.5 Sonnet","display_name":"Claude 3.5 Sonnet","type":"chat","context_length":200000,"max_output_tokens":200000,"capabilities":{"vision":true,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"modalities":{"input":["text","image"],"output":["text","image"]},"metadata":{"developer":"Anthropic","developerId":2,"providerId":14,"modelRatio":1.65,"cacheRatio":1,"completionRatio":5,"description":"本站claude模型","descriptionEn":"Claude model of this site","order":0,"flag":0,"modalities":["text","image"],"typeHints":["t2t"],"source":"public-provider-conf"},"vision":true},{"id":"anthropic-3-5-sonnet-20241022","name":"Claude 3.5 Sonnet","display_name":"Claude 3.5 Sonnet","type":"chat","context_length":200000,"max_output_tokens":200000,"capabilities":{"vision":true,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"modalities":{"input":["text","image"],"output":["text","image"]},"metadata":{"developer":"Anthropic","developerId":2,"providerId":14,"modelRatio":1.65,"cacheRatio":1,"completionRatio":5,"description":"本站claude模型","descriptionEn":"Claude model of this site","order":0,"flag":2,"modalities":["text","image"],"typeHints":["t2t"],"source":"public-provider-conf"},"vision":true},{"id":"anthropic-3-7-sonnet-20250219","name":"claude-3-7-sonnet","display_name":"claude-3-7-sonnet","type":"chat","context_length":0,"max_output_tokens":0,"capabilities":{"vision":true,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"modalities":{"input":["text","image"],"output":["text","image"]},"metadata":{"developer":"Anthropic","developerId":2,"providerId":14,"modelRatio":1.65,"cacheRatio":1,"completionRatio":5,"description":"cursor专用","descriptionEn":"For cursor use only","order":0,"flag":2,"tags":["best","multi_modal","sota"],"modalities":["text","image"],"typeHints":["t2t"],"source":"public-provider-conf"},"vision":true},{"id":"baidu/ERNIE-4.5-300B-A47B","name":"baidu/ERNIE-4.5-300B-A47B","display_name":"baidu/ERNIE-4.5-300B-A47B","type":"chat","context_length":0,"max_output_tokens":0,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"developer":"Baidu","developerId":25,"providerId":44,"modelRatio":0.16,"cacheRatio":0,"completionRatio":4,"description":"ERNIE-4.5-300B-A47B 是由百度公司开发的一款基于混合专家（MoE）架构的大语言模型。该模型总参数量为 3000 亿，但在推理时每个 token 仅激活 470 亿参数，从而在保证强大性能的同时兼顾了计算效率。作为 ERNIE 4.5 系列的核心模型之一，在文本理解、生成、推理和编程等任务上展现出卓越的能力。该模型采用了一种创新的多模态异构 MoE 预训练方法，通过文本与视觉模态的联合训练，有效提升了模型的综合能力，尤其在指令遵循和世界知识记忆方面效果突出。百度已将该模型连同系列内其他模型一同开源，旨在推动 AI 技术的研发与应用","descriptionEn":"ERNIE-4.5-300B-A47B is a large language model developed by Baidu based on a Mixture of Experts (MoE) architecture. The model has a total of 300 billion parameters, but only activates 47 billion parameters per token during inference, which balances strong performance with computational efficiency. As one of the core models in the ERNIE 4.5 series, it demonstrates outstanding capabilities in tasks such as text understanding, generation, reasoning, and programming. The model employs an innovative multimodal heterogeneous MoE pretraining approach, leveraging joint training of textual and visual modalities to effectively enhance the model’s overall abilities, particularly excelling in instruction following and world knowledge memorization. Baidu has open-sourced this model along with other models in the series, aiming to promote the research and application of AI technology.","order":100,"flag":1,"source":"public-provider-conf"},"vision":false},{"id":"bge-large-en","name":"bge-large-en","display_name":"bge-large-en","type":"embedding","context_length":0,"max_output_tokens":0,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"developer":"Baidu","developerId":25,"providerId":15,"modelRatio":0.034,"cacheRatio":1,"completionRatio":1,"description":"bge-large-en 由智源研究院开源，是当前中文任务下最强向量表征模型，各项语义表征能力全面超越同类开源模型。","descriptionEn":"bge-large-en, open-sourced by the Beijing Academy of Artificial Intelligence (BAAI), is currently the most powerful vector representation model for Chinese tasks, with its semantic representation capabilities comprehensively surpassing those of similar open-source models.","order":100,"flag":0,"typeHints":["embedding"],"source":"public-provider-conf"},"vision":false},{"id":"bge-large-zh","name":"bge-large-zh","display_name":"bge-large-zh","type":"embedding","context_length":0,"max_output_tokens":0,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"developer":"Baidu","developerId":25,"providerId":15,"modelRatio":0.034,"cacheRatio":1,"completionRatio":1,"description":"bge-large-zh 由智源研究院开源，是当前中文任务下最强向量表征模型，各项语义表征能力全面超越同类开源模型。","descriptionEn":"bge-large-zh, open-sourced by the Beijing Academy of Artificial Intelligence (BAAI), is currently the most powerful vector representation model for Chinese tasks, with its semantic representation capabilities comprehensively surpassing those of similar open-source models.","order":100,"flag":0,"typeHints":["embedding"],"source":"public-provider-conf"},"vision":false},{"id":"chatgpt-4o-latest","name":"gpt-4o","display_name":"gpt-4o","type":"chat","context_length":0,"max_output_tokens":0,"capabilities":{"vision":true,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"modalities":{"input":["text","image"],"output":["text","image"]},"metadata":{"developer":"OpenAI","developerId":12,"providerId":1,"modelRatio":2.5,"cacheRatio":1,"completionRatio":3,"description":"该模型将指向ChatGPT使用的最新GPT-4o模型。","descriptionEn":"This model will point to the latest GPT-4o model used by ChatGPT.","order":110,"flag":0,"tags":["multi_modal","bold"],"modalities":["text","image"],"typeHints":["t2t"],"source":"public-provider-conf"},"vision":true},{"id":"chutesai/Llama-4-Maverick-17B-128E-Instruct-FP8","name":"Llama-4-Maverick-17B","display_name":"Llama-4-Maverick-17B","type":"chat","context_length":0,"max_output_tokens":0,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"developer":"Llama","developerId":11,"providerId":8,"modelRatio":0.125,"cacheRatio":0,"completionRatio":1,"description":"有chutes.ai 提供\nLlama 4系列模型是原生的多模态AI模型，能够实现文本和多模态体验。这些模型利用专家混合架构，在文本和图像理解方面提供行业领先的性能。\n这些Llama 4模型标志着Llama生态系统新时代的开始。我们推出了两个高效的Llama 4系列模型：Llama 4 Scout，一个拥有170亿参数和16个专家的模型，以及Llama 4 Maverick，一个拥有170亿参数和128个专家的模型。","descriptionEn":"chutes.ai\nThe Llama 4 collection of models are natively multimodal AI models that enable text and multimodal experiences. These models leverage a mixture-of-experts architecture to offer industry-leading performance in text and image understanding.\n\nThese Llama 4 models mark the beginning of a new era for the Llama ecosystem. We are launching two efficient models in the Llama 4 series, Llama 4 Scout, a 17 billion parameter model with 16 experts, and Llama 4 Maverick, a 17 billion parameter model with 128 experts.","order":701,"flag":0,"source":"public-provider-conf"},"vision":false},{"id":"chutesai/Llama-4-Scout-17B-16E-Instruct","name":"Llama-4-Scout-17B","display_name":"Llama-4-Scout-17B","type":"chat","context_length":0,"max_output_tokens":0,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"developer":"Llama","developerId":11,"providerId":8,"modelRatio":0.1,"cacheRatio":0,"completionRatio":1,"description":"有chutes.ai 提供\nLlama 4系列模型是原生的多模态AI模型，能够实现文本和多模态体验。这些模型利用专家混合架构，在文本和图像理解方面提供行业领先的性能。\n这些Llama 4模型标志着Llama生态系统新时代的开始。我们推出了两个高效的Llama 4系列模型：Llama 4 Scout，一个拥有170亿参数和16个专家的模型，以及Llama 4 Maverick，一个拥有170亿参数和128个专家的模型。","descriptionEn":"chutes.ai\nThe Llama 4 collection of models are natively multimodal AI models that enable text and multimodal experiences. These models leverage a mixture-of-experts architecture to offer industry-leading performance in text and image understanding.\nThese Llama 4 models mark the beginning of a new era for the Llama ecosystem. We are launching two efficient models in the Llama 4 series, Llama 4 Scout, a 17 billion parameter model with 16 experts, and Llama 4 Maverick, a 17 billion parameter model with 128 experts.","order":699,"flag":0,"source":"public-provider-conf"},"vision":false},{"id":"chutesai/Mistral-Small-3.1-24B-Instruct-2503","name":"Mistral-Small-3.1-24B","display_name":"Mistral-Small-3.1-24B","type":"chat","context_length":0,"max_output_tokens":0,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"developer":"Mistral","developerId":10,"providerId":8,"modelRatio":0.1,"cacheRatio":1,"completionRatio":4,"description":"Mistral最新开源小模型；由chutes.ai提供","descriptionEn":"Mistral's latest open-source small model; provided by chutes.ai.","order":101,"flag":0,"source":"public-provider-conf"},"vision":false},{"id":"claude-3-5-haiku-20241022","name":"claude-3-5-haiku","display_name":"claude-3-5-haiku","type":"chat","context_length":0,"max_output_tokens":0,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"developer":"Anthropic","developerId":2,"providerId":14,"modelRatio":0.55,"cacheRatio":1,"completionRatio":5,"description":"Claude 3.5 Haiku 是Claude最快模型的下一代。该模型AiHubMix同时自动路由官方三个渠道Claude、AWS Claude、谷歌Vertex AI Claude,以实现高并发负载均衡","descriptionEn":"Claude 3.5 Haiku is the next generation of Claude's fastest model. The AiHubMix model simultaneously and automatically routes through three official channels—Claude, AWS Claude, and Google Vertex AI Claude—to achieve high-concurrency load balancing.","order":98,"flag":0,"source":"public-provider-conf"},"vision":false},{"id":"claude-3-5-haiku-latest","name":"claude-3-5-haiku","display_name":"claude-3-5-haiku","type":"chat","context_length":0,"max_output_tokens":0,"capabilities":{"vision":true,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"modalities":{"input":["text","image"],"output":["text","image"]},"metadata":{"developer":"Anthropic","developerId":2,"providerId":14,"modelRatio":0.55,"cacheRatio":1,"completionRatio":5,"order":0,"flag":0,"tags":["lightning","economical"],"modalities":["text","image"],"typeHints":["t2t"],"source":"public-provider-conf"},"vision":true},{"id":"claude-3-5-sonnet-20240620","name":"Claude 3.5 Sonnet","display_name":"Claude 3.5 Sonnet","type":"chat","context_length":0,"max_output_tokens":0,"capabilities":{"vision":true,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"modalities":{"input":["text","image"],"output":["text","image"]},"metadata":{"developer":"Anthropic","developerId":2,"providerId":14,"modelRatio":1.65,"cacheRatio":1,"completionRatio":5,"order":0,"flag":0,"tags":["multi_modal","best"],"modalities":["text","image"],"typeHints":["t2t"],"source":"public-provider-conf"},"vision":true},{"id":"claude-3-5-sonnet-20241022","name":"Claude 3.5 Sonnet","display_name":"Claude 3.5 Sonnet","type":"chat","context_length":200000,"max_output_tokens":200000,"capabilities":{"vision":true,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"modalities":{"input":["text","image"],"output":["text","image"]},"metadata":{"developer":"Anthropic","developerId":2,"providerId":14,"modelRatio":1.65,"cacheRatio":1,"completionRatio":5,"description":"Claude 3.5 Sonnet最新模型；该模型AiHubMix同时自动路由官方三个渠道Claude、AWS Claude、谷歌Vertex AI Claude,以实现高并发负载均衡","descriptionEn":"Claude 3.5 Sonnet is the latest model; this AiHubMix model automatically routes through the three official Claude channels—Claude, AWS Claude, and Google Vertex AI Claude—to achieve high-concurrency load balancing.","order":130,"flag":0,"tags":["multi_modal","best"],"modalities":["text","image"],"typeHints":["t2t"],"source":"public-provider-conf"},"vision":true},{"id":"claude-3-5-sonnet-latest","name":"Claude 3.5 Sonnet","display_name":"Claude 3.5 Sonnet","type":"chat","context_length":200000,"max_output_tokens":200000,"capabilities":{"vision":true,"function_calling":true,"reasoning":false,"tool_calling":true},"reasoning":false,"tool_call":true,"modalities":{"input":["text","image"],"output":["text","image"]},"metadata":{"developer":"Anthropic","developerId":2,"providerId":14,"modelRatio":1.65,"cacheRatio":1,"completionRatio":5,"description":"自动指向最新版本；目前指向claude-3-5-sonnet-20241022","descriptionEn":"Automatically points to the latest version; currently pointing to claude-3-5-sonnet-20241022.","order":9,"flag":0,"features":["function_calling","structured_outputs"],"tags":["multi_modal","best","bold"],"modalities":["text","image"],"typeHints":["t2t"],"source":"public-provider-conf"},"vision":true},{"id":"claude-3-5-sonnet@20240620","name":"Claude 3.5 Sonnet","display_name":"Claude 3.5 Sonnet","type":"chat","context_length":0,"max_output_tokens":0,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"developer":"Anthropic","developerId":2,"providerId":42,"modelRatio":1.65,"cacheRatio":1,"completionRatio":5,"description":"Claude部署在谷歌云上的","order":0,"flag":0,"source":"public-provider-conf"},"vision":false},{"id":"claude-3-7-sonnet-20250219","name":"Claude 3.7 Sonnet","display_name":"Claude 3.7 Sonnet","type":"chat","context_length":200000,"max_output_tokens":200000,"capabilities":{"vision":true,"function_calling":false,"reasoning":true,"tool_calling":false},"reasoning":true,"tool_call":false,"modalities":{"input":["text","image"],"output":["text","image"]},"metadata":{"developer":"Anthropic","developerId":2,"providerId":14,"modelRatio":1.65,"cacheRatio":1,"completionRatio":5,"description":"通过原始claude sdk支持thinking参数；","descriptionEn":"Support for the thinking parameter through the original Claude SDK.","order":500,"flag":2,"features":["thinking"],"tags":["multi_modal","best","sota","bold"],"modalities":["text","image"],"typeHints":["t2t"],"source":"public-provider-conf"},"vision":true},{"id":"claude-3-haiku-20240307","name":"Claude 3 Haiku","display_name":"Claude 3 Haiku","type":"chat","context_length":0,"max_output_tokens":0,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"developer":"Anthropic","developerId":2,"providerId":14,"modelRatio":0.14,"cacheRatio":1,"completionRatio":5,"order":0,"flag":0,"source":"public-provider-conf"},"vision":false},{"id":"claude-3-opus-20240229","name":"Claude 3 Opus","display_name":"Claude 3 Opus","type":"chat","context_length":0,"max_output_tokens":0,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"developer":"Anthropic","developerId":2,"providerId":14,"modelRatio":8.4,"cacheRatio":1,"completionRatio":5,"description":"claude上一代最强模型；","descriptionEn":"Claude’s previous generation strongest model","order":45,"flag":0,"source":"public-provider-conf"},"vision":false},{"id":"claude-3-sonnet-20240229","name":"Claude 3 Sonnet","display_name":"Claude 3 Sonnet","type":"chat","context_length":200000,"max_output_tokens":200000,"capabilities":{"vision":true,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"modalities":{"input":["text","image"],"output":["text","image"]},"metadata":{"developer":"Anthropic","developerId":2,"providerId":14,"modelRatio":2,"cacheRatio":1,"completionRatio":5,"order":0,"flag":0,"modalities":["text","image"],"typeHints":["t2t"],"source":"public-provider-conf"},"vision":true},{"id":"claude-opus-4-0","name":"claude-opus-4-0","display_name":"claude-opus-4-0","type":"chat","context_length":0,"max_output_tokens":0,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"developer":"Anthropic","developerId":2,"providerId":14,"modelRatio":8.4,"cacheRatio":1,"completionRatio":5,"description":"Alias \nclaude-opus-4-20250514","descriptionEn":"Alias \nclaude-opus-4-20250514","order":1,"flag":0,"source":"public-provider-conf"},"vision":false},{"id":"claude-opus-4-1-20250805","name":"claude-opus-4-1-20250805","display_name":"claude-opus-4-1-20250805","type":"chat","context_length":0,"max_output_tokens":0,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"developer":"Anthropic","developerId":2,"providerId":14,"modelRatio":8.25,"cacheRatio":1,"completionRatio":5,"description":"Opus 4.1 是 Claude Opus 4 的一个升级版本，主要在智能体任务、实际编码和推理方面进行了改进。对比 Opus 4和 Opus 4.1在软件工程准确性方面的有小幅提升，Opus 4.1 的准确性更高，达到了 74.5%。","descriptionEn":"Opus 4.1 is an upgraded version of Claude Opus 4, with improvements mainly in agent tasks, practical coding, and reasoning. Compared to Opus 4, there is a slight improvement in software engineering accuracy; Opus 4.1 has higher accuracy at 74.5%.","order":954,"flag":1,"source":"public-provider-conf"},"vision":false},{"id":"claude-opus-4-20250514","name":"claude-opus-4-20250514","display_name":"claude-opus-4-20250514","type":"chat","context_length":200000,"max_output_tokens":200000,"capabilities":{"vision":true,"function_calling":true,"reasoning":true,"tool_calling":true},"reasoning":true,"tool_call":true,"modalities":{"input":["text","image"],"output":["text","image"]},"metadata":{"developer":"Anthropic","developerId":2,"providerId":14,"modelRatio":8.4,"cacheRatio":1,"completionRatio":5,"description":"定位：Claude Opus 4 是 Anthropic 迄今为止最强大的模型，专为处理复杂、长时间运行的任务而设计。 ￼\n主要特点：\n\t•\t卓越的编码能力：在 SWE-bench 编码基准测试中得分 72.5%，在 Terminal-bench 测试中得分 43.2%，领先于 OpenAI 的 GPT-4.1 和 Google 的 Gemini 2.5 Pro 等竞争对手。  ￼\n\t•\t长时间自主运行：能够连续工作数小时，保持专注，适合需要持续推理的任务。\n\t•\t增强的推理能力：配备“思维摘要”功能，能够将复杂的思维过程简化为易于理解的摘要，提升用户对模型推理过程的可解释性。  ￼\n\t•\t高级安全控制：由于其强大的能力，Opus 4 实施了更严格的安全措施，以防止潜在的滥用风险。  ￼\n适用场景：适用于需要深入推理、复杂编码和长时间任务的高级应用，如科研、法律分析和大型软件开发项目。 ￼","descriptionEn":"Positioning:\nClaude Opus 4 is Anthropic's most powerful model to date, specifically designed for complex, long-running tasks requiring deep reasoning and advanced capabilities.\nKey Features:\nExceptional Coding Skills: Achieves a 72.5% score on SWE-bench and 43.2% on Terminal-bench, surpassing competitors like OpenAI's GPT-4.1 and Google's Gemini 2.5 Pro.\nLong-term Autonomous Operations: Capable of maintaining continuous focus and effectiveness over extended periods, suitable for tasks demanding prolonged reasoning.\nEnhanced Reasoning Capabilities: Incorporates a \"Thought Summarization\" feature, simplifying complex reasoning processes into understandable summaries, improving interpretability.\nAdvanced Safety Measures: Features robust security controls due to its powerful capabilities, aiming to prevent potential misuse.\nIdeal Use Cases:\nBest suited for advanced applications such as scientific research, legal analysis, and large-scale software development.","order":860,"flag":1,"features":["thinking","tools","function_calling","structured_outputs"],"tags":["multi_modal","best","sota"],"modalities":["text","image"],"typeHints":["t2t"],"source":"public-provider-conf"},"vision":true},{"id":"claude-sonnet-4-0","name":"claude-sonnet-4-0","display_name":"claude-sonnet-4-0","type":"chat","context_length":0,"max_output_tokens":0,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"developer":"Anthropic","developerId":2,"providerId":14,"modelRatio":1.65,"cacheRatio":1,"completionRatio":5,"description":"Alias \nclaude-sonnet-4-20250514","descriptionEn":"Alias \nclaude-sonnet-4-20250514","order":1,"flag":0,"source":"public-provider-conf"},"vision":false},{"id":"claude-sonnet-4-20250514","name":"claude-sonnet-4-20250514","display_name":"claude-sonnet-4-20250514","type":"chat","context_length":200000,"max_output_tokens":200000,"capabilities":{"vision":true,"function_calling":true,"reasoning":true,"tool_calling":true},"reasoning":true,"tool_call":true,"modalities":{"input":["text","image"],"output":["text","image"]},"metadata":{"developer":"Anthropic","developerId":2,"providerId":14,"modelRatio":1.65,"cacheRatio":1,"completionRatio":5,"description":"定位：Claude Sonnet 4 是一款高效且性价比高的模型，作为 Claude Sonnet 3.7 的升级版，适合日常任务和中等复杂度的应用。 ￼\n主要特点：\n\t•\t优异的编码性能：在 SWE-bench 编码基准测试中得分 72.7%，在 Terminal-bench 测试中得分 35.5%，显示出出色的编码能力。  ￼\n\t•\t高效的推理能力：在保持响应速度的同时，提供更精确的推理和指令遵循能力。\n\t•\t增强的记忆功能：在获得本地文件访问权限的情况下，能够更好地存储和提取关键信息，适用于需要长期记忆的任务。  ￼\n\t•\t广泛的可用性：Sonnet 4 可通过 Anthropic API、Amazon Bedrock 和 Google Cloud 的 Vertex AI 平台访问，免费用户也可以使用。  ￼\n适用场景：适合日常办公、内容创作、教育和中等复杂度的编码任务，特别适合需要高效响应和成本控制的用户。","descriptionEn":"Positioning:\nClaude Sonnet 4 is an efficient, cost-effective model, an upgraded successor to Claude Sonnet 3.7, optimized for everyday tasks and medium-complexity applications.\nKey Features:\nStrong Coding Performance: Scores 72.7% on SWE-bench and 35.5% on Terminal-bench, demonstrating excellent programming abilities.\nEfficient Reasoning: Balances rapid response times with precise reasoning and adherence to instructions.\nImproved Memory Capabilities: Enhanced ability to store and retrieve critical information effectively when given local file access.\nBroad Accessibility: Available to both free and paid users via Anthropic API, Amazon Bedrock, and Google Cloud's Vertex AI platform.\nIdeal Use Cases:\nIdeal for everyday office tasks, content creation, educational purposes, and mid-complexity programming projects where cost-effectiveness and responsiveness are priorities.","order":855,"flag":1,"billingConfig":"{\n    \"model_name\": \"claude-sonnet-4-20250514\",\n    \"default_tier\": \"tier1\",\n    \"token_based_tier_configs\":\n    {\n        \"tier1\":\n        {\n            \"tier_condition\":\n            {\n                \"min_tokens\": 0,\n                \"max_tokens\": 200000\n            },\n            \"model_ratio\": 1.65,\n            \"prompt_tokens_ratio\": 1.0,\n            \"completion_tokens_ratio\": 5.0,\n            \"cached_tokens_ratio\": 0.1,\n            \"cache_write_5_minutes_tokens_ratio\": 1.25,\n            \"cache_write_1_hour_tokens_ratio\":2\n        },\n        \"tier2\":\n        {\n            \"tier_condition\":\n            {\n                \"min_tokens\": 200001,\n                \"max_tokens\": -1\n            },\n            \"model_ratio\": 2.2,\n            \"prompt_tokens_ratio\": 1.0,\n            \"completion_tokens_ratio\": 3.75,\n            \"cached_tokens_ratio\": 0.1,\n            \"cache_write_5_minutes_tokens_ratio\": 1.25,\n            \"cache_write_1_hour_tokens_ratio\":2\n            \n        }\n    },\n    \"per_unit_price_config\":\n    {\n        \"web_search_price\": 0.01\n    },\n    \"enabled_billing_items\":\n    [\n        \"prompt_tokens\",\n        \"completion_tokens\",\n        \"cached_tokens\",\n        \"web_search_requests\",\n        \"cache_write_5_minutes_tokens\",\n        \"cache_write_1_hour_tokens\"\n    ]\n}","features":["thinking","tools","function_calling","structured_outputs"],"tags":["multi_modal","best","sota","bold"],"modalities":["text","image"],"typeHints":["t2t"],"source":"public-provider-conf"},"vision":true},{"id":"claude-sonnet-4-5-20250929","name":"claude-sonnet-4-5-20250929","display_name":"claude-sonnet-4-5-20250929","type":"chat","context_length":0,"max_output_tokens":0,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"developer":"Anthropic","developerId":2,"providerId":14,"modelRatio":1.65,"cacheRatio":0.1,"completionRatio":5,"description":"Sonnet 4.5 是世界上最好的代理、编码和计算机使用模型。它也是我们在长时间运行任务中最准确、最详细的模型，具有增强的编码、金融和网络安全领域知识。","descriptionEn":"Sonnet 4.5 is the best model in the world for agents, coding, and computer use. It’s also our most accurate and detailed model for long-running tasks, with enhanced domain knowledge in coding, finance, and cybersecurity.","order":1001,"flag":1,"billingConfig":"{\n    \"model_name\": \"claude-sonnet-4-5-20250929\",\n    \"default_tier\": \"tier1\",\n    \"token_based_tier_configs\":\n    {\n        \"tier1\":\n        {\n            \"tier_condition\":\n            {\n                \"min_tokens\": 0,\n                \"max_tokens\": 200000\n            },\n            \"model_ratio\": 1.65,\n            \"prompt_tokens_ratio\": 1.0,\n            \"completion_tokens_ratio\": 5.0,\n            \"cached_tokens_ratio\": 0.1,\n            \"cache_write_5_minutes_tokens_ratio\": 1.25,\n            \"cache_write_1_hour_tokens_ratio\":2\n        },\n        \"tier2\":\n        {\n            \"tier_condition\":\n            {\n                \"min_tokens\": 200001,\n                \"max_tokens\": -1\n            },\n            \"model_ratio\": 2.2,\n            \"prompt_tokens_ratio\": 1.0,\n            \"completion_tokens_ratio\": 3.75,\n            \"cached_tokens_ratio\": 0.1,\n            \"cache_write_5_minutes_tokens_ratio\": 1.25,\n            \"cache_write_1_hour_tokens_ratio\":2\n            \n        }\n    },\n    \"per_unit_price_config\":\n    {\n        \"web_search_price\": 0.01\n    },\n    \"enabled_billing_items\":\n    [\n        \"prompt_tokens\",\n        \"completion_tokens\",\n        \"cached_tokens\",\n        \"web_search_requests\",\n        \"cache_write_5_minutes_tokens\",\n        \"cache_write_1_hour_tokens\"\n    ]\n}","source":"public-provider-conf"},"vision":false},{"id":"codestral-latest","name":"Codestral 25.01","display_name":"Codestral 25.01","type":"chat","context_length":0,"max_output_tokens":0,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"developer":"Mistral","developerId":10,"providerId":28,"modelRatio":0.2,"cacheRatio":1,"completionRatio":3,"description":"Mistral 推出了新的code模型 - Codestral 25.01;https://mistral.ai/news/codestral-2501/","descriptionEn":"Mistral has launched a new code model - Codestral 25.01; https://mistral.ai/news/codestral-2501/","order":100,"flag":0,"source":"public-provider-conf"},"vision":false},{"id":"codex-mini-latest","name":"codex-mini-latest","display_name":"codex-mini-latest","type":"chat","context_length":200000,"max_output_tokens":200000,"capabilities":{"vision":true,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"modalities":{"input":["text","image"],"output":["text","image"]},"metadata":{"developer":"OpenAI","developerId":12,"providerId":1,"modelRatio":0.75,"cacheRatio":0.25,"completionRatio":4,"description":"仅支持v1/responses 接口调用； 接口文档：https://docs.aihubmix.com/cn/api/Responses-API\ncodex-mini-latest 是专为在 Codex CLI 中使用而微调的 o4-mini 版本。对于直接在 API 中使用，我们建议从 gpt-4.1 开始。支持官方缓存，自动命中后输入部分费用降低 75%","descriptionEn":"Only supports v1/responses API calls.https://docs.aihubmix.com/en/api/Responses-API\ncodex-mini-latest is a fine-tuned version of o4-mini specifically for use in Codex CLI. For direct use in the API, we recommend starting with gpt-4.1.","order":600,"flag":1,"tags":["best","economical"],"modalities":["text","image"],"typeHints":["t2t"],"source":"public-provider-conf"},"vision":true},{"id":"cogview-3-plus","name":"cogview-3-plus","display_name":"cogview-3-plus","type":"chat","context_length":0,"max_output_tokens":0,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"developer":"智谱 ChatGLM","developerId":5,"providerId":16,"modelRatio":5,"cacheRatio":1,"completionRatio":1,"order":0,"flag":0,"source":"public-provider-conf"},"vision":false},{"id":"command","name":"command","display_name":"command","type":"chat","context_length":0,"max_output_tokens":0,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"modalities":{"input":["text"],"output":["text"]},"metadata":{"developer":"Cohere","developerId":6,"providerId":35,"modelRatio":0.5,"cacheRatio":1,"completionRatio":2,"order":0,"flag":0,"modalities":["text"],"typeHints":["t2t"],"source":"public-provider-conf"},"vision":false},{"id":"command-a-03-2025","name":"Command A","display_name":"Command A","type":"chat","context_length":0,"max_output_tokens":0,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"modalities":{"input":["text"],"output":["text"]},"metadata":{"developer":"Cohere","developerId":6,"providerId":35,"modelRatio":1.25,"cacheRatio":0,"completionRatio":4,"description":"Command A 是Cohere迄今为止性能最强的模型，在工具使用、代理、检索增强生成（RAG）和多语言用例方面表现出色。Command A 的上下文长度为 256K，仅需两个 GPU 即可运行，吞吐量比 Command R+ 08-2024 高出 150%。","descriptionEn":"Command A is Cohere most performant model to date, excelling at tool use, agents, retrieval augmented generation (RAG), and multilingual use cases. Command A has a context length of 256K, only requires two GPUs to run, and has 150% higher throughput compared to Command R+ 08-2024.","order":40,"flag":1,"tags":["bold"],"modalities":["text"],"typeHints":["t2t"],"source":"public-provider-conf"},"vision":false},{"id":"command-light","name":"command-light","display_name":"command-light","type":"chat","context_length":0,"max_output_tokens":0,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"developer":"Cohere","developerId":6,"providerId":35,"modelRatio":0.5,"cacheRatio":1,"completionRatio":2,"order":0,"flag":0,"source":"public-provider-conf"},"vision":false},{"id":"command-light-nightly","name":"command-light","display_name":"command-light","type":"chat","context_length":0,"max_output_tokens":0,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"developer":"Cohere","developerId":6,"providerId":35,"modelRatio":0.5,"cacheRatio":1,"completionRatio":2,"order":0,"flag":0,"source":"public-provider-conf"},"vision":false},{"id":"command-nightly","name":"command-nightly","display_name":"command-nightly","type":"chat","context_length":0,"max_output_tokens":0,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"developer":"Cohere","developerId":6,"providerId":35,"modelRatio":0.5,"cacheRatio":1,"completionRatio":2,"order":0,"flag":0,"source":"public-provider-conf"},"vision":false},{"id":"command-r","name":"command-r","display_name":"command-r","type":"chat","context_length":0,"max_output_tokens":0,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"modalities":{"input":["text"],"output":["text"]},"metadata":{"developer":"Cohere","developerId":6,"providerId":35,"modelRatio":0.32,"cacheRatio":1,"completionRatio":3,"order":0,"flag":0,"modalities":["text"],"typeHints":["t2t"],"source":"public-provider-conf"},"vision":false},{"id":"command-r-plus","name":"command-r-plus","display_name":"command-r-plus","type":"chat","context_length":0,"max_output_tokens":0,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"modalities":{"input":["text"],"output":["text"]},"metadata":{"developer":"Cohere","developerId":6,"providerId":35,"modelRatio":1.92,"cacheRatio":1,"completionRatio":5,"order":0,"flag":0,"modalities":["text"],"typeHints":["t2t"],"source":"public-provider-conf"},"vision":false},{"id":"computer-use-preview","name":"computer-use-preview","display_name":"computer-use-preview","type":"chat","context_length":0,"max_output_tokens":0,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"developer":"OpenAI","developerId":12,"providerId":1,"modelRatio":1.5,"cacheRatio":1,"completionRatio":4,"order":1,"flag":1,"source":"public-provider-conf"},"vision":false},{"id":"dall-e-2","name":"dall-e-2","display_name":"dall-e-2","type":"chat","context_length":0,"max_output_tokens":0,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"developer":"OpenAI","developerId":12,"providerId":1,"modelRatio":8,"cacheRatio":1,"completionRatio":1,"order":0,"flag":0,"source":"public-provider-conf"},"vision":false},{"id":"dall-e-3","name":"dall-e-3","display_name":"dall-e-3","type":"image-generation","context_length":0,"max_output_tokens":0,"capabilities":{"vision":true,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"modalities":{"input":["text","image"],"output":["text","image"]},"metadata":{"developer":"OpenAI","developerId":12,"providerId":1,"modelRatio":20,"cacheRatio":1,"completionRatio":1,"order":45,"flag":0,"displayInput":"-","displayOutput":"$ 0.04 / IMG","tags":["best"],"modalities":["text","image"],"typeHints":["t2i"],"source":"public-provider-conf"},"vision":true},{"id":"davinci-002","name":"davinci","display_name":"davinci","type":"chat","context_length":0,"max_output_tokens":0,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"developer":"OpenAI","developerId":12,"providerId":1,"modelRatio":1,"cacheRatio":1,"completionRatio":1,"order":0,"flag":0,"source":"public-provider-conf"},"vision":false},{"id":"deepseek-ai/DeepSeek-Prover-V2-671B","name":"deepseek-ai/DeepSeek-Prover-V2-671B","display_name":"deepseek-ai/DeepSeek-Prover-V2-671B","type":"chat","context_length":0,"max_output_tokens":0,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"developer":"DeepSeek","developerId":7,"providerId":8,"modelRatio":0.05,"cacheRatio":1,"completionRatio":1,"description":"由chutes.ai提供\nDeepSeek Prover V2 是一个拥有 6710 亿参数的模型，推测专注于逻辑和数学领域。很可能是 DeepSeek-Prover-V1.5 的升级版。目前关于该模型知之甚少，因为 DeepSeek 在 Hugging Face 上发布时没有任何公告或描述。","descriptionEn":"Provided by chutes.ai\nDeepSeek Prover V2 is a 671B parameter model, speculated to be geared towards logic and mathematics. Likely an upgrade from DeepSeek-Prover-V1.5 Not much is known about the model yet, as DeepSeek released it on Hugging Face without an announcement or description.","order":500,"flag":0,"source":"public-provider-conf"},"vision":false},{"id":"deepseek-ai/DeepSeek-R1","name":"DeepSeek-R1","display_name":"DeepSeek-R1","type":"chat","context_length":0,"max_output_tokens":0,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"developer":"DeepSeek","developerId":7,"providerId":36,"modelRatio":0.25,"cacheRatio":1,"completionRatio":1,"description":"来自多个开源部署","descriptionEn":"Deployed from multiple open-source sources","order":100,"flag":0,"source":"public-provider-conf"},"vision":false},{"id":"deepseek-ai/DeepSeek-R1-0528","name":"deepseek-ai/DeepSeek-R1-0528","display_name":"deepseek-ai/DeepSeek-R1-0528","type":"chat","context_length":131072,"max_output_tokens":65536,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":true,"tool_call":false,"metadata":{"developer":"DeepSeek","developerId":7,"providerId":8,"modelRatio":0.3,"cacheRatio":1,"completionRatio":1,"description":"由chutes.ai 提供\n最新版本 R1","descriptionEn":"Provided by chutes.ai\nLatest version R1","order":381,"flag":1,"source":"public-provider-conf"},"vision":false},{"id":"deepseek-ai/DeepSeek-R1-Distill-Qwen-14B","name":"deepseek-ai/DeepSeek-R1-Distill-Qwen-14B","display_name":"deepseek-ai/DeepSeek-R1-Distill-Qwen-14B","type":"chat","context_length":0,"max_output_tokens":0,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"developer":"DeepSeek","developerId":7,"providerId":36,"modelRatio":0.05,"cacheRatio":1,"completionRatio":1,"description":"来自siliconflow开源部署，模型本身通过知识蒸馏得到的模型","descriptionEn":"Open source deployment from SiliconFlow, the model itself is obtained through knowledge distillation.","order":0,"flag":0,"source":"public-provider-conf"},"vision":false},{"id":"deepseek-ai/DeepSeek-R1-Distill-Qwen-32B","name":"deepseek-ai/DeepSeek-R1-Distill-Qwen-32B","display_name":"deepseek-ai/DeepSeek-R1-Distill-Qwen-32B","type":"chat","context_length":0,"max_output_tokens":0,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"developer":"DeepSeek","developerId":7,"providerId":36,"modelRatio":0.1,"cacheRatio":1,"completionRatio":1,"description":"来自siliconflow开源部署，模型本身通过知识蒸馏得到的模型","descriptionEn":"Open source deployment from SiliconFlow, the model itself is obtained through knowledge distillation.","order":0,"flag":0,"source":"public-provider-conf"},"vision":false},{"id":"deepseek-ai/DeepSeek-R1-Distill-Qwen-7B","name":"deepseek-ai/DeepSeek-R1-Distill-Qwen-7B","display_name":"deepseek-ai/DeepSeek-R1-Distill-Qwen-7B","type":"chat","context_length":0,"max_output_tokens":0,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"developer":"DeepSeek","developerId":7,"providerId":36,"modelRatio":0.005,"cacheRatio":1,"completionRatio":1,"description":"来自siliconflow开源部署，模型本身通过知识蒸馏得到的模型","descriptionEn":"Open source deployment from SiliconFlow, the model itself is obtained through knowledge distillation.","order":0,"flag":0,"source":"public-provider-conf"},"vision":false},{"id":"deepseek-ai/DeepSeek-R1-Zero","name":"deepseek-ai/DeepSeek-R1-Zero","display_name":"deepseek-ai/DeepSeek-R1-Zero","type":"chat","context_length":0,"max_output_tokens":0,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"developer":"DeepSeek","developerId":7,"providerId":8,"modelRatio":1.1,"cacheRatio":1,"completionRatio":1,"description":"来自chutes.ai开源部署；推理FP8;zero是R1的前置最初版本，没有优化，如果不是研究不推荐使用","descriptionEn":"Openly deployed by chutes.ai; inference with FP8; zero is the initial preliminary version of R1 without optimizations and is not recommended for use unless for research purposes.","order":43,"flag":0,"source":"public-provider-conf"},"vision":false},{"id":"deepseek-ai/DeepSeek-V2.5","name":"DeepSeek-V2.5","display_name":"DeepSeek-V2.5","type":"chat","context_length":0,"max_output_tokens":0,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"developer":"DeepSeek","developerId":7,"providerId":44,"modelRatio":0.08,"cacheRatio":1,"completionRatio":2,"order":0,"flag":0,"source":"public-provider-conf"},"vision":false},{"id":"deepseek-ai/DeepSeek-V3","name":"DeepSeek-V3","display_name":"DeepSeek-V3","type":"chat","context_length":0,"max_output_tokens":0,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"developer":"DeepSeek","developerId":7,"providerId":8,"modelRatio":0.15,"cacheRatio":1,"completionRatio":1,"description":"来自多个开源部署路由；相对稳定提供","descriptionEn":"Sourced from multiple open-source deployment routes; relatively stable provision.","order":13,"flag":0,"source":"public-provider-conf"},"vision":false},{"id":"deepseek-ai/DeepSeek-V3-0324","name":"deepseek-ai/DeepSeek-V3-0324","display_name":"deepseek-ai/DeepSeek-V3-0324","type":"chat","context_length":131072,"max_output_tokens":65536,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"modalities":{"input":["text"],"output":["text"]},"metadata":{"developer":"DeepSeek","developerId":7,"providerId":8,"modelRatio":0.1,"cacheRatio":0,"completionRatio":4,"description":"由chutes.ai提供的 deepseek 最新版本 v3-0324；这个是版本，不可用于生产环境，勿高并发请求；仅用于体验测试，生成级别的正在努力部署\nDeepSeek V3是一个拥有 685 亿参数的专家混合模型，是 DeepSeek 团队旗舰聊天模型系列的最新版本。\n它继承了DeepSeek V3模型，并在多种任务上表现出色。","descriptionEn":"Provided by chutes.ai;  \nDeepseek latest version v3-0324;  \nDeepSeek V3 is an expert mixture model with 68.5 billion parameters, and it is the latest version in the flagship chat model series of the DeepSeek team. It inherits from the DeepSeek V3 model and performs excellently across various tasks.","order":250,"flag":2,"tags":["best","economical"],"modalities":["text"],"typeHints":["t2t"],"source":"public-provider-conf"},"vision":false},{"id":"deepseek-ai/deepseek-vl2","name":"deepseek-ai/deepseek-vl2","display_name":"deepseek-ai/deepseek-vl2","type":"chat","context_length":0,"max_output_tokens":0,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"developer":"DeepSeek","developerId":7,"providerId":44,"modelRatio":0.08,"cacheRatio":1,"completionRatio":1,"order":0,"flag":0,"source":"public-provider-conf"},"vision":false},{"id":"deepseek-chat","name":"DeepSeek-V3.1","display_name":"DeepSeek-V3.1","type":"chat","context_length":128000,"max_output_tokens":128000,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"developer":"DeepSeek","developerId":7,"providerId":36,"modelRatio":0.28,"cacheRatio":0.125,"completionRatio":3,"description":"DeepSeek-V3.1-Terminus (non-thinking mode)","descriptionEn":"DeepSeek-V3.1-Terminus (non-thinking mode)","order":99,"flag":0,"source":"public-provider-conf"},"vision":false},{"id":"deepseek-r1-250120","name":"deepseek-r1-250120","display_name":"deepseek-r1-250120","type":"chat","context_length":0,"max_output_tokens":0,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"developer":"DeepSeek","developerId":7,"providerId":40,"modelRatio":0.273,"cacheRatio":1,"completionRatio":4,"order":0,"flag":0,"source":"public-provider-conf"},"vision":false},{"id":"deepseek-r1-250528","name":"deepseek-r1-250528","display_name":"deepseek-r1-250528","type":"chat","context_length":0,"max_output_tokens":0,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"developer":"DeepSeek","developerId":7,"providerId":40,"modelRatio":0.273,"cacheRatio":1,"completionRatio":4,"description":"来自字节跳动。","descriptionEn":"From ByteDance.","order":0,"flag":0,"source":"public-provider-conf"},"vision":false},{"id":"deepseek-r1-distill-llama-70b","name":"deepseek-r1-distill-llama-70b","display_name":"deepseek-r1-distill-llama-70b","type":"chat","context_length":0,"max_output_tokens":0,"capabilities":{"vision":false,"function_calling":false,"reasoning":true,"tool_calling":false},"reasoning":true,"tool_call":false,"modalities":{"input":["text"],"output":["text"]},"metadata":{"developer":"DeepSeek","developerId":7,"providerId":36,"modelRatio":0.4,"cacheRatio":1,"completionRatio":2,"description":"由groq提供，DeepSeek-R1-Distill模型是基于开源模型进行微调的，使用的是由DeepSeek-R1生成的样本。我们对它们的配置和分词器进行了稍微修改。请使用我们的设置来运行这些模型。","descriptionEn":"Provided by Groq, the DeepSeek-R1-Distill model is fine-tuned based on an open-source model, using samples generated by DeepSeek-R1. We have made slight modifications to their configurations and tokenizers. Please use our settings to run these models.","order":188,"flag":0,"features":["thinking"],"tags":["lightning"],"modalities":["text"],"typeHints":["t2t"],"source":"public-provider-conf"},"vision":false},{"id":"deepseek-r1-distill-qianfan-llama-8b","name":"deepseek-r1-distill-qianfan-llama-8b","display_name":"deepseek-r1-distill-qianfan-llama-8b","type":"chat","context_length":0,"max_output_tokens":0,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"developer":"DeepSeek","developerId":11,"providerId":24,"modelRatio":0.0685,"cacheRatio":1,"completionRatio":4,"order":0,"flag":0,"source":"public-provider-conf"},"vision":false},{"id":"deepseek-reasoner","name":"DeepSeek-R1","display_name":"DeepSeek-R1","type":"chat","context_length":0,"max_output_tokens":0,"capabilities":{"vision":false,"function_calling":false,"reasoning":true,"tool_calling":false},"reasoning":true,"tool_call":false,"modalities":{"input":["text"],"output":["text"]},"metadata":{"developer":"DeepSeek","developerId":7,"providerId":36,"modelRatio":0.14,"cacheRatio":0.1,"completionRatio":1.5,"description":"DeepSeek-V3.2-Exp-Think","descriptionEn":"DeepSeek-V3.2-Exp-Think","order":248,"flag":0,"features":["thinking"],"modalities":["text"],"typeHints":["t2t"],"source":"public-provider-conf"},"vision":false},{"id":"deepseek-v3-250324","name":"deepseek-v3-250324","display_name":"deepseek-v3-250324","type":"chat","context_length":0,"max_output_tokens":0,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"developer":"DeepSeek","developerId":7,"providerId":40,"modelRatio":0.136,"cacheRatio":1,"completionRatio":4,"order":0,"flag":0,"source":"public-provider-conf"},"vision":false},{"id":"deepseek-v3.1-250821","name":"deepseek-v3.1-250821","display_name":"deepseek-v3.1-250821","type":"chat","context_length":0,"max_output_tokens":0,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"developer":"DeepSeek","developerId":7,"providerId":8,"modelRatio":0.28,"cacheRatio":1,"completionRatio":3,"description":"DeepSeek V3.1是深度求索提供的文本生成类模型，拥有混合推理架构，实现了思考模式和非思考模式的有效融合。\nDeepSeek-V3.1-250821为DeepSeek V3.1 的非思考模式，不支持开启思考。","descriptionEn":"DeepSeek V3.1 is a text generation model provided by DeepSeek, featuring a hybrid inference architecture that effectively integrates thinking and non-thinking modes.  \nDeepSeek-V3.1-250821 is the non-thinking mode of DeepSeek V3.1 and does not support enabling thinking.","order":700,"flag":1,"source":"public-provider-conf"},"vision":false},{"id":"deepseek-v3.1-think-250821","name":"deepseek-v3.1-think-250821","display_name":"deepseek-v3.1-think-250821","type":"chat","context_length":0,"max_output_tokens":0,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"developer":"DeepSeek","developerId":7,"providerId":15,"modelRatio":0.28,"cacheRatio":1,"completionRatio":3,"description":"DeepSeek-V3.1-Think-250821 为DeepSeek V3.1 的思考模式。\nDeepSeek V3.1是深度求索提供的文本生成类模型，拥有混合推理架构，实现了思考模式和非思考模式的有效融合。\n","descriptionEn":"DeepSeek-V3.1-Think-250821 is the thinking mode of DeepSeek V3.1.  \nDeepSeek V3.1 is a text generation model provided by DeepSeek, featuring a hybrid reasoning architecture that achieves an effective integration of thinking and non-thinking modes.","order":700,"flag":1,"source":"public-provider-conf"},"vision":false},{"id":"distil-whisper-large-v3-en","name":"whisper-large-v3","display_name":"whisper-large-v3","type":"chat","context_length":0,"max_output_tokens":0,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"modalities":{"input":["audio"],"output":["audio"]},"metadata":{"developer":"OpenAI","developerId":12,"providerId":29,"modelRatio":2.778,"cacheRatio":1,"completionRatio":1,"description":"Groq开源部署非","order":0,"flag":0,"modalities":["audio"],"typeHints":["stt"],"source":"public-provider-conf"},"vision":false},{"id":"doubao-embedding-large-text-240915","name":"doubao-embedding-large-text-240915","display_name":"doubao-embedding-large-text-240915","type":"embedding","context_length":0,"max_output_tokens":0,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"developer":"Doubao","developerId":4,"providerId":40,"modelRatio":0.05,"cacheRatio":1,"completionRatio":1,"description":"doubao-embedding-large-text-240915\nDoubao Embedding 是一款由字节跳动研发的语义向量化模型，主要面向向量检索的使用场景，支持中、英双语，最长 4K 上下文长度。\n","descriptionEn":"doubao-embedding-large-text-240915\nDoubao Embedding is a semantic vectorization model developed by ByteDance, primarily designed for vector search scenarios. It supports both Chinese and English languages and has a maximum context length of approximately 4K tokens.","order":60,"flag":0,"typeHints":["embedding"],"source":"public-provider-conf"},"vision":false},{"id":"doubao-embedding-text-240715","name":"doubao-embedding-text-240715","display_name":"doubao-embedding-text-240715","type":"embedding","context_length":0,"max_output_tokens":0,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"developer":"Doubao","developerId":4,"providerId":40,"modelRatio":0.35,"cacheRatio":1,"completionRatio":1,"description":"doubao-embedding-text-240715\nDoubao Embedding 是一款由字节跳动研发的语义向量化模型，主要面向向量检索的使用场景，支持中、英双语，最长 4K 上下文长度。\n","descriptionEn":"doubao-embedding-text-240715\nDoubao Embedding is a semantic vectorization model developed by ByteDance, primarily designed for vector search scenarios. It supports both Chinese and English languages and has a maximum context length of approximately 4K tokens.","order":45,"flag":0,"typeHints":["embedding"],"source":"public-provider-conf"},"vision":false},{"id":"doubao-seed-1-6-250615","name":"doubao-seed-1-6-250615","display_name":"doubao-seed-1-6-250615","type":"chat","context_length":256000,"max_output_tokens":256000,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"developer":"Doubao","developerId":4,"providerId":40,"modelRatio":0.09,"cacheRatio":1,"completionRatio":14,"description":"官方按分段计费，之前取了最低档导致被刷，损失比较大；7 月 31 日 00:30 起暂时调整至统一按第三档收费；分段计费我们尽快支持\nDoubao-Seed-1.6全新多模态深度思考模型，同时支持auto/thinking/non-thinking三种思考模式。 non-thinking模式下，模型效果对比Doubao-1.5-pro/250115大幅提升。支持 256k 上下文窗口，输出长度支持最大 16k tokens。","descriptionEn":"Doubao-Seed-1.6 is a brand-new multimodal deep thinking model that supports three thinking modes: auto, thinking, and non-thinking. In non-thinking mode, the model's performance is significantly improved compared to Doubao-1.5-pro/250115. It supports a 256k context window and an output length of up to 16k tokens.","order":210,"flag":1,"billingConfig":"{\n  \"model_name\": \"doubao-seed-1-6-250615\",\n  \"default_tier\": \"tier1\",\n  \"token_based_tier_configs\": {\n    \"tier1\": {\n      \"tier_condition\": {\n        \"min_tokens\": 0,\n        \"max_tokens\": 32000\n      },\n      \"model_ratio\": 0.054795,\n      \"prompt_tokens_ratio\": 1.0,\n      \"completion_tokens_ratio\": 10.0,\n      \"cached_tokens_ratio\": 0.2\n    },\n    \"tier2\": {\n      \"tier_condition\": {\n        \"min_tokens\": 32001,\n        \"max_tokens\": 128000\n      },\n      \"model_ratio\": 0.082192,\n      \"prompt_tokens_ratio\": 1.0,\n      \"completion_tokens_ratio\": 13.33,\n      \"cached_tokens_ratio\": 0.133\n    },\n    \"tier3\": {\n      \"tier_condition\": {\n        \"min_tokens\": 128001,\n        \"max_tokens\": 256000\n      },\n      \"model_ratio\": 0.164384,\n      \"prompt_tokens_ratio\": 1.0,\n      \"completion_tokens_ratio\": 10.0,\n      \"cached_tokens_ratio\": 0.067\n    }\n  },\n  \"per_unit_price_config\": {\n    \"cache_storage_price\": 0.002329\n  },\n  \"enabled_billing_items\": [\n    \"prompt_tokens\",\n    \"completion_tokens\",\n    \"cached_tokens\",\n    \"cache_storage_hours\"\n  ]\n}","source":"public-provider-conf"},"vision":false},{"id":"doubao-seed-1-6-flash-250615","name":"doubao-seed-1-6-flash-250615","display_name":"doubao-seed-1-6-flash-250615","type":"chat","context_length":0,"max_output_tokens":0,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"developer":"Doubao","developerId":4,"providerId":40,"modelRatio":0.022,"cacheRatio":1,"completionRatio":10,"description":"Doubao-Seed-1.6-flash推理速度极致的多模态深度思考模型，TPOT仅需10ms； 同时支持文本和视觉理解，文本理解能力超过上一代lite，视觉理解比肩友商pro系列模型。支持 256k 上下文窗口，输出长度支持最大 16k tokens。","descriptionEn":"Doubao-Seed-1.6-flash is an extremely fast multimodal deep thinking model, with TPOT requiring only 10ms. It supports both text and visual understanding, with its text comprehension skills surpassing the previous generation lite model and its visual understanding on par with competitor's pro series models. It supports a 256k context window and an output length of up to 16k tokens.","order":210,"flag":1,"billingConfig":"{\n  \"model_name\": \"doubao-seed-1-6-flash-250615\",\n  \"default_tier\": \"tier1\",\n  \"token_based_tier_configs\": {\n    \"tier1\": {\n      \"tier_condition\": {\n        \"min_tokens\": 0,\n        \"max_tokens\": 32000\n      },\n      \"model_ratio\": 0.010274,\n      \"prompt_tokens_ratio\": 1.0,\n      \"completion_tokens_ratio\": 10.0,\n      \"cached_tokens_ratio\": 0.2\n    },\n    \"tier2\": {\n      \"tier_condition\": {\n        \"min_tokens\": 32001,\n        \"max_tokens\": 128000\n      },\n      \"model_ratio\": 0.020548,\n      \"prompt_tokens_ratio\": 1.0,\n      \"completion_tokens_ratio\": 10.0,\n      \"cached_tokens_ratio\": 0.1\n    },\n    \"tier3\": {\n      \"tier_condition\": {\n        \"min_tokens\": 128001,\n        \"max_tokens\": 256000\n      },\n      \"model_ratio\": 0.041096,\n      \"prompt_tokens_ratio\": 1.0,\n      \"completion_tokens_ratio\": 10.0,\n      \"cached_tokens_ratio\": 0.05\n    }\n  },\n  \"per_unit_price_config\": {\n    \"cache_storage_price\": 0.002329\n  },\n  \"enabled_billing_items\": [\n    \"prompt_tokens\",\n    \"completion_tokens\",\n    \"cached_tokens\",\n    \"cache_storage_hours\"\n  ]\n}","source":"public-provider-conf"},"vision":false},{"id":"doubao-seed-1-6-thinking-250615","name":"doubao-seed-1-6-thinking-250615","display_name":"doubao-seed-1-6-thinking-250615","type":"chat","context_length":256000,"max_output_tokens":256000,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"developer":"Doubao","developerId":4,"providerId":40,"modelRatio":0.09,"cacheRatio":1,"completionRatio":14,"description":"Doubao-Seed-1.6-thinking模型思考能力大幅强化， 对比Doubao-1.5-thinking-pro，在Coding、Math、 逻辑推理等基础能力上进一步提升， 支持视觉理解。 支持 256k 上下文窗口，输出长度支持最大 16k tokens。","descriptionEn":"The Doubao-Seed-1.6-thinking model has significantly enhanced reasoning capabilities. Compared with Doubao-1.5-thinking-pro, it has further improvements in fundamental abilities such as coding, mathematics, and logical reasoning, and now also supports visual understanding. It supports a 256k context window, with output length supporting up to 16k tokens.","order":210,"flag":1,"billingConfig":"{\n  \"model_name\": \"doubao-seed-1-6-thinking-250615\",\n  \"default_tier\": \"tier1\",\n  \"token_based_tier_configs\": {\n    \"tier1\": {\n      \"tier_condition\": {\n        \"min_tokens\": 0,\n        \"max_tokens\": 32000\n      },\n      \"model_ratio\": 0.054795,\n      \"prompt_tokens_ratio\": 1.0,\n      \"completion_tokens_ratio\": 10.0,\n      \"cached_tokens_ratio\": 0.2\n    },\n    \"tier2\": {\n      \"tier_condition\": {\n        \"min_tokens\": 32001,\n        \"max_tokens\": 128000\n      },\n      \"model_ratio\": 0.082192,\n      \"prompt_tokens_ratio\": 1.0,\n      \"completion_tokens_ratio\": 13.33,\n      \"cached_tokens_ratio\": 0.133\n    },\n    \"tier3\": {\n      \"tier_condition\": {\n        \"min_tokens\": 128001,\n        \"max_tokens\": 256000\n      },\n      \"model_ratio\": 0.164384,\n      \"prompt_tokens_ratio\": 1.0,\n      \"completion_tokens_ratio\": 10.0,\n      \"cached_tokens_ratio\": 0.067\n    }\n  },\n  \"per_unit_price_config\": {\n    \"cache_storage_price\": 0.002329\n  },\n  \"enabled_billing_items\": [\n    \"prompt_tokens\",\n    \"completion_tokens\",\n    \"cached_tokens\",\n    \"cache_storage_hours\"\n  ]\n}","source":"public-provider-conf"},"vision":false},{"id":"doubao-seed-1-6-vision-250815","name":"doubao-seed-1-6-vision-250815","display_name":"doubao-seed-1-6-vision-250815","type":"chat","context_length":0,"max_output_tokens":0,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"developer":"Doubao","developerId":4,"providerId":40,"modelRatio":0.054795,"cacheRatio":0.2,"completionRatio":10,"description":"Doubao-Seed-1.6-vision 视觉深度思考模型，在教育、图像审核、巡检与安防和AI 搜索问答等场景下展现出更强的通用多模态理解和推理能力。支持 256k 上下文窗口，输出长度支持最大 64k tokens。","descriptionEn":"Doubao-Seed-1.6-vision is a visual deep-thinking model that demonstrates stronger general multimodal understanding and reasoning capabilities in scenarios such as education, image moderation, inspection and security, and AI search Q&A. It supports a 256K context window and an output length of up to 64K tokens.","order":209,"flag":0,"billingConfig":"{\n  \"model_name\": \"doubao-seed-1-6-vision-250815\",\n  \"default_tier\": \"tier1\",\n  \"token_based_tier_configs\": {\n    \"tier1\": {\n      \"tier_condition\": {\n        \"min_tokens\": 0,\n        \"max_tokens\": 32000\n      },\n      \"model_ratio\": 0.054795,\n      \"prompt_tokens_ratio\": 1.0,\n      \"completion_tokens_ratio\": 10.0,\n      \"cached_tokens_ratio\": 0.2\n    },\n    \"tier2\": {\n      \"tier_condition\": {\n        \"min_tokens\": 32001,\n        \"max_tokens\": 128000\n      },\n      \"model_ratio\": 0.082192,\n      \"prompt_tokens_ratio\": 1.0,\n      \"completion_tokens_ratio\": 13.33,\n      \"cached_tokens_ratio\": 0.133\n    },\n    \"tier3\": {\n      \"tier_condition\": {\n        \"min_tokens\": 128001,\n        \"max_tokens\": 256000\n      },\n      \"model_ratio\": 0.164384,\n      \"prompt_tokens_ratio\": 1.0,\n      \"completion_tokens_ratio\": 10.0,\n      \"cached_tokens_ratio\": 0.067\n    }\n  },\n  \"per_unit_price_config\": {\n    \"cache_storage_price\": 0.002329\n  },\n  \"enabled_billing_items\": [\n    \"prompt_tokens\",\n    \"completion_tokens\",\n    \"cached_tokens\",\n    \"cache_storage_hours\"\n  ]\n}","source":"public-provider-conf"},"vision":false},{"id":"doubao-seedream-4-0-250828","name":"doubao-seedream-4-0-250828","display_name":"doubao-seedream-4-0-250828","type":"image-generation","context_length":0,"max_output_tokens":0,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"developer":"Doubao","developerId":4,"providerId":40,"modelRatio":1,"cacheRatio":0,"completionRatio":0,"description":"\"Seedream 4.0 是基于领先架构的SOTA级多模态图像创作模型。其打破传统文生图模型的创作边界，原生支持文本、单图和多图输入，用户可自由融合文本与图像，在同一模型下实现基于主体一致性的多图融合创作、图像编辑、组图生成等多样玩法，让图像创作更加自由可控\nSeedream 4.0 支持单次输入最多 10 张图像进行复合编辑，并能通过对提示词的深度推理，自动适配最优的图像比例尺寸与生成数量，可一次性连续输出最多 15 张内容关联的图像。此外，模型显著提升了中文生成的准确率与内容多样性，且支持 4K 超高清输出，为专业图像创作提供了从生成到编辑的一站式解决方案。\"","descriptionEn":"\"Seedream 4.0 is a SOTA-level multimodal image creation model based on leading architecture. It breaks the creative boundaries of traditional text-to-image models by natively supporting text, single image, and multiple image inputs. Users can freely combine text and images to achieve various creative styles within the same model, such as multi-image fusion creation based on subject consistency, image editing, and set image generation, making image creation more flexible and controllable.\nSeedream 4.0 supports composite editing with up to 10 images in a single input. Through deep reasoning of prompt words, it automatically adapts the optimal image aspect ratio and generation quantity, enabling continuous output of up to 15 content-related images at one time. Additionally, the model significantly improves the accuracy and content diversity of Chinese generation, supports 4K ultra-high-definition output, and provides a one-stop solution from generation to editing for professional image creation.\"","order":800,"flag":0,"imagePriceConfig":"{\"generate\":{\"standard\":{\"standard\":0.021}}}","typeHints":["t2i"],"source":"public-provider-conf"},"vision":false},{"id":"embedding-v1","name":"embedding-v1","display_name":"embedding-v1","type":"embedding","context_length":0,"max_output_tokens":0,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"developer":"Baidu","developerId":25,"providerId":15,"modelRatio":0.034,"cacheRatio":1,"completionRatio":1,"description":"Embedding-V1是一个基于百度文心大模型技术的文本表示模型，可以将文本转化为用数值表示的向量形式，用于文本检索、信息推荐、知识挖掘等场景。 Embedding-V1提供了Embeddings接口，可以根据输入内容生成对应的向量表示。您可以通过调用该接口，将文本输入到模型中，获取到对应的向量表示，从而进行后续的文本处理和分析。","descriptionEn":"Embedding-V1 is a text representation model based on Baidu's Wenxin large model technology, capable of converting text into numerical vector forms for applications such as text retrieval, information recommendation, and knowledge mining. Embedding-V1 provides an Embeddings interface that generates corresponding vector representations based on the input content. By calling this interface, you can input text into the model and obtain the corresponding vector representations for subsequent text processing and analysis.","order":600,"flag":0,"typeHints":["embedding"],"source":"public-provider-conf"},"vision":false},{"id":"ernie-4.5-0.3b","name":"ernie-4.5-0.3b","display_name":"ernie-4.5-0.3b","type":"chat","context_length":0,"max_output_tokens":0,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"developer":"Baidu","developerId":25,"providerId":15,"modelRatio":0.0068,"cacheRatio":1,"completionRatio":4,"description":"文心大模型4.5是百度自主研发的新一代原生多模态基础大模型，通过多个模态联合建模实现协同优化，多模态理解能力优秀；具备更精进的语言能力，理解、生成、逻辑、记忆能力全面提升，去幻觉、逻辑推理、代码能力显著提升。","descriptionEn":"Wenxin Large Model 4.5 is a next-generation native multimodal foundational large model independently developed by Baidu. It achieves collaborative optimization through joint modeling of multiple modalities, demonstrating excellent multimodal understanding capabilities. The model possesses enhanced language abilities, with comprehensive improvements in understanding, generation, reasoning, and memory. It significantly reduces hallucinations and shows notable advancements in logical reasoning and coding skills.","order":100,"flag":0,"source":"public-provider-conf"},"vision":false},{"id":"ernie-4.5-21b-a3b","name":"ernie-4.5-21b-a3b","display_name":"ernie-4.5-21b-a3b","type":"chat","context_length":0,"max_output_tokens":0,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"developer":"Baidu","developerId":25,"providerId":15,"modelRatio":0.034,"cacheRatio":1,"completionRatio":4,"description":"文心大模型4.5是百度自主研发的新一代原生多模态基础大模型，通过多个模态联合建模实现协同优化，多模态理解能力优秀；具备更精进的语言能力，理解、生成、逻辑、记忆能力全面提升，去幻觉、逻辑推理、代码能力显著提升。ERNIE-4.5-21B-A3B 是 MoE 结构的对齐开源模型, 总参 21B，激活 3B。","descriptionEn":"Wenxin Large Model 4.5 is a next-generation native multimodal foundational model independently developed by Baidu. It achieves collaborative optimization through joint modeling of multiple modalities, demonstrating excellent multimodal understanding capabilities; it possesses more advanced language abilities, with comprehensive improvements in comprehension, generation, logic, and memory, as well as significant enhancements in hallucination reduction, logical reasoning, and coding capabilities.ERNIE-4.5-21B-A3B is an aligned open-source model with a MoE structure, having a total of 21 billion parameters and 3 billion activated parameters.","order":500,"flag":0,"source":"public-provider-conf"},"vision":false},{"id":"ernie-4.5-21b-a3b-thinking","name":"ernie-4.5-21b-a3b-thinking","display_name":"ernie-4.5-21b-a3b-thinking","type":"chat","context_length":120000,"max_output_tokens":120000,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"developer":"Baidu","developerId":25,"providerId":15,"modelRatio":0.034,"cacheRatio":1,"completionRatio":4,"description":"文心大模型4.5是百度自主研发的新一代原生多模态基础大模型，通过多个模态联合建模实现协同优化，多模态理解能力优秀；具备更精进的语言能力，理解、生成、逻辑、记忆能力全面提升，去幻觉、逻辑推理、代码能力显著提升。ERNIE-4.5-21B-A3B-Thinking 是一个文本 MoE 后训练模型, 总参 21B，激活 3B，推理质量和深度显著提升。","descriptionEn":"Wenxin Large Model 4.5 is a next-generation native multimodal foundational model independently developed by Baidu. It achieves collaborative optimization through joint modeling of multiple modalities, demonstrating excellent multimodal understanding capabilities; it possesses more advanced language abilities, with comprehensive improvements in comprehension, generation, logic, and memory, as well as significant enhancements in hallucination reduction, logical reasoning, and coding capabilities.ERNIE-4.5-21B-A3B-Thinking is a text MoE post-training model with a total of 21 billion parameters and 3 billion activated parameters, significantly enhancing inference quality and depth.","order":600,"flag":1,"source":"public-provider-conf"},"vision":false},{"id":"ernie-4.5-turbo-128k-preview","name":"ernie-4.5-turbo-128k-preview","display_name":"ernie-4.5-turbo-128k-preview","type":"chat","context_length":0,"max_output_tokens":0,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"developer":"Baidu","developerId":25,"providerId":15,"modelRatio":0.054,"cacheRatio":1,"completionRatio":4,"description":"文心4.5 Turbo在去幻觉、逻辑推理和代码能力等方面也有着明显增强。对比文心4.5，速度更快、价格更低。","descriptionEn":"Wenxin 4.5 Turbo also shows significant enhancements in reducing hallucinations, logical reasoning, and coding capabilities. Compared to Wenxin 4.5, it is faster and more cost-effective.","order":100,"flag":0,"source":"public-provider-conf"},"vision":false},{"id":"ernie-4.5-turbo-latest","name":"ernie-4.5-turbo-latest","display_name":"ernie-4.5-turbo-latest","type":"chat","context_length":128000,"max_output_tokens":128000,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"developer":"Baidu","developerId":25,"providerId":15,"modelRatio":0.055,"cacheRatio":1,"completionRatio":4,"description":"文心4.5 Turbo在去幻觉、逻辑推理和代码能力等方面也有着明显增强。对比文心4.5，速度更快、价格更低。","descriptionEn":"Wenxin 4.5 Turbo also has significant improvements in hallucination reduction, logical reasoning, and coding capabilities. Compared to Wenxin 4.5, it is faster and more affordable.","order":600,"flag":0,"source":"public-provider-conf"},"vision":false},{"id":"ernie-4.5-turbo-vl","name":"ernie-4.5-turbo-vl","display_name":"ernie-4.5-turbo-vl","type":"chat","context_length":128000,"max_output_tokens":128000,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"developer":"Baidu","developerId":25,"providerId":15,"modelRatio":0.2,"cacheRatio":1,"completionRatio":3,"description":"文心一言大模型全新版本，图片理解、创作、翻译、代码等能力显著提升，首次支持32K上下文长度，首Token时延显著降低。","descriptionEn":"The new version of the Wenxin Yiyan large model significantly improves capabilities in image understanding, creation, translation, and coding. It supports a context length of up to 32K tokens for the first time, with a notable reduction in the latency of the first token.","order":500,"flag":0,"source":"public-provider-conf"},"vision":false},{"id":"ernie-4.5-turbo-vl-32k-preview","name":"ernie-4.5-turbo-vl-32k-preview","display_name":"ernie-4.5-turbo-vl-32k-preview","type":"chat","context_length":0,"max_output_tokens":0,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"developer":"Baidu","developerId":25,"providerId":15,"modelRatio":0.2,"cacheRatio":1,"completionRatio":3,"description":"文心一言大模型全新版本，图片理解、创作、翻译、代码等能力显著提升，首次支持32K上下文长度，首Token时延显著降低。","descriptionEn":"The new version of the Wenxin Yiyan large model significantly improves capabilities in image understanding, creation, translation, and coding. It supports a context length of up to 32K tokens for the first time, with a notable reduction in the latency of the first token.","order":100,"flag":0,"source":"public-provider-conf"},"vision":false},{"id":"ernie-4.5-turbo-vl-latest","name":"ernie-4.5-turbo-vl-latest","display_name":"ernie-4.5-turbo-vl-latest","type":"chat","context_length":128000,"max_output_tokens":128000,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"developer":"Baidu","developerId":25,"providerId":15,"modelRatio":0.2,"cacheRatio":1,"completionRatio":3,"description":"文心一言大模型全新版本，图片理解、创作、翻译、代码等能力显著提升，首次支持32K上下文长度，首Token时延显著降低。","descriptionEn":"The new version of the Wenxin Yiyan large model significantly improves capabilities in image understanding, creation, translation, and coding. It supports a context length of up to 32K tokens for the first time, with a notable reduction in the latency of the first token.","order":600,"flag":0,"source":"public-provider-conf"},"vision":false},{"id":"ernie-irag-edit","name":"ernie-irag-edit","display_name":"ernie-irag-edit","type":"image-generation","context_length":0,"max_output_tokens":0,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"developer":"Baidu","developerId":25,"providerId":15,"modelRatio":1,"cacheRatio":0,"completionRatio":0,"description":"百度自研的ERNIE iRAG Edit图像编辑模型支持基于图片进行erase（消除对象）、repaint（重绘对象）、variation（生成变体）等操作。","descriptionEn":"Baidu's self-developed ERNIE iRAG Edit image editing model supports operations based on images such as erase (object removal), repaint (object redrawing), and variation (variant generation).","order":600,"flag":0,"imagePriceConfig":"{\"generate\":{\"standard\":{\"standard\":0.019}}}","typeHints":["t2i"],"source":"public-provider-conf"},"vision":false},{"id":"ernie-x1-turbo-32k-preview","name":"ernie-x1-turbo-32k-preview","display_name":"ernie-x1-turbo-32k-preview","type":"chat","context_length":0,"max_output_tokens":0,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"developer":"Baidu","developerId":25,"providerId":15,"modelRatio":0.068,"cacheRatio":1,"completionRatio":4,"description":"文心大模型X1具备更强的理解、规划、反思、进化能力。作为能力更全面的深度思考模型，文心X1兼备准确、创意和文采，在中文知识问答、文学创作、文稿写作、日常对话、逻辑推理、复杂计算及工具调用等方面表现尤为出色。","descriptionEn":"Wenxin Large Model X1 possesses enhanced abilities in understanding, planning, reflection, and evolution. As a more comprehensive deep-thinking model, Wenxin X1 combines accuracy, creativity, and literary elegance, excelling particularly in Chinese knowledge Q&A, literary creation, document writing, daily conversations, logical reasoning, complex calculations, and tool invocation.","order":100,"flag":0,"source":"public-provider-conf"},"vision":false},{"id":"ernie-x1.1-preview","name":"ernie-x1.1-preview","display_name":"ernie-x1.1-preview","type":"chat","context_length":0,"max_output_tokens":0,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"developer":"Baidu","developerId":25,"providerId":15,"modelRatio":0.068,"cacheRatio":1,"completionRatio":4,"description":"文心大模型X1.1在问答、工具调用、智能体、指令遵循、逻辑推理、数学、代码任务的效果显著提升，事实性显著提升；上下文长度扩展到64K tokens，支持更长的输入与对话历史，在保持响应速度的同时，提高了长链路推理的连贯性。","descriptionEn":"The Wenxin large model X1.1 has made significant improvements in question answering, tool invocation, intelligent agents, instruction following, logical reasoning, mathematics, and coding tasks, with notable enhancements in factual accuracy. The context length has been extended to 64K tokens, supporting longer inputs and dialogue history, which improves the coherence of long-chain reasoning while maintaining response speed.","order":101,"flag":1,"source":"public-provider-conf"},"vision":false},{"id":"flux-kontext-max","name":"flux-kontext-max","display_name":"flux-kontext-max","type":"image-generation","context_length":0,"max_output_tokens":0,"capabilities":{"vision":true,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"modalities":{"input":["text","image"],"output":["text","image"]},"metadata":{"developer":"Flux","developerId":27,"providerId":53,"modelRatio":1.1,"cacheRatio":0,"completionRatio":1,"description":"黑森林实验室推出的一款高端文本引导图像编辑模型，专为最大性能设计。它在高级提示遵循、高质量排版生成和结果一致性方面表现出色，适合需要精确、上下文感知编辑和快速迭代的专业工作流程。支持复杂转换，同时保持角色一致性和视觉保真度。","descriptionEn":"Flux.1 Kontext [max] is a premium text-based image editing model from Black Forest Labs, designed for maximum performance. It excels in advanced prompt adherence, high-quality typography generation, and consistent results, making it ideal for professional workflows requiring precise, context-aware edits and rapid iteration. It supports complex transformations while maintaining character consistency and visual fidelity.  ","order":0,"flag":1,"displayInput":"-","displayOutput":"$0.088 / IMG","modalities":["text","image"],"typeHints":["t2i"],"source":"public-provider-conf"},"vision":true},{"id":"flux-kontext-pro","name":"flux-kontext-pro","display_name":"flux-kontext-pro","type":"image-generation","context_length":0,"max_output_tokens":0,"capabilities":{"vision":true,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"modalities":{"input":["text","image"],"output":["text","image"]},"metadata":{"developer":"Flux","developerId":27,"providerId":53,"modelRatio":1.11,"cacheRatio":0,"completionRatio":1,"description":"黑森林实验室开发的专业级 AI 图像编辑模型，优化用于快速迭代工作流程。它提供高质量输出，具备出色的提示遵循能力和角色保留功能，支持文本替换或风格转换等针对性编辑，同时不影响图像其他部分。非常适合高效、上下文感知的编辑。","descriptionEn":"A professional-grade AI image editing model by Black Forest Labs, optimized for fast, iterative workflows. It delivers high-quality outputs with excellent prompt following and character preservation, enabling targeted edits like text replacement or style transfer without affecting the rest of the image. Accessible via API, it’s perfect for efficient, context-aware editing. ","order":0,"flag":1,"displayInput":"-","displayOutput":"$0.044 / IMG","modalities":["text","image"],"typeHints":["t2i"],"source":"public-provider-conf"},"vision":true},{"id":"gemini-1.5-flash","name":"gemini-1.5-flash","display_name":"gemini-1.5-flash","type":"chat","context_length":2000000,"max_output_tokens":2000000,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"modalities":{"input":["text"],"output":["text"]},"metadata":{"developer":"Google","developerId":8,"providerId":24,"modelRatio":0.0375,"cacheRatio":1,"completionRatio":4,"order":0,"flag":0,"billingConfig":"{\n  \"model_name\": \"gemini-1.5-flash\",\n  \"default_tier\": \"tier1\",\n  \"token_based_tier_configs\": {\n    \"tier1\": {\n      \"tier_condition\": {\n        \"min_tokens\": 0,\n        \"max_tokens\": 128000\n      },\n      \"model_ratio\": 0.0375,\n      \"prompt_tokens_ratio\": 1.0,\n      \"completion_tokens_ratio\": 4.0,\n      \"cached_tokens_ratio\": 0.25\n    },\n    \"tier2\": {\n      \"tier_condition\": {\n        \"min_tokens\": 128001,\n        \"max_tokens\": -1\n      },\n      \"model_ratio\": 0.075,\n      \"prompt_tokens_ratio\": 1.0,\n      \"completion_tokens_ratio\": 4.0,\n      \"cached_tokens_ratio\": 0.25\n    }\n  },\n  \"per_unit_price_config\": {\n    \"web_search_price\": 0.035,\n    \"cache_storage_price\": 1.00\n  },\n  \"enabled_billing_items\": [\n    \"prompt_tokens\",\n    \"completion_tokens\",\n    \"cached_tokens\",\n    \"web_search_requests\",\n    \"cache_storage_hours\"\n  ]\n}","features":["long_context"],"tags":["multi_modal","economical","lightning"],"modalities":["text"],"typeHints":["t2t"],"source":"public-provider-conf"},"vision":false},{"id":"gemini-1.5-flash-002","name":"gemini-1.5-flash","display_name":"gemini-1.5-flash","type":"chat","context_length":2000000,"max_output_tokens":2000000,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"modalities":{"input":["text"],"output":["text"]},"metadata":{"developer":"Google","developerId":8,"providerId":24,"modelRatio":0.0375,"cacheRatio":1,"completionRatio":4,"order":0,"flag":0,"billingConfig":"{   \"model_name\": \"gemini-1.5-flash\",   \"default_tier\": \"tier1\",   \"token_based_tier_configs\": {     \"tier1\": {       \"tier_condition\": {         \"min_tokens\": 0,         \"max_tokens\": 128000       },       \"model_ratio\": 0.0375,       \"prompt_tokens_ratio\": 1.0,       \"completion_tokens_ratio\": 4.0,       \"cached_tokens_ratio\": 0.25     },     \"tier2\": {       \"tier_condition\": {         \"min_tokens\": 128001,         \"max_tokens\": -1       },       \"model_ratio\": 0.075,       \"prompt_tokens_ratio\": 1.0,       \"completion_tokens_ratio\": 4.0,       \"cached_tokens_ratio\": 0.25     }   },   \"per_unit_price_config\": {     \"web_search_price\": 0.035,     \"cache_storage_price\": 1.00   },   \"enabled_billing_items\": [     \"prompt_tokens\",     \"completion_tokens\",     \"cached_tokens\",     \"web_search_requests\",     \"cache_storage_hours\"   ] }","features":["long_context"],"tags":["economical","lightning"],"modalities":["text"],"typeHints":["t2t"],"source":"public-provider-conf"},"vision":false},{"id":"gemini-1.5-flash-exp-0827","name":"gemini-1.5-flash","display_name":"gemini-1.5-flash","type":"chat","context_length":0,"max_output_tokens":0,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"developer":"Google","developerId":8,"providerId":24,"modelRatio":0.0375,"cacheRatio":1,"completionRatio":4,"order":0,"flag":0,"source":"public-provider-conf"},"vision":false},{"id":"gemini-1.5-pro","name":"Gemini 1.5 Pro","display_name":"Gemini 1.5 Pro","type":"chat","context_length":2000000,"max_output_tokens":2000000,"capabilities":{"vision":true,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"modalities":{"input":["text","image"],"output":["text","image"]},"metadata":{"developer":"Google","developerId":8,"providerId":24,"modelRatio":0.625,"cacheRatio":1,"completionRatio":4,"order":0,"flag":0,"billingConfig":"{\n  \"model_name\": \"gemini-1.5-pro\",\n  \"default_tier\": \"tier1\",\n  \"token_based_tier_configs\": {\n    \"tier1\": {\n      \"tier_condition\": {\n        \"min_tokens\": 0,\n        \"max_tokens\": 128000\n      },\n      \"model_ratio\": 0.625,\n      \"prompt_tokens_ratio\": 1.0,\n      \"completion_tokens_ratio\": 4.0,\n      \"cached_tokens_ratio\": 0.25\n    },\n    \"tier2\": {\n      \"tier_condition\": {\n        \"min_tokens\": 128001,\n        \"max_tokens\": -1\n      },\n      \"model_ratio\": 1.25,\n      \"prompt_tokens_ratio\": 1.0,\n      \"completion_tokens_ratio\": 4.0,\n      \"cached_tokens_ratio\": 0.25\n    }\n  },\n  \"per_unit_price_config\": {\n    \"web_search_price\": 0.035,\n    \"cache_storage_price\": 4.50\n  },\n  \"enabled_billing_items\": [\n    \"prompt_tokens\",\n    \"completion_tokens\",\n    \"cached_tokens\",\n    \"web_search_requests\",\n    \"cache_storage_hours\"\n  ]\n}","features":["long_context"],"tags":["multi_modal"],"modalities":["text","image"],"typeHints":["t2t"],"source":"public-provider-conf"},"vision":true},{"id":"gemini-1.5-pro-002","name":"Gemini 1.5 Pro","display_name":"Gemini 1.5 Pro","type":"chat","context_length":0,"max_output_tokens":0,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"developer":"Google","developerId":8,"providerId":24,"modelRatio":0.625,"cacheRatio":1,"completionRatio":4,"order":0,"flag":0,"source":"public-provider-conf"},"vision":false},{"id":"gemini-1.5-pro-exp-0801","name":"Gemini 1.5 Pro","display_name":"Gemini 1.5 Pro","type":"chat","context_length":2000000,"max_output_tokens":2000000,"capabilities":{"vision":true,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"modalities":{"input":["text","image","audio","video"],"output":["text","image","audio","video"]},"metadata":{"developer":"Google","developerId":8,"providerId":24,"modelRatio":0.625,"cacheRatio":1,"completionRatio":4,"order":0,"flag":0,"features":["long_context"],"modalities":["text","image","audio","video"],"typeHints":["t2t"],"source":"public-provider-conf"},"vision":true},{"id":"gemini-1.5-pro-exp-0827","name":"Gemini 1.5 Pro","display_name":"Gemini 1.5 Pro","type":"chat","context_length":2000000,"max_output_tokens":2000000,"capabilities":{"vision":true,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"modalities":{"input":["text","image","audio","video"],"output":["text","image","audio","video"]},"metadata":{"developer":"Google","developerId":8,"providerId":24,"modelRatio":0.625,"cacheRatio":1,"completionRatio":4,"order":0,"flag":0,"features":["long_context"],"modalities":["text","image","audio","video"],"typeHints":["t2t"],"source":"public-provider-conf"},"vision":true},{"id":"gemini-2.0-flash","name":"Gemini 2.0 Flash","display_name":"Gemini 2.0 Flash","type":"chat","context_length":1000000,"max_output_tokens":1000000,"capabilities":{"vision":true,"function_calling":true,"reasoning":false,"tool_calling":true},"reasoning":false,"tool_call":true,"modalities":{"input":["text","image","audio","video"],"output":["text","image","audio","video"]},"metadata":{"developer":"Google","developerId":8,"providerId":24,"modelRatio":0.05,"cacheRatio":0.25,"completionRatio":4,"description":"Gemini 2.0 Flash 是谷歌最新推出的高性价比模型，具有极低的幻觉率，同时保持快速响应速度，为开发者提供高精度且高效的 AI 解决方案，特别适合对事实准确性要求较高的应用场景。支持无限并发，可用于正式生产环境。\n","descriptionEn":"Gemini 2.0 Flash is Google's latest lightweight model featuring extremely low hallucination rates while maintaining fast response times, offering developers high-precision and efficient AI solutions particularly suited for applications requiring high factual accuracy.","order":702,"flag":2,"billingConfig":"{\"model_name\": \"gemini-2.0-flash\", \"default_tier\": \"tier1\", \"enabled_billing_items\": [\"prompt_tokens\", \"completion_tokens\", \"cached_tokens\", \"input_audio_tokens\", \"cached_audio_tokens\", \"web_search_requests\", \"image_generation\", \"cache_storage_hours\"], \"per_unit_price_config\": {\"web_search_price\": 0.035, \"cache_storage_price\": 1.0, \"image_generation_price\": 0.039}, \"token_based_tier_configs\": {\"tier1\": {\"model_ratio\": 0.05, \"tier_condition\": {\"max_tokens\": -1, \"min_tokens\": 0}, \"cached_tokens_ratio\": 2.5, \"prompt_tokens_ratio\": 1.0, \"completion_tokens_ratio\": 4.0, \"input_audio_tokens_ratio\": 7.0, \"cached_audio_tokens_ratio\": 1.75}}}","features":["tools","function_calling","structured_outputs","long_context"],"tags":["optimized","lightning","multi_modal","economical"],"modalities":["text","image","audio","video"],"typeHints":["t2t"],"source":"public-provider-conf"},"vision":true},{"id":"gemini-2.0-flash-001","name":"gemini-2.0-flash","display_name":"gemini-2.0-flash","type":"chat","context_length":0,"max_output_tokens":0,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"developer":"Google","developerId":8,"providerId":42,"modelRatio":0.05,"cacheRatio":1,"completionRatio":4,"description":"Google gemini 的企业版本vertex ai","descriptionEn":"Google Gemini's enterprise version VertexAI","order":0,"flag":0,"billingConfig":"{\"model_name\": \"gemini-2.0-flash\", \"default_tier\": \"tier1\", \"enabled_billing_items\": [\"prompt_tokens\", \"completion_tokens\", \"cached_tokens\", \"input_audio_tokens\", \"cached_audio_tokens\", \"web_search_requests\", \"image_generation\", \"cache_storage_hours\"], \"per_unit_price_config\": {\"web_search_price\": 0.035, \"cache_storage_price\": 1.0, \"image_generation_price\": 0.039}, \"token_based_tier_configs\": {\"tier1\": {\"model_ratio\": 0.05, \"tier_condition\": {\"max_tokens\": -1, \"min_tokens\": 0}, \"cached_tokens_ratio\": 2.5, \"prompt_tokens_ratio\": 1.0, \"completion_tokens_ratio\": 4.0, \"input_audio_tokens_ratio\": 7.0, \"cached_audio_tokens_ratio\": 1.75}}}","source":"public-provider-conf"},"vision":false},{"id":"gemini-2.0-flash-exp","name":"Gemini 2.0 Flash","display_name":"Gemini 2.0 Flash","type":"image-generation","context_length":1050000,"max_output_tokens":1050000,"capabilities":{"vision":true,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"modalities":{"input":["text","image","audio","video"],"output":["text","image","audio","video"]},"metadata":{"developer":"Google","developerId":8,"providerId":24,"modelRatio":0.01,"cacheRatio":1,"completionRatio":4,"description":"Gemini 2.0 Flash实验版本；目前指向最新的gemini-2.0-flash-exp-image-generation 图像生成和编辑；exp谷歌实验版可能不稳定，请勿用在生成环境\nhttps://doc.aihubmix.com/api/Gemini%20%E5%9B%BE%E7%89%87%E7%94%9F%E6%88%90%E5%92%8C%E7%BC%96%E8%BE%91\n需要新增参数来体验新特性 \"modalities\":[\"text\",\"image\"]\n图片以 Base64 编码形式传递与输出\n作为实验模型，建议明确指出 \"输出图片\"，否则可能只有文本\n输出图片的默认高度为 1024px\npython 调用需要最新的 openai sdk 支持，请先运行 pip install -U openai","descriptionEn":"https://doc.aihubmix.com/en/api/Gemini%20%E5%9B%BE%E7%89%87%E7%94%9F%E6%88%90%E5%92%8C%E7%BC%96%E8%BE%91\nInstructions:\n\nNeed to add parameters to experience new features: \"modalities\":[\"text\",\"image\"]\nImages are passed and output in Base64 encoding\nAs an experimental model, it's recommended to explicitly specify \"output image\", otherwise it might only output text\nDefault height for output images is 1024px\nPython calls require the latest OpenAI SDK, run pip install -U openai first","order":150,"flag":1,"features":["long_context"],"tags":["multi_modal"],"modalities":["text","image","audio","video"],"typeHints":["t2t","t2i"],"source":"public-provider-conf"},"vision":true},{"id":"gemini-2.0-flash-exp-image-generation","name":"gemini-2.0-flash-exp-image-generation","display_name":"gemini-2.0-flash-exp-image-generation","type":"chat","context_length":0,"max_output_tokens":0,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"developer":"Google","developerId":8,"providerId":24,"modelRatio":0.05,"cacheRatio":1,"completionRatio":4,"order":0,"flag":0,"source":"public-provider-conf"},"vision":false},{"id":"gemini-2.0-flash-lite","name":"gemini-2.0-flash-lite","display_name":"gemini-2.0-flash-lite","type":"chat","context_length":1050000,"max_output_tokens":1050000,"capabilities":{"vision":true,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"modalities":{"input":["text","image","audio","video"],"output":["text","image","audio","video"]},"metadata":{"developer":"Google","developerId":8,"providerId":24,"modelRatio":0.038,"cacheRatio":1,"completionRatio":4,"description":"gemini-2.0-flash轻量正式版","descriptionEn":"Gemini-2.0-flash Lightweight Official Version","order":0,"flag":0,"billingConfig":"{\n  \"model_name\": \"gemini-2.0-flash-lite\",\n  \"default_tier\": \"tier1\",\n  \"token_based_tier_configs\": {\n    \"tier1\": {\n      \"tier_condition\": {\n        \"min_tokens\": 0,\n        \"max_tokens\": -1\n      },\n      \"model_ratio\": 0.0375,\n      \"prompt_tokens_ratio\": 1.0,\n      \"completion_tokens_ratio\": 4.0\n    }\n  },\n  \"per_unit_price_config\": {},\n  \"enabled_billing_items\": [\n    \"prompt_tokens\",\n    \"completion_tokens\"\n  ]\n}","features":["long_context"],"tags":["multi_modal","economical","lightning"],"modalities":["text","image","audio","video"],"typeHints":["t2t"],"source":"public-provider-conf"},"vision":true},{"id":"gemini-2.0-flash-lite-001","name":"gemini-2.0-flash-lite","display_name":"gemini-2.0-flash-lite","type":"chat","context_length":0,"max_output_tokens":0,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"developer":"Google","developerId":8,"providerId":42,"modelRatio":0.038,"cacheRatio":1,"completionRatio":4,"description":"Google gemini 的企业版本VertexAI","descriptionEn":"Google Gemini's enterprise version VertexAI","order":0,"flag":0,"billingConfig":"{   \"model_name\": \"gemini-2.0-flash-lite\",   \"default_tier\": \"tier1\",   \"token_based_tier_configs\": {     \"tier1\": {       \"tier_condition\": {         \"min_tokens\": 0,         \"max_tokens\": -1       },       \"model_ratio\": 0.0375,       \"prompt_tokens_ratio\": 1.0,       \"completion_tokens_ratio\": 4.0     }   },   \"per_unit_price_config\": {},   \"enabled_billing_items\": [     \"prompt_tokens\",     \"completion_tokens\"   ] }","source":"public-provider-conf"},"vision":false},{"id":"gemini-2.0-flash-lite-preview-02-05","name":"gemini-2.0-flash-lite","display_name":"gemini-2.0-flash-lite","type":"chat","context_length":0,"max_output_tokens":0,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"developer":"Google","developerId":8,"providerId":24,"modelRatio":0.0375,"cacheRatio":1,"completionRatio":4,"description":"gemini-2.0-flash轻量版","descriptionEn":"Gemini 2.0 Flash lightweight version","order":80,"flag":1,"billingConfig":"{   \"model_name\": \"gemini-2.0-flash-lite\",   \"default_tier\": \"tier1\",   \"token_based_tier_configs\": {     \"tier1\": {       \"tier_condition\": {         \"min_tokens\": 0,         \"max_tokens\": -1       },       \"model_ratio\": 0.0375,       \"prompt_tokens_ratio\": 1.0,       \"completion_tokens_ratio\": 4.0     }   },   \"per_unit_price_config\": {},   \"enabled_billing_items\": [     \"prompt_tokens\",     \"completion_tokens\"   ] }","source":"public-provider-conf"},"vision":false},{"id":"gemini-2.0-flash-preview-image-generation","name":"gemini-2.0-flash-preview-image-generation","display_name":"gemini-2.0-flash-preview-image-generation","type":"image-generation","context_length":1050000,"max_output_tokens":1050000,"capabilities":{"vision":true,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"modalities":{"input":["text","image"],"output":["text","image"]},"metadata":{"developer":"Google","developerId":8,"providerId":24,"modelRatio":0.05,"cacheRatio":0,"completionRatio":4,"description":"Gemini 2.0 flash exp 绘图模型的正式预览版。与 Imagen 3.0 相比，Gemini 的图像生成更适合于需要上下文理解和推理的场景，而非追求极致的艺术表现和视觉质量。","descriptionEn":"Gemini 2.0 Flash EXP is the official preview version of the drawing model. Compared to Imagen 3.0, Gemini’s image generation is better suited for scenarios that require contextual understanding and reasoning, rather than the pursuit of ultimate artistic performance and visual quality.","order":701,"flag":1,"displayInput":"$ 0.1 / M Tokens","displayOutput":"$ 0.4 / M Tokens","tags":["multi_modal","best"],"modalities":["text","image"],"typeHints":["t2t","t2i"],"source":"public-provider-conf"},"vision":true},{"id":"gemini-2.0-flash-search","name":"Gemini 2.0 Flash","display_name":"Gemini 2.0 Flash","type":"chat","context_length":0,"max_output_tokens":0,"capabilities":{"vision":true,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"modalities":{"input":["text","image","audio","video"],"output":["text","image","audio","video"]},"metadata":{"developer":"Google","developerId":8,"providerId":24,"modelRatio":0.05,"cacheRatio":1,"completionRatio":4,"description":"集成了谷歌官方搜索联网功能","descriptionEn":"Integrated with Google's official search and internet connectivity features.","order":300,"flag":0,"billingConfig":"{\"model_name\": \"gemini-2.0-flash\", \"default_tier\": \"tier1\", \"enabled_billing_items\": [\"prompt_tokens\", \"completion_tokens\", \"cached_tokens\", \"input_audio_tokens\", \"cached_audio_tokens\", \"web_search_requests\", \"image_generation\", \"cache_storage_hours\"], \"per_unit_price_config\": {\"web_search_price\": 0.035, \"cache_storage_price\": 1.0, \"image_generation_price\": 0.039}, \"token_based_tier_configs\": {\"tier1\": {\"model_ratio\": 0.05, \"tier_condition\": {\"max_tokens\": -1, \"min_tokens\": 0}, \"cached_tokens_ratio\": 2.5, \"prompt_tokens_ratio\": 1.0, \"completion_tokens_ratio\": 4.0, \"input_audio_tokens_ratio\": 7.0, \"cached_audio_tokens_ratio\": 1.75}}}","features":["web"],"tags":["multi_modal","best","optimized","lightning"],"modalities":["text","image","audio","video"],"typeHints":["t2t","search"],"source":"public-provider-conf"},"vision":true},{"id":"gemini-2.0-flash-thinking-exp","name":"gemini-2.0-flash-thinking-exp","display_name":"gemini-2.0-flash-thinking-exp","type":"chat","context_length":0,"max_output_tokens":0,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"developer":"Google","developerId":8,"providerId":24,"modelRatio":0.038,"cacheRatio":1,"completionRatio":4,"order":1,"flag":1,"source":"public-provider-conf"},"vision":false},{"id":"gemini-2.0-flash-thinking-exp-01-21","name":"Gemini 2.0 Flash Thinking","display_name":"Gemini 2.0 Flash Thinking","type":"chat","context_length":1050000,"max_output_tokens":1050000,"capabilities":{"vision":true,"function_calling":false,"reasoning":true,"tool_calling":false},"reasoning":true,"tool_call":false,"modalities":{"input":["text","image","audio","video"],"output":["text","image","audio","video"]},"metadata":{"developer":"Google","developerId":8,"providerId":24,"modelRatio":0.038,"cacheRatio":1,"completionRatio":4,"description":"最新版本，Gemini 2.0 Flash Thinking思维模式是一个实验性模型，旨在生成模型在响应过程中所经历的“思考过程”。因此，双子座 2.0 闪电思维模式在其响应中具备比基础Gemini 2.0 Flash 模型更强的推理能力。","descriptionEn":"The latest version, Gemini 2.0 Flash Thinking mode, is an experimental model designed to generate the \"thought process\" that the model goes through during its responses. Therefore, Gemini 2.0 Flash Thinking mode has stronger reasoning capabilities in its responses compared to the base Gemini 2.0 Flash model.","order":112,"flag":0,"features":["thinking","long_context"],"tags":["lightning"],"modalities":["text","image","audio","video"],"typeHints":["t2t"],"source":"public-provider-conf"},"vision":true},{"id":"gemini-2.0-flash-thinking-exp-1219","name":"Gemini 2.0 Flash Thinking","display_name":"Gemini 2.0 Flash Thinking","type":"chat","context_length":0,"max_output_tokens":0,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"developer":"Google","developerId":8,"providerId":24,"modelRatio":0.038,"cacheRatio":1,"completionRatio":4,"description":"Gemini 2.0 Flash Thinking思维模式是一个实验性模型，旨在生成模型在响应过程中所经历的“思考过程”。因此，双子座 2.0 闪电思维模式在其响应中具备比基础Gemini 2.0 Flash 模型更强的推理能力。","descriptionEn":"The Gemini 2.0 Flash Thinking mode is an experimental model designed to generate the \"thinking process\" that the model undergoes during its response. Therefore, the Gemini 2.0 Flash Thinking mode possesses stronger reasoning capabilities in its responses compared to the base Gemini 2.0 Flash model.","order":12,"flag":0,"source":"public-provider-conf"},"vision":false},{"id":"gemini-2.0-pro-exp-02-05","name":"gemini-2.0-pro","display_name":"gemini-2.0-pro","type":"image-generation","context_length":0,"max_output_tokens":0,"capabilities":{"vision":true,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"modalities":{"input":["text","image","audio","video"],"output":["text","image","audio","video"]},"metadata":{"developer":"Google","developerId":8,"providerId":24,"modelRatio":0.625,"cacheRatio":1,"completionRatio":4,"description":"gemini-2.0-pro最新实验版本","descriptionEn":"The latest experimental version of Gemini-2.0-Pro","order":102,"flag":0,"tags":["multi_modal","best"],"modalities":["text","image","audio","video"],"typeHints":["t2t","t2i"],"source":"public-provider-conf"},"vision":true},{"id":"gemini-2.5-flash","name":"gemini-2.5-flash","display_name":"gemini-2.5-flash","type":"chat","context_length":1000000,"max_output_tokens":1000000,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"developer":"Google","developerId":8,"providerId":24,"modelRatio":0.15,"cacheRatio":0.25,"completionRatio":8.33,"description":"gemini-2.5-flash 正式稳定版本","descriptionEn":"gemini-2.5-flash official stable version","order":850,"flag":1,"billingConfig":"{\"model_name\": \"gemini-2.5-flash\", \"default_tier\": \"tier1\", \"enabled_billing_items\": [\"prompt_tokens\", \"completion_tokens\", \"cached_tokens\", \"input_audio_tokens\", \"cached_audio_tokens\", \"web_search_requests\", \"cache_storage_hours\"], \"per_unit_price_config\": {\"web_search_price\": 0.035, \"cache_storage_price\": 1.0}, \"token_based_tier_configs\": {\"tier1\": {\"model_ratio\": 0.15, \"tier_condition\": {\"max_tokens\": -1, \"min_tokens\": 0}, \"cached_tokens_ratio\": 0.25, \"prompt_tokens_ratio\": 1.0, \"completion_tokens_ratio\": 8.33, \"input_audio_tokens_ratio\": 3.33, \"cached_audio_tokens_ratio\": 0.83}}}","source":"public-provider-conf"},"vision":false},{"id":"gemini-2.5-flash-image-preview","name":"gemini-2.5-flash-image-preview","display_name":"gemini-2.5-flash-image-preview","type":"image-generation","context_length":32000,"max_output_tokens":32000,"capabilities":{"vision":true,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"modalities":{"input":["image","text"],"output":["image","text"]},"metadata":{"developer":"Google","developerId":8,"providerId":24,"modelRatio":0.15,"cacheRatio":1,"completionRatio":4,"description":"Aihubmix 支持gemini-2.5-flash-image-preview 模；可以通过 openai 兼容的 chat 接口添加额外参数modalities=[\"text\", \"image\"],即可；文档https://docs.aihubmix.com/cn/api/Multimodal-Interaction-with-Gemini#gemini-2-5-flash-%E5%9B%BE%E5%83%8F%E7%94%9F%E6%88%90","descriptionEn":"Aihubmix supports the gemini-2.5-flash-image-preview model; you can add extra parameters modalities=[\"text\", \"image\"] through the OpenAI-compatible chat interface; https://docs.aihubmix.com/en/api/Gemini-Guides#gemini-2-5-flash%3A-quick-task-support","order":999,"flag":2,"displayInput":"0.1tokens/M","displayOutput":"0.04$/image ;2.49m/tokens","billingConfig":"{     \"model_name\": \"gemini-2.5-flash-image-preview\",     \"default_tier\": \"tier1\",     \"token_based_tier_configs\":     {         \"tier1\":         {             \"tier_condition\":             {                 \"min_tokens\": 0,                 \"max_tokens\": -1             },             \"model_ratio\": 0.15,             \"prompt_tokens_ratio\": 1.0,             \"completion_tokens_ratio\": 8.33,             \"input_image_tokens_ratio\": 1,             \"output_image_tokens_ratio\": 100         }     },     \"per_unit_price_config\":     {},     \"enabled_billing_items\":     [         \"prompt_tokens\",         \"completion_tokens\",         \"input_image_tokens\",         \"output_image_tokens\"     ] } ","modalities":["image","text"],"typeHints":["t2i"],"source":"public-provider-conf"},"vision":true},{"id":"gemini-2.5-flash-lite","name":"gemini-2.5-flash-lite","display_name":"gemini-2.5-flash-lite","type":"chat","context_length":1000000,"max_output_tokens":1000000,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"developer":"Google","developerId":8,"providerId":24,"modelRatio":0.05,"cacheRatio":1,"completionRatio":4,"description":"gemini-2.5-flash-lite 正式版本","descriptionEn":"Gemini 2.5 Flash Lite Official Version","order":850,"flag":1,"billingConfig":"{\"model_name\": \"gemini-2.5-flash-lite\", \"default_tier\": \"tier1\", \"enabled_billing_items\": [\"prompt_tokens\", \"completion_tokens\", \"cached_tokens\", \"input_audio_tokens\", \"cached_audio_tokens\", \"web_search_requests\", \"cache_storage_hours\"], \"per_unit_price_config\": {\"web_search_price\": 0.035, \"cache_storage_price\": 1.0}, \"token_based_tier_configs\": {\"tier1\": {\"model_ratio\": 0.05, \"tier_condition\": {\"max_tokens\": -1, \"min_tokens\": 0}, \"cached_tokens_ratio\": 0.25, \"prompt_tokens_ratio\": 1.0, \"completion_tokens_ratio\": 4.0, \"input_audio_tokens_ratio\": 3.0, \"cached_audio_tokens_ratio\": 1.25}}}","source":"public-provider-conf"},"vision":false},{"id":"gemini-2.5-flash-lite-preview-06-17","name":"gemini-2.5-flash-lite-preview-06-17","display_name":"gemini-2.5-flash-lite-preview-06-17","type":"chat","context_length":1000000,"max_output_tokens":1000000,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"developer":"Google","developerId":8,"providerId":24,"modelRatio":0.05,"cacheRatio":1,"completionRatio":4,"description":"gemini-2.5-flash-lite-preview-06-17 预览版","descriptionEn":"gemini-2.5-flash-lite-preview-06-17 ","order":0,"flag":1,"billingConfig":"{\"model_name\": \"gemini-2.5-flash-lite\", \"default_tier\": \"tier1\", \"enabled_billing_items\": [\"prompt_tokens\", \"completion_tokens\", \"cached_tokens\", \"input_audio_tokens\", \"cached_audio_tokens\", \"web_search_requests\", \"cache_storage_hours\"], \"per_unit_price_config\": {\"web_search_price\": 0.035, \"cache_storage_price\": 1.0}, \"token_based_tier_configs\": {\"tier1\": {\"model_ratio\": 0.05, \"tier_condition\": {\"max_tokens\": -1, \"min_tokens\": 0}, \"cached_tokens_ratio\": 0.25, \"prompt_tokens_ratio\": 1.0, \"completion_tokens_ratio\": 4.0, \"input_audio_tokens_ratio\": 3.0, \"cached_audio_tokens_ratio\": 1.25}}}","source":"public-provider-conf"},"vision":false},{"id":"gemini-2.5-flash-lite-preview-09-2025","name":"gemini-2.5-flash-lite-preview-09-2025","display_name":"gemini-2.5-flash-lite-preview-09-2025","type":"chat","context_length":0,"max_output_tokens":0,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"developer":"Google","developerId":8,"providerId":24,"modelRatio":0.05,"cacheRatio":1,"completionRatio":4,"description":"gemini-2.5-flash-lite-preview-09-2025","descriptionEn":"gemini-2.5-flash-lite-preview-09-2025","order":101,"flag":1,"source":"public-provider-conf"},"vision":false},{"id":"gemini-2.5-flash-nothink","name":"gemini-2.5-flash-nothink","display_name":"gemini-2.5-flash-nothink","type":"chat","context_length":1000000,"max_output_tokens":1000000,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"developer":"Google","developerId":8,"providerId":24,"modelRatio":0.15,"cacheRatio":0.25,"completionRatio":8.33,"description":"gemini-2.5-flash默认是开启思考的，关闭思考请求名字为gemini-2.5-flash-nothink仅支持 openai 兼容格式调用不支持 gemini sdk；gemini 原生 sdk 请直接设置参数budget=0","descriptionEn":"Gemini-2.5-flash defaults to thinking enabled; to disable thinking, request the name gemini-2.5-flash-nothink, which only supports OpenAI-compatible format calls and does not support Gemini SDK; for the native Gemini SDK, please set the parameter budget=0 directly.","order":849,"flag":1,"billingConfig":"{\"model_name\": \"gemini-2.5-flash\", \"default_tier\": \"tier1\", \"enabled_billing_items\": [\"prompt_tokens\", \"completion_tokens\", \"cached_tokens\", \"input_audio_tokens\", \"cached_audio_tokens\", \"web_search_requests\", \"cache_storage_hours\"], \"per_unit_price_config\": {\"web_search_price\": 0.035, \"cache_storage_price\": 1.0}, \"token_based_tier_configs\": {\"tier1\": {\"model_ratio\": 0.15, \"tier_condition\": {\"max_tokens\": -1, \"min_tokens\": 0}, \"cached_tokens_ratio\": 0.25, \"prompt_tokens_ratio\": 1.0, \"completion_tokens_ratio\": 8.33, \"input_audio_tokens_ratio\": 3.33, \"cached_audio_tokens_ratio\": 0.83}}}","source":"public-provider-conf"},"vision":false},{"id":"gemini-2.5-flash-preview-04-17","name":"gemini-2.5-flash","display_name":"gemini-2.5-flash","type":"chat","context_length":1050000,"max_output_tokens":1050000,"capabilities":{"vision":true,"function_calling":false,"reasoning":true,"tool_calling":false},"reasoning":true,"tool_call":false,"modalities":{"input":["text","image"],"output":["text","image"]},"metadata":{"developer":"Google","developerId":8,"providerId":24,"modelRatio":0.075,"cacheRatio":0.25,"completionRatio":23,"description":"🧠 Google 最新发布的 Gemini 2.5 Flash 是一款融合速度、成本效益与可控推理能力的 AI 模型。​它引入了「思考预算」机制，让开发者可以根据任务复杂度，精细调控模型的推理深度，从而在质量、成本和响应速度之间找到最佳平衡。\n\n该模型具备推理能力，能在回答前进行“思考”，帮助理解提示、分解复杂任务和规划回应，使复杂问题的回答更准确全面。在 LMArena 的 Hard Prompts 测试中，表现仅次于 2.5 Pro。","descriptionEn":"Google's latest release, Gemini 2.5 Flash, is an AI model that combines speed, cost-effectiveness, and controllable reasoning capabilities. It introduces a \"thinking budget\" mechanism, allowing developers to fine-tune the model's reasoning depth based on task complexity, thereby achieving an optimal balance between quality, cost, and response time.","order":766,"flag":1,"billingConfig":"{\"model_name\": \"gemini-2.5-flash\", \"default_tier\": \"tier1\", \"enabled_billing_items\": [\"prompt_tokens\", \"completion_tokens\", \"cached_tokens\", \"input_audio_tokens\", \"cached_audio_tokens\", \"web_search_requests\", \"cache_storage_hours\"], \"per_unit_price_config\": {\"web_search_price\": 0.035, \"cache_storage_price\": 1.0}, \"token_based_tier_configs\": {\"tier1\": {\"model_ratio\": 0.15, \"tier_condition\": {\"max_tokens\": -1, \"min_tokens\": 0}, \"cached_tokens_ratio\": 0.25, \"prompt_tokens_ratio\": 1.0, \"completion_tokens_ratio\": 8.33, \"input_audio_tokens_ratio\": 3.33, \"cached_audio_tokens_ratio\": 0.83}}}","features":["thinking","structured_outputs","long_context"],"tags":["multi_modal","best","optimized"],"modalities":["text","image"],"typeHints":["t2t"],"source":"public-provider-conf"},"vision":true},{"id":"gemini-2.5-flash-preview-05-20","name":"gemini-2.5-flash-preview-05-20","display_name":"gemini-2.5-flash-preview-05-20","type":"chat","context_length":1000000,"max_output_tokens":1000000,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"developer":"Google","developerId":8,"providerId":24,"modelRatio":0.15,"cacheRatio":0.25,"completionRatio":8.33,"description":"gemini-2.5-flash-preview 预览；gemini-2.5-flash-preview-05-20 这个版本扣费已经变成gemini-2.5-flash 正式版本了；我们 6 月 25 日开始同步","descriptionEn":"gemini-2.5-flash-preview ","order":850,"flag":1,"billingConfig":"{\"model_name\": \"gemini-2.5-flash\", \"default_tier\": \"tier1\", \"enabled_billing_items\": [\"prompt_tokens\", \"completion_tokens\", \"cached_tokens\", \"input_audio_tokens\", \"cached_audio_tokens\", \"web_search_requests\", \"cache_storage_hours\"], \"per_unit_price_config\": {\"web_search_price\": 0.035, \"cache_storage_price\": 1.0}, \"token_based_tier_configs\": {\"tier1\": {\"model_ratio\": 0.15, \"tier_condition\": {\"max_tokens\": -1, \"min_tokens\": 0}, \"cached_tokens_ratio\": 0.25, \"prompt_tokens_ratio\": 1.0, \"completion_tokens_ratio\": 8.33, \"input_audio_tokens_ratio\": 3.33, \"cached_audio_tokens_ratio\": 0.83}}}","source":"public-provider-conf"},"vision":false},{"id":"gemini-2.5-flash-preview-09-2025","name":"gemini-2.5-flash-preview-09-2025","display_name":"gemini-2.5-flash-preview-09-2025","type":"chat","context_length":0,"max_output_tokens":0,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"developer":"Google","developerId":8,"providerId":24,"modelRatio":0.15,"cacheRatio":0.25,"completionRatio":8.33,"description":"gemini-2.5-flash-preview-09-2025","descriptionEn":"gemini-2.5-flash-preview-09-2025","order":100,"flag":1,"source":"public-provider-conf"},"vision":false},{"id":"gemini-2.5-flash-search","name":"gemini-2.5-flash-search","display_name":"gemini-2.5-flash-search","type":"chat","context_length":1000000,"max_output_tokens":1000000,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"developer":"Google","developerId":8,"providerId":24,"modelRatio":0.15,"cacheRatio":0.25,"completionRatio":8.33,"description":"gemini-2.5-flash-search集成了谷歌官方的搜索功能；搜索功能会额外有一个单独的费用日志直接融入到扣分，日志明细未展示；后续会修复展示；仅支持 openai 兼容格式调用不支持 gemini sdk；gemini 原生 sdk 请直接设置参数官方搜索参数即可","descriptionEn":"gemini-2.5-flash-search integrates Google's official search functionality; the search feature will have an additional separate fee log directly incorporated into the scoring, with detailed logs not displayed; this will be fixed and displayed later; only supports OpenAI-compatible formats for invocation, does not support Gemini SDK; for Gemini's native SDK, please set parameters directly using the official search parameters.","order":849,"flag":1,"billingConfig":"{\"model_name\": \"gemini-2.5-flash\", \"default_tier\": \"tier1\", \"enabled_billing_items\": [\"prompt_tokens\", \"completion_tokens\", \"cached_tokens\", \"input_audio_tokens\", \"cached_audio_tokens\", \"web_search_requests\", \"cache_storage_hours\"], \"per_unit_price_config\": {\"web_search_price\": 0.035, \"cache_storage_price\": 1.0}, \"token_based_tier_configs\": {\"tier1\": {\"model_ratio\": 0.15, \"tier_condition\": {\"max_tokens\": -1, \"min_tokens\": 0}, \"cached_tokens_ratio\": 0.25, \"prompt_tokens_ratio\": 1.0, \"completion_tokens_ratio\": 8.33, \"input_audio_tokens_ratio\": 3.33, \"cached_audio_tokens_ratio\": 0.83}}}","features":["web"],"typeHints":["search"],"source":"public-provider-conf"},"vision":false},{"id":"gemini-2.5-pro","name":"gemini-2.5-pro","display_name":"gemini-2.5-pro","type":"chat","context_length":1000000,"max_output_tokens":1000000,"capabilities":{"vision":true,"function_calling":true,"reasoning":true,"tool_calling":true},"reasoning":true,"tool_call":true,"modalities":{"input":["text","image","audio","video"],"output":["text","image","audio","video"]},"metadata":{"developer":"Google","developerId":8,"providerId":24,"modelRatio":0.625,"cacheRatio":0.25,"completionRatio":8,"description":"gemini-2.5-pro 最新发布的稳定版本","descriptionEn":"gemini-2.5-pro latest released stable version","order":900,"flag":2,"billingConfig":"{\n  \"model_name\": \"gemini-2.5-pro\",\n  \"default_tier\": \"tier1\",\n  \"token_based_tier_configs\": {\n    \"tier1\": {\n      \"tier_condition\": {\n        \"min_tokens\": 0,\n        \"max_tokens\": 200000\n      },\n      \"model_ratio\": 0.625,\n      \"prompt_tokens_ratio\": 1.0,\n      \"completion_tokens_ratio\": 8.0,\n      \"cached_tokens_ratio\": 0.248\n    },\n    \"tier2\": {\n      \"tier_condition\": {\n        \"min_tokens\": 200001,\n        \"max_tokens\": -1\n      },\n      \"model_ratio\": 1.25,\n      \"prompt_tokens_ratio\": 1.0,\n      \"completion_tokens_ratio\": 6.0,\n      \"cached_tokens_ratio\": 0.25\n    }\n  },\n  \"per_unit_price_config\": {\n    \"web_search_price\": 0.035,\n    \"cache_storage_price\": 4.50\n  },\n  \"enabled_billing_items\": [\n    \"prompt_tokens\",\n    \"completion_tokens\",\n    \"cached_tokens\",\n    \"web_search_requests\",\n    \"cache_storage_hours\"\n  ]\n}","features":["tools","function_calling","structured_outputs","long_context","web","thinking","deepsearch"],"tags":["best"],"modalities":["text","image","audio","video"],"typeHints":["t2t"],"source":"public-provider-conf"},"vision":true},{"id":"gemini-2.5-pro-exp-03-25","name":"gemini-2.5-pro-exp","display_name":"gemini-2.5-pro-exp","type":"chat","context_length":1000000,"max_output_tokens":1000000,"capabilities":{"vision":true,"function_calling":true,"reasoning":false,"tool_calling":true},"reasoning":false,"tool_call":true,"modalities":{"input":["text","image","audio","video"],"output":["text","image","audio","video"]},"metadata":{"developer":"Google","developerId":8,"providerId":24,"modelRatio":0.625,"cacheRatio":1,"completionRatio":4,"description":"谷歌最新的实验模型，很不稳定，仅供体验。\n它具备强大的推理和编码能力，能在回答前进行「思考」，提升复杂任务的性能和准确性。支持多模态输入（文本、音频、图像、视频）和 100 万 token 的上下文窗口，适用于高级编程、数学和科学任务。\n\n","descriptionEn":"Google’s latest experimental model, highly unstable, for experience only.\nIt boasts strong reasoning and coding capabilities, able to \"think\" before responding, enhancing performance and accuracy in complex tasks. It supports multimodal inputs (text, audio, images, video) and a 1 million token context window, suitable for advanced programming, math, and science tasks.\n\nThis means Gemini 2.5 can handle more complex problems in coding, science and math, and support more context-aware agents.","order":0,"flag":1,"billingConfig":"{   \"model_name\": \"gemini-2.5-pro\",   \"default_tier\": \"tier1\",   \"token_based_tier_configs\": {     \"tier1\": {       \"tier_condition\": {         \"min_tokens\": 0,         \"max_tokens\": 200000       },       \"model_ratio\": 0.625,       \"prompt_tokens_ratio\": 1.0,       \"completion_tokens_ratio\": 8.0,       \"cached_tokens_ratio\": 0.248     },     \"tier2\": {       \"tier_condition\": {         \"min_tokens\": 200001,         \"max_tokens\": -1       },       \"model_ratio\": 1.25,       \"prompt_tokens_ratio\": 1.0,       \"completion_tokens_ratio\": 6.0,       \"cached_tokens_ratio\": 0.25     }   },   \"per_unit_price_config\": {     \"web_search_price\": 0.035,     \"cache_storage_price\": 4.50   },   \"enabled_billing_items\": [     \"prompt_tokens\",     \"completion_tokens\",     \"cached_tokens\",     \"web_search_requests\",     \"cache_storage_hours\"   ] }","features":["structured_outputs","tools","long_context"],"tags":["multi_modal"],"modalities":["text","image","audio","video"],"typeHints":["t2t"],"source":"public-provider-conf"},"vision":true},{"id":"gemini-2.5-pro-preview-03-25","name":"gemini 2.5 pro","display_name":"gemini 2.5 pro","type":"chat","context_length":1000000,"max_output_tokens":1000000,"capabilities":{"vision":true,"function_calling":false,"reasoning":true,"tool_calling":false},"reasoning":true,"tool_call":false,"modalities":{"input":["text","image"],"output":["text","image"]},"metadata":{"developer":"Google","developerId":8,"providerId":24,"modelRatio":0.625,"cacheRatio":0.25,"completionRatio":8,"description":"支持高并发。\nGemini 2.5 Pro 预览版来了，限额更高，让您可以进行生产测试。\ngoogle最新最强模型；","descriptionEn":"Supports high concurrency.  \nThe Gemini 2.5 Pro preview version is here, with higher limits for production testing.  \nGoogle's latest and most powerful model;","order":765,"flag":2,"billingConfig":"{   \"model_name\": \"gemini-2.5-pro\",   \"default_tier\": \"tier1\",   \"token_based_tier_configs\": {     \"tier1\": {       \"tier_condition\": {         \"min_tokens\": 0,         \"max_tokens\": 200000       },       \"model_ratio\": 0.625,       \"prompt_tokens_ratio\": 1.0,       \"completion_tokens_ratio\": 8.0,       \"cached_tokens_ratio\": 0.248     },     \"tier2\": {       \"tier_condition\": {         \"min_tokens\": 200001,         \"max_tokens\": -1       },       \"model_ratio\": 1.25,       \"prompt_tokens_ratio\": 1.0,       \"completion_tokens_ratio\": 6.0,       \"cached_tokens_ratio\": 0.25     }   },   \"per_unit_price_config\": {     \"web_search_price\": 0.035,     \"cache_storage_price\": 4.50   },   \"enabled_billing_items\": [     \"prompt_tokens\",     \"completion_tokens\",     \"cached_tokens\",     \"web_search_requests\",     \"cache_storage_hours\"   ] }","features":["thinking"],"tags":["multi_modal"],"modalities":["text","image"],"typeHints":["t2t"],"source":"public-provider-conf"},"vision":true},{"id":"gemini-2.5-pro-preview-03-25-search","name":"gemini-2.5-pro-preview-","display_name":"gemini-2.5-pro-preview-","type":"chat","context_length":1000000,"max_output_tokens":1000000,"capabilities":{"vision":false,"function_calling":true,"reasoning":true,"tool_calling":true},"reasoning":true,"tool_call":true,"metadata":{"developer":"Google","developerId":8,"providerId":24,"modelRatio":0.625,"cacheRatio":1,"completionRatio":8,"description":"gemini-2.5-pro-preview-03-25-search集成了谷歌官方的搜索功能；搜索功能会额外有一个单独的费用日志直接融入到扣分，日志明细未展示；后续会修复展示；","descriptionEn":"Integrated with Google's official search function.","order":750,"flag":1,"billingConfig":"{   \"model_name\": \"gemini-2.5-pro\",   \"default_tier\": \"tier1\",   \"token_based_tier_configs\": {     \"tier1\": {       \"tier_condition\": {         \"min_tokens\": 0,         \"max_tokens\": 200000       },       \"model_ratio\": 0.625,       \"prompt_tokens_ratio\": 1.0,       \"completion_tokens_ratio\": 8.0,       \"cached_tokens_ratio\": 0.248     },     \"tier2\": {       \"tier_condition\": {         \"min_tokens\": 200001,         \"max_tokens\": -1       },       \"model_ratio\": 1.25,       \"prompt_tokens_ratio\": 1.0,       \"completion_tokens_ratio\": 6.0,       \"cached_tokens_ratio\": 0.25     }   },   \"per_unit_price_config\": {     \"web_search_price\": 0.035,     \"cache_storage_price\": 4.50   },   \"enabled_billing_items\": [     \"prompt_tokens\",     \"completion_tokens\",     \"cached_tokens\",     \"web_search_requests\",     \"cache_storage_hours\"   ] }","features":["thinking","web","tools","function_calling","structured_outputs","long_context"],"typeHints":["t2t","search"],"source":"public-provider-conf"},"vision":false},{"id":"gemini-2.5-pro-preview-05-06","name":"gemini-2.5-pro-preview-05-06","display_name":"gemini-2.5-pro-preview-05-06","type":"chat","context_length":1000000,"max_output_tokens":1000000,"capabilities":{"vision":true,"function_calling":false,"reasoning":true,"tool_calling":false},"reasoning":true,"tool_call":false,"modalities":{"input":["text","image","audio","video"],"output":["text","image","audio","video"]},"metadata":{"developer":"Google","developerId":8,"providerId":24,"modelRatio":0.625,"cacheRatio":0.25,"completionRatio":8,"description":"gemini-2.5-pro 最新模型","descriptionEn":"gemini-2.5-pro latest model","order":766,"flag":1,"billingConfig":"{   \"model_name\": \"gemini-2.5-pro\",   \"default_tier\": \"tier1\",   \"token_based_tier_configs\": {     \"tier1\": {       \"tier_condition\": {         \"min_tokens\": 0,         \"max_tokens\": 200000       },       \"model_ratio\": 0.625,       \"prompt_tokens_ratio\": 1.0,       \"completion_tokens_ratio\": 8.0,       \"cached_tokens_ratio\": 0.248     },     \"tier2\": {       \"tier_condition\": {         \"min_tokens\": 200001,         \"max_tokens\": -1       },       \"model_ratio\": 1.25,       \"prompt_tokens_ratio\": 1.0,       \"completion_tokens_ratio\": 6.0,       \"cached_tokens_ratio\": 0.25     }   },   \"per_unit_price_config\": {     \"web_search_price\": 0.035,     \"cache_storage_price\": 4.50   },   \"enabled_billing_items\": [     \"prompt_tokens\",     \"completion_tokens\",     \"cached_tokens\",     \"web_search_requests\",     \"cache_storage_hours\"   ] }","features":["thinking","long_context"],"tags":["multi_modal","best","sota"],"modalities":["text","image","audio","video"],"typeHints":["t2t"],"source":"public-provider-conf"},"vision":true},{"id":"gemini-2.5-pro-preview-05-06-search","name":"gemini-2.5-pro-preview-05-06-search","display_name":"gemini-2.5-pro-preview-05-06-search","type":"chat","context_length":1000000,"max_output_tokens":1000000,"capabilities":{"vision":true,"function_calling":false,"reasoning":true,"tool_calling":false},"reasoning":true,"tool_call":false,"modalities":{"input":["text","image","audio","video"],"output":["text","image","audio","video"]},"metadata":{"developer":"Google","developerId":8,"providerId":24,"modelRatio":0.625,"cacheRatio":1,"completionRatio":8,"description":"gemini-2.5-pro-preview-05-06-search集成了谷歌官方的搜索功能；搜索功能会额外有一个单独的费用日志直接融入到扣分，日志明细未展示；后续会修复展示；","descriptionEn":"Integrated with Google's official search function.","order":755,"flag":1,"billingConfig":"{   \"model_name\": \"gemini-2.5-pro\",   \"default_tier\": \"tier1\",   \"token_based_tier_configs\": {     \"tier1\": {       \"tier_condition\": {         \"min_tokens\": 0,         \"max_tokens\": 200000       },       \"model_ratio\": 0.625,       \"prompt_tokens_ratio\": 1.0,       \"completion_tokens_ratio\": 8.0,       \"cached_tokens_ratio\": 0.248     },     \"tier2\": {       \"tier_condition\": {         \"min_tokens\": 200001,         \"max_tokens\": -1       },       \"model_ratio\": 1.25,       \"prompt_tokens_ratio\": 1.0,       \"completion_tokens_ratio\": 6.0,       \"cached_tokens_ratio\": 0.25     }   },   \"per_unit_price_config\": {     \"web_search_price\": 0.035,     \"cache_storage_price\": 4.50   },   \"enabled_billing_items\": [     \"prompt_tokens\",     \"completion_tokens\",     \"cached_tokens\",     \"web_search_requests\",     \"cache_storage_hours\"   ] }","features":["thinking","web"],"modalities":["text","image","audio","video"],"typeHints":["t2t","search"],"source":"public-provider-conf"},"vision":true},{"id":"gemini-2.5-pro-preview-06-05","name":"gemini-2.5-pro-preview-06-05","display_name":"gemini-2.5-pro-preview-06-05","type":"chat","context_length":1000000,"max_output_tokens":1000000,"capabilities":{"vision":true,"function_calling":true,"reasoning":true,"tool_calling":true},"reasoning":true,"tool_call":true,"modalities":{"input":["text","image","audio","video"],"output":["text","image","audio","video"]},"metadata":{"developer":"Google","developerId":8,"providerId":24,"modelRatio":0.625,"cacheRatio":0.25,"completionRatio":8,"description":"Gemini 2.5 Pro Preview (06-05) 是 Google 最新的多模态旗舰模型，融合卓越的编码与推理能力。其 100 万 token 的超大上下文窗口（未来将扩展至 200 万）使其在 WebDevArena 和 LMArena 排行榜上名列前茅，特别适合开发美观且功能强大的交互式 Web 应用、代码转换及复杂工作流。新引入的「推理预算」功能巧妙平衡成本与性能，优化的工具调用和响应风格进一步提升开发效率，是开发者快速原型设计与高级编码的理想之选。","descriptionEn":"Google’s latest multimodal flagship model, combining exceptional coding and reasoning capabilities. Its massive 1 million token context window (soon to expand to 2 million) places it at the top of the WebDevArena and LMArena leaderboards. It is particularly well-suited for developing aesthetically pleasing and highly functional interactive web applications, code transformation, and complex workflows. The newly introduced \"reasoning budget\" feature cleverly balances cost and performance, while optimized tool calls and response styles further enhance development efficiency, making it the ideal choice for rapid prototyping and advanced coding.","order":300,"flag":1,"billingConfig":"{   \"model_name\": \"gemini-2.5-pro\",   \"default_tier\": \"tier1\",   \"token_based_tier_configs\": {     \"tier1\": {       \"tier_condition\": {         \"min_tokens\": 0,         \"max_tokens\": 200000       },       \"model_ratio\": 0.625,       \"prompt_tokens_ratio\": 1.0,       \"completion_tokens_ratio\": 8.0,       \"cached_tokens_ratio\": 0.248     },     \"tier2\": {       \"tier_condition\": {         \"min_tokens\": 200001,         \"max_tokens\": -1       },       \"model_ratio\": 1.25,       \"prompt_tokens_ratio\": 1.0,       \"completion_tokens_ratio\": 6.0,       \"cached_tokens_ratio\": 0.25     }   },   \"per_unit_price_config\": {     \"web_search_price\": 0.035,     \"cache_storage_price\": 4.50   },   \"enabled_billing_items\": [     \"prompt_tokens\",     \"completion_tokens\",     \"cached_tokens\",     \"web_search_requests\",     \"cache_storage_hours\"   ] }","features":["thinking","tools","function_calling","structured_outputs","long_context"],"tags":["multi_modal","best"],"modalities":["text","image","audio","video"],"typeHints":["t2t"],"source":"public-provider-conf"},"vision":true},{"id":"gemini-2.5-pro-preview-06-05-search","name":"gemini-2.5-pro-preview-06-05-search","display_name":"gemini-2.5-pro-preview-06-05-search","type":"chat","context_length":1000000,"max_output_tokens":1000000,"capabilities":{"vision":true,"function_calling":true,"reasoning":true,"tool_calling":true},"reasoning":true,"tool_call":true,"modalities":{"input":["text","image","audio","video"],"output":["text","image","audio","video"]},"metadata":{"developer":"Google","developerId":8,"providerId":24,"modelRatio":0.625,"cacheRatio":0.25,"completionRatio":8,"description":"gemini-2.5-pro-preview-06-05-search集成了谷歌官方的搜索功能；仅支持 openai 兼容接口调用；如需gemini 原生 sdk 调用请直接用官方开启 search 参数；搜索功能会额外有一个单独的费用日志直接融入到扣分，日志明细未展示；后续会修复展示；","descriptionEn":"Integrated with Google's official search function.","order":700,"flag":1,"billingConfig":"{   \"model_name\": \"gemini-2.5-pro\",   \"default_tier\": \"tier1\",   \"token_based_tier_configs\": {     \"tier1\": {       \"tier_condition\": {         \"min_tokens\": 0,         \"max_tokens\": 200000       },       \"model_ratio\": 0.625,       \"prompt_tokens_ratio\": 1.0,       \"completion_tokens_ratio\": 8.0,       \"cached_tokens_ratio\": 0.248     },     \"tier2\": {       \"tier_condition\": {         \"min_tokens\": 200001,         \"max_tokens\": -1       },       \"model_ratio\": 1.25,       \"prompt_tokens_ratio\": 1.0,       \"completion_tokens_ratio\": 6.0,       \"cached_tokens_ratio\": 0.25     }   },   \"per_unit_price_config\": {     \"web_search_price\": 0.035,     \"cache_storage_price\": 4.50   },   \"enabled_billing_items\": [     \"prompt_tokens\",     \"completion_tokens\",     \"cached_tokens\",     \"web_search_requests\",     \"cache_storage_hours\"   ] }","features":["thinking","web","tools","function_calling","structured_outputs","long_context"],"tags":["multi_modal"],"modalities":["text","image","audio","video"],"typeHints":["t2t","search"],"source":"public-provider-conf"},"vision":true},{"id":"gemini-2.5-pro-search","name":"gemini-2.5-pro-search","display_name":"gemini-2.5-pro-search","type":"chat","context_length":1000000,"max_output_tokens":1000000,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"developer":"Google","developerId":8,"providerId":24,"modelRatio":0.625,"cacheRatio":0.25,"completionRatio":8,"description":"gemini-2.5-pro-search集成了谷歌官方的搜索功能；搜索功能会额外有一个单独的费用日志直接融入到扣分，日志明细未展示；后续会修复展示；仅支持 openai 兼容格式调用不支持 gemini sdk；gemini 原生 sdk 请直接设置参数官方搜索参数即可","descriptionEn":"gemini-2.5-pro-search integrates Google's official search functionality; the search feature will have an additional separate fee log directly incorporated into the scoring, with detailed logs not displayed; this will be fixed and displayed later; only supports OpenAI-compatible formats for invocation, does not support Gemini SDK; for Gemini's native SDK, please set parameters directly using the official search parameters.","order":899,"flag":1,"billingConfig":"{   \"model_name\": \"gemini-2.5-pro-search\",   \"default_tier\": \"tier1\",   \"token_based_tier_configs\": {     \"tier1\": {       \"tier_condition\": {         \"min_tokens\": 0,         \"max_tokens\": 200000       },       \"model_ratio\": 0.625,       \"prompt_tokens_ratio\": 1.0,       \"completion_tokens_ratio\": 8.0,       \"cached_tokens_ratio\": 0.248     },     \"tier2\": {       \"tier_condition\": {         \"min_tokens\": 200001,         \"max_tokens\": -1       },       \"model_ratio\": 1.25,       \"prompt_tokens_ratio\": 1.0,       \"completion_tokens_ratio\": 6.0,       \"cached_tokens_ratio\": 0.25     }   },   \"per_unit_price_config\": {     \"web_search_price\": 0.035,     \"cache_storage_price\": 4.50   },   \"enabled_billing_items\": [     \"prompt_tokens\",     \"completion_tokens\",     \"cached_tokens\",     \"web_search_requests\",     \"cache_storage_hours\"   ] }","features":["web"],"typeHints":["search"],"source":"public-provider-conf"},"vision":false},{"id":"gemini-embedding-001","name":"gemini-embedding-001","display_name":"gemini-embedding-001","type":"embedding","context_length":0,"max_output_tokens":0,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"developer":"Google","developerId":8,"providerId":24,"modelRatio":0.075,"cacheRatio":1,"completionRatio":1,"description":"最新版本","descriptionEn":"Latest version","order":400,"flag":1,"typeHints":["embedding"],"source":"public-provider-conf"},"vision":false},{"id":"gemini-embedding-exp-03-07","name":"gemini-embedding-exp-03-07","display_name":"gemini-embedding-exp-03-07","type":"embedding","context_length":0,"max_output_tokens":0,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"modalities":{"input":["text"],"output":["text"]},"metadata":{"developer":"Google","developerId":8,"providerId":24,"modelRatio":0.01,"cacheRatio":1,"completionRatio":1,"order":0,"flag":0,"modalities":["text"],"typeHints":["embedding"],"source":"public-provider-conf"},"vision":false},{"id":"gemini-exp-1114","name":"Gemini 2","display_name":"Gemini 2","type":"chat","context_length":0,"max_output_tokens":0,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"developer":"Google","developerId":8,"providerId":24,"modelRatio":0.625,"cacheRatio":1,"completionRatio":4,"order":0,"flag":0,"source":"public-provider-conf"},"vision":false},{"id":"gemini-exp-1121","name":"Gemini 2","display_name":"Gemini 2","type":"chat","context_length":0,"max_output_tokens":0,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"developer":"Google","developerId":8,"providerId":24,"modelRatio":0.625,"cacheRatio":1,"completionRatio":4,"order":0,"flag":0,"source":"public-provider-conf"},"vision":false},{"id":"gemini-exp-1206","name":"Gemini 2","display_name":"Gemini 2","type":"chat","context_length":0,"max_output_tokens":0,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"developer":"Google","developerId":8,"providerId":24,"modelRatio":0.625,"cacheRatio":1,"completionRatio":4,"description":"谷歌最新实验性模型，目前谷歌最强模型","descriptionEn":"Google's latest experimental model, currently Google's most powerful model.","order":99,"flag":0,"source":"public-provider-conf"},"vision":false},{"id":"gemini-flash-latest","name":"gemini-flash-latest","display_name":"gemini-flash-latest","type":"chat","context_length":0,"max_output_tokens":0,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"developer":"Google","developerId":8,"providerId":24,"modelRatio":0.15,"cacheRatio":0.25,"completionRatio":8.33,"description":"指向最新的版本gemini-2.5-flash-preview-09-2025\n更新的 Gemini 2.5 Flash  \n最新的 2.5 Flash 模型在两个我们收到持续反馈的关键领域进行了改进：\n\n更好的自主工具使用：我们改进了模型使用工具的方式，使其在更复杂、自主和多步骤应用中的表现更佳。该模型在关键自主基准测试中表现显著提升，包括 SWE-Bench Verified 上相比上次发布提升了 5%（48.9% → 54%）。  \n更高效：开启思考模式后，模型现在显著提高了成本效率——以更少的令牌实现更高质量输出，降低延迟和成本（见上方图表）。","descriptionEn":"Pointing to the latest version gemini-2.5-flash-preview-09-2025\nThis latest 2.5 Flash model comes with improvements in two key areas we heard consistent feedback on:\n\nBetter agentic tool use: We've improved how the model uses tools, leading to better performance in more complex, agentic and multi-step applications. This model shows noticeable improvements on key agentic benchmarks, including a 5% gain on SWE-Bench Verified, compared to our last release (48.9% → 54%).\nMore efficient: With thinking on, the model is now significantly more cost-efficient—achieving higher quality outputs while using fewer tokens, reducing latency and cost (see charts above).","order":974,"flag":1,"source":"public-provider-conf"},"vision":false},{"id":"gemini-flash-lite-latest","name":"gemini-flash-lite-latest","display_name":"gemini-flash-lite-latest","type":"chat","context_length":0,"max_output_tokens":0,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"developer":"Google","developerId":8,"providerId":24,"modelRatio":0.05,"cacheRatio":1,"completionRatio":4,"description":"指向最新版本gemini-2.5-flash-lite-preview-09-2025","descriptionEn":"Pointing to the latest versiongemini-2.5-flash-lite-preview-09-2025","order":973,"flag":1,"source":"public-provider-conf"},"vision":false},{"id":"gemma-3-12b-it","name":"gemma-3-12b-it","display_name":"gemma-3-12b-it","type":"chat","context_length":0,"max_output_tokens":0,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"developer":"Google","developerId":8,"providerId":24,"modelRatio":0.1,"cacheRatio":0,"completionRatio":1,"description":"Gemma 3 模型是多模态模型，用于处理文本和图片输入以及生成文本输出，并为经过预训练的变体和指令调优的变体提供开放式权重。Gemma 3 具有 128K 的大型上下文窗口，支持超过 140 种语言，并且比之前的版本提供更多尺寸。Gemma 3 模型非常适合各种文本生成和图片理解任务，包括问答、摘要和推理。由于其相对较小的体积，您可以在资源有限的环境（例如笔记本电脑、台式机或您自己的云基础架构）中部署它们，从而让所有人都能使用先进的 AI 模型，并帮助他们进行创新。","descriptionEn":"Gemma 3 models are multimodal, handling text and image input and generating text output, with open weights for both pre-trained variants and instruction-tuned variants. Gemma 3 has a large, 128K context window, multilingual support in over 140 languages, and is available in more sizes than previous versions. Gemma 3 models are well-suited for a variety of text generation and image understanding tasks, including question answering, summarization, and reasoning. Their relatively small size makes it possible to deploy them in environments with limited resources such as laptops, desktops or your own cloud infrastructure, democratizing access to state of the art AI models and helping foster innovation for everyone.","order":200,"flag":1,"source":"public-provider-conf"},"vision":false},{"id":"gemma-3-1b-it","name":"gemma-3-1b-it","display_name":"gemma-3-1b-it","type":"chat","context_length":0,"max_output_tokens":0,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"developer":"Google","developerId":8,"providerId":24,"modelRatio":0.1,"cacheRatio":0,"completionRatio":1,"description":"Gemma 3 模型是多模态模型，用于处理文本和图片输入以及生成文本输出，并为经过预训练的变体和指令调优的变体提供开放式权重。Gemma 3 具有 128K 的大型上下文窗口，支持超过 140 种语言，并且比之前的版本提供更多尺寸。Gemma 3 模型非常适合各种文本生成和图片理解任务，包括问答、摘要和推理。由于其相对较小的体积，您可以在资源有限的环境（例如笔记本电脑、台式机或您自己的云基础架构）中部署它们，从而让所有人都能使用先进的 AI 模型，并帮助他们进行创新。","descriptionEn":"Gemma 3 models are multimodal, handling text and image input and generating text output, with open weights for both pre-trained variants and instruction-tuned variants. Gemma 3 has a large, 128K context window, multilingual support in over 140 languages, and is available in more sizes than previous versions. Gemma 3 models are well-suited for a variety of text generation and image understanding tasks, including question answering, summarization, and reasoning. Their relatively small size makes it possible to deploy them in environments with limited resources such as laptops, desktops or your own cloud infrastructure, democratizing access to state of the art AI models and helping foster innovation for everyone.","order":200,"flag":1,"source":"public-provider-conf"},"vision":false},{"id":"gemma-3-27b-it","name":"gemma-3-27b-it","display_name":"gemma-3-27b-it","type":"chat","context_length":0,"max_output_tokens":0,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"developer":"Google","developerId":8,"providerId":24,"modelRatio":0.1,"cacheRatio":0,"completionRatio":1,"description":"Gemma 3 模型是多模态模型，用于处理文本和图片输入以及生成文本输出，并为经过预训练的变体和指令调优的变体提供开放式权重。Gemma 3 具有 128K 的大型上下文窗口，支持超过 140 种语言，并且比之前的版本提供更多尺寸。Gemma 3 模型非常适合各种文本生成和图片理解任务，包括问答、摘要和推理。由于其相对较小的体积，您可以在资源有限的环境（例如笔记本电脑、台式机或您自己的云基础架构）中部署它们，从而让所有人都能使用先进的 AI 模型，并帮助他们进行创新。","descriptionEn":"Gemma 3 models are multimodal, handling text and image input and generating text output, with open weights for both pre-trained variants and instruction-tuned variants. Gemma 3 has a large, 128K context window, multilingual support in over 140 languages, and is available in more sizes than previous versions. Gemma 3 models are well-suited for a variety of text generation and image understanding tasks, including question answering, summarization, and reasoning. Their relatively small size makes it possible to deploy them in environments with limited resources such as laptops, desktops or your own cloud infrastructure, democratizing access to state of the art AI models and helping foster innovation for everyone.","order":200,"flag":1,"source":"public-provider-conf"},"vision":false},{"id":"gemma-3-4b-it","name":"gemma-3-4b-it","display_name":"gemma-3-4b-it","type":"chat","context_length":0,"max_output_tokens":0,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"developer":"Google","developerId":8,"providerId":24,"modelRatio":0.1,"cacheRatio":0,"completionRatio":1,"description":"Gemma 3 模型是多模态模型，用于处理文本和图片输入以及生成文本输出，并为经过预训练的变体和指令调优的变体提供开放式权重。Gemma 3 具有 128K 的大型上下文窗口，支持超过 140 种语言，并且比之前的版本提供更多尺寸。Gemma 3 模型非常适合各种文本生成和图片理解任务，包括问答、摘要和推理。由于其相对较小的体积，您可以在资源有限的环境（例如笔记本电脑、台式机或您自己的云基础架构）中部署它们，从而让所有人都能使用先进的 AI 模型，并帮助他们进行创新。","descriptionEn":"Gemma 3 models are multimodal, handling text and image input and generating text output, with open weights for both pre-trained variants and instruction-tuned variants. Gemma 3 has a large, 128K context window, multilingual support in over 140 languages, and is available in more sizes than previous versions. Gemma 3 models are well-suited for a variety of text generation and image understanding tasks, including question answering, summarization, and reasoning. Their relatively small size makes it possible to deploy them in environments with limited resources such as laptops, desktops or your own cloud infrastructure, democratizing access to state of the art AI models and helping foster innovation for everyone.","order":200,"flag":1,"source":"public-provider-conf"},"vision":false},{"id":"gemma-3n-e4b-it","name":"gemma-3n-e4b-it","display_name":"gemma-3n-e4b-it","type":"chat","context_length":0,"max_output_tokens":0,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"developer":"Google","developerId":8,"providerId":24,"modelRatio":0.1,"cacheRatio":0,"completionRatio":1,"description":"Gemma 3n 是一款生成式 AI 模型，针对手机、笔记本电脑和平板电脑等日常设备进行了优化。该模型在参数高效处理方面有所创新，包括逐层嵌入 (PLE) 参数缓存和 MatFormer 模型架构，可灵活降低计算和内存需求。这些模型具有音频输入处理、文本和视觉数据处理等功能。","descriptionEn":"Gemma 3n is a generative AI model optimized for use in everyday devices, such as phones, laptops, and tablets. This model includes innovations in parameter-efficient processing, including Per-Layer Embedding (PLE) parameter caching and a MatFormer model architecture that provides the flexibility to reduce compute and memory requirements. These models feature audio input handling, as well as text and visual data.","order":200,"flag":1,"source":"public-provider-conf"},"vision":false},{"id":"gemma2-9b-it","name":"gemma2-9b","display_name":"gemma2-9b","type":"chat","context_length":0,"max_output_tokens":0,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"developer":"Google","developerId":8,"providerId":29,"modelRatio":0.2,"cacheRatio":1,"completionRatio":1,"order":0,"flag":0,"source":"public-provider-conf"},"vision":false},{"id":"glm-3-turbo","name":"glm-3-turbo","display_name":"glm-3-turbo","type":"chat","context_length":0,"max_output_tokens":0,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"developer":"智谱 ChatGLM","developerId":5,"providerId":16,"modelRatio":0.355,"cacheRatio":1,"completionRatio":1,"order":0,"flag":0,"source":"public-provider-conf"},"vision":false},{"id":"glm-4","name":"glm-4","display_name":"glm-4","type":"chat","context_length":0,"max_output_tokens":0,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"developer":"智谱 ChatGLM","developerId":5,"providerId":16,"modelRatio":7.1,"cacheRatio":1,"completionRatio":1,"order":0,"flag":0,"source":"public-provider-conf"},"vision":false},{"id":"glm-4-flash","name":"glm-4-flash","display_name":"glm-4-flash","type":"chat","context_length":0,"max_output_tokens":0,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"developer":"智谱 ChatGLM","developerId":5,"providerId":16,"modelRatio":0.05,"cacheRatio":1,"completionRatio":1,"order":0,"flag":0,"source":"public-provider-conf"},"vision":false},{"id":"glm-4-plus","name":"glm-4-plus","display_name":"glm-4-plus","type":"chat","context_length":0,"max_output_tokens":0,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"developer":"智谱 ChatGLM","developerId":5,"providerId":16,"modelRatio":4,"cacheRatio":1,"completionRatio":1,"order":0,"flag":0,"source":"public-provider-conf"},"vision":false},{"id":"glm-4.5","name":"glm-4.5","display_name":"glm-4.5","type":"chat","context_length":0,"max_output_tokens":0,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"developer":"ChatGLM","developerId":5,"providerId":16,"modelRatio":0.25,"cacheRatio":1,"completionRatio":4,"order":10,"flag":1,"source":"public-provider-conf"},"vision":false},{"id":"glm-4.5-air","name":"glm-4.5-air","display_name":"glm-4.5-air","type":"chat","context_length":0,"max_output_tokens":0,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"developer":"ChatGLM","developerId":5,"providerId":16,"modelRatio":0.07,"cacheRatio":1,"completionRatio":6,"order":10,"flag":1,"source":"public-provider-conf"},"vision":false},{"id":"glm-4.5-airx","name":"glm-4.5-airx","display_name":"glm-4.5-airx","type":"chat","context_length":0,"max_output_tokens":0,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"developer":"ChatGLM","developerId":5,"providerId":8,"modelRatio":0.55,"cacheRatio":0.2,"completionRatio":4.1,"description":"GLM-4.5-AirX 为 GLM-4.5-Air 的极速版，响应速度更快，专为大规模高速度需求打造。","descriptionEn":"GLM-4.5-AirX is the high-speed version of GLM-4.5-Air, with faster response times, specifically designed for large-scale high-speed demands.","order":0,"flag":1,"source":"public-provider-conf"},"vision":false},{"id":"glm-4.5-flash","name":"glm-4.5-flash","display_name":"glm-4.5-flash","type":"chat","context_length":0,"max_output_tokens":0,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"developer":"ChatGLM","developerId":5,"providerId":8,"modelRatio":0.01,"cacheRatio":1,"completionRatio":1,"order":1,"flag":1,"tags":["multi_modal","best","optimized","economical","lightning","bold","sota","discount","free"],"source":"public-provider-conf"},"vision":false},{"id":"glm-4.5-x","name":"glm-4.5-x","display_name":"glm-4.5-x","type":"chat","context_length":0,"max_output_tokens":0,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"developer":"ChatGLM","developerId":5,"providerId":8,"modelRatio":1.1,"cacheRatio":0.2,"completionRatio":4.05,"description":"GLM-4.5-X 为 GLM-4.5 的极速版，在性能强劲的同时，生成速度可达 100 tokens/秒。","descriptionEn":"GLM-4.5-X is the high-speed version of GLM-4.5, offering powerful performance with a generation speed of up to 100 tokens per second.","order":500,"flag":1,"source":"public-provider-conf"},"vision":false},{"id":"glm-4.5v","name":"glm-4.5v","display_name":"glm-4.5v","type":"chat","context_length":0,"max_output_tokens":0,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"developer":"ChatGLM","developerId":5,"providerId":16,"modelRatio":0.3,"cacheRatio":1,"completionRatio":3,"description":"智谱官方提供\nGLM-4.5V 是智谱最强大的视觉推理模型，全球同级别开源模型 SOTA，覆盖图像、视频、文档理解及 GUI 等核心任务。","descriptionEn":"GLM-4.5V is Zhipu's most powerful visual reasoning model, the state-of-the-art open-source model of its kind globally, covering core tasks such as image, video, document understanding, and GUI.","order":850,"flag":0,"source":"public-provider-conf"},"vision":false},{"id":"glm-4.6","name":"glm-4.6","display_name":"glm-4.6","type":"chat","context_length":0,"max_output_tokens":0,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"developer":"ChatGLM","developerId":5,"providerId":16,"modelRatio":0.3,"cacheRatio":0.1833,"completionRatio":3.666666,"description":"GLM-4.6 是智谱最新的旗舰模型，其总参数量 355B，激活参数 32B。GLM-4.6 所有核心能力上均完成了对 GLM-4.5 的超越，具体如下：\n高级编码能力：在公开基准与真实编程任务中，GLM-4.6的代码能力对齐Claude Sonnet 4，是国内已知的最好的Coding模型。\n上下文长度：上下文窗口由128K→200K，适应更长的代码和智能体任务。\n推理能力：推理能力提升，并支持在推理过程中调用工具。\n搜索能力：增强了模型在工具调用和搜索智能体上的表现，在智能体框架中表现更好。\n写作能力：在文风、可读性与角色扮演场景中更符合人类偏好。\n多语言翻译：进一步增强跨语种任务的处理效果。","descriptionEn":"GLM-4.6 is Zhipu’s latest flagship model, with a total of 355 billion parameters and 32 billion activation parameters. In every core capability, GLM-4.6 surpasses GLM-4.5, as detailed below:\n\nAdvanced coding ability: On public benchmarks and real-world programming tasks, GLM-4.6’s coding performance matches Claude Sonnet 4, making it the best-known coding model in China.\nContext length: The context window has been extended from 128K to 200K tokens, accommodating longer code and agent tasks.\nReasoning ability: Reasoning performance has been improved, with support for tool calls during inference.\nSearch ability: Enhanced performance in tool invocation and search agents, delivering better results within agent frameworks.\nWriting ability: Better alignment with human preferences in writing style, readability, and role-play scenarios.\nMultilingual translation: Further improved handling of cross-language tasks.","order":1000,"flag":1,"source":"public-provider-conf"},"vision":false},{"id":"glm-zero-preview","name":"glm-zero-preview","display_name":"glm-zero-preview","type":"chat","context_length":0,"max_output_tokens":0,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"developer":"ChatGLM","developerId":5,"providerId":16,"modelRatio":1,"cacheRatio":1,"completionRatio":1,"description":"简单讲就是智普版o1","descriptionEn":"Simply put, it is the intelligent enhanced version of O1.","order":20,"flag":0,"source":"public-provider-conf"},"vision":false},{"id":"gme-qwen2-vl-2b-instruct","name":"gme-qwen2-vl-2b-instruct","display_name":"gme-qwen2-vl-2b-instruct","type":"embedding","context_length":0,"max_output_tokens":0,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"developer":"Qwen","developerId":13,"providerId":15,"modelRatio":0.069,"cacheRatio":1,"completionRatio":1,"description":"GME-Qwen2VL系列统一的多模态Embedding模型基于Qwen2-VL 多模态大型语言模型 (MLLMs)训练。\nGME模型支持三种类型的输入：文本、图像和图像-文本对，所有这些输入类型都可以生成通用的向量表示，并具有优秀的检索性能。","descriptionEn":"The GME-Qwen2VL series is a unified multimodal Embedding model trained based on the Qwen2-VL multimodal large language model (MLLMs). The GME model supports three types of inputs: text, images, and image-text pairs. All these input types can generate universal vector representations and exhibit excellent retrieval performance.","order":600,"flag":0,"typeHints":["embedding"],"source":"public-provider-conf"},"vision":false},{"id":"google/gemma-2-27b-it","name":"gemma-2-27b-it","display_name":"gemma-2-27b-it","type":"chat","context_length":0,"max_output_tokens":0,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"developer":"Google","developerId":8,"providerId":24,"modelRatio":0.4,"cacheRatio":1,"completionRatio":1,"order":0,"flag":0,"source":"public-provider-conf"},"vision":false},{"id":"google/gemma-3-27b-it","name":"gemma-3-27b","display_name":"gemma-3-27b","type":"chat","context_length":0,"max_output_tokens":0,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"developer":"Google","developerId":8,"providerId":8,"modelRatio":0.1,"cacheRatio":0,"completionRatio":1,"description":"Gemma是谷歌推出的一系列轻量级、先进的开放模型，基于创建Gemini模型所使用的相同研究和技术。Gemma 3模型是多模态的，能够处理文本和图像输入，并生成文本输出，同时提供预训练变体和指令调优变体的开放权重。Gemma 3具有128K的大上下文窗口，支持超过140种语言的多语言功能，并且比之前版本提供更多尺寸。Gemma 3模型非常适合各种文本生成和图像理解任务，包括问答、摘要和推理。它们相对较小的体积使得可以在资源有限的环境中部署，例如笔记本电脑、台式机或您自己的云基础设施，从而实现尖端AI模型的民主化访问，帮助每个人促进创新。该模型已准备好用于商业用途。","descriptionEn":"Gemma is a family of lightweight, state-of-the-art open models from Google, built from the same research and technology used to create the Gemini models. Gemma 3 models are multimodal, handling text and image input and generating text output, with open weights for both pre-trained variants and instruction-tuned variants. Gemma 3 has a large, 128K context window, multilingual support in over 140 languages, and is available in more sizes than previous versions. Gemma 3 models are well-suited for a variety of text generation and image understanding tasks, including question answering, summarization, and reasoning. Their relatively small size makes it possible to deploy them in environments with limited resources such as laptops, desktops or your own cloud infrastructure, democratizing access to state of the art AI models and helping foster innovation for everyone. This model is ready for commercial use.","order":60,"flag":0,"source":"public-provider-conf"},"vision":false},{"id":"gpt-3.5-turbo","name":"gpt-3.5-turbo","display_name":"gpt-3.5-turbo","type":"chat","context_length":0,"max_output_tokens":0,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"developer":"OpenAI","developerId":12,"providerId":1,"modelRatio":0.25,"cacheRatio":1,"completionRatio":3,"order":0,"flag":0,"source":"public-provider-conf"},"vision":false},{"id":"gpt-3.5-turbo-0125","name":"gpt-3.5-turbo","display_name":"gpt-3.5-turbo","type":"chat","context_length":0,"max_output_tokens":0,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"developer":"OpenAI","developerId":12,"providerId":1,"modelRatio":0.25,"cacheRatio":1,"completionRatio":3,"order":0,"flag":0,"source":"public-provider-conf"},"vision":false},{"id":"gpt-3.5-turbo-1106","name":"gpt-3.5-turbo","display_name":"gpt-3.5-turbo","type":"chat","context_length":0,"max_output_tokens":0,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"developer":"OpenAI","developerId":12,"providerId":1,"modelRatio":0.5,"cacheRatio":1,"completionRatio":2,"order":0,"flag":0,"source":"public-provider-conf"},"vision":false},{"id":"gpt-3.5-turbo-16k","name":"gpt-3.5-turbo","display_name":"gpt-3.5-turbo","type":"chat","context_length":0,"max_output_tokens":0,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"developer":"OpenAI","developerId":12,"providerId":1,"modelRatio":1.5,"cacheRatio":1,"completionRatio":1.333333333,"order":0,"flag":0,"source":"public-provider-conf"},"vision":false},{"id":"gpt-3.5-turbo-instruct","name":"gpt-3.5-turbo-instruct","display_name":"gpt-3.5-turbo-instruct","type":"chat","context_length":0,"max_output_tokens":0,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"developer":"OpenAI","developerId":12,"providerId":1,"modelRatio":0.75,"cacheRatio":1,"completionRatio":1.333333333,"order":0,"flag":0,"source":"public-provider-conf"},"vision":false},{"id":"gpt-4","name":"gpt-4","display_name":"gpt-4","type":"chat","context_length":0,"max_output_tokens":0,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"developer":"OpenAI","developerId":12,"providerId":1,"modelRatio":15,"cacheRatio":1,"completionRatio":2,"order":0,"flag":0,"source":"public-provider-conf"},"vision":false},{"id":"gpt-4-0125-preview","name":"gpt-4","display_name":"gpt-4","type":"chat","context_length":0,"max_output_tokens":0,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"developer":"OpenAI","developerId":12,"providerId":1,"modelRatio":5,"cacheRatio":1,"completionRatio":3,"order":0,"flag":0,"source":"public-provider-conf"},"vision":false},{"id":"gpt-4-0613","name":"gpt-4","display_name":"gpt-4","type":"chat","context_length":0,"max_output_tokens":0,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"developer":"OpenAI","developerId":12,"providerId":1,"modelRatio":15,"cacheRatio":1,"completionRatio":2,"order":0,"flag":0,"source":"public-provider-conf"},"vision":false},{"id":"gpt-4-1106-preview","name":"gpt-4","display_name":"gpt-4","type":"chat","context_length":0,"max_output_tokens":0,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"developer":"OpenAI","developerId":12,"providerId":1,"modelRatio":5,"cacheRatio":1,"completionRatio":3,"order":0,"flag":0,"source":"public-provider-conf"},"vision":false},{"id":"gpt-4-32k","name":"gpt-4-32k","display_name":"gpt-4-32k","type":"chat","context_length":0,"max_output_tokens":0,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"developer":"OpenAI","developerId":12,"providerId":1,"modelRatio":30,"cacheRatio":1,"completionRatio":2,"description":"最聪明的gpt-4版本；openai官方已经不在提供，本站的32k全部是官方部署在azure openai上的微软提供的","descriptionEn":"The smartest version of GPT-4; OpenAI no longer offers it officially. All the 32k versions on this site are provided by Microsoft, deployed on Azure OpenAI by the official Microsoft service.","order":10,"flag":0,"source":"public-provider-conf"},"vision":false},{"id":"gpt-4-turbo","name":"gpt-4-turbo","display_name":"gpt-4-turbo","type":"chat","context_length":0,"max_output_tokens":0,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"developer":"OpenAI","developerId":12,"providerId":1,"modelRatio":5,"cacheRatio":1,"completionRatio":3,"order":0,"flag":0,"source":"public-provider-conf"},"vision":false},{"id":"gpt-4-turbo-2024-04-09","name":"gpt-4-turbo","display_name":"gpt-4-turbo","type":"chat","context_length":0,"max_output_tokens":0,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"developer":"OpenAI","developerId":12,"providerId":1,"modelRatio":5,"cacheRatio":1,"completionRatio":3,"order":0,"flag":0,"source":"public-provider-conf"},"vision":false},{"id":"gpt-4-turbo-preview","name":"gpt-4-turbo","display_name":"gpt-4-turbo","type":"chat","context_length":0,"max_output_tokens":0,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"developer":"OpenAI","developerId":12,"providerId":1,"modelRatio":5,"cacheRatio":1,"completionRatio":3,"order":0,"flag":0,"source":"public-provider-conf"},"vision":false},{"id":"gpt-4.1","name":"gpt-4.1","display_name":"gpt-4.1","type":"chat","context_length":1050000,"max_output_tokens":1050000,"capabilities":{"vision":true,"function_calling":true,"reasoning":false,"tool_calling":true},"reasoning":false,"tool_call":true,"modalities":{"input":["text","image"],"output":["text","image"]},"metadata":{"developer":"OpenAI","developerId":12,"providerId":1,"modelRatio":1,"cacheRatio":0.25,"completionRatio":4,"description":"最新的旗舰多模态模型，支持百万 token 上下文，编码能力（SWE-bench 54.6%）和指令遵循（Scale AI 38.3%）大幅超越 GPT-4o，成本降低 26%，适合复杂任务。自动缓存机制，命中便宜 75%。\n\n","descriptionEn":"The latest flagship multimodal model supports million-token context, with encoding capability (SWE-bench 54.6%) and instruction-following (Scale AI 38.3%) performance significantly surpassing GPT-4o, while reducing costs by 26%, making it suitable for complex tasks. Its automatic caching mechanism offers a 75% cost reduction on cache hits.","order":800,"flag":2,"billingConfig":"{\"model_name\": \"gpt-4.1\", \"default_tier\": \"tier1\", \"enabled_billing_items\": [\"prompt_tokens\", \"completion_tokens\", \"cached_tokens\", \"image_generation\", \"web_search_requests\"], \"per_unit_price_config\": {\"web_search_price\": 0.025}, \"token_based_tier_configs\": {\"tier1\": {\"model_ratio\": 1.0, \"tier_condition\": {\"max_tokens\": -1, \"min_tokens\": 0}, \"cached_tokens_ratio\": 0.25, \"prompt_tokens_ratio\": 1.0, \"completion_tokens_ratio\": 4.0}}}","features":["tools","function_calling","structured_outputs","long_context"],"tags":["best"],"modalities":["text","image"],"typeHints":["t2t"],"source":"public-provider-conf"},"vision":true},{"id":"gpt-4.1-mini","name":"gpt-4.1-mini","display_name":"gpt-4.1-mini","type":"chat","context_length":1050000,"max_output_tokens":1050000,"capabilities":{"vision":true,"function_calling":true,"reasoning":false,"tool_calling":true},"reasoning":false,"tool_call":true,"modalities":{"input":["text","image"],"output":["text","image"]},"metadata":{"developer":"OpenAI","developerId":12,"providerId":1,"modelRatio":0.2,"cacheRatio":0.25,"completionRatio":4,"description":"轻量高性能模型，百万 token 上下文，接近旗舰编码与图像理解能力，成本降 83%，适合快速开发与中小型应用。  自动缓存机制，命中便宜 75%。","descriptionEn":"Lightweight, high-performance model with million-token context and near-flagship-level encoding and image understanding capabilities, while reducing costs by 83%. It is suitable for rapid development and small to medium-sized applications. The automatic caching mechanism provides a 75% cost reduction on cache hits.","order":799,"flag":1,"billingConfig":"{\"model_name\": \"gpt-4.1-mini\", \"default_tier\": \"tier1\", \"enabled_billing_items\": [\"prompt_tokens\", \"completion_tokens\", \"cached_tokens\", \"image_generation\", \"web_search_requests\"], \"per_unit_price_config\": {\"web_search_price\": 0.025}, \"token_based_tier_configs\": {\"tier1\": {\"model_ratio\": 0.2, \"tier_condition\": {\"max_tokens\": -1, \"min_tokens\": 0}, \"cached_tokens_ratio\": 0.25, \"prompt_tokens_ratio\": 1.0, \"completion_tokens_ratio\": 4.0}}}","features":["tools","structured_outputs","function_calling","long_context"],"tags":["economical","lightning"],"modalities":["text","image"],"typeHints":["t2t"],"source":"public-provider-conf"},"vision":true},{"id":"gpt-4.1-nano","name":"gpt-4.1-nano","display_name":"gpt-4.1-nano","type":"chat","context_length":1050000,"max_output_tokens":1050000,"capabilities":{"vision":true,"function_calling":true,"reasoning":false,"tool_calling":true},"reasoning":false,"tool_call":true,"modalities":{"input":["text","image"],"output":["text","image"]},"metadata":{"developer":"OpenAI","developerId":12,"providerId":1,"modelRatio":0.05,"cacheRatio":0.25,"completionRatio":4,"description":"超轻量模型，百万 token 上下文，优化速度与低延迟，成本仅 0.1 美元/百万输入 token，适合边缘计算与实时交互。自动缓存机制，命中便宜 75%。","descriptionEn":"Ultra-lightweight model with million-token context, optimized for speed and low latency, costing only $0.10 per million input tokens. It is suitable for edge computing and real-time interaction. The automatic caching mechanism offers a 75% cost reduction on cache hits.","order":798,"flag":1,"billingConfig":"{\"model_name\": \"gpt-4.1-nano\", \"default_tier\": \"tier1\", \"enabled_billing_items\": [\"prompt_tokens\", \"completion_tokens\", \"cached_tokens\", \"image_generation\", \"web_search_requests\"], \"per_unit_price_config\": {\"web_search_price\": 0.01}, \"token_based_tier_configs\": {\"tier1\": {\"model_ratio\": 0.05, \"tier_condition\": {\"max_tokens\": -1, \"min_tokens\": 0}, \"cached_tokens_ratio\": 0.25, \"prompt_tokens_ratio\": 1.0, \"completion_tokens_ratio\": 4.0}}}","features":["tools","function_calling","structured_outputs","long_context"],"tags":["lightning"],"modalities":["text","image"],"typeHints":["t2t"],"source":"public-provider-conf"},"vision":true},{"id":"gpt-4o","name":"gpt-4o","display_name":"gpt-4o","type":"chat","context_length":128000,"max_output_tokens":128000,"capabilities":{"vision":true,"function_calling":true,"reasoning":false,"tool_calling":true},"reasoning":false,"tool_call":true,"modalities":{"input":["text","image"],"output":["text","image"]},"metadata":{"developer":"OpenAI","developerId":12,"providerId":1,"modelRatio":1.25,"cacheRatio":0.5,"completionRatio":4,"description":"openai稳定版多模态模型，这个模型官方指向版本为gpt-4o-2024-08-06；本站支持官方的自动缓存，命中部分扣费会自动减半","descriptionEn":"The stable multimodal model from OpenAI, with the official designated version being gpt-4o-2024-08-06; our site supports the official automatic caching, and charges for hits on some parts will be automatically halved.","order":111,"flag":0,"billingConfig":"{\"model_name\": \"gpt-4o\", \"default_tier\": \"tier1\", \"enabled_billing_items\": [\"prompt_tokens\", \"completion_tokens\", \"cached_tokens\", \"image_generation\", \"web_search_requests\"], \"per_unit_price_config\": {\"web_search_price\": 0.025}, \"token_based_tier_configs\": {\"tier1\": {\"model_ratio\": 1.25, \"tier_condition\": {\"max_tokens\": -1, \"min_tokens\": 0}, \"cached_tokens_ratio\": 0.5, \"prompt_tokens_ratio\": 1.0, \"completion_tokens_ratio\": 4.0}}}","features":["tools","function_calling","structured_outputs"],"tags":["multi_modal","best"],"modalities":["text","image"],"typeHints":["t2t"],"source":"public-provider-conf"},"vision":true},{"id":"gpt-4o-2024-05-13","name":"gpt-4o","display_name":"gpt-4o","type":"chat","context_length":0,"max_output_tokens":0,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"developer":"OpenAI","developerId":12,"providerId":1,"modelRatio":2.5,"cacheRatio":1,"completionRatio":3,"order":0,"flag":0,"billingConfig":"{\"model_name\": \"gpt-4o-2024-05-13\", \"default_tier\": \"tier1\", \"enabled_billing_items\": [\"prompt_tokens\", \"completion_tokens\", \"cached_tokens\", \"image_generation\", \"web_search_requests\"], \"per_unit_price_config\": {\"web_search_price\": 0.025}, \"token_based_tier_configs\": {\"tier1\": {\"model_ratio\": 2.5, \"tier_condition\": {\"max_tokens\": -1, \"min_tokens\": 0}, \"cached_tokens_ratio\": 1.0, \"prompt_tokens_ratio\": 1.0, \"completion_tokens_ratio\": 3.0}}}","source":"public-provider-conf"},"vision":false},{"id":"gpt-4o-2024-08-06","name":"gpt-4o","display_name":"gpt-4o","type":"chat","context_length":0,"max_output_tokens":0,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"developer":"OpenAI","developerId":12,"providerId":1,"modelRatio":1.25,"cacheRatio":0.5,"completionRatio":4,"description":"支持缓存，命中扣费自动减半","descriptionEn":"Supports caching, with automatic halving of charges upon a cache hit.","order":56,"flag":0,"source":"public-provider-conf"},"vision":false},{"id":"gpt-4o-2024-11-20","name":"gpt-4o","display_name":"gpt-4o","type":"chat","context_length":128000,"max_output_tokens":128000,"capabilities":{"vision":true,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"modalities":{"input":["text","image"],"output":["text","image"]},"metadata":{"developer":"OpenAI","developerId":12,"providerId":1,"modelRatio":1.25,"cacheRatio":0.5,"completionRatio":4,"description":"gpt-4o模型最新版本；推荐使用这个版本，目前比普通4o机智","descriptionEn":"The latest version of the GPT-4o model; it is recommended to use this version, as it is currently smarter than the regular 4o.","order":112,"flag":0,"tags":["multi_modal","best","bold"],"modalities":["text","image"],"typeHints":["t2t"],"source":"public-provider-conf"},"vision":true},{"id":"gpt-4o-audio-preview","name":"gpt-4o-audio-preview","display_name":"gpt-4o-audio-preview","type":"audio","context_length":0,"max_output_tokens":0,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"modalities":{"input":["text","audio"],"output":["text","audio"]},"metadata":{"developer":"OpenAI","developerId":12,"providerId":1,"modelRatio":1.25,"cacheRatio":1,"completionRatio":4,"description":"openai声音输入输出模型，价格和官方一致，暂时只展示文字部分价格，声音价格见openai官网；后台扣费和官方一致","descriptionEn":"OpenAI voice input and output model, with prices consistent with the official ones. For now, only the text portion prices are displayed; voice prices can be found on the official OpenAI website. Backend billing is the same as the official.","order":101,"flag":0,"displayInput":"$ 40 /M","displayOutput":"$ 80 /M","tags":["multi_modal","bold"],"modalities":["text","audio"],"typeHints":["t2t","tts"],"source":"public-provider-conf"},"vision":false},{"id":"gpt-4o-audio-preview-2024-10-01","name":"gpt-4o-audio-preview","display_name":"gpt-4o-audio-preview","type":"chat","context_length":0,"max_output_tokens":0,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"developer":"OpenAI","developerId":12,"providerId":1,"modelRatio":2,"cacheRatio":1,"completionRatio":2,"order":0,"flag":0,"source":"public-provider-conf"},"vision":false},{"id":"gpt-4o-image","name":"gpt-4o-image","display_name":"gpt-4o-image","type":"image-generation","context_length":0,"max_output_tokens":0,"capabilities":{"vision":true,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"modalities":{"input":["text","image"],"output":["text","image"]},"metadata":{"developer":"OpenAI","developerId":12,"providerId":1,"modelRatio":1.5,"cacheRatio":0,"completionRatio":1,"description":"GPT 4o 绘图接口尝鲜：完美复刻Web 端的生图能力，支持文生图、图文生图；每次0.005美元（约0.04人民币）。特别注意这个接口极度不稳定，且即使生成失败也会被扣费，介意的话切勿使用；","descriptionEn":"First Taste of GPT-4o's Image Generation API: Perfectly mirrors the web version's raw image creation capabilities, supporting both text-to-image and image+text-to-image generation. Each creation costs as little as $0.005.","order":199,"flag":1,"displayInput":"-","displayOutput":"$0.005 / IMG","tags":["best","sota"],"modalities":["text","image"],"typeHints":["t2i"],"source":"public-provider-conf"},"vision":true},{"id":"gpt-4o-image-vip","name":"gpt-4o-image-vip","display_name":"gpt-4o-image-vip","type":"image-generation","context_length":0,"max_output_tokens":0,"capabilities":{"vision":true,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"modalities":{"input":["text","image"],"output":["text","image"]},"metadata":{"developer":"OpenAI","developerId":12,"providerId":1,"modelRatio":3.5,"cacheRatio":0,"completionRatio":1,"description":"GPT 4o 绘图接口尝鲜：完美复刻Web 端的生图能力，支持文生图、图文生图；每次0.009美元（约0.06人民币）。\n注意目前很不稳定，体验为主。特别注意这个接口极度不稳定，且即使生成失败也会被扣费，介意的话切勿使用；","descriptionEn":"First Taste of GPT-4o's Image Generation API: Perfectly mirrors the web version's raw image creation capabilities, supporting both text-to-image and image+text-to-image generation. Each creation costs as little as $0.009.","order":200,"flag":1,"displayInput":"-","displayOutput":"$0.009 / IMG","modalities":["text","image"],"typeHints":["t2i"],"source":"public-provider-conf"},"vision":true},{"id":"gpt-4o-mini","name":"gpt-4o-mini","display_name":"gpt-4o-mini","type":"chat","context_length":128000,"max_output_tokens":128000,"capabilities":{"vision":true,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"modalities":{"input":["text","image"],"output":["text","image"]},"metadata":{"developer":"OpenAI","developerId":12,"providerId":1,"modelRatio":0.075,"cacheRatio":0.5,"completionRatio":4,"description":"gpt-4o的轻量级版本，便宜速度快，适合处理简单任务；本站支持该模型的官方的自动缓存，命中部分扣费会自动减半","descriptionEn":"The lightweight version of GPT-4o, which is affordable and fast, suitable for handling simple tasks; our site supports the official automatic caching for this model, and charges for cache hits will be automatically halved.","order":108,"flag":0,"billingConfig":"{\"model_name\": \"gpt-4o-mini\", \"default_tier\": \"tier1\", \"enabled_billing_items\": [\"prompt_tokens\", \"completion_tokens\", \"cached_tokens\", \"image_generation\", \"web_search_requests\"], \"per_unit_price_config\": {\"web_search_price\": 0.025}, \"token_based_tier_configs\": {\"tier1\": {\"model_ratio\": 0.075, \"tier_condition\": {\"max_tokens\": -1, \"min_tokens\": 0}, \"cached_tokens_ratio\": 0.5, \"prompt_tokens_ratio\": 1.0, \"completion_tokens_ratio\": 4.0}}}","tags":["multi_modal","best","economical","lightning"],"modalities":["text","image"],"typeHints":["t2t"],"source":"public-provider-conf"},"vision":true},{"id":"gpt-4o-mini-2024-07-18","name":"gpt-4o-mini","display_name":"gpt-4o-mini","type":"chat","context_length":0,"max_output_tokens":0,"capabilities":{"vision":true,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"modalities":{"input":["text","image"],"output":["text","image"]},"metadata":{"developer":"OpenAI","developerId":12,"providerId":1,"modelRatio":0.075,"cacheRatio":0.5,"completionRatio":4,"order":0,"flag":0,"tags":["multi_modal","economical","lightning"],"modalities":["text","image"],"typeHints":["t2t"],"source":"public-provider-conf"},"vision":true},{"id":"gpt-4o-mini-audio-preview","name":"gpt-4o-mini-audio-preview","display_name":"gpt-4o-mini-audio-preview","type":"audio","context_length":0,"max_output_tokens":0,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"modalities":{"input":["audio"],"output":["audio"]},"metadata":{"developer":"OpenAI","developerId":12,"providerId":1,"modelRatio":0.075,"cacheRatio":1,"completionRatio":4,"description":"openai声音输入输出模型，价格和官方一致，暂时只展示文字部分价格，声音价格见openai官网；后台扣费和官方一致","order":100,"flag":0,"modalities":["audio"],"typeHints":["tts"],"source":"public-provider-conf"},"vision":false},{"id":"gpt-4o-mini-search-preview","name":"gpt-4o-mini-search-preview","display_name":"gpt-4o-mini-search-preview","type":"chat","context_length":128000,"max_output_tokens":128000,"capabilities":{"vision":true,"function_calling":true,"reasoning":false,"tool_calling":true},"reasoning":false,"tool_call":true,"modalities":{"input":["text","image"],"output":["text","image"]},"metadata":{"developer":"OpenAI","developerId":12,"providerId":1,"modelRatio":0.075,"cacheRatio":0.5,"completionRatio":4,"description":"使用聊天完成 API，您可以直接访问 ChatGPT 中搜索所用的微调模型和工具。\n\n在使用聊天完成时，模型总是会在响应您的查询之前从网络检索信息。要将 web_search_preview 作为仅在必要时调用的工具（如 gpt-4o 和 gpt-4o-mini），请切换到使用响应 API。\n\n目前，您需要使用以下其中一个模型才能在聊天完成中使用网页搜索：\n\ngpt-4o-search-preview  \ngpt-4o-mini-search-preview  \n\n网页搜索参数示例  \n```javascript\nimport OpenAI from \"openai\";  \nconst client = new OpenAI();  \n\nconst completion = await client.chat.completions.create({  \n    model: \"gpt-4o-search-preview\",  \n    web_search_options: {},  \n    messages: [{  \n        \"role\": \"user\",  \n        \"content\": \"今天有什么积极的新闻故事？\"  \n    }],  \n});  \n\nconsole.log(completion.choices[0].message.content); \n```\n\n输出和引用   \n选择数组中的 API 响应项将包括：\n\nmessage.content 包含来自模型的文本结果，包括任何内联引用   \nannotations 包含被引用 URL 的列表   \n\n默认情况下，模型的响应将包含来自网页搜索结果找到的 URL 的内联引用。此外，url_citation 注释对象将包含被引用源的网址和标题，以及这些源在模型响应中使用的位置起始和结束索引字符。","descriptionEn":"Using the Chat Completions API, you can directly access the fine-tuned models and tool used by Search in ChatGPT.\n\nWhen using Chat Completions, the model always retrieves information from the web before responding to your query. To use web_search_preview as a tool that models like gpt-4o and gpt-4o-mini invoke only when necessary, switch to using the Responses API.\n\nCurrently, you need to use one of these models to use web search in Chat Completions:\n\ngpt-4o-search-preview\ngpt-4o-mini-search-preview\nWeb search parameter example\nimport OpenAI from \"openai\";\nconst client = new OpenAI();\n\nconst completion = await client.chat.completions.create({\n    model: \"gpt-4o-search-preview\",\n    web_search_options: {},\n    messages: [{\n        \"role\": \"user\",\n        \"content\": \"What was a positive news story from today?\"\n    }],\n});\n\nconsole.log(completion.choices[0].message.content);\nOutput and citations\nThe API response item in the choices array will include:\n\nmessage.content with the text result from the model, inclusive of any inline citations\nannotations with a list of cited URLs\nBy default, the model's response will include inline citations for URLs found in the web search results. In addition to this, the url_citation annotation object will contain the URL and title of the cited source, as well as the start and end index characters in the model's response where those sources were used.","order":549,"flag":1,"features":["web","function_calling","structured_outputs"],"tags":["multi_modal","best"],"modalities":["text","image"],"typeHints":["t2t","search"],"source":"public-provider-conf"},"vision":true},{"id":"gpt-4o-mini-tts","name":"gpt-4o-mini-tts","display_name":"gpt-4o-mini-tts","type":"audio","context_length":0,"max_output_tokens":0,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"modalities":{"input":["audio"],"output":["audio"]},"metadata":{"developer":"OpenAI","developerId":12,"providerId":1,"modelRatio":7.5,"cacheRatio":1,"completionRatio":1,"description":"OpenAI 最新 TTS 模型，接口与tts-1一致（/v1/audio/speech），但官方计费规则已更改，接口未返回计费数据，导致 aihubmix 平台的计费与官方存在较大误差，有时偏高，有时偏低。如介意费用误差，请勿使用。","descriptionEn":"OpenAI’s latest TTS model, gpt-4o-mini-tts, uses the same API endpoint (/v1/audio/speech) as tts-1. However, OpenAI introduced a new pricing method without providing billing details via API, causing discrepancies between official pricing and aihubmix’s charges—some requests may cost more, others less. Avoid using this model if precise billing accuracy is essential.","order":160,"flag":1,"displayInput":"$ 15 / M Tokens","displayOutput":"-","tags":["bold","lightning"],"modalities":["audio"],"typeHints":["tts"],"source":"public-provider-conf"},"vision":false},{"id":"gpt-4o-search-preview","name":"gpt-4o-search-preview","display_name":"gpt-4o-search-preview","type":"chat","context_length":128000,"max_output_tokens":128000,"capabilities":{"vision":true,"function_calling":true,"reasoning":false,"tool_calling":true},"reasoning":false,"tool_call":true,"modalities":{"input":["text","image"],"output":["text","image"]},"metadata":{"developer":"OpenAI","developerId":12,"providerId":1,"modelRatio":1.25,"cacheRatio":0.5,"completionRatio":4,"description":"使用聊天完成 API，您可以直接访问 ChatGPT 中搜索所用的微调模型和工具。\n\n在使用聊天完成时，模型总是会在响应您的查询之前从网络检索信息。要将 web_search_preview 作为仅在必要时调用的工具（如 gpt-4o 和 gpt-4o-mini），请切换到使用响应 API。\n\n目前，您需要使用以下其中一个模型才能在聊天完成中使用网页搜索：\n\ngpt-4o-search-preview  \ngpt-4o-mini-search-preview  \n\n网页搜索参数示例  \n```javascript\nimport OpenAI from \"openai\";  \nconst client = new OpenAI();  \n\nconst completion = await client.chat.completions.create({  \n    model: \"gpt-4o-search-preview\",  \n    web_search_options: {},  \n    messages: [{  \n        \"role\": \"user\",  \n        \"content\": \"今天有什么积极的新闻故事？\"  \n    }],  \n});  \n\nconsole.log(completion.choices[0].message.content); \n```\n\n输出和引用   \n选择数组中的 API 响应项将包括：\n\nmessage.content 包含来自模型的文本结果，包括任何内联引用   \nannotations 包含被引用 URL 的列表   \n\n默认情况下，模型的响应将包含来自网页搜索结果找到的 URL 的内联引用。此外，url_citation 注释对象将包含被引用源的网址和标题，以及这些源在模型响应中使用的位置起始和结束索引字符。","descriptionEn":"Using the Chat Completions API, you can directly access the fine-tuned models and tool used by Search in ChatGPT.\n\nWhen using Chat Completions, the model always retrieves information from the web before responding to your query. To use web_search_preview as a tool that models like gpt-4o and gpt-4o-mini invoke only when necessary, switch to using the Responses API.\n\nCurrently, you need to use one of these models to use web search in Chat Completions:\n\ngpt-4o-search-preview\ngpt-4o-mini-search-preview\nWeb search parameter example\nimport OpenAI from \"openai\";\nconst client = new OpenAI();\n\nconst completion = await client.chat.completions.create({\n    model: \"gpt-4o-search-preview\",\n    web_search_options: {},\n    messages: [{\n        \"role\": \"user\",\n        \"content\": \"What was a positive news story from today?\"\n    }],\n});\n\nconsole.log(completion.choices[0].message.content);\nOutput and citations\nThe API response item in the choices array will include:\n\nmessage.content with the text result from the model, inclusive of any inline citations\nannotations with a list of cited URLs\nBy default, the model's response will include inline citations for URLs found in the web search results. In addition to this, the url_citation annotation object will contain the URL and title of the cited source, as well as the start and end index characters in the model's response where those sources were used.","order":550,"flag":1,"features":["web","function_calling","structured_outputs"],"tags":["multi_modal","best"],"modalities":["text","image"],"typeHints":["t2t","search"],"source":"public-provider-conf"},"vision":true},{"id":"gpt-5","name":"gpt-5","display_name":"gpt-5","type":"chat","context_length":0,"max_output_tokens":0,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"developer":"OpenAI","developerId":12,"providerId":1,"modelRatio":0.625,"cacheRatio":0.1,"completionRatio":8,"description":"GPT-5是 OpenAI 在各个领域中用于编码、推理和代理任务的旗舰模型。","descriptionEn":"GPT-5 is OpenAI flagship model for coding, reasoning, and agentic tasks across domains.","order":971,"flag":1,"billingConfig":"{\"model_name\": \"gpt-5\", \"default_tier\": \"tier1\", \"enabled_billing_items\": [\"prompt_tokens\", \"completion_tokens\", \"cached_tokens\", \"image_generation\", \"web_search_requests\"], \"per_unit_price_config\": {\"web_search_price\": 0.01}, \"token_based_tier_configs\": {\"tier1\": {\"model_ratio\": 0.625, \"tier_condition\": {\"max_tokens\": -1, \"min_tokens\": 0}, \"cached_tokens_ratio\": 0.1, \"prompt_tokens_ratio\": 1.0, \"completion_tokens_ratio\": 8.0}}}","source":"public-provider-conf"},"vision":false},{"id":"gpt-5-chat-latest","name":"gpt-5-chat-latest","display_name":"gpt-5-chat-latest","type":"chat","context_length":0,"max_output_tokens":0,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"developer":"OpenAI","developerId":12,"providerId":1,"modelRatio":0.625,"cacheRatio":0.1,"completionRatio":8,"description":"GPT-5-chat指的是当前在 ChatGPT 中使用的 GPT-5 最新版本。GPT-5 是我们下一代高智能旗舰模型。它接受文本和图像输入，并生成文本输出。","descriptionEn":"GPT-5 Chat points to the GPT-5 snapshot currently used in ChatGPT. GPT-5 is our next-generation, high-intelligence flagship model. It accepts both text and image inputs, and produces text outputs.","order":968,"flag":1,"source":"public-provider-conf"},"vision":false},{"id":"gpt-5-codex","name":"gpt-5-codex","display_name":"gpt-5-codex","type":"chat","context_length":0,"max_output_tokens":0,"capabilities":{"vision":false,"function_calling":false,"reasoning":true,"tool_calling":false},"reasoning":true,"tool_call":false,"metadata":{"developer":"OpenAI","developerId":12,"providerId":1,"modelRatio":0.625,"cacheRatio":0.1,"completionRatio":8,"description":"GPT-5-Codex 是 GPT-5 的一个版本，针对 Codex 或类似环境中的自主编码任务进行了优化。它仅在 Responses API 中可用，底层模型快照将定期更新。https://docs.aihubmix.com/cn/api/Responses-API","descriptionEn":"GPT-5-Codex is a version of GPT-5 optimized for agentic coding tasks in Codex or similar environments. It's available in the Responses API only and the underlying model snapshot will be regularly updated. If you want to learn more about；https://docs.aihubmix.com/en/api/Responses-API","order":973,"flag":1,"features":["thinking"],"source":"public-provider-conf"},"vision":false},{"id":"gpt-5-mini","name":"gpt-5-mini","display_name":"gpt-5-mini","type":"chat","context_length":0,"max_output_tokens":0,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"developer":"OpenAI","developerId":12,"providerId":1,"modelRatio":0.125,"cacheRatio":0.1,"completionRatio":8,"description":"GPT-5 mini 是 GPT-5 的一个更快、更具成本效益的版本。它非常适合明确的任务和精确的提示。","descriptionEn":"GPT-5 mini is a faster, more cost-efficient version of GPT-5. It's great for well-defined tasks and precise prompts. ","order":970,"flag":1,"billingConfig":"{\"model_name\": \"gpt-5-mini\", \"default_tier\": \"tier1\", \"enabled_billing_items\": [\"prompt_tokens\", \"completion_tokens\", \"cached_tokens\", \"image_generation\", \"web_search_requests\"], \"per_unit_price_config\": {\"web_search_price\": 0.01}, \"token_based_tier_configs\": {\"tier1\": {\"model_ratio\": 0.125, \"tier_condition\": {\"max_tokens\": -1, \"min_tokens\": 0}, \"cached_tokens_ratio\": 0.1, \"prompt_tokens_ratio\": 1.0, \"completion_tokens_ratio\": 8.0}}}","source":"public-provider-conf"},"vision":false},{"id":"gpt-5-nano","name":"gpt-5-nano","display_name":"gpt-5-nano","type":"chat","context_length":0,"max_output_tokens":0,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"developer":"OpenAI","developerId":12,"providerId":1,"modelRatio":0.025,"cacheRatio":0.1,"completionRatio":8,"description":"GPT-5 Nano是我们最快、最便宜的GPT-5版本。它非常适合摘要和分类任务。","descriptionEn":"GPT-5 Nano is our fastest, cheapest version of GPT-5. It's great for summarization and classification tasks.","order":969,"flag":1,"billingConfig":"{\"model_name\": \"gpt-5-nano\", \"default_tier\": \"tier1\", \"enabled_billing_items\": [\"prompt_tokens\", \"completion_tokens\", \"cached_tokens\", \"image_generation\", \"web_search_requests\"], \"per_unit_price_config\": {\"web_search_price\": 0.01}, \"token_based_tier_configs\": {\"tier1\": {\"model_ratio\": 0.025, \"tier_condition\": {\"max_tokens\": -1, \"min_tokens\": 0}, \"cached_tokens_ratio\": 0.1, \"prompt_tokens_ratio\": 1.0, \"completion_tokens_ratio\": 8.0}}}","source":"public-provider-conf"},"vision":false},{"id":"gpt-image-1","name":"gpt-image-1","display_name":"gpt-image-1","type":"image-generation","context_length":0,"max_output_tokens":0,"capabilities":{"vision":true,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"modalities":{"input":["text","image"],"output":["text","image"]},"metadata":{"developer":"OpenAI","developerId":12,"providerId":1,"modelRatio":2.5,"cacheRatio":1,"completionRatio":8,"description":"OpenAI 最新画图模型 gpt-image-1，支持文生图（generate）、图文生图（edit）。\n使用前请运行 pip install -U openai 升级到最新的 openai 包。\n\n","descriptionEn":"Azure OpenAI’s gpt-image-1 image generation API offers both text-to-image generation and image-to-image editing with text guidance capabilities.\nBefore using this API, please ensure you have the latest OpenAI package installed by running pip install -U openai.","order":812,"flag":2,"displayInput":" $ 5 /M (text)","displayOutput":" $ 0.6 / IMG (high quality) ","tags":["sota"],"modalities":["text","image"],"typeHints":["t2i"],"source":"public-provider-conf"},"vision":true},{"id":"gpt-oss-120b","name":"gpt-oss-120b","display_name":"gpt-oss-120b","type":"chat","context_length":0,"max_output_tokens":0,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"developer":"OpenAI","developerId":12,"providerId":8,"modelRatio":0.09,"cacheRatio":1,"completionRatio":5,"description":"azure 部署gpt-oss-120b\n","descriptionEn":"The model gpt-oss-120b provided by Azure deployment.","order":400,"flag":1,"source":"public-provider-conf"},"vision":false},{"id":"grok-3","name":"grok-3","display_name":"grok-3","type":"chat","context_length":0,"max_output_tokens":0,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"developer":"Grok","developerId":9,"providerId":46,"modelRatio":1.5,"cacheRatio":1,"completionRatio":5,"description":"grok最新模型","descriptionEn":"Grok's latest model","order":46,"flag":1,"source":"public-provider-conf"},"vision":false},{"id":"grok-3-mini","name":"grok-3-mini","display_name":"grok-3-mini","type":"chat","context_length":0,"max_output_tokens":0,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"developer":"Grok","developerId":9,"providerId":46,"modelRatio":0.15,"cacheRatio":0,"completionRatio":1.67,"order":43,"flag":0,"source":"public-provider-conf"},"vision":false},{"id":"grok-4","name":"grok-4","display_name":"grok-4","type":"chat","context_length":0,"max_output_tokens":0,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"developer":"Grok","developerId":9,"providerId":46,"modelRatio":1.65,"cacheRatio":0.25,"completionRatio":5,"description":"Grok最新旗舰模型，在自然语言、数学和推理方面提供了无与伦比的性能——堪称完美的‘多面手’。\n当前指向模型版本为grok-4-0709；注意该模型由于资源有限暂时比官方贵 10% 预计后续会降至官方原价","descriptionEn":"Grok, their latest and greatest flagship model, offers unparalleled performance in natural language, math, and reasoning – the perfect jack of all trades.\nThe current pointing model version is grok-4-0709.","order":800,"flag":1,"source":"public-provider-conf"},"vision":false},{"id":"grok-4-fast-non-reasoning","name":"grok-4-fast-non-reasoning","display_name":"grok-4-fast-non-reasoning","type":"chat","context_length":0,"max_output_tokens":0,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"developer":"Grok","developerId":9,"providerId":29,"modelRatio":0.1,"cacheRatio":0.25,"completionRatio":2.5,"description":"Grok-4-fast 是由 xAI 开发的一款高性价比的推理模型，它以卓越的token效率提供了前沿的性能。该模型拥有200万个token的上下文窗口、先进的Web和X搜索能力，以及一个统一的架构，支持“推理”和“非推理”两种模式。与Grok 4相比，它平均减少了40%的思考token，并在实现相同性能的情况下将价格降低了98%。","descriptionEn":"Grok-4-fast is a cost-effective inference model developed by xAI that delivers cutting-edge performance with excellent token efficiency. The model features a 2 million token context window, advanced Web and X search capabilities, and a unified architecture supporting both \"inference\" and \"non-inference\" modes. Compared to Grok 4, it reduces thinking tokens by an average of 40% and lowers the price by 98% while achieving the same performance.","order":800,"flag":1,"source":"public-provider-conf"},"vision":false},{"id":"grok-4-fast-reasoning","name":"grok-4-fast-reasoning","display_name":"grok-4-fast-reasoning","type":"chat","context_length":0,"max_output_tokens":0,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"developer":"Grok","developerId":9,"providerId":29,"modelRatio":0.1,"cacheRatio":0.25,"completionRatio":2.5,"description":"Grok-4-fast 是由 xAI 开发的一款高性价比的推理模型，它以卓越的token效率提供了前沿的性能。该模型拥有200万个token的上下文窗口、先进的Web和X搜索能力，以及一个统一的架构，支持“推理”和“非推理”两种模式。与Grok 4相比，它平均减少了40%的思考token，并在实现相同性能的情况下将价格降低了98%。","descriptionEn":"Grok-4-fast is a cost-effective inference model developed by xAI that delivers cutting-edge performance with excellent token efficiency. The model features a 2 million token context window, advanced Web and X search capabilities, and a unified architecture supporting both \"inference\" and \"non-inference\" modes. Compared to Grok 4, it reduces thinking tokens by an average of 40% and lowers the price by 98% while achieving the same performance.","order":800,"flag":1,"source":"public-provider-conf"},"vision":false},{"id":"grok-code-fast-1","name":"grok-code-fast-1","display_name":"grok-code-fast-1","type":"chat","context_length":0,"max_output_tokens":0,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"developer":"Grok","developerId":9,"providerId":8,"modelRatio":0.1,"cacheRatio":0.1,"completionRatio":7.5,"description":"我们很高兴地介绍 grok-code-fast-1，这是一款快速且经济的推理模型，擅长自主编码。","descriptionEn":"We're thrilled to introduce grok-code-fast-1, a speedy and economical reasoning model that excels at agentic coding.","order":850,"flag":1,"source":"public-provider-conf"},"vision":false},{"id":"gte-rerank-v2","name":"gte-rerank-v2","display_name":"gte-rerank-v2","type":"chat","context_length":0,"max_output_tokens":0,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"developer":"Qwen","developerId":13,"providerId":17,"modelRatio":0.055,"cacheRatio":1,"completionRatio":1,"description":"gte-rerank-v2是通义实验室研发的多语言文本统一排序模型，面向全球多个主流语种，提供高水平的文本排序服务。通常用于语义检索、RAG等场景，可以简单、有效地提升文本检索的效果。给定査询(Query)和一系列候选文本(documents)，模型会根据与查询的语义相关性从高到低对候选文本进行排序。","descriptionEn":"gte-rerank-v2 is a multilingual unified text ranking model developed by Tongyi Laboratory, serving multiple mainstream global languages and providing high-level text ranking services. It is commonly used in scenarios such as semantic retrieval and RAG, enabling simple and effective improvement of text search results. Given a query and a series of candidate documents, the model ranks the candidate texts from highest to lowest based on their semantic relevance to the query.","order":600,"flag":0,"source":"public-provider-conf"},"vision":false},{"id":"imagen-3.0-generate-002","name":"imagen-3.0-generate-002","display_name":"imagen-3.0-generate-002","type":"image-generation","context_length":0,"max_output_tokens":0,"capabilities":{"vision":true,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"modalities":{"input":["text","image"],"output":["text","image"]},"metadata":{"developer":"Google","developerId":8,"providerId":24,"modelRatio":1,"cacheRatio":0,"completionRatio":1,"description":"Google 文本到图像生成模型，能够根据自然语言提示生成高质量的图像。与前代模型相比，Imagen 3.0 在细节、光照和减少视觉伪影方面有显著提升。它支持多种艺术风格的渲染，从照片写实主义到印象派，以及抽象和动漫风格。","descriptionEn":"Imagen 3.0 is Google's latest text-to-image generation model, capable of creating high-quality images from natural language prompts. Compared to its predecessors, Imagen 3.0 offers significant improvements in detail, lighting, and reduced visual artifacts. It supports rendering in various artistic styles, from photorealism to impressionism, as well as abstract and anime styles.","order":701,"flag":1,"displayInput":"-","displayOutput":"$0.03 / IMG","tags":["multi_modal"],"modalities":["text","image"],"typeHints":["t2i"],"source":"public-provider-conf"},"vision":true},{"id":"imagen-4.0-fast-generate-001","name":"imagen-4.0-fast-generate-001","display_name":"imagen-4.0-fast-generate-001","type":"image-generation","context_length":0,"max_output_tokens":0,"capabilities":{"vision":true,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"modalities":{"input":["text","image"],"output":["text","image"]},"metadata":{"developer":"Google","developerId":8,"providerId":42,"modelRatio":1,"cacheRatio":1,"completionRatio":1,"description":"Imagen-4.0 最新快速版本","order":815,"flag":1,"displayOutput":"$0.02 / IMG","imagePriceConfig":"{\"generate\":{\"standard\":{\"standard\":0.02}}} ","modalities":["text","image"],"typeHints":["t2i"],"source":"public-provider-conf"},"vision":true},{"id":"imagen-4.0-generate-001","name":"imagen-4.0-generate-001","display_name":"imagen-4.0-generate-001","type":"image-generation","context_length":0,"max_output_tokens":0,"capabilities":{"vision":true,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"modalities":{"input":["text","image"],"output":["text","image"]},"metadata":{"developer":"Google","developerId":8,"providerId":42,"modelRatio":1,"cacheRatio":1,"completionRatio":1,"order":815,"flag":1,"displayOutput":"$0.04 / IMG","imagePriceConfig":"{\"generate\":{\"standard\":{\"standard\":0.04}}}","modalities":["text","image"],"typeHints":["t2i"],"source":"public-provider-conf"},"vision":true},{"id":"imagen-4.0-generate-preview-05-20","name":"imagen-4.0-generate-preview-05-20","display_name":"imagen-4.0-generate-preview-05-20","type":"image-generation","context_length":0,"max_output_tokens":0,"capabilities":{"vision":true,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"modalities":{"input":["text","image"],"output":["text","image"]},"metadata":{"developer":"Google","developerId":8,"providerId":24,"modelRatio":1,"cacheRatio":0,"completionRatio":1,"description":"谷歌最新的生图模型","descriptionEn":"Google's latest raw image model","order":0,"flag":1,"displayInput":"-","displayOutput":"$0.04 / IMG","tags":["multi_modal"],"modalities":["text","image"],"typeHints":["t2i"],"source":"public-provider-conf"},"vision":true},{"id":"imagen-4.0-generate-preview-06-06","name":"imagen-4.0-generate-preview-06-06","display_name":"imagen-4.0-generate-preview-06-06","type":"image-generation","context_length":0,"max_output_tokens":0,"capabilities":{"vision":true,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"modalities":{"input":["text","image"],"output":["text","image"]},"metadata":{"developer":"Google","developerId":8,"providerId":42,"modelRatio":1,"cacheRatio":0,"completionRatio":1,"description":"Imagen-4.0 最新预览版","order":815,"flag":1,"displayInput":"-","displayOutput":"$0.04 / IMG","modalities":["text","image"],"typeHints":["t2i"],"source":"public-provider-conf"},"vision":true},{"id":"imagen-4.0-ultra-generate-001","name":"imagen-4.0-ultra-generate-001","display_name":"imagen-4.0-ultra-generate-001","type":"image-generation","context_length":0,"max_output_tokens":0,"capabilities":{"vision":true,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"modalities":{"input":["text","image"],"output":["text","image"]},"metadata":{"developer":"Google","developerId":8,"providerId":42,"modelRatio":1,"cacheRatio":1,"completionRatio":1,"description":"Imagen-4.0 最新正式版本","order":815,"flag":1,"displayOutput":"$0.06 / IMG","imagePriceConfig":"{\"generate\":{\"standard\":{\"standard\":0.06}}}","modalities":["text","image"],"typeHints":["t2i"],"source":"public-provider-conf"},"vision":true},{"id":"imagen-4.0-ultra-generate-exp-05-20","name":"imagen-4.0-ultra-generate-exp-05-20","display_name":"imagen-4.0-ultra-generate-exp-05-20","type":"image-generation","context_length":0,"max_output_tokens":0,"capabilities":{"vision":true,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"modalities":{"input":["text","image"],"output":["text","image"]},"metadata":{"developer":"Google","developerId":8,"providerId":24,"modelRatio":1,"cacheRatio":0,"completionRatio":1,"description":"imagen 4.0 体验版，仅供尝鲜测试，正式环境建议使用 imagen-4.0-generate-preview-05-20","descriptionEn":"Image 4.0 Beta version, for testing purposes only. For production environment, it is recommended to use imagen-4.0-generate-preview-05-20.","order":700,"flag":1,"displayInput":"-","displayOutput":"$0.06 / IMG","tags":["multi_modal"],"modalities":["text","image"],"typeHints":["t2i"],"source":"public-provider-conf"},"vision":true},{"id":"imagen-4.0-ultra-generate-preview-06-06","name":"imagen-4.0-ultra-generate-preview-06-06","display_name":"imagen-4.0-ultra-generate-preview-06-06","type":"image-generation","context_length":0,"max_output_tokens":0,"capabilities":{"vision":true,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"modalities":{"input":["text","image"],"output":["text","image"]},"metadata":{"developer":"Google","developerId":8,"providerId":42,"modelRatio":1,"cacheRatio":0,"completionRatio":1,"description":"Imagen-4.0 Ultra 最新预览版","order":814,"flag":1,"displayInput":"-","displayOutput":"$0.06 / IMG","modalities":["text","image"],"typeHints":["t2i"],"source":"public-provider-conf"},"vision":true},{"id":"inclusionAI/Ling-flash-2.0","name":"inclusionAI/Ling-flash-2.0","display_name":"inclusionAI/Ling-flash-2.0","type":"chat","context_length":0,"max_output_tokens":0,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"developer":"Qwen","developerId":13,"providerId":8,"modelRatio":0.068,"cacheRatio":1,"completionRatio":4,"description":"Ling-flash-2.0 是 inclusionAI 研发的一款语言模型，总参数量为1000亿，其中每个标记激活6.1亿参数（不包含嵌入层参数为4.8亿）。作为 Ling 2.0 架构系列的一部分，它被设计成一种轻量级且强大的专家混合（MoE）模型。该模型旨在实现与400亿参数级别的密集模型以及其他更大规模 MoE 模型相当甚至更优的性能，但激活参数量却显著较小。该模型代表了一种通过极致的架构设计和训练方法，追求高性能和高效能的策略。","descriptionEn":"Ling-flash-2.0 is a language model from inclusionAI with a total of 100 billion parameters, of which 6.1 billion are activated per token (4.8 billion non-embedding). As part of the Ling 2.0 architecture series, it is designed as a lightweight yet powerful Mixture-of-Experts (MoE) model. It aims to deliver performance comparable to or even exceeding that of 40B-level dense models and other larger MoE models, but with a significantly smaller active parameter count. The model represents a strategy focused on achieving high performance and efficiency through extreme architectural design and training methods.","order":600,"flag":0,"source":"public-provider-conf"},"vision":false},{"id":"inclusionAI/Ling-mini-2.0","name":"inclusionAI/Ling-mini-2.0","display_name":"inclusionAI/Ling-mini-2.0","type":"chat","context_length":0,"max_output_tokens":0,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"developer":"Qwen","developerId":13,"providerId":8,"modelRatio":0.034,"cacheRatio":1,"completionRatio":4,"description":"Ling-mini-2.0 是一款基于 MoE 架构 的小尺寸高性能大语言模型。它拥有 16B 总参数，但每个 token 仅激活 1.4B（non-embedding 789M），从而实现了极高的生成速度。得益于高效的 MoE 设计与大规模高质量训练数据，尽管激活参数仅为 1.4B，Ling-mini-2.0 依然在下游任务中展现出可媲美 10B 以下 dense LLM 及更大规模 MoE 模型的顶尖性能","descriptionEn":"Ling-mini-2.0 is a small-sized, high-performance large language model based on the MoE architecture. It has a total of 16 billion parameters, but only activates 1.4 billion parameters per token (non-embedding 789 million), achieving extremely high generation speed. Thanks to the efficient MoE design and large-scale high-quality training data, despite activating only 1.4 billion parameters, Ling-mini-2.0 still demonstrates top-tier performance on downstream tasks comparable to dense LLMs under 10 billion parameters and even larger-scale MoE models.","order":600,"flag":0,"source":"public-provider-conf"},"vision":false},{"id":"irag-1.0","name":"irag-1.0","display_name":"irag-1.0","type":"image-generation","context_length":0,"max_output_tokens":0,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"developer":"Baidu","developerId":25,"providerId":15,"modelRatio":1,"cacheRatio":0,"completionRatio":0,"description":"百度自研的ERNIE iRAG（ERNIE image based RAG），检索增强的文生图技术，将百度搜索的亿级图片资源跟强大的基础模型能力相结合，就可以生成各种超真实的图片，整体效果远远超过文生图原生系统，去掉了AI味儿，而且成本很低。ERNIE iRAG具备无幻觉、超真实、立等可取等特点。","descriptionEn":"Baidu's self-developed ERNIE iRAG (ERNIE image-based RAG), a retrieval-augmented text-to-image technology, combines Baidu Search's hundreds of millions of image resources with powerful foundational model capabilities to generate various ultra-realistic images. The overall effect far surpasses native text-to-image systems, eliminating the typical AI feel while maintaining low costs. ERNIE iRAG features no hallucinations, ultra-realism, and instant usability.","order":600,"flag":0,"imagePriceConfig":"{\"generate\":{\"standard\":{\"standard\":0.019}}}","typeHints":["t2i"],"source":"public-provider-conf"},"vision":false},{"id":"jina-colbert-v2","name":"jina-colbert-v2","display_name":"jina-colbert-v2","type":"embedding","context_length":8000,"max_output_tokens":8000,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"modalities":{"input":["text"],"output":["text"]},"metadata":{"developer":"Jina AI","developerId":22,"providerId":50,"modelRatio":0.025,"cacheRatio":1,"completionRatio":1,"description":"多语言 ColBERT 模型，560M 参数，用于嵌入和重排序。","descriptionEn":"Multi-language ColBERT embeddings model, 560M parameters, used for embedding and reranking.","order":555,"flag":1,"modalities":["text"],"typeHints":["embedding","reranking"],"source":"public-provider-conf"},"vision":false},{"id":"jina-deepsearch-v1","name":"jina-deepsearch-v1","display_name":"jina-deepsearch-v1","type":"chat","context_length":1000000,"max_output_tokens":1000000,"capabilities":{"vision":true,"function_calling":false,"reasoning":true,"tool_calling":false},"reasoning":true,"tool_call":false,"modalities":{"input":["text","image"],"output":["text","image"]},"metadata":{"developer":"Jina AI","developerId":22,"providerId":50,"modelRatio":0.025,"cacheRatio":1,"completionRatio":1,"description":"DeepSearch 结合了搜索、阅读和推理能力，直到找到最佳答案。DeepSearch 完全兼容 OpenAI 的 Chat API 格式，最长上下文 1 M Tokens。\n它默认的流式调用 (stream) 会返回思考过程，关闭则不输出思考部分。","descriptionEn":"DeepSearch combines search, reading, and reasoning capabilities to pursue the best possible answer. It's fully compatible with OpenAI's Chat API format—just replace api.openai.com with aihubmix.com to get started.  \nThe stream will return the thinking process.","order":600,"flag":1,"features":["thinking","web","deepsearch"],"tags":["best"],"modalities":["text","image"],"typeHints":["t2t","search"],"source":"public-provider-conf"},"vision":true},{"id":"jina-embeddings-v2-base-code","name":"jina-embeddings-v2-base-code","display_name":"jina-embeddings-v2-base-code","type":"embedding","context_length":8000,"max_output_tokens":8000,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"modalities":{"input":["text"],"output":["text"]},"metadata":{"developer":"Jina AI","developerId":22,"providerId":50,"modelRatio":0.025,"cacheRatio":1,"completionRatio":1,"description":"针对代码和文档搜索优化的向量嵌入模型，768 维，137M 参数。","descriptionEn":"Model optimized for code and document search, 768-dimensional, 137M parameters.","order":0,"flag":0,"modalities":["text"],"typeHints":["embedding"],"source":"public-provider-conf"},"vision":false},{"id":"jina-embeddings-v3","name":"jina-embeddings-v3","display_name":"jina-embeddings-v3","type":"embedding","context_length":8000,"max_output_tokens":8000,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"modalities":{"input":["text"],"output":["text"]},"metadata":{"developer":"Jina AI","developerId":22,"providerId":50,"modelRatio":0.025,"cacheRatio":0,"completionRatio":1,"description":"文本向量嵌入模型、多语言、1024 维、570M 参数。","descriptionEn":"Text Embeddings Model, multilingual, 1024-dimensional, 570M parameters.","order":545,"flag":1,"tags":["best"],"modalities":["text"],"typeHints":["embedding"],"source":"public-provider-conf"},"vision":false},{"id":"jina-embeddings-v4","name":"jina-embeddings-v4","display_name":"jina-embeddings-v4","type":"embedding","context_length":0,"max_output_tokens":0,"capabilities":{"vision":true,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"modalities":{"input":["text","image"],"output":["text","image"]},"metadata":{"developer":"Jina AI","developerId":22,"providerId":50,"modelRatio":0.025,"cacheRatio":1,"completionRatio":1,"description":"38 亿参数的通用向量模型 (embedding model)，用于多模态和多语言检索，支持单向量和多向量向量模型 (embedding) 输出。","descriptionEn":"A general-purpose vector model with 3.8 billion parameters, used for multimodal and multilingual retrieval, supporting both unidirectional and multi-vector embedding outputs.","order":600,"flag":1,"tags":["multi_modal","best"],"modalities":["text","image"],"typeHints":["embedding"],"source":"public-provider-conf"},"vision":true},{"id":"jina-reranker-m0","name":"jina-reranker-m0","display_name":"jina-reranker-m0","type":"chat","context_length":10000,"max_output_tokens":10000,"capabilities":{"vision":true,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"modalities":{"input":["text","image"],"output":["text","image"]},"metadata":{"developer":"Jina AI","developerId":22,"providerId":50,"modelRatio":0.025,"cacheRatio":1,"completionRatio":1,"description":"多模态多语言文档重排序模型，10K Tokens 上下文，2.4B 参数，用于包含图文的文档排序。","descriptionEn":"Multimodal multilingual document reranker, 10K context, 2.4B parameters, for visual document sorting.","order":558,"flag":1,"tags":["multi_modal","best"],"modalities":["text","image"],"typeHints":["reranking"],"source":"public-provider-conf"},"vision":true},{"id":"kimi-k2-0711-preview","name":"kimi-k2-0711-preview","display_name":"kimi-k2-0711-preview","type":"chat","context_length":0,"max_output_tokens":0,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"developer":"Moonshot AI","developerId":15,"providerId":25,"modelRatio":0.31,"cacheRatio":0,"completionRatio":4,"description":"kimi-k2 是一款具备超强代码和 Agent 能力的 MoE 架构基础模型，总参数 1T，激活参数 32B。在通用知识推理、编程、数学、Agent 等主要类别的基准性能测试中，K2 模型的性能超过其他主流开源模型。","descriptionEn":"kimi-k2 is a MoE architecture foundation model with powerful coding and Agent capabilities, having a total of 1 trillion parameters and 32 billion active parameters. In benchmark performance tests across major categories such as general knowledge reasoning, programming, mathematics, and Agent tasks, the K2 model outperforms other mainstream open-source models.","order":800,"flag":0,"source":"public-provider-conf"},"vision":false},{"id":"kimi-k2-0905-preview","name":"kimi-k2-0905-preview","display_name":"kimi-k2-0905-preview","type":"chat","context_length":0,"max_output_tokens":0,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"developer":"Moonshot AI","developerId":15,"providerId":25,"modelRatio":0.274,"cacheRatio":0.25,"completionRatio":4,"description":"kimi-k2 是一款具备超强代码和 Agent 能力的 MoE 架构基础模型，总参数 1T，激活参数 32B。在通用知识推理、编程、数学、Agent 等主要类别的基准性能测试中，K2 模型的性能超过其他主流开源模型\nkimi-k2-0905-preview 模型上下文长度为 256k，具备更强的 Agentic Coding 能力、更突出的前端代码的美观度和实用性、以及更好的上下文理解能力。","descriptionEn":"kimi-k2 is a MoE architecture base model with exceptionally strong coding and agent capabilities, containing a total of 1 trillion parameters and 32 billion activated parameters. In benchmark performance tests across key categories such as general knowledge reasoning, programming, mathematics, and agents, the K2 model outperforms other mainstream open-source models.\nThe kimi-k2-0905-preview model features a context length of 256k and offers enhanced agentic coding abilities, improved aesthetics and practicality of front-end code, as well as better context understanding capabilities.","order":800,"flag":0,"source":"public-provider-conf"},"vision":false},{"id":"kimi-k2-turbo-preview","name":"kimi-k2-turbo-preview","display_name":"kimi-k2-turbo-preview","type":"chat","context_length":0,"max_output_tokens":0,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"developer":"Moonshot AI","developerId":15,"providerId":25,"modelRatio":0.6,"cacheRatio":0.25,"completionRatio":4,"description":"kimi-k2-turbo-preview 模型是 kimi-k2 的高速版，模型参数与 kimi-k2 一致，但输出速度由每秒 10 Tokens 提升至每秒 40 Tokens\n","descriptionEn":"The kimi-k2-turbo-preview model is a high-speed version of kimi-k2, with the same model parameters as kimi-k2, but the output speed has been increased from 10 tokens per second to 40 tokens per second.","order":800,"flag":1,"source":"public-provider-conf"},"vision":false},{"id":"kimi-latest","name":"kimi-latest","display_name":"kimi-latest","type":"chat","context_length":0,"max_output_tokens":0,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"developer":"Moonshot AI","developerId":15,"providerId":25,"modelRatio":2,"cacheRatio":1,"completionRatio":1,"description":"官方计费根据输入内容长度8k,32k,128k分3挡计费，本站不支持该计费结构，取中32k挡为计费标准，价格敏感介意勿用","descriptionEn":"The official billing is tiered based on input lengths of 8k, 32k, and 128k. This site does not support that billing structure and uses the middle 32k tier as the standard for charging. If you are price-sensitive, please avoid using it.","order":199,"flag":1,"source":"public-provider-conf"},"vision":false},{"id":"kimi-thinking-preview","name":"kimi-thinking-preview","display_name":"kimi-thinking-preview","type":"chat","context_length":0,"max_output_tokens":0,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"developer":"Moonshot AI","developerId":15,"providerId":25,"modelRatio":15,"cacheRatio":1,"completionRatio":1,"description":"kimi最新推理模型","descriptionEn":"The latest kimi model.","order":60,"flag":1,"source":"public-provider-conf"},"vision":false},{"id":"learnlm-1.5-pro-experimental","name":"Gemini 1.5 Pro","display_name":"Gemini 1.5 Pro","type":"chat","context_length":0,"max_output_tokens":0,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"developer":"Google","developerId":8,"providerId":24,"modelRatio":0.625,"cacheRatio":1,"completionRatio":4,"order":0,"flag":0,"source":"public-provider-conf"},"vision":false},{"id":"llama-3.1-8b-instant","name":"llama-3.1-8b","display_name":"llama-3.1-8b","type":"chat","context_length":0,"max_output_tokens":0,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"developer":"Llama","developerId":11,"providerId":29,"modelRatio":0.15,"cacheRatio":1,"completionRatio":2,"order":0,"flag":0,"source":"public-provider-conf"},"vision":false},{"id":"llama-3.3-70b","name":"llama-3.3-70b","display_name":"llama-3.3-70b","type":"chat","context_length":0,"max_output_tokens":0,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"developer":"Llama","developerId":11,"providerId":8,"modelRatio":0.3,"cacheRatio":1,"completionRatio":1,"description":"cerebras","descriptionEn":"cerebras","order":50,"flag":0,"source":"public-provider-conf"},"vision":false},{"id":"llama-3.3-70b-versatile","name":"llama-3.3-70b","display_name":"llama-3.3-70b","type":"chat","context_length":0,"max_output_tokens":0,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"developer":"Meta","developerId":11,"providerId":29,"modelRatio":0.3,"cacheRatio":1,"completionRatio":1,"order":0,"flag":0,"source":"public-provider-conf"},"vision":false},{"id":"llama-4-maverick-17b-128e-instruct","name":"llama-4-maverick-17b-128e-instruct","display_name":"llama-4-maverick-17b-128e-instruct","type":"chat","context_length":0,"max_output_tokens":0,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"developer":"Llama","developerId":11,"providerId":8,"modelRatio":0.1,"cacheRatio":1,"completionRatio":1,"description":"cerebras","descriptionEn":"cerebras","order":1,"flag":0,"source":"public-provider-conf"},"vision":false},{"id":"llama-4-scout-17b-16e-instruct","name":"llama-4-scout-17b-16e-instruct","display_name":"llama-4-scout-17b-16e-instruct","type":"chat","context_length":0,"max_output_tokens":0,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"developer":"Llama","developerId":11,"providerId":8,"modelRatio":0.1,"cacheRatio":1,"completionRatio":1,"description":"cerebras","descriptionEn":"cerebras","order":1,"flag":1,"source":"public-provider-conf"},"vision":false},{"id":"llama3-70b-8192","name":"llama3-70b","display_name":"llama3-70b","type":"chat","context_length":0,"max_output_tokens":0,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"developer":"Meta","developerId":11,"providerId":29,"modelRatio":0.35,"cacheRatio":1,"completionRatio":1.338983051,"order":0,"flag":0,"source":"public-provider-conf"},"vision":false},{"id":"llama3-8b-8192","name":"llama3-8b","display_name":"llama3-8b","type":"chat","context_length":0,"max_output_tokens":0,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"developer":"Meta","developerId":11,"providerId":29,"modelRatio":0.03,"cacheRatio":1,"completionRatio":2,"order":0,"flag":0,"source":"public-provider-conf"},"vision":false},{"id":"llama3.1-8b","name":"llama3.1-8b","display_name":"llama3.1-8b","type":"chat","context_length":0,"max_output_tokens":0,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"developer":"Llama","developerId":11,"providerId":8,"modelRatio":0.15,"cacheRatio":1,"completionRatio":2,"description":"cerebras","descriptionEn":"cerebras","order":1,"flag":0,"source":"public-provider-conf"},"vision":false},{"id":"meta-llama-3-70b","name":"meta-llama-3-70b","display_name":"meta-llama-3-70b","type":"chat","context_length":0,"max_output_tokens":0,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"developer":"Meta","developerId":11,"providerId":24,"modelRatio":2.3975,"cacheRatio":1,"completionRatio":1,"order":0,"flag":0,"source":"public-provider-conf"},"vision":false},{"id":"meta-llama-3-8b","name":"meta-llama-3-8b","display_name":"meta-llama-3-8b","type":"chat","context_length":0,"max_output_tokens":0,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"developer":"Meta","developerId":11,"providerId":24,"modelRatio":0.274,"cacheRatio":1,"completionRatio":1,"order":0,"flag":0,"source":"public-provider-conf"},"vision":false},{"id":"meta-llama/llama-4-scout-17b-16e-instruct","name":"llama-4-scout","display_name":"llama-4-scout","type":"chat","context_length":0,"max_output_tokens":0,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"developer":"Llama","developerId":11,"providerId":29,"modelRatio":0.1,"cacheRatio":1,"completionRatio":1,"description":"由groq提供","descriptionEn":"groq","order":54,"flag":0,"source":"public-provider-conf"},"vision":false},{"id":"moonshot-v1-128k","name":"moonshot-v1-128k","display_name":"moonshot-v1-128k","type":"chat","context_length":0,"max_output_tokens":0,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"developer":"Moonshot AI","developerId":15,"providerId":25,"modelRatio":5,"cacheRatio":1,"completionRatio":1,"order":0,"flag":0,"source":"public-provider-conf"},"vision":false},{"id":"moonshot-v1-128k-vision-preview","name":"moonshot-v1-128k-vision-preview","display_name":"moonshot-v1-128k-vision-preview","type":"chat","context_length":0,"max_output_tokens":0,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"developer":"Moonshot AI","developerId":15,"providerId":25,"modelRatio":5,"cacheRatio":1,"completionRatio":1,"order":0,"flag":0,"source":"public-provider-conf"},"vision":false},{"id":"moonshot-v1-32k","name":"moonshot-v1-32k","display_name":"moonshot-v1-32k","type":"chat","context_length":0,"max_output_tokens":0,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"developer":"Moonshot AI","developerId":15,"providerId":25,"modelRatio":2,"cacheRatio":1,"completionRatio":1,"order":0,"flag":0,"source":"public-provider-conf"},"vision":false},{"id":"moonshot-v1-32k-vision-preview","name":"moonshot-v1-32k-vision-preview","display_name":"moonshot-v1-32k-vision-preview","type":"chat","context_length":0,"max_output_tokens":0,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"developer":"Moonshot AI","developerId":15,"providerId":25,"modelRatio":2,"cacheRatio":1,"completionRatio":1,"order":0,"flag":0,"source":"public-provider-conf"},"vision":false},{"id":"moonshot-v1-8k","name":"moonshot-v1-8k","display_name":"moonshot-v1-8k","type":"chat","context_length":0,"max_output_tokens":0,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"developer":"Moonshot AI","developerId":15,"providerId":25,"modelRatio":1,"cacheRatio":1,"completionRatio":1,"order":0,"flag":0,"source":"public-provider-conf"},"vision":false},{"id":"moonshot-v1-8k-vision-preview","name":"moonshot-v1-8k-vision-preview","display_name":"moonshot-v1-8k-vision-preview","type":"chat","context_length":0,"max_output_tokens":0,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"developer":"Moonshot AI","developerId":15,"providerId":25,"modelRatio":1,"cacheRatio":1,"completionRatio":1,"order":0,"flag":0,"source":"public-provider-conf"},"vision":false},{"id":"moonshotai/Kimi-Dev-72B","name":"moonshotai/Kimi-Dev-72B","display_name":"moonshotai/Kimi-Dev-72B","type":"chat","context_length":0,"max_output_tokens":0,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"developer":"Moonshot AI","developerId":15,"providerId":44,"modelRatio":0.16,"cacheRatio":0,"completionRatio":4,"description":"Kimi-Dev-72B 是新一代开源编程大模型，在 SWE-bench Verified 上取得 60.4% 的领先成绩。通过大规模强化学习优化，能在真实 Docker 环境中自动修复代码，仅在通过完整测试集时获得奖励，从而保证解决方案的正确性和鲁棒性，更贴近真实软件开发标准。","descriptionEn":"Kimi-Dev-72B is a new generation open-source programming large model that achieved a leading performance of 60.4% on SWE-bench Verified. Through large-scale reinforcement learning optimization, it can automatically fix code in real Docker environments, receiving rewards only when passing the complete test suite, thereby ensuring the correctness and robustness of solutions and aligning more closely with real software development standards.","order":100,"flag":1,"source":"public-provider-conf"},"vision":false},{"id":"moonshotai/Moonlight-16B-A3B-Instruct","name":"Moonlight-16B-A3B","display_name":"Moonlight-16B-A3B","type":"chat","context_length":0,"max_output_tokens":0,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"developer":"Moonshot AI","developerId":15,"providerId":8,"modelRatio":0.1,"cacheRatio":0,"completionRatio":1,"description":"由chutes.ai提供","descriptionEn":"Provided by chutes.ai.","order":100,"flag":1,"source":"public-provider-conf"},"vision":false},{"id":"moonshotai/kimi-k2-instruct","name":"moonshotai/kimi-k2-instruct","display_name":"moonshotai/kimi-k2-instruct","type":"chat","context_length":0,"max_output_tokens":0,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"developer":"Moonshot AI","developerId":15,"providerId":8,"modelRatio":0.31,"cacheRatio":1,"completionRatio":4,"description":"Kimi K2 是 Moonshot AI 的最先进的专家混合（MoE）语言模型，拥有 1 万亿总参数和 320 亿激活参数。它专为智能代理设计，在工具使用、编程和跨领域自主问题解决方面表现出色。","descriptionEn":"Kimi K2 is Moonshot AI's state-of-the-art Mixture-of-Experts (MoE) language model with 1 trillion total parameters and 32 billion activated parameters. Designed for agentic intelligence, it excels at tool use, coding, and autonomous problem-solving across diverse domains.","order":845,"flag":0,"source":"public-provider-conf"},"vision":false},{"id":"nvidia/Llama-3_1-Nemotron-Ultra-253B-v1","name":"nvidia/Llama-3_1-Nemotron-Ultra-253B-v1","display_name":"nvidia/Llama-3_1-Nemotron-Ultra-253B-v1","type":"chat","context_length":0,"max_output_tokens":0,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"developer":"Nvidia","developerId":17,"providerId":8,"modelRatio":0.25,"cacheRatio":0,"completionRatio":1,"description":"Llama-3.1-Nemotron-Ultra-253B 是一个拥有 2530 亿参数、专注于推理的语言模型，经过优化以提高效率，擅长数学、编程和通用指令执行任务，可在单个 8xH100 节点上运行。","descriptionEn":"Llama-3.1-Nemotron-Ultra-253B is a 253 billion parameter reasoning-focused language model optimized for efficiency that excels at math, coding, and general instruction-following tasks while running on a single 8xH100 node.","order":12,"flag":1,"source":"public-provider-conf"},"vision":false},{"id":"nvidia/llama-3.1-nemotron-70b-instruct","name":"llama-3.1-nemotron-70b","display_name":"llama-3.1-nemotron-70b","type":"chat","context_length":0,"max_output_tokens":0,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"developer":"Nvidia","developerId":17,"providerId":8,"modelRatio":0.3,"cacheRatio":1,"completionRatio":1,"order":0,"flag":0,"source":"public-provider-conf"},"vision":false},{"id":"o1","name":"o1","display_name":"o1","type":"chat","context_length":200,"max_output_tokens":200,"capabilities":{"vision":false,"function_calling":false,"reasoning":true,"tool_calling":false},"reasoning":true,"tool_call":false,"modalities":{"input":["text"],"output":["text"]},"metadata":{"developer":"OpenAI","developerId":12,"providerId":1,"modelRatio":7.5,"cacheRatio":0.5,"completionRatio":4,"description":"openai最强o系列模型，支持官方命中缓存输入价格减半；","descriptionEn":"OpenAI's most powerful O-series model supports official cache hits that halve the input cost.","order":410,"flag":2,"billingConfig":"{\"model_name\": \"o1\", \"default_tier\": \"tier1\", \"enabled_billing_items\": [\"prompt_tokens\", \"completion_tokens\", \"cached_tokens\", \"image_generation\", \"web_search_requests\"], \"per_unit_price_config\": {\"web_search_price\": 0.01}, \"token_based_tier_configs\": {\"tier1\": {\"model_ratio\": 7.5, \"tier_condition\": {\"max_tokens\": -1, \"min_tokens\": 0}, \"cached_tokens_ratio\": 0.5, \"prompt_tokens_ratio\": 1.0, \"completion_tokens_ratio\": 4.0}}}","features":["thinking"],"tags":["multi_modal","best","bold"],"modalities":["text"],"typeHints":["t2t"],"source":"public-provider-conf"},"vision":false},{"id":"o1-2024-12-17","name":"o1","display_name":"o1","type":"chat","context_length":0,"max_output_tokens":0,"capabilities":{"vision":true,"function_calling":false,"reasoning":true,"tool_calling":false},"reasoning":true,"tool_call":false,"modalities":{"input":["text","image"],"output":["text","image"]},"metadata":{"developer":"OpenAI","developerId":12,"providerId":1,"modelRatio":7.5,"cacheRatio":0.5,"completionRatio":4,"order":1,"flag":0,"features":["thinking"],"tags":["best"],"modalities":["text","image"],"typeHints":["t2t"],"source":"public-provider-conf"},"vision":true},{"id":"o1-mini","name":"o1-mini","display_name":"o1-mini","type":"chat","context_length":0,"max_output_tokens":0,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"developer":"OpenAI","developerId":12,"providerId":1,"modelRatio":1.5,"cacheRatio":0.5,"completionRatio":4,"description":"o1-mini 更快，便宜 80%，在编码任务上与 o1-preview 具有竞争力。AiHubMix同时使用openai和微软azure openai渠道","descriptionEn":"o1-mini is faster and 80% cheaper, and is competitive with o1-preview on coding tasks. AiHubMix uses both OpenAI and Microsoft Azure OpenAI channels simultaneously.","order":113,"flag":0,"billingConfig":"{\"model_name\": \"o1-mini\", \"default_tier\": \"tier1\", \"enabled_billing_items\": [\"prompt_tokens\", \"completion_tokens\", \"cached_tokens\", \"image_generation\", \"web_search_requests\"], \"per_unit_price_config\": {\"web_search_price\": 0.01}, \"token_based_tier_configs\": {\"tier1\": {\"model_ratio\": 0.55, \"tier_condition\": {\"max_tokens\": -1, \"min_tokens\": 0}, \"cached_tokens_ratio\": 0.5, \"prompt_tokens_ratio\": 1.0, \"completion_tokens_ratio\": 4.0}}}","source":"public-provider-conf"},"vision":false},{"id":"o1-mini-2024-09-12","name":"o1-mini","display_name":"o1-mini","type":"chat","context_length":0,"max_output_tokens":0,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"developer":"OpenAI","developerId":12,"providerId":1,"modelRatio":1.5,"cacheRatio":0.5,"completionRatio":4,"order":0,"flag":0,"source":"public-provider-conf"},"vision":false},{"id":"o1-preview","name":"o1-preview","display_name":"o1-preview","type":"chat","context_length":0,"max_output_tokens":0,"capabilities":{"vision":true,"function_calling":false,"reasoning":true,"tool_calling":false},"reasoning":true,"tool_call":false,"modalities":{"input":["text","image"],"output":["text","image"]},"metadata":{"developer":"OpenAI","developerId":12,"providerId":1,"modelRatio":7.5,"cacheRatio":0.5,"completionRatio":4,"description":"OpenAI最新和最强大的推理型模型；AiHubMix使用openai和微软azure openai两个渠道同时提供以达到高并发负载均衡；","descriptionEn":"The latest and most powerful inference model from OpenAI; AiHubMix uses both OpenAI and Microsoft Azure OpenAI channels simultaneously to achieve high-concurrency load balancing.","order":114,"flag":0,"features":["thinking"],"modalities":["text","image"],"typeHints":["t2t"],"source":"public-provider-conf"},"vision":true},{"id":"o1-preview-2024-09-12","name":"o1-preview","display_name":"o1-preview","type":"chat","context_length":0,"max_output_tokens":0,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"developer":"OpenAI","developerId":12,"providerId":1,"modelRatio":7.5,"cacheRatio":0.5,"completionRatio":4,"order":10,"flag":0,"source":"public-provider-conf"},"vision":false},{"id":"o1-pro","name":"o1-pro","display_name":"o1-pro","type":"chat","context_length":200000,"max_output_tokens":200000,"capabilities":{"vision":false,"function_calling":false,"reasoning":true,"tool_calling":false},"reasoning":true,"tool_call":false,"modalities":{"input":["text"],"output":["text"]},"metadata":{"developer":"OpenAI","developerId":12,"providerId":1,"modelRatio":85,"cacheRatio":1,"completionRatio":4,"description":"价格极其昂，请勿轻易调用；\n仅支持 v1/responses 接口；调用方法见文档https://docs.aihubmix.com/cn/api/Responses-API\no1 系列模型通过强化学习进行训练，以在回答之前思考并执行复杂推理。o1-pro 模型使用更多计算资源以更深入地思考，并提供始终更好的答案。","descriptionEn":"The o1 series of models are trained with reinforcement learning to think before they answer and perform complex reasoning. The o1-pro model uses more compute to think harder and provide consistently better answers.","order":350,"flag":0,"billingConfig":"{\"model_name\": \"o1-pro\", \"default_tier\": \"tier1\", \"enabled_billing_items\": [\"prompt_tokens\", \"completion_tokens\", \"cached_tokens\", \"image_generation\", \"web_search_requests\"], \"per_unit_price_config\": {\"web_search_price\": 0.01}, \"token_based_tier_configs\": {\"tier1\": {\"model_ratio\": 75, \"tier_condition\": {\"max_tokens\": -1, \"min_tokens\": 0}, \"cached_tokens_ratio\": 1.0, \"prompt_tokens_ratio\": 1.0, \"completion_tokens_ratio\": 4.0}}}","features":["thinking"],"tags":["best","sota"],"modalities":["text"],"typeHints":["t2t"],"source":"public-provider-conf"},"vision":false},{"id":"o3","name":"o3","display_name":"o3","type":"chat","context_length":200000,"max_output_tokens":200000,"capabilities":{"vision":true,"function_calling":true,"reasoning":true,"tool_calling":true},"reasoning":true,"tool_call":true,"modalities":{"input":["text","image"],"output":["text","image"]},"metadata":{"developer":"OpenAI","developerId":12,"providerId":1,"modelRatio":1,"cacheRatio":0.25,"completionRatio":4,"description":" o3 是 OpenAI 的旗舰模型，在多个领域表现强大，为编码、数学、科学和视觉推理任务树立了新的标准。自动缓存机制，命中便宜 75%。","descriptionEn":"OpenAI o3 is a powerful model across multiple domains, setting a new standard for coding, math, science, and visual reasoning tasks.","order":901,"flag":1,"billingConfig":"{\"model_name\": \"o3\", \"default_tier\": \"tier1\", \"enabled_billing_items\": [\"prompt_tokens\", \"completion_tokens\", \"cached_tokens\", \"image_generation\", \"web_search_requests\"], \"per_unit_price_config\": {\"web_search_price\": 0.01}, \"token_based_tier_configs\": {\"tier1\": {\"model_ratio\": 1.0, \"tier_condition\": {\"max_tokens\": -1, \"min_tokens\": 0}, \"cached_tokens_ratio\": 0.25, \"prompt_tokens_ratio\": 1.0, \"completion_tokens_ratio\": 4.0}}}","features":["thinking","tools","function_calling","structured_outputs"],"tags":["multi_modal","best","sota","bold"],"modalities":["text","image"],"typeHints":["t2t"],"source":"public-provider-conf"},"vision":true},{"id":"o3-mini","name":"o3-mini","display_name":"o3-mini","type":"chat","context_length":200000,"max_output_tokens":200000,"capabilities":{"vision":true,"function_calling":false,"reasoning":true,"tool_calling":false},"reasoning":true,"tool_call":false,"modalities":{"input":["text","image"],"output":["text","image"]},"metadata":{"developer":"OpenAI","developerId":12,"providerId":1,"modelRatio":0.55,"cacheRatio":0.5,"completionRatio":4,"description":"openai 最新的快速推理模型，擅长 STEAM 任务，性价比极高。\n支持官方命中缓存输入价格减半。","descriptionEn":"OpenAI's latest fast inference model excels at STEAM tasks and offers exceptional cost-effectiveness. Official support for cache hits reduces input prices by half.","order":455,"flag":0,"billingConfig":"{\"model_name\": \"o3-mini\", \"default_tier\": \"tier1\", \"enabled_billing_items\": [\"prompt_tokens\", \"completion_tokens\", \"cached_tokens\", \"image_generation\", \"web_search_requests\"], \"per_unit_price_config\": {\"web_search_price\": 0.01}, \"token_based_tier_configs\": {\"tier1\": {\"model_ratio\": 0.55, \"tier_condition\": {\"max_tokens\": -1, \"min_tokens\": 0}, \"cached_tokens_ratio\": 0.5, \"prompt_tokens_ratio\": 1.0, \"completion_tokens_ratio\": 4.0}}}","features":["thinking"],"tags":["multi_modal","best","optimized","economical","lightning"],"modalities":["text","image"],"typeHints":["t2t"],"source":"public-provider-conf"},"vision":true},{"id":"o3-pro","name":"o3-pro","display_name":"o3-pro","type":"chat","context_length":0,"max_output_tokens":0,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"developer":"OpenAI","developerId":12,"providerId":1,"modelRatio":10,"cacheRatio":1,"completionRatio":4,"description":"o3-pro\n该模型仅支持Responses API 接口请求；模型思考时间比较长返回会很慢；\n仅支持 v1/responses 接口；调用方法见文档https://docs.aihubmix.com/cn/api/Responses-API","descriptionEn":"o3-pro\nThis model only supports Requests API interface requests.The model's thinking time is relatively long, so the response will be slow.","order":900,"flag":1,"billingConfig":"{\"model_name\": \"o3-pro\", \"default_tier\": \"tier1\", \"enabled_billing_items\": [\"prompt_tokens\", \"completion_tokens\", \"cached_tokens\", \"image_generation\", \"web_search_requests\"], \"per_unit_price_config\": {\"web_search_price\": 0.01}, \"token_based_tier_configs\": {\"tier1\": {\"model_ratio\": 10.0, \"tier_condition\": {\"max_tokens\": -1, \"min_tokens\": 0}, \"cached_tokens_ratio\": 1.0, \"prompt_tokens_ratio\": 1.0, \"completion_tokens_ratio\": 4.0}}}","tags":["multi_modal"],"source":"public-provider-conf"},"vision":false},{"id":"o4-mini","name":"o4-mini","display_name":"o4-mini","type":"chat","context_length":0,"max_output_tokens":0,"capabilities":{"vision":true,"function_calling":false,"reasoning":true,"tool_calling":false},"reasoning":true,"tool_call":false,"modalities":{"input":["text","image"],"output":["text","image"]},"metadata":{"developer":"OpenAI","developerId":12,"providerId":1,"modelRatio":0.55,"cacheRatio":0.25,"completionRatio":4,"description":"o4-mini 是一个在速度和成本效益方面表现出色的智能模型。这使得它能够支持比 o3 显著更高的使用限制，成为所有需要推理问题的用户的强大高容量、高吞吐量选择。自动缓存机制，命中便宜 75%。","descriptionEn":"o4-mini is a remarkably smart model for its speed and cost-efficiency. This allows it to support significantly higher usage limits than o3, making it a strong high-volume, high-throughput option for everyone with questions that benefit from reasoning.","order":808,"flag":1,"billingConfig":"{\"model_name\": \"o4-mini\", \"default_tier\": \"tier1\", \"enabled_billing_items\": [\"prompt_tokens\", \"completion_tokens\", \"cached_tokens\", \"image_generation\", \"web_search_requests\"], \"per_unit_price_config\": {\"web_search_price\": 0.01}, \"token_based_tier_configs\": {\"tier1\": {\"model_ratio\": 0.55, \"tier_condition\": {\"max_tokens\": -1, \"min_tokens\": 0}, \"cached_tokens_ratio\": 0.25, \"prompt_tokens_ratio\": 1.0, \"completion_tokens_ratio\": 4.0}}}","features":["thinking"],"tags":["best","optimized","economical","lightning","multi_modal"],"modalities":["text","image"],"typeHints":["t2t"],"source":"public-provider-conf"},"vision":true},{"id":"omni-moderation-latest","name":"omni-moderation","display_name":"omni-moderation","type":"chat","context_length":0,"max_output_tokens":0,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"developer":"OpenAI","developerId":12,"providerId":1,"modelRatio":0.1,"cacheRatio":1,"completionRatio":1,"order":0,"flag":0,"source":"public-provider-conf"},"vision":false},{"id":"openai/gpt-oss-120b","name":"openai/gpt-oss-120b","display_name":"openai/gpt-oss-120b","type":"chat","context_length":0,"max_output_tokens":0,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"developer":"OpenAI","developerId":12,"providerId":29,"modelRatio":0.09,"cacheRatio":1,"completionRatio":5,"description":"GPT-OSS 120B 是 OpenAI 的旗舰开源模型，基于混合专家（MoE）架构，拥有 200 亿参数和 128 个专家。","descriptionEn":"GPT-OSS 120B is OpenAI's flagship open source model, built on a Mixture-of-Experts (MoE) architecture with 20 billion parameters and 128 experts.","order":946,"flag":1,"source":"public-provider-conf"},"vision":false},{"id":"openai/gpt-oss-20b","name":"openai/gpt-oss-20b","display_name":"openai/gpt-oss-20b","type":"chat","context_length":0,"max_output_tokens":0,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"developer":"OpenAI","developerId":12,"providerId":29,"modelRatio":0.055,"cacheRatio":1,"completionRatio":5,"description":"GPT-OSS 20B 是 OpenAI 的旗舰开源模型，基于混合专家（MoE）架构，拥有 200 亿个参数和 32 个专家。","descriptionEn":"GPT-OSS 20B is OpenAI's flagship open source model, built on a Mixture-of-Experts (MoE) architecture with 20 billion parameters and 32 experts.","order":945,"flag":1,"source":"public-provider-conf"},"vision":false},{"id":"qianfan-chinese-llama-2-13b","name":"qianfan-chinese-llama-2-13b","display_name":"qianfan-chinese-llama-2-13b","type":"chat","context_length":0,"max_output_tokens":0,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"developer":"Baidu","developerId":11,"providerId":24,"modelRatio":0.411,"cacheRatio":1,"completionRatio":1,"order":0,"flag":0,"source":"public-provider-conf"},"vision":false},{"id":"qianfan-llama-vl-8b","name":"qianfan-llama-vl-8b","display_name":"qianfan-llama-vl-8b","type":"chat","context_length":0,"max_output_tokens":0,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"developer":"Baidu","developerId":11,"providerId":24,"modelRatio":0.137,"cacheRatio":1,"completionRatio":2.5,"order":0,"flag":0,"source":"public-provider-conf"},"vision":false},{"id":"qianfan-qi-vl","name":"qianfan-qi-vl","display_name":"qianfan-qi-vl","type":"chat","context_length":0,"max_output_tokens":0,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"developer":"Baidu","developerId":25,"providerId":15,"modelRatio":0.1,"cacheRatio":1,"completionRatio":3,"description":"Qianfan-QI-VL模型是是百度云-千帆平台自研的图片质量检测视觉理解大模型(Quality Inspection Large Vision Language Model,Qianfan-QI-VL)。适用于电商场景下对电商上传的商品图片进行质量检测，检测能力包含AIGC人体瑕疵检测、马赛克识别、水印识别和商标检测。","descriptionEn":"The Qianfan-QI-VL model is a proprietary image quality inspection and visual understanding large model (Quality Inspection Large Vision Language Model, Qianfan-QI-VL) developed by Baidu Cloud’s Qianfan platform. It is designed for quality inspection of product images uploaded in e-commerce scenarios, with detection capabilities including AIGC human defect detection, mosaic recognition, watermark recognition, and trademark detection.","order":100,"flag":0,"source":"public-provider-conf"},"vision":false},{"id":"qwen-3-235b-a22b-instruct-2507","name":"qwen-3-235b-a22b-instruct-2507","display_name":"qwen-3-235b-a22b-instruct-2507","type":"chat","context_length":0,"max_output_tokens":0,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"developer":"Qwen","developerId":13,"providerId":8,"modelRatio":0.14,"cacheRatio":1,"completionRatio":5,"description":"cerebras","descriptionEn":"cerebras","order":20,"flag":1,"source":"public-provider-conf"},"vision":false},{"id":"qwen-3-235b-a22b-thinking-2507","name":"qwen-3-235b-a22b-thinking-2507","display_name":"qwen-3-235b-a22b-thinking-2507","type":"chat","context_length":0,"max_output_tokens":0,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"developer":"Qwen","developerId":13,"providerId":8,"modelRatio":0.14,"cacheRatio":1,"completionRatio":10,"description":"cerebras","descriptionEn":"cerebras","order":400,"flag":1,"source":"public-provider-conf"},"vision":false},{"id":"qwen-3-32b","name":"qwen-3-32b","display_name":"qwen-3-32b","type":"chat","context_length":0,"max_output_tokens":0,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"developer":"Qwen","developerId":13,"providerId":8,"modelRatio":0.2,"cacheRatio":1,"completionRatio":4,"description":"cerebras","descriptionEn":"cerebras","order":40,"flag":0,"source":"public-provider-conf"},"vision":false},{"id":"qwen-3-coder-480b","name":"qwen-3-coder-480b","display_name":"qwen-3-coder-480b","type":"chat","context_length":0,"max_output_tokens":0,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"developer":"Qwen","developerId":13,"providerId":8,"modelRatio":0.7,"cacheRatio":1,"completionRatio":4,"description":"cerebras","descriptionEn":"cerebras","order":400,"flag":1,"source":"public-provider-conf"},"vision":false},{"id":"qwen-flash","name":"qwen-flash","display_name":"qwen-flash","type":"chat","context_length":0,"max_output_tokens":0,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"developer":"Qwen","developerId":13,"providerId":17,"modelRatio":0.01,"cacheRatio":1,"completionRatio":10,"description":"该模型采取阶梯计费。","descriptionEn":"The model adopts tiered pricing.","order":0,"flag":0,"billingConfig":"{\"model_name\": \"qwen-flash\", \"default_tier\": \"tier1\", \"enabled_billing_items\": [\"prompt_tokens\", \"completion_tokens\", \"cached_tokens\"], \"token_based_tier_configs\": {\"tier1\": {\"model_ratio\": 0.010273, \"tier_condition\": {\"max_tokens\": 128000, \"min_tokens\": 0}, \"prompt_tokens_ratio\": 1.0, \"completion_tokens_ratio\": 10.0}, \"tier2\": {\"model_ratio\": 0.041096, \"tier_condition\": {\"max_tokens\": 256000, \"min_tokens\": 128001}, \"prompt_tokens_ratio\": 1.0, \"completion_tokens_ratio\": 10.0}, \"tier3\": {\"model_ratio\": 0.082191, \"tier_condition\": {\"max_tokens\": 1000000, \"min_tokens\": 256001}, \"prompt_tokens_ratio\": 1.0, \"completion_tokens_ratio\": 10.0}}}","source":"public-provider-conf"},"vision":false},{"id":"qwen-flash-2025-07-28","name":"qwen-flash-2025-07-28","display_name":"qwen-flash-2025-07-28","type":"chat","context_length":0,"max_output_tokens":0,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"developer":"Qwen","developerId":13,"providerId":17,"modelRatio":0.01,"cacheRatio":1,"completionRatio":10,"description":"该模型采取阶梯计费。","descriptionEn":"The model adopts tiered pricing.","order":0,"flag":0,"billingConfig":"{\"model_name\": \"qwen-flash-2025-07-28\", \"default_tier\": \"tier1\", \"enabled_billing_items\": [\"prompt_tokens\", \"completion_tokens\", \"cached_tokens\"], \"token_based_tier_configs\": {\"tier1\": {\"model_ratio\": 0.010273, \"tier_condition\": {\"max_tokens\": 128000, \"min_tokens\": 0}, \"prompt_tokens_ratio\": 1.0, \"completion_tokens_ratio\": 10.0}, \"tier2\": {\"model_ratio\": 0.041095, \"tier_condition\": {\"max_tokens\": 256000, \"min_tokens\": 128001}, \"prompt_tokens_ratio\": 1.0, \"completion_tokens_ratio\": 10.0}, \"tier3\": {\"model_ratio\": 0.082191, \"tier_condition\": {\"max_tokens\": 1000000, \"min_tokens\": 256001}, \"prompt_tokens_ratio\": 1.0, \"completion_tokens_ratio\": 10.0}}}","source":"public-provider-conf"},"vision":false},{"id":"qwen-image","name":"qwen-image","display_name":"qwen-image","type":"image-generation","context_length":0,"max_output_tokens":0,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"developer":"Qwen","developerId":13,"providerId":15,"modelRatio":1,"cacheRatio":0,"completionRatio":0,"description":"Qwen-Image是 Qwen 系列中的一个图像生成基础模型，在复杂文本渲染和精确图像编辑方面取得了显著进展。实验显示，该模型在图像生成和编辑方面具有强大的通用能力，特别是在中文文本渲染方面表现出色。","descriptionEn":"Qwen-Image is a foundational image generation model in the Qwen series, achieving significant progress in complex text rendering and precise image editing. Experiments show that the model has strong general capabilities in image generation and editing, especially excelling in Chinese text rendering.","order":600,"flag":0,"imagePriceConfig":"{\"generate\":{\"standard\":{\"standard\":0.034}}}","typeHints":["t2i"],"source":"public-provider-conf"},"vision":false},{"id":"qwen-image-edit","name":"qwen-image-edit","display_name":"qwen-image-edit","type":"image-generation","context_length":0,"max_output_tokens":0,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"developer":"Qwen","developerId":13,"providerId":15,"modelRatio":1,"cacheRatio":0,"completionRatio":0,"description":"Qwen-Image-Edit 是 Qwen-Image 的图像编辑版本。Qwen-Image-Edit 基于 20B Qwen-Image 模型，成功将 Qwen-Image 独特的文本渲染功能扩展到图像编辑任务，实现精准的文本编辑。此外，Qwen-Image-Edit 可将输入图像同时输入 Qwen2.5-VL（用于视觉语义控制）和 VAE 编码器（用于视觉外观控制），从而实现语义和外观编辑功能。","descriptionEn":"Qwen-Image-Edit is the image editing version of Qwen-Image. Based on the 20B Qwen-Image model, Qwen-Image-Edit successfully extends Qwen-Image's unique text rendering capabilities to image editing tasks, achieving precise text editing. Additionally, Qwen-Image-Edit can input the same image into Qwen2.5-VL (for visual semantic control) and the VAE encoder (for visual appearance control), enabling both semantic and appearance editing functionalities.","order":799,"flag":0,"imagePriceConfig":"{\"generate\":{\"standard\":{\"standard\":0.041}}}","typeHints":["t2i"],"source":"public-provider-conf"},"vision":false},{"id":"qwen-long","name":"qwen-long","display_name":"qwen-long","type":"chat","context_length":0,"max_output_tokens":0,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"developer":"Qwen","developerId":13,"providerId":17,"modelRatio":0.05,"cacheRatio":1,"completionRatio":4,"order":0,"flag":0,"source":"public-provider-conf"},"vision":false},{"id":"qwen-max","name":"qwen-max","display_name":"qwen-max","type":"chat","context_length":0,"max_output_tokens":0,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"developer":"Qwen","developerId":13,"providerId":17,"modelRatio":0.19,"cacheRatio":1,"completionRatio":4,"order":0,"flag":0,"source":"public-provider-conf"},"vision":false},{"id":"qwen-max-0125","name":"Qwen2.5-Max","display_name":"Qwen2.5-Max","type":"chat","context_length":0,"max_output_tokens":0,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"developer":"Qwen","developerId":13,"providerId":17,"modelRatio":0.19,"cacheRatio":1,"completionRatio":4,"description":"Qwen2.5-Max最新模型","descriptionEn":"Qwen 2.5-Max latest model","order":98,"flag":1,"source":"public-provider-conf"},"vision":false},{"id":"qwen-max-longcontext","name":"qwen-max-longcontext","display_name":"qwen-max-longcontext","type":"chat","context_length":0,"max_output_tokens":0,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"developer":"Qwen","developerId":13,"providerId":17,"modelRatio":3.5,"cacheRatio":1,"completionRatio":3,"order":0,"flag":0,"source":"public-provider-conf"},"vision":false},{"id":"qwen-plus","name":"qwen-plus","display_name":"qwen-plus","type":"chat","context_length":0,"max_output_tokens":0,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"developer":"Qwen","developerId":13,"providerId":17,"modelRatio":0.35,"cacheRatio":1,"completionRatio":3,"order":0,"flag":0,"source":"public-provider-conf"},"vision":false},{"id":"qwen-plus-2025-04-28","name":"qwen-plus-2025-04-28","display_name":"qwen-plus-2025-04-28","type":"chat","context_length":0,"max_output_tokens":0,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"developer":"Qwen","developerId":13,"providerId":17,"modelRatio":0.065,"cacheRatio":0,"completionRatio":20,"description":"Qwen3系列Plus模型，实现思考模式和非思考模式的有效融合，可在对话中切换模式。推理能力显著超过QwQ、通用能力显著超过Qwen2.5-Plus，达到同规模业界SOTA水平。此版本为2025年4月28日快照模型。","descriptionEn":"The Qwen3 series Plus model effectively integrates thinking and non-thinking modes, allowing for mode switching during conversations. Its reasoning abilities significantly surpass those of QwQ, and its general capabilities are markedly superior to Qwen2.5-Plus, reaching state-of-the-art (SOTA) levels among models of the same scale. This version is a snapshot model as of April 28, 2025.","order":39,"flag":1,"typeHints":["t2t"],"source":"public-provider-conf"},"vision":false},{"id":"qwen-plus-2025-07-28","name":"qwen-plus-2025-07-28","display_name":"qwen-plus-2025-07-28","type":"chat","context_length":0,"max_output_tokens":0,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"developer":"Qwen","developerId":13,"providerId":17,"modelRatio":0.055,"cacheRatio":1,"completionRatio":2.5,"description":"通义千问系列能力均衡的模型，推理效果和速度介于通义千问-Max和通义千问-Turbo之间，适合中等复杂任务。该模型采取阶梯计费。","descriptionEn":"The Tongyi Qianwen series balanced capability model has inference performance and speed between Tongyi Qianwen-Max and Tongyi Qianwen-Turbo, making it suitable for moderately complex tasks. This model adopts tiered pricing.","order":50,"flag":0,"billingConfig":"{\"model_name\": \"qwen-plus-2025-07-28\", \"default_tier\": \"tier1\", \"enabled_billing_items\": [\"prompt_tokens\", \"completion_tokens\", \"cached_tokens\"], \"token_based_tier_configs\": {\"tier1\": {\"model_ratio\": 0.054794, \"tier_condition\": {\"max_tokens\": 128000, \"min_tokens\": 0}, \"prompt_tokens_ratio\": 1.0, \"completion_tokens_ratio\": 2.5}, \"tier2\": {\"model_ratio\": 0.164383, \"tier_condition\": {\"max_tokens\": 256000, \"min_tokens\": 128001}, \"prompt_tokens_ratio\": 1.0, \"completion_tokens_ratio\": 8.333333}, \"tier3\": {\"model_ratio\": 0.328767, \"tier_condition\": {\"max_tokens\": 1000000, \"min_tokens\": 256001}, \"prompt_tokens_ratio\": 1.0, \"completion_tokens_ratio\": 10.0}}}","source":"public-provider-conf"},"vision":false},{"id":"qwen-plus-latest","name":"qwen-plus-latest","display_name":"qwen-plus-latest","type":"chat","context_length":0,"max_output_tokens":0,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"developer":"Qwen","developerId":13,"providerId":17,"modelRatio":0.055,"cacheRatio":1,"completionRatio":2.5,"description":"通义千问系列能力均衡的模型，推理效果和速度介于通义千问-Max和通义千问-Turbo之间，适合中等复杂任务。本模型是动态更新版本，模型更新不会提前通知。目前指向的版本是qwen-plus-2025-07-28。该模型采取阶梯计费。","descriptionEn":"The Qwen series models with balanced capabilities have inference performance and speed between Qwen-Max and Qwen-Turbo, making them suitable for moderately complex tasks. This model is a dynamically updated version, and updates will not be announced in advance. The current version is qwen-plus-2025-04-28.The model adopts tiered pricing.","order":50,"flag":1,"billingConfig":"{\"model_name\": \"qwen-plus-latest\", \"default_tier\": \"tier1\", \"enabled_billing_items\": [\"prompt_tokens\", \"completion_tokens\", \"cached_tokens\"], \"token_based_tier_configs\": {\"tier1\": {\"model_ratio\": 0.054794, \"tier_condition\": {\"max_tokens\": 128000, \"min_tokens\": 0}, \"prompt_tokens_ratio\": 1.0, \"completion_tokens_ratio\": 2.5}, \"tier2\": {\"model_ratio\": 0.164383, \"tier_condition\": {\"max_tokens\": 256000, \"min_tokens\": 128001}, \"prompt_tokens_ratio\": 1.0, \"completion_tokens_ratio\": 8.333333}, \"tier3\": {\"model_ratio\": 0.328767, \"tier_condition\": {\"max_tokens\": 1000000, \"min_tokens\": 256001}, \"prompt_tokens_ratio\": 1.0, \"completion_tokens_ratio\": 10.0}}}","typeHints":["t2t"],"source":"public-provider-conf"},"vision":false},{"id":"qwen-qwq-32b","name":"qwen-qwq-32b","display_name":"qwen-qwq-32b","type":"chat","context_length":0,"max_output_tokens":0,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"developer":"Qwen","developerId":13,"providerId":17,"modelRatio":0.2,"cacheRatio":1,"completionRatio":2,"order":99,"flag":0,"source":"public-provider-conf"},"vision":false},{"id":"qwen-turbo","name":"qwen-turbo","display_name":"qwen-turbo","type":"chat","context_length":1000000,"max_output_tokens":1000000,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"modalities":{"input":["text"],"output":["text"]},"metadata":{"developer":"Qwen","developerId":13,"providerId":17,"modelRatio":0.18,"cacheRatio":1,"completionRatio":3,"order":0,"flag":0,"features":["long_context"],"modalities":["text"],"typeHints":["t2t"],"source":"public-provider-conf"},"vision":false},{"id":"qwen-turbo-2024-11-01","name":"Qwen2.5-Turbo","display_name":"Qwen2.5-Turbo","type":"chat","context_length":1000000,"max_output_tokens":1000000,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"modalities":{"input":["text"],"output":["text"]},"metadata":{"developer":"Qwen","developerId":13,"providerId":17,"modelRatio":0.18,"cacheRatio":1,"completionRatio":3,"order":0,"flag":0,"features":["long_context"],"modalities":["text"],"typeHints":["t2t"],"source":"public-provider-conf"},"vision":false},{"id":"qwen-turbo-2025-04-28","name":"qwen-turbo-2025-04-28","display_name":"qwen-turbo-2025-04-28","type":"chat","context_length":0,"max_output_tokens":0,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"developer":"Qwen","developerId":13,"providerId":17,"modelRatio":0.023,"cacheRatio":0,"completionRatio":20,"description":"Qwen3系列Turbo模型，实现思考模式和非思考模式的有效融合，可在对话中切换模式。推理能力以更小参数规模比肩QwQ-32B、通用能力显著超过Qwen2.5-Turbo，达到同规模业界SOTA水平。此版本为2025年4月28日快照模型。","descriptionEn":"The Qwen3 series Turbo model effectively integrates thinking and non-thinking modes, allowing seamless switching between modes during conversations. With a smaller parameter size, its reasoning ability rivals that of QwQ-32B, and its general capabilities significantly surpass those of Qwen2.5-Turbo, reaching state-of-the-art (SOTA) levels among models of the same scale. This version is a snapshot model as of April 28, 2025.","order":40,"flag":1,"typeHints":["t2t"],"source":"public-provider-conf"},"vision":false},{"id":"qwen-turbo-latest","name":"qwen-turbo-latest","display_name":"qwen-turbo-latest","type":"chat","context_length":0,"max_output_tokens":0,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"developer":"Qwen","developerId":13,"providerId":17,"modelRatio":0.023,"cacheRatio":0,"completionRatio":20,"description":"通义千问系列速度最快、成本很低的模型，适合简单任务。本模型是动态更新版本，模型更新不会提前通知，模型中英文综合能力显著提升，模型人类偏好显著提升，模型推理能力和复杂指令理解能力显著增强，困难任务上的表现更优，数学、代码能力显著提升。目前指向qwen-turbo-2025-04-28。","descriptionEn":"The Qwen series model with the fastest speed and lowest cost, suitable for simple tasks. This model is a dynamically updated version, and updates will not be announced in advance. The model's overall Chinese and English abilities have been significantly improved, human preference alignment has been greatly enhanced, inference capability and complex instruction understanding have been substantially strengthened, performance on difficult tasks is better, and mathematics and coding skills have been significantly improved. The current version is qwen-turbo-2025-04-28.","order":49,"flag":1,"typeHints":["t2t"],"source":"public-provider-conf"},"vision":false},{"id":"qwen2.5-14b-instruct","name":"qwen2.5-14b","display_name":"qwen2.5-14b","type":"chat","context_length":0,"max_output_tokens":0,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"developer":"Qwen","developerId":13,"providerId":17,"modelRatio":0.2,"cacheRatio":1,"completionRatio":3,"order":0,"flag":0,"source":"public-provider-conf"},"vision":false},{"id":"qwen2.5-32b-instruct","name":"qwen2.5-32b","display_name":"qwen2.5-32b","type":"chat","context_length":0,"max_output_tokens":0,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"developer":"Qwen","developerId":13,"providerId":17,"modelRatio":0.3,"cacheRatio":1,"completionRatio":2,"order":0,"flag":0,"source":"public-provider-conf"},"vision":false},{"id":"qwen2.5-3b-instruct","name":"qwen2.5-3b","display_name":"qwen2.5-3b","type":"chat","context_length":0,"max_output_tokens":0,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"developer":"Qwen","developerId":13,"providerId":17,"modelRatio":0.2,"cacheRatio":1,"completionRatio":2,"order":0,"flag":0,"source":"public-provider-conf"},"vision":false},{"id":"qwen2.5-72b-instruct","name":"qwen2.5-72b","display_name":"qwen2.5-72b","type":"chat","context_length":0,"max_output_tokens":0,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"developer":"Qwen","developerId":13,"providerId":17,"modelRatio":0.4,"cacheRatio":1,"completionRatio":3,"order":0,"flag":0,"source":"public-provider-conf"},"vision":false},{"id":"qwen2.5-7b-instruct","name":"qwen2.5-7b","display_name":"qwen2.5-7b","type":"chat","context_length":0,"max_output_tokens":0,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"developer":"Qwen","developerId":13,"providerId":17,"modelRatio":0.2,"cacheRatio":1,"completionRatio":2,"order":0,"flag":0,"source":"public-provider-conf"},"vision":false},{"id":"qwen2.5-coder-1.5b-instruct","name":"qwen2.5-coder-1.5b","display_name":"qwen2.5-coder-1.5b","type":"chat","context_length":0,"max_output_tokens":0,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"developer":"Qwen","developerId":13,"providerId":17,"modelRatio":0.1,"cacheRatio":1,"completionRatio":2,"order":0,"flag":0,"source":"public-provider-conf"},"vision":false},{"id":"qwen2.5-coder-7b-instruct","name":"qwen2.5-coder-7b","display_name":"qwen2.5-coder-7b","type":"chat","context_length":0,"max_output_tokens":0,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"developer":"Qwen","developerId":13,"providerId":17,"modelRatio":0.1,"cacheRatio":1,"completionRatio":2,"order":0,"flag":0,"source":"public-provider-conf"},"vision":false},{"id":"qwen2.5-math-72b-instruct","name":"qwen2.5-math-72b","display_name":"qwen2.5-math-72b","type":"chat","context_length":0,"max_output_tokens":0,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"developer":"Qwen","developerId":13,"providerId":17,"modelRatio":0.4,"cacheRatio":1,"completionRatio":3,"order":0,"flag":0,"source":"public-provider-conf"},"vision":false},{"id":"qwen2.5-math-7b-instruct","name":"qwen2.5-math-7b","display_name":"qwen2.5-math-7b","type":"chat","context_length":0,"max_output_tokens":0,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"developer":"Qwen","developerId":13,"providerId":17,"modelRatio":0.1,"cacheRatio":1,"completionRatio":2,"order":0,"flag":0,"source":"public-provider-conf"},"vision":false},{"id":"qwen2.5-vl-72b-instruct","name":"qwen2.5-vl-72b","display_name":"qwen2.5-vl-72b","type":"chat","context_length":0,"max_output_tokens":0,"capabilities":{"vision":true,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"modalities":{"input":["text","image"],"output":["text","image"]},"metadata":{"developer":"Qwen","developerId":13,"providerId":17,"modelRatio":1.2,"cacheRatio":1,"completionRatio":3,"description":"中文领域识别能力强劲，不输 ChatGPT 4o","descriptionEn":"Strong capability in Chinese domain recognition, comparable to ChatGPT-4.0.","order":100,"flag":1,"tags":["multi_modal"],"modalities":["text","image"],"typeHints":["t2t"],"source":"public-provider-conf"},"vision":true},{"id":"qwen3-0.6b","name":"qwen3-0.6b","display_name":"qwen3-0.6b","type":"chat","context_length":0,"max_output_tokens":0,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"developer":"Qwen","developerId":13,"providerId":17,"modelRatio":0.023,"cacheRatio":0,"completionRatio":10,"description":"实现思考模式和非思考模式的有效融合，可在对话中切换模式。通用能力显著超过Qwen2.5小规模系列。","descriptionEn":"Effectively integrates thinking and non-thinking modes, allowing mode switching during conversations. Its general capabilities significantly surpass those of the Qwen2.5 small-scale series.","order":41,"flag":1,"typeHints":["t2t"],"source":"public-provider-conf"},"vision":false},{"id":"qwen3-1.7b","name":"qwen3-1.7b","display_name":"qwen3-1.7b","type":"chat","context_length":0,"max_output_tokens":0,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"developer":"Qwen","developerId":13,"providerId":17,"modelRatio":0.023,"cacheRatio":0,"completionRatio":10,"description":"实现思考模式和非思考模式的有效融合，可在对话中切换模式。通用能力显著超过Qwen2.5小规模系列，模型人类偏好能力显著增强，创意写作、角色扮演、多轮对话、指令遵循能力均有明显提升，用户体验预期明显更佳。","descriptionEn":"Effectively integrates thinking and non-thinking modes, allowing mode switching during conversations. Its general capabilities significantly surpass those of the Qwen2.5 small-scale series, with greatly enhanced human preference alignment. There are notable improvements in creative writing, role-playing, multi-turn dialogue, and instruction following, resulting in a significantly better expected user experience.","order":42,"flag":1,"typeHints":["t2t"],"source":"public-provider-conf"},"vision":false},{"id":"qwen3-14b","name":"qwen3-14b","display_name":"qwen3-14b","type":"chat","context_length":0,"max_output_tokens":0,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"developer":"Qwen","developerId":13,"providerId":17,"modelRatio":0.08,"cacheRatio":0,"completionRatio":10,"description":"实现思考模式和非思考模式的有效融合，可在对话中切换模式。推理能力达到同规模业界SOTA水平、通用能力显著超过Qwen2.5-14B。","descriptionEn":"Achieves effective integration of thinking and non-thinking modes, enabling mode switching during conversations. Its reasoning ability reaches state-of-the-art (SOTA) levels among models of the same scale, and its general capability significantly surpasses Qwen2.5-14B.","order":45,"flag":1,"typeHints":["t2t"],"source":"public-provider-conf"},"vision":false},{"id":"qwen3-235b-a22b","name":"qwen3-235b-a22b","display_name":"qwen3-235b-a22b","type":"chat","context_length":0,"max_output_tokens":0,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"developer":"Qwen","developerId":13,"providerId":17,"modelRatio":0.16,"cacheRatio":0,"completionRatio":10,"description":"实现思考模式和非思考模式的有效融合，可在对话中切换模式。推理能力显著超过QwQ、通用能力显著超过Qwen2.5-72B-Instruct，达到同规模业界SOTA水平。","descriptionEn":"Achieves effective integration of thinking and non-thinking modes, allowing mode switching during conversations. Its reasoning ability significantly surpasses QwQ, and its general capability notably exceeds Qwen2.5-72B-Instruct, reaching SOTA (state-of-the-art) levels among industry models of the same scale.","order":48,"flag":1,"typeHints":["t2t"],"source":"public-provider-conf"},"vision":false},{"id":"qwen3-235b-a22b-instruct-2507","name":"qwen3-235b-a22b-instruct-2507","display_name":"qwen3-235b-a22b-instruct-2507","type":"chat","context_length":0,"max_output_tokens":0,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"developer":"Qwen","developerId":13,"providerId":17,"modelRatio":0.14,"cacheRatio":1,"completionRatio":4,"order":200,"flag":0,"source":"public-provider-conf"},"vision":false},{"id":"qwen3-235b-a22b-thinking-2507","name":"qwen3-235b-a22b-thinking-2507","display_name":"qwen3-235b-a22b-thinking-2507","type":"chat","context_length":0,"max_output_tokens":0,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"developer":"Qwen","developerId":13,"providerId":17,"modelRatio":0.14,"cacheRatio":1,"completionRatio":10,"description":"基于Qwen3的思考模式开源模型，相较上一版本（通义千问3-235B-A22B）逻辑能力、通用能力、知识增强及创作能力均有大幅提升，适用于高难度强推理场景。","descriptionEn":"The open-source thinking model based on Qwen3 has significantly improved in logical ability, general capability, knowledge enhancement, and creative ability compared to the previous version (Tongyi Qianwen 3-235B-A22B). It is suitable for high-difficulty and strong reasoning scenarios.","order":704,"flag":0,"source":"public-provider-conf"},"vision":false},{"id":"qwen3-30b-a3b","name":"qwen3-30b-a3b","display_name":"qwen3-30b-a3b","type":"chat","context_length":0,"max_output_tokens":0,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"developer":"Qwen","developerId":13,"providerId":17,"modelRatio":0.06,"cacheRatio":0,"completionRatio":10,"description":"实现思考模式和非思考模式的有效融合，可在对话中切换模式。推理能力以更小参数规模比肩QwQ-32B、通用能力显著超过Qwen2.5-14B，达到同规模业界SOTA水平。","descriptionEn":"Achieves effective integration of thinking and non-thinking modes, allowing mode switching during conversations. Its reasoning ability matches that of QwQ-32B with a smaller parameter size, and its general capability significantly surpasses Qwen2.5-14B, reaching state-of-the-art (SOTA) levels among industry models of the same scale.","order":47,"flag":1,"typeHints":["t2t"],"source":"public-provider-conf"},"vision":false},{"id":"qwen3-30b-a3b-instruct-2507","name":"qwen3-30b-a3b-instruct-2507","display_name":"qwen3-30b-a3b-instruct-2507","type":"chat","context_length":0,"max_output_tokens":0,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"developer":"Qwen","developerId":13,"providerId":17,"modelRatio":0.06,"cacheRatio":1,"completionRatio":4,"description":"非思考版\n在推理任务上显著提高了性能，包括逻辑推理、数学、科学、编码以及通常需要人类专业知识的学术基准。  \n明显改善了一般能力，例如遵循指令、工具使用、文本生成和与人类偏好的对齐。  \n增强了256K长上下文理解能力。","descriptionEn":"Significantly improved performance on reasoning tasks, including logical reasoning, mathematics, science, coding, and academic benchmarks that typically require human expertise.\nMarkedly better general capabilities, such as instruction following, tool usage, text generation, and alignment with human preferences.\nEnhanced 256K long-context understanding capabilities.","order":402,"flag":1,"source":"public-provider-conf"},"vision":false},{"id":"qwen3-30b-a3b-thinking-2507","name":"qwen3-30b-a3b-thinking-2507","display_name":"qwen3-30b-a3b-thinking-2507","type":"chat","context_length":0,"max_output_tokens":0,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"developer":"Qwen","developerId":13,"providerId":17,"modelRatio":0.06,"cacheRatio":1,"completionRatio":10,"description":"在推理任务上显著提高了性能，包括逻辑推理、数学、科学、编码以及通常需要人类专业知识的学术基准。  \n明显改善了一般能力，例如遵循指令、工具使用、文本生成和与人类偏好的对齐。  \n增强了256K长上下文理解能力。","descriptionEn":"Significantly improved performance on reasoning tasks, including logical reasoning, mathematics, science, coding, and academic benchmarks that typically require human expertise.\nMarkedly better general capabilities, such as instruction following, tool usage, text generation, and alignment with human preferences.\nEnhanced 256K long-context understanding capabilities.","order":401,"flag":1,"source":"public-provider-conf"},"vision":false},{"id":"qwen3-32b","name":"qwen3-32b","display_name":"qwen3-32b","type":"chat","context_length":0,"max_output_tokens":0,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"developer":"Qwen","developerId":13,"providerId":17,"modelRatio":0.16,"cacheRatio":0,"completionRatio":10,"description":"实现思考模式和非思考模式的有效融合，可在对话中切换模式。推理能力显著超过QwQ、通用能力显著超过Qwen2.5-32B-Instruct，达到同规模业界SOTA水平。","descriptionEn":"Achieves effective integration of thinking and non-thinking modes, allowing mode switching during conversations. Its reasoning ability significantly surpasses QwQ, and its general capability significantly exceeds Qwen2.5-32B-Instruct, reaching state-of-the-art (SOTA) levels among industry models of the same scale.","order":46,"flag":1,"typeHints":["t2t"],"source":"public-provider-conf"},"vision":false},{"id":"qwen3-4b","name":"qwen3-4b","display_name":"qwen3-4b","type":"chat","context_length":0,"max_output_tokens":0,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"developer":"Qwen","developerId":13,"providerId":17,"modelRatio":0.023,"cacheRatio":0,"completionRatio":10,"description":"实现思考模式和非思考模式的有效融合，可在对话中切换模式。推理能力达到同规模业界SOTA水平、模型人类偏好能力显著增强，创意写作、角色扮演、多轮对话、指令遵循能力均有明显提升，用户体验预期明显更佳。","descriptionEn":"Achieves effective integration of thinking and non-thinking modes, allowing mode switching during conversations. Its reasoning ability reaches state-of-the-art (SOTA) levels among models of the same scale, with significantly enhanced human preference alignment. There are notable improvements in creative writing, role-playing, multi-turn dialogue, and instruction following, resulting in a noticeably better user experience.","order":43,"flag":1,"typeHints":["t2t"],"source":"public-provider-conf"},"vision":false},{"id":"qwen3-8b","name":"qwen3-8b","display_name":"qwen3-8b","type":"chat","context_length":0,"max_output_tokens":0,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"developer":"Qwen","developerId":13,"providerId":17,"modelRatio":0.04,"cacheRatio":0,"completionRatio":10,"description":"实现思考模式和非思考模式的有效融合，可在对话中切换模式。推理能力达到同规模业界SOTA水平、通用能力显著超过Qwen2.5-7B。","descriptionEn":"Achieves effective integration of thinking and non-thinking modes, enabling mode switching during conversations. Its reasoning ability reaches state-of-the-art (SOTA) levels among models of the same scale, and its general capability significantly surpasses Qwen2.5-7B.","order":44,"flag":1,"typeHints":["t2t"],"source":"public-provider-conf"},"vision":false},{"id":"qwen3-coder-30b-a3b-instruct","name":"qwen3-coder-30b-a3b-instruct","display_name":"qwen3-coder-30b-a3b-instruct","type":"chat","context_length":0,"max_output_tokens":0,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"developer":"Qwen","developerId":13,"providerId":17,"modelRatio":0.1,"cacheRatio":1,"completionRatio":4,"description":"基于Qwen3的代码生成模型，具有强大的Coding Agent能力，代码能力达到开源模型 SOTA。\n该模型采用阶梯计费。","descriptionEn":"The code generation model based on Qwen3 has powerful Coding Agent capabilities, achieving state-of-the-art performance compared to open-source models.The model adopts tiered pricing.","order":702,"flag":0,"billingConfig":"{\"model_name\": \"qwen3-coder-30b-a3b-instruct\", \"default_tier\": \"tier1\", \"enabled_billing_items\": [\"prompt_tokens\", \"completion_tokens\", \"cached_tokens\"], \"token_based_tier_configs\": {\"tier1\": {\"model_ratio\": 0.102739, \"tier_condition\": {\"max_tokens\": 32000, \"min_tokens\": 0}, \"prompt_tokens_ratio\": 1.0, \"completion_tokens_ratio\": 4.0}, \"tier2\": {\"model_ratio\": 0.154109, \"tier_condition\": {\"max_tokens\": 128000, \"min_tokens\": 32001}, \"prompt_tokens_ratio\": 1.0, \"completion_tokens_ratio\": 4.0}, \"tier3\": {\"model_ratio\": 0.513698, \"tier_condition\": {\"max_tokens\": 200000, \"min_tokens\": 128001}, \"prompt_tokens_ratio\": 1.0, \"completion_tokens_ratio\": 5.0}}}","source":"public-provider-conf"},"vision":false},{"id":"qwen3-coder-480b-a35b-instruct","name":"qwen3-coder-480b-a35b-instruct","display_name":"qwen3-coder-480b-a35b-instruct","type":"chat","context_length":0,"max_output_tokens":0,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"developer":"Qwen","developerId":13,"providerId":17,"modelRatio":0.41,"cacheRatio":1,"completionRatio":4,"description":"基于Qwen3的代码生成模型，具有强大的Coding Agent能力，代码能力达到开源模型 SOTA。\n该模型采用阶梯计费。","descriptionEn":"The code generation model based on Qwen3 has powerful Coding Agent capabilities, achieving state-of-the-art performance compared to open-source models.The model adopts tiered pricing.","order":702,"flag":1,"billingConfig":"{\"model_name\": \"qwen3-coder-480b-a35b-instruct\", \"default_tier\": \"tier1\", \"enabled_billing_items\": [\"prompt_tokens\", \"completion_tokens\", \"cached_tokens\"], \"token_based_tier_configs\": {\"tier1\": {\"model_ratio\": 0.410958, \"tier_condition\": {\"max_tokens\": 32000, \"min_tokens\": 0}, \"prompt_tokens_ratio\": 1.0, \"completion_tokens_ratio\": 4.0}, \"tier2\": {\"model_ratio\": 0.616438, \"tier_condition\": {\"max_tokens\": 128000, \"min_tokens\": 32001}, \"prompt_tokens_ratio\": 1.0, \"completion_tokens_ratio\": 4.0}, \"tier3\": {\"model_ratio\": 1.027397, \"tier_condition\": {\"max_tokens\": 200000, \"min_tokens\": 128001}, \"prompt_tokens_ratio\": 1.0, \"completion_tokens_ratio\": 4.0}}}","source":"public-provider-conf"},"vision":false},{"id":"qwen3-coder-flash","name":"qwen3-coder-flash","display_name":"qwen3-coder-flash","type":"chat","context_length":0,"max_output_tokens":0,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"developer":"Qwen","developerId":13,"providerId":17,"modelRatio":0.068,"cacheRatio":1,"completionRatio":4,"order":0,"flag":1,"billingConfig":"{\"model_name\": \"qwen3-coder-flash\", \"default_tier\": \"tier1\", \"enabled_billing_items\": [\"prompt_tokens\", \"completion_tokens\", \"cached_tokens\"], \"token_based_tier_configs\": {\"tier1\": {\"model_ratio\": 0.068493, \"tier_condition\": {\"max_tokens\": 32000, \"min_tokens\": 0}, \"prompt_tokens_ratio\": 1.0, \"completion_tokens_ratio\": 4.0}, \"tier2\": {\"model_ratio\": 0.102739, \"tier_condition\": {\"max_tokens\": 128000, \"min_tokens\": 32001}, \"prompt_tokens_ratio\": 1.0, \"completion_tokens_ratio\": 4.0}, \"tier3\": {\"model_ratio\": 0.171232, \"tier_condition\": {\"max_tokens\": 256000, \"min_tokens\": 128001}, \"prompt_tokens_ratio\": 1.0, \"completion_tokens_ratio\": 4.0}, \"tier4\": {\"model_ratio\": 0.342465, \"tier_condition\": {\"max_tokens\": 1000000, \"min_tokens\": 256001}, \"prompt_tokens_ratio\": 1.0, \"completion_tokens_ratio\": 5.0}}}","source":"public-provider-conf"},"vision":false},{"id":"qwen3-coder-flash-2025-07-28","name":"qwen3-coder-flash-2025-07-28","display_name":"qwen3-coder-flash-2025-07-28","type":"chat","context_length":0,"max_output_tokens":0,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"developer":"Qwen","developerId":13,"providerId":17,"modelRatio":0.068,"cacheRatio":1,"completionRatio":4,"order":0,"flag":0,"billingConfig":"{\"model_name\": \"qwen3-coder-flash-2025-07-28\", \"default_tier\": \"tier1\", \"enabled_billing_items\": [\"prompt_tokens\", \"completion_tokens\", \"cached_tokens\"], \"token_based_tier_configs\": {\"tier1\": {\"model_ratio\": 0.068493, \"tier_condition\": {\"max_tokens\": 32000, \"min_tokens\": 0}, \"prompt_tokens_ratio\": 1.0, \"completion_tokens_ratio\": 4.0}, \"tier2\": {\"model_ratio\": 0.102739, \"tier_condition\": {\"max_tokens\": 128000, \"min_tokens\": 32001}, \"prompt_tokens_ratio\": 1.0, \"completion_tokens_ratio\": 4.0}, \"tier3\": {\"model_ratio\": 0.171232, \"tier_condition\": {\"max_tokens\": 256000, \"min_tokens\": 128001}, \"prompt_tokens_ratio\": 1.0, \"completion_tokens_ratio\": 4.0}, \"tier4\": {\"model_ratio\": 0.342465, \"tier_condition\": {\"max_tokens\": 1000000, \"min_tokens\": 256001}, \"prompt_tokens_ratio\": 1.0, \"completion_tokens_ratio\": 5.0}}}","source":"public-provider-conf"},"vision":false},{"id":"qwen3-coder-plus","name":"qwen3-coder-plus","display_name":"qwen3-coder-plus","type":"chat","context_length":0,"max_output_tokens":0,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"developer":"Qwen","developerId":13,"providerId":17,"modelRatio":0.27,"cacheRatio":0.2,"completionRatio":4,"description":"基于Qwen3的代码生成模型，具有强大的Coding Agent能力，擅长工具调用和环境交互，能够实现自主编程、代码能力卓越的同时兼具通用能力。该模型采取阶梯计费。","descriptionEn":"The code generation model based on Qwen3 has powerful Coding Agent capabilities, excels in tool invocation and environment interaction, and can achieve autonomous programming with outstanding coding abilities while also possessing general capabilities.The model adopts tiered pricing.","order":700,"flag":0,"billingConfig":"{\"model_name\": \"qwen3-coder-plus\", \"default_tier\": \"tier1\", \"enabled_billing_items\": [\"prompt_tokens\", \"completion_tokens\", \"cached_tokens\"], \"token_based_tier_configs\": {\"tier1\": {\"model_ratio\": 0.273972, \"tier_condition\": {\"max_tokens\": 32000, \"min_tokens\": 0}, \"prompt_tokens_ratio\": 1.0, \"completion_tokens_ratio\": 4.0}, \"tier2\": {\"model_ratio\": 0.410958, \"tier_condition\": {\"max_tokens\": 128000, \"min_tokens\": 32001}, \"prompt_tokens_ratio\": 1.0, \"completion_tokens_ratio\": 4.0}, \"tier3\": {\"model_ratio\": 0.684931, \"tier_condition\": {\"max_tokens\": 256000, \"min_tokens\": 128001}, \"prompt_tokens_ratio\": 1.0, \"completion_tokens_ratio\": 4.0}, \"tier4\": {\"model_ratio\": 1.369863, \"tier_condition\": {\"max_tokens\": 1000000, \"min_tokens\": 256001}, \"prompt_tokens_ratio\": 1.0, \"completion_tokens_ratio\": 10.0}}}","source":"public-provider-conf"},"vision":false},{"id":"qwen3-coder-plus-2025-07-22","name":"qwen3-coder-plus-2025-07-22","display_name":"qwen3-coder-plus-2025-07-22","type":"chat","context_length":0,"max_output_tokens":0,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"developer":"Qwen","developerId":13,"providerId":17,"modelRatio":0.27,"cacheRatio":1,"completionRatio":4,"description":"基于Qwen3的代码生成模型，具有强大的Coding Agent能力，擅长工具调用和环境交互，能够实现自主编程、代码能力卓越的同时兼具通用能力。该模型采取阶梯计费。","descriptionEn":"The code generation model based on Qwen3 has powerful Coding Agent capabilities, excels in tool invocation and environment interaction, and can achieve autonomous programming with outstanding coding abilities while also possessing general capabilities.The model adopts tiered pricing.","order":700,"flag":1,"billingConfig":"{\"model_name\": \"qwen3-coder-plus-2025-07-22\", \"default_tier\": \"tier1\", \"enabled_billing_items\": [\"prompt_tokens\", \"completion_tokens\", \"cached_tokens\"], \"token_based_tier_configs\": {\"tier1\": {\"model_ratio\": 0.273972, \"tier_condition\": {\"max_tokens\": 32000, \"min_tokens\": 0}, \"prompt_tokens_ratio\": 1.0, \"completion_tokens_ratio\": 4.0}, \"tier2\": {\"model_ratio\": 0.410958, \"tier_condition\": {\"max_tokens\": 128000, \"min_tokens\": 32001}, \"prompt_tokens_ratio\": 1.0, \"completion_tokens_ratio\": 4.0}, \"tier3\": {\"model_ratio\": 0.684931, \"tier_condition\": {\"max_tokens\": 256000, \"min_tokens\": 128001}, \"prompt_tokens_ratio\": 1.0, \"completion_tokens_ratio\": 4.0}, \"tier4\": {\"model_ratio\": 1.369863, \"tier_condition\": {\"max_tokens\": 1000000, \"min_tokens\": 256001}, \"prompt_tokens_ratio\": 1.0, \"completion_tokens_ratio\": 10.0}}}","source":"public-provider-conf"},"vision":false},{"id":"qwen3-embedding-0.6b","name":"qwen3-embedding-0.6b","display_name":"qwen3-embedding-0.6b","type":"embedding","context_length":0,"max_output_tokens":0,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"developer":"Qwen","developerId":13,"providerId":15,"modelRatio":0.034,"cacheRatio":1,"completionRatio":1,"description":"Qwen3 Embedding 模型系列是 Qwen 家族的最新专有模型，专门设计用于文本嵌入和排序任务。基于 Qwen3 系列的密集基础模型，它提供了各种大小（0.6B、4B 和 8B）的全面文本嵌入和重排序模型。该系列继承了其基础模型卓越的多语言能力、长文本理解和推理技能。Qwen3 Embedding 系列表现出了在多种文本嵌入和排序任务中的显著进步，包括文本检索、代码检索、文本分类、文本聚类和双语文本挖掘。","descriptionEn":"The Qwen3 Embedding model series is the latest proprietary model family from Qwen, specifically designed for text embedding and ranking tasks. Based on the dense base models of the Qwen3 series, it offers comprehensive text embedding and reranking models in various sizes (0.6B, 4B, and 8B). This series inherits the excellent multilingual capabilities, long-text understanding, and reasoning skills of its base models. The Qwen3 Embedding series demonstrates significant advancements in various text embedding and ranking tasks, including text retrieval, code retrieval, text classification, text clustering, and bilingual text mining.","order":600,"flag":0,"typeHints":["embedding"],"source":"public-provider-conf"},"vision":false},{"id":"qwen3-embedding-4b","name":"qwen3-embedding-4b","display_name":"qwen3-embedding-4b","type":"embedding","context_length":0,"max_output_tokens":0,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"developer":"Qwen","developerId":13,"providerId":15,"modelRatio":0.034,"cacheRatio":1,"completionRatio":1,"description":"Qwen3 Embedding 模型系列是 Qwen 家族的最新专有模型，专门设计用于文本嵌入和排序任务。基于 Qwen3 系列的密集基础模型，它提供了各种大小（0.6B、4B 和 8B）的全面文本嵌入和重排序模型。该系列继承了其基础模型卓越的多语言能力、长文本理解和推理技能。Qwen3 Embedding 系列表现出了在多种文本嵌入和排序任务中的显著进步，包括文本检索、代码检索、文本分类、文本聚类和双语文本挖掘。\n","descriptionEn":"The Qwen3 Embedding model series is the latest proprietary model family from Qwen, specifically designed for text embedding and ranking tasks. Based on the dense base models of the Qwen3 series, it offers comprehensive text embedding and reranking models in various sizes (0.6B, 4B, and 8B). This series inherits the excellent multilingual capabilities, long-text understanding, and reasoning skills of its base models. The Qwen3 Embedding series demonstrates significant advancements in various text embedding and ranking tasks, including text retrieval, code retrieval, text classification, text clustering, and bilingual text mining.","order":600,"flag":0,"typeHints":["embedding"],"source":"public-provider-conf"},"vision":false},{"id":"qwen3-embedding-8b","name":"qwen3-embedding-8b","display_name":"qwen3-embedding-8b","type":"embedding","context_length":0,"max_output_tokens":0,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"developer":"Qwen","developerId":13,"providerId":15,"modelRatio":0.034,"cacheRatio":1,"completionRatio":1,"description":"Qwen3 Embedding 模型系列是 Qwen 家族的最新专有模型，专门设计用于文本嵌入和排序任务。基于 Qwen3 系列的密集基础模型，它提供了各种大小（0.6B、4B 和 8B）的全面文本嵌入和重排序模型。该系列继承了其基础模型卓越的多语言能力、长文本理解和推理技能。Qwen3 Embedding 系列表现出了在多种文本嵌入和排序任务中的显著进步，包括文本检索、代码检索、文本分类、文本聚类和双语文本挖掘。\n","descriptionEn":"The Qwen3 Embedding model series is the latest proprietary model family from Qwen, specifically designed for text embedding and ranking tasks. Based on the dense base models of the Qwen3 series, it offers comprehensive text embedding and reranking models in various sizes (0.6B, 4B, and 8B). This series inherits the excellent multilingual capabilities, long-text understanding, and reasoning skills of its base models. The Qwen3 Embedding series demonstrates significant advancements in various text embedding and ranking tasks, including text retrieval, code retrieval, text classification, text clustering, and bilingual text mining.","order":600,"flag":0,"typeHints":["embedding"],"source":"public-provider-conf"},"vision":false},{"id":"qwen3-max","name":"qwen3-max","display_name":"qwen3-max","type":"chat","context_length":0,"max_output_tokens":0,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"developer":"Qwen","developerId":13,"providerId":17,"modelRatio":0.411,"cacheRatio":0.2,"completionRatio":4,"description":"通义千问3系列Max模型，相较preview版本在智能体编程与工具调用方向进行了专项升级。本次发布的正式版模型达到领域SOTA水平，适配场景更加复杂的智能体需求。","descriptionEn":"The Tongyi Qianwen 3 series Max model has undergone special upgrades in intelligent agent programming and tool invocation compared to the preview version. The officially released model this time reaches SOTA level in the field and is adapted to more complex intelligent agent scenarios.","order":800,"flag":1,"billingConfig":"{\n  \"model_name\": \"qwen3-max\",\n  \"default_tier\": \"tier1\",\n  \"token_based_tier_configs\": {\n    \"tier1\": {\n      \"tier_condition\": {\n        \"min_tokens\": 0,\n        \"max_tokens\": 32000\n      },\n      \"model_ratio\": 0.410958,\n      \"prompt_tokens_ratio\": 1.0,\n      \"completion_tokens_ratio\": 4.0,\n      \"cached_tokens_ratio\": 0.2\n    },\n    \"tier2\": {\n      \"tier_condition\": {\n        \"min_tokens\": 32001,\n        \"max_tokens\": 128000\n      },\n      \"model_ratio\": 0.684931,\n      \"prompt_tokens_ratio\": 1.0,\n      \"completion_tokens_ratio\": 4.0,\n      \"cached_tokens_ratio\": 0.2\n    },\n    \"tier3\": {\n      \"tier_condition\": {\n        \"min_tokens\": 128001,\n        \"max_tokens\": 256000\n      },\n      \"model_ratio\": 1.027397,\n      \"prompt_tokens_ratio\": 1.0,\n      \"completion_tokens_ratio\": 4.0,\n      \"cached_tokens_ratio\": 0.2\n    }\n  },\n  \"enabled_billing_items\": [\n    \"prompt_tokens\",\n    \"completion_tokens\",\n    \"cached_tokens\"\n  ]\n}","source":"public-provider-conf"},"vision":false},{"id":"qwen3-max-preview","name":"qwen3-max-preview","display_name":"qwen3-max-preview","type":"chat","context_length":0,"max_output_tokens":0,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"developer":"Qwen","developerId":13,"providerId":17,"modelRatio":0.411,"cacheRatio":1,"completionRatio":4,"description":"最新的qwen3-max-preview模型：Qwen3 系列Max模型Preview版本，相较Qwen 2.5系列整体通用能力有大幅度提升，中英文通用文本理解能力、复杂指令遵循能力、主观开放任务能力、多语言能力、工具调用能力均显著增强；模型知识幻觉更少。","descriptionEn":"The latest qwen3-max-preview model is the preview version of the Qwen3 series Max model. Compared to the Qwen 2.5 series, it features significant improvements in overall general capabilities, including enhanced bilingual (Chinese and English) text comprehension, complex instruction following, subjective open-task performance, multilingual abilities, and tool usage. Additionally, the model exhibits reduced knowledge hallucination.","order":705,"flag":1,"billingConfig":"{\n  \"model_name\": \"qwen3-max-preview\",\n  \"default_tier\": \"tier1\",\n  \"token_based_tier_configs\": {\n    \"tier1\": {\n      \"tier_condition\": {\n        \"min_tokens\": 0,\n        \"max_tokens\": 32000\n      },\n      \"model_ratio\": 0.410959,\n      \"prompt_tokens_ratio\": 1.0,\n      \"completion_tokens_ratio\": 4.0\n    },\n    \"tier2\": {\n      \"tier_condition\": {\n        \"min_tokens\": 32001,\n        \"max_tokens\": 128000\n      },\n      \"model_ratio\": 0.684932,\n      \"prompt_tokens_ratio\": 1.0,\n      \"completion_tokens_ratio\": 4.0\n    },\n    \"tier3\": {\n      \"tier_condition\": {\n        \"min_tokens\": 128001,\n        \"max_tokens\": 2520000\n      },\n      \"model_ratio\": 1.027397,\n      \"prompt_tokens_ratio\": 1.0,\n      \"completion_tokens_ratio\": 4.0\n    }\n  },\n  \"enabled_billing_items\": [\n    \"prompt_tokens\",\n    \"completion_tokens\",\n    \"cached_tokens\"\n  ]\n}","source":"public-provider-conf"},"vision":false},{"id":"qwen3-vl-235b-a22b-instruct","name":"qwen3-vl-235b-a22b-instruct","display_name":"qwen3-vl-235b-a22b-instruct","type":"chat","context_length":0,"max_output_tokens":0,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"developer":"Qwen","developerId":13,"providerId":17,"modelRatio":0.137,"cacheRatio":1,"completionRatio":4,"description":"Qwen3系列开源模型，包含混合模型、思考模型与非思考模型，思考能力与通用能力均达到同规模业界SOTA水平。","descriptionEn":"The Qwen3 series open-source models include hybrid models, thinking models, and non-thinking models, with both reasoning capabilities and general abilities reaching industry SOTA levels at the same scale.","order":800,"flag":1,"source":"public-provider-conf"},"vision":false},{"id":"qwen3-vl-235b-a22b-thinking","name":"qwen3-vl-235b-a22b-thinking","display_name":"qwen3-vl-235b-a22b-thinking","type":"chat","context_length":0,"max_output_tokens":0,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"developer":"Qwen","developerId":13,"providerId":17,"modelRatio":0.137,"cacheRatio":1,"completionRatio":10,"description":"Qwen3系列开源模型，包含混合模型、思考模型与非思考模型，思考能力与通用能力均达到同规模业界SOTA水平。","descriptionEn":"The Qwen3 series open-source models include hybrid models, thinking models, and non-thinking models, with both reasoning capabilities and general abilities reaching industry SOTA levels at the same scale.","order":800,"flag":1,"source":"public-provider-conf"},"vision":false},{"id":"qwen3-vl-plus","name":"qwen3-vl-plus","display_name":"qwen3-vl-plus","type":"chat","context_length":0,"max_output_tokens":0,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"developer":"Qwen","developerId":13,"providerId":17,"modelRatio":0.0685,"cacheRatio":0.2,"completionRatio":10,"description":"Qwen3系列视觉理解模型，实现思考模式和非思考模式的有效融合，视觉智能体能力在OS World等公开测试集上达到世界顶尖水平。此版本在视觉coding、空间感知、多模态思考等方向全面升级；视觉感知与识别能力大幅提升，支持超长视频理解。","descriptionEn":"The Qwen3 series visual understanding model achieves an effective fusion of thinking and non-thinking modes. Its visual agent capabilities reach world-class levels on public test sets such as OS World. This version features comprehensive upgrades in visual coding, spatial perception, and multimodal reasoning; visual perception and recognition abilities are greatly enhanced, supporting ultra-long video understanding.","order":800,"flag":1,"billingConfig":"{\n  \"model_name\": \"qwen3-vl-plus\",\n  \"default_tier\": \"tier1\",\n  \"token_based_tier_configs\": {\n    \"tier1\": {\n      \"tier_condition\": {\n        \"min_tokens\": 0,\n        \"max_tokens\": 32000\n      },\n      \"model_ratio\": 0.068493,\n      \"prompt_tokens_ratio\": 1.0,\n      \"completion_tokens_ratio\": 10.0,\n      \"cached_tokens_ratio\": 0.2\n    },\n    \"tier2\": {\n      \"tier_condition\": {\n        \"min_tokens\": 32001,\n        \"max_tokens\": 128000\n      },\n      \"model_ratio\": 0.102739,\n      \"prompt_tokens_ratio\": 1.0,\n      \"completion_tokens_ratio\": 10.0,\n      \"cached_tokens_ratio\": 0.2\n    },\n    \"tier3\": {\n      \"tier_condition\": {\n        \"min_tokens\": 128001,\n        \"max_tokens\": 256000\n      },\n      \"model_ratio\": 0.205479,\n      \"prompt_tokens_ratio\": 1.0,\n      \"completion_tokens_ratio\": 10.0,\n      \"cached_tokens_ratio\": 0.2\n    }\n  },\n  \"enabled_billing_items\": [\n    \"prompt_tokens\",\n    \"completion_tokens\",\n    \"cached_tokens\"\n  ]\n}","source":"public-provider-conf"},"vision":false},{"id":"sora-2","name":"sora-2","display_name":"sora-2","type":"chat","context_length":0,"max_output_tokens":0,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"developer":"OpenAI","developerId":12,"providerId":1,"modelRatio":10,"cacheRatio":1,"completionRatio":1,"description":"该模型为逆向 OpenAI 网页版本sora-2非正规的 api，官方并未正式对外开放 api，仅供娱乐；无论生成失败还是成功都会被收费，按次收费；介意请勿使用；用 chat 接口即可使用","descriptionEn":"This model is an unofficial reverse-engineered API of the OpenAI web version sora-2. The official API has not been formally released to the public and is for entertainment purposes only; charges apply per request regardless of success or failure; please do not use if you mind this; it can be used via the chat interface.","order":900,"flag":1,"source":"public-provider-conf"},"vision":false},{"id":"step-2-16k","name":"step-2","display_name":"step-2","type":"chat","context_length":0,"max_output_tokens":0,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"developer":"阶跃星辰","developerId":16,"providerId":8,"modelRatio":1,"cacheRatio":1,"completionRatio":1,"order":0,"flag":0,"source":"public-provider-conf"},"vision":false},{"id":"stepfun-ai/step3","name":"stepfun-ai/step3","display_name":"stepfun-ai/step3","type":"chat","context_length":0,"max_output_tokens":0,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"developer":"StepFun","developerId":16,"providerId":8,"modelRatio":0.55,"cacheRatio":1,"completionRatio":2.5,"description":"Step3 是 StepFun 推出的多模态推理模型，采用 321 B 参数、38 B 激活的 MoE 架构。它采用端到端设计，降低解码成本，在视觉‑语言推理上提供顶级表现。通过多矩阵分解注意力（MFA）和注意力‑FFN 解耦（AFD），Step3 在高端和低端加速器上都保持高效。预训练阶段模型处理了 20 T 文本 token 和 4 T 图文混合 token，覆盖十余种语言。 在数学、代码和多模态等基准上，Step3 均领先于同类开源模型。","descriptionEn":"Step3 is a multimodal reasoning model released by StepFun. It uses a Mixture‑of‑Experts (MoE) architecture with 321 billion total parameters and 38 billion activation parameters. The model follows an end‑to‑end design that reduces decoding cost while delivering top‑tier performance on vision‑language reasoning tasks. Thanks to the combined use of Multi‑Head Factorized Attention (MFA) and Attention‑FFN Decoupling (AFD), Step3 remains highly efficient on both flagship and low‑end accelerators. During pre‑training, it processed over 20 trillion text tokens and 4 trillion image‑text mixed tokens, covering more than ten languages. On benchmarks for mathematics, code, and multimodal tasks, Step3 consistently outperforms other open‑source models.","order":50,"flag":1,"source":"public-provider-conf"},"vision":false},{"id":"tao-8k","name":"tao-8k","display_name":"tao-8k","type":"embedding","context_length":0,"max_output_tokens":0,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"developer":"Baidu","developerId":25,"providerId":15,"modelRatio":0.034,"cacheRatio":1,"completionRatio":1,"description":"tao-8k是由Huggingface开发者amu研发并开源的长文本向量表示模型，支持8k上下文长度，模型效果在C-MTEB上居前列，是当前最优的中文长文本embeddings模型之一。","order":600,"flag":0,"typeHints":["embedding"],"source":"public-provider-conf"},"vision":false},{"id":"tencent/Hunyuan-A13B-Instruct","name":"tencent/Hunyuan-A13B-Instruct","display_name":"tencent/Hunyuan-A13B-Instruct","type":"chat","context_length":0,"max_output_tokens":0,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"developer":"Hunyuan","developerId":24,"providerId":8,"modelRatio":0.07,"cacheRatio":1,"completionRatio":4,"description":"Hunyuan-A13B-Instruct 参数量800 亿，激活 130 亿参数即可对标更大模型，支持“快思考/慢思考”混合推理；长文理解稳定；经 BFCL-v3 与 τ-Bench 验证，Agent 能力领先；结合 GQA 与多量化格式，实现高效推理。","descriptionEn":"Hunyuan-A13B-Instruct has 8 billion parameters and can match larger models by activating only 1.3 billion parameters, supporting \"fast thinking/slow thinking\" hybrid inference. It offers stable long text understanding. Verified by BFCL-v3 and τ-Bench, its Agent capabilities are leading in the field. Combined with GQA and multiple quantization formats, it enables efficient inference.","order":100,"flag":1,"source":"public-provider-conf"},"vision":false},{"id":"tencent/Hunyuan-MT-7B","name":"tencent/Hunyuan-MT-7B","display_name":"tencent/Hunyuan-MT-7B","type":"chat","context_length":0,"max_output_tokens":0,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"developer":"Hunyuan","developerId":24,"providerId":23,"modelRatio":0.1,"cacheRatio":1,"completionRatio":1,"description":"Hunyuan-MT-7B 是一个拥有 70 亿参数的轻量级翻译模型，用于将源文本翻译成目标语言。该模型支持 33 种语言以及 5 种中国少数民族语言的互译。在 WMT25 国际机器翻译竞赛中，Hunyuan-MT-7B 在其参与的 31 个语言类别中获得了 30 个第一名，展现了其卓越的翻译能力。针对翻译场景，腾讯混元提出了一个从预训练到监督微调、再到翻译强化和集成强化的完整训练范式，使其在同等规模的模型中达到了业界领先的性能。该模型计算效率高、易于部署，适合多种应用场景。","descriptionEn":"Hunyuan-MT-7B is a lightweight translation model with 7 billion parameters, designed to translate source text into target languages. The model supports translation among 33 languages as well as 5 Chinese minority languages. In the WMT25 International Machine Translation Competition, Hunyuan-MT-7B achieved first place in 30 out of 31 language categories it participated in, demonstrating its exceptional translation capabilities. For translation scenarios, Tencent Hunyuan proposed a complete training paradigm from pre-training to supervised fine-tuning, followed by translation reinforcement and ensemble reinforcement, enabling it to achieve industry-leading performance among models of similar scale. The model is computationally efficient, easy to deploy, and suitable for various application scenarios.","order":90,"flag":0,"source":"public-provider-conf"},"vision":false},{"id":"text-ada-001","name":"text-ada-001","display_name":"text-ada-001","type":"chat","context_length":0,"max_output_tokens":0,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"developer":"OpenAI","developerId":12,"providerId":1,"modelRatio":0.2,"cacheRatio":1,"completionRatio":1,"order":0,"flag":0,"source":"public-provider-conf"},"vision":false},{"id":"text-babbage-001","name":"text-babbage-001","display_name":"text-babbage-001","type":"chat","context_length":0,"max_output_tokens":0,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"developer":"OpenAI","developerId":12,"providerId":1,"modelRatio":0.25,"cacheRatio":1,"completionRatio":1,"order":0,"flag":0,"source":"public-provider-conf"},"vision":false},{"id":"text-davinci-002","name":"text-davinci","display_name":"text-davinci","type":"chat","context_length":0,"max_output_tokens":0,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"developer":"OpenAI","developerId":12,"providerId":1,"modelRatio":10,"cacheRatio":1,"completionRatio":1,"order":0,"flag":0,"source":"public-provider-conf"},"vision":false},{"id":"text-davinci-003","name":"text-davinci","display_name":"text-davinci","type":"chat","context_length":0,"max_output_tokens":0,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"developer":"OpenAI","developerId":12,"providerId":1,"modelRatio":10,"cacheRatio":1,"completionRatio":1,"order":0,"flag":0,"source":"public-provider-conf"},"vision":false},{"id":"text-davinci-edit-001","name":"text-davinci-edit-001","display_name":"text-davinci-edit-001","type":"chat","context_length":0,"max_output_tokens":0,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"developer":"OpenAI","developerId":12,"providerId":1,"modelRatio":10,"cacheRatio":1,"completionRatio":1,"order":0,"flag":0,"source":"public-provider-conf"},"vision":false},{"id":"text-embedding-004","name":"text-embedding-004","display_name":"text-embedding-004","type":"chat","context_length":0,"max_output_tokens":0,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"developer":"Google","developerId":8,"providerId":24,"modelRatio":0.01,"cacheRatio":1,"completionRatio":1,"order":34,"flag":1,"source":"public-provider-conf"},"vision":false},{"id":"text-embedding-3-large","name":"text-embedding-3-large","display_name":"text-embedding-3-large","type":"embedding","context_length":0,"max_output_tokens":0,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"modalities":{"input":["text"],"output":["text"]},"metadata":{"developer":"OpenAI","developerId":12,"providerId":1,"modelRatio":0.065,"cacheRatio":1,"completionRatio":1,"order":0,"flag":0,"modalities":["text"],"typeHints":["embedding"],"source":"public-provider-conf"},"vision":false},{"id":"text-embedding-3-small","name":"text-embedding-3-small","display_name":"text-embedding-3-small","type":"embedding","context_length":0,"max_output_tokens":0,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"modalities":{"input":["text"],"output":["text"]},"metadata":{"developer":"OpenAI","developerId":12,"providerId":1,"modelRatio":0.01,"cacheRatio":1,"completionRatio":1,"order":0,"flag":0,"modalities":["text"],"typeHints":["embedding"],"source":"public-provider-conf"},"vision":false},{"id":"text-embedding-ada-002","name":"text-embedding-ada-002","display_name":"text-embedding-ada-002","type":"embedding","context_length":0,"max_output_tokens":0,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"modalities":{"input":["text"],"output":["text"]},"metadata":{"developer":"OpenAI","developerId":12,"providerId":1,"modelRatio":0.05,"cacheRatio":1,"completionRatio":1,"order":0,"flag":0,"modalities":["text"],"typeHints":["embedding"],"source":"public-provider-conf"},"vision":false},{"id":"text-embedding-v4","name":"text-embedding-v4","display_name":"text-embedding-v4","type":"embedding","context_length":0,"max_output_tokens":0,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"developer":"Qwen","developerId":13,"providerId":17,"modelRatio":0.04,"cacheRatio":1,"completionRatio":1,"description":"是通义实验室基于Qwen3训练的多语言文本统一向量模型，相较V3版本在文本检索、聚类、分类性能大幅提升；在MTEB多语言、中英、Code检索等评测任务上效果提升15%~40%；支持64~2048维用户自定义向量维度。","descriptionEn":"This is the Tongyi Laboratory's multilingual unified text vector model trained based on Qwen3, which significantly improves performance in text retrieval, clustering, and classification compared to version V3; it achieves a 15% to 40% improvement on evaluation tasks such as MTEB multilingual, Chinese-English, and code retrieval; supports user-defined vector dimensions ranging from 64 to 2048.","order":50,"flag":1,"typeHints":["embedding"],"source":"public-provider-conf"},"vision":false},{"id":"text-moderation-stable","name":"text-moderation","display_name":"text-moderation","type":"chat","context_length":0,"max_output_tokens":0,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"developer":"OpenAI","developerId":12,"providerId":1,"modelRatio":0.1,"cacheRatio":1,"completionRatio":1,"order":0,"flag":0,"source":"public-provider-conf"},"vision":false},{"id":"tngtech/DeepSeek-R1T-Chimera","name":"tngtech/DeepSeek-R1T-Chimera","display_name":"tngtech/DeepSeek-R1T-Chimera","type":"chat","context_length":0,"max_output_tokens":0,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"developer":"DeepSeek","developerId":7,"providerId":8,"modelRatio":0.01,"cacheRatio":1,"completionRatio":1,"description":"由chutes.ai提供\nDeepSeek-R1T-Chimera 将 DeepSeek-R1 的推理能力与 DeepSeek-V3（0324）的令牌效率优势融合，基于 MoE Transformer 架构并针对通用文本生成进行优化。模型整合了两者的预训练权重，以 MIT 许可证发布，适用于科研与商业用途。","descriptionEn":"Provided by chutes.ai\nDeepSeek-R1T-Chimera merges DeepSeek-R1’s reasoning strengths with DeepSeek-V3 (0324)’s token-efficiency improvements into a MoE Transformer optimized for general text generation. It integrates pretrained weights from both models and is released under the MIT license for research and commercial use.\n","order":150,"flag":0,"source":"public-provider-conf"},"vision":false},{"id":"tts-1","name":"tts-1","display_name":"tts-1","type":"audio","context_length":0,"max_output_tokens":0,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"modalities":{"input":["audio"],"output":["audio"]},"metadata":{"developer":"OpenAI","developerId":12,"providerId":1,"modelRatio":7.5,"cacheRatio":1,"completionRatio":1,"order":0,"flag":0,"modalities":["audio"],"typeHints":["tts"],"source":"public-provider-conf"},"vision":false},{"id":"tts-1-hd","name":"tts-1-hd","display_name":"tts-1-hd","type":"audio","context_length":0,"max_output_tokens":0,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"modalities":{"input":["audio"],"output":["audio"]},"metadata":{"developer":"OpenAI","developerId":12,"providerId":1,"modelRatio":15,"cacheRatio":1,"completionRatio":1,"order":0,"flag":0,"modalities":["audio"],"typeHints":["tts"],"source":"public-provider-conf"},"vision":false},{"id":"unsloth/gemma-3-12b-it","name":"gemma-3-12b","display_name":"gemma-3-12b","type":"chat","context_length":0,"max_output_tokens":0,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"developer":"Google","developerId":8,"providerId":8,"modelRatio":0.1,"cacheRatio":0,"completionRatio":4,"description":"由chutes.ai提供","descriptionEn":"Provided by chutes.ai.","order":99,"flag":0,"source":"public-provider-conf"},"vision":false},{"id":"unsloth/gemma-3-27b-it","name":"gemma-3-27b","display_name":"gemma-3-27b","type":"chat","context_length":0,"max_output_tokens":0,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"developer":"Google","developerId":8,"providerId":8,"modelRatio":0.11,"cacheRatio":0,"completionRatio":1,"description":"谷歌最新开源模型；由chutes.ai提供","descriptionEn":"Google's latest open-source model; provided by chutes.ai","order":100,"flag":1,"source":"public-provider-conf"},"vision":false},{"id":"veo-2.0-generate-001","name":"veo-2.0-generate-001","display_name":"veo-2.0-generate-001","type":"chat","context_length":0,"max_output_tokens":0,"capabilities":{"vision":true,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"modalities":{"input":["video"],"output":["video"]},"metadata":{"developer":"Google","developerId":8,"providerId":24,"modelRatio":1,"cacheRatio":0,"completionRatio":1,"description":"Veo 2.0 是一款先进的视频生成模型，能够根据文本或图像提示生成高质量的视频内容。它在理解真实世界物理和人类动作方面表现出色，能够生成流畅的角色运动和逼真的场景。Veo 2.0支持多种视觉风格和摄像机控制选项，包括镜头类型、拍摄角度和运动效果。可以生成分辨率高达 720p、时长为 8 秒的视频片段。","descriptionEn":"Veo 2.0 is an advanced video generation model capable of producing high-quality videos based on text or image prompts. It excels in understanding real-world physics and human motion, resulting in fluid character movements and lifelike scenes. Veo 2.0 supports various visual styles and camera control options, including lens types, angles, and motion effects. Users can generate 8-second video clips at 720p resolution.","order":820,"flag":1,"displayInput":"-","displayOutput":"$ 0.35 / S","imagePriceConfig":"{\"generate\":{\"standard\":{\"standard\":0.35}}}","tags":["multi_modal"],"modalities":["video"],"typeHints":["t2v"],"source":"public-provider-conf"},"vision":true},{"id":"veo-3","name":"veo3","display_name":"veo3","type":"chat","context_length":0,"max_output_tokens":0,"capabilities":{"vision":true,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"modalities":{"input":["text","image","audio","video"],"output":["text","image","audio","video"]},"metadata":{"developer":"Google","developerId":8,"providerId":1,"modelRatio":1,"cacheRatio":0,"completionRatio":1,"description":"veo3 逆向尝鲜，OpenAI chat 端口兼容格式可调用。单次生成视频的总价格为 $0.41","descriptionEn":"veo3 reverse access with a total cost of just $0.41 per video generation., OpenAI chat port compatible format.","order":0,"flag":1,"displayInput":"-","displayOutput":"$ 0.41 / Request","tags":["multi_modal"],"modalities":["text","image","audio","video"],"typeHints":["t2v"],"source":"public-provider-conf"},"vision":true},{"id":"veo-3.0-generate-preview","name":"veo-3.0-generate-preview","display_name":"veo-3.0-generate-preview","type":"chat","context_length":0,"max_output_tokens":0,"capabilities":{"vision":true,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"modalities":{"input":["text","image","video"],"output":["text","image","video"]},"metadata":{"developer":"Google","developerId":8,"providerId":24,"modelRatio":1,"cacheRatio":0,"completionRatio":1,"description":" Veo 3.0 生成预览版是一款先进的AI视频生成模型，支持文本生成高清晰度视频并同步音效，具备出色的物理模拟和唇形同步能力。用户可通过简短故事提示生成栩栩如生的视频片。🎟️ 限时 10% 优惠中。\n","descriptionEn":" Veo 3.0 Generate Preview is an advanced AI video generation model that supports text-to-video creation with synchronized audio, featuring excellent physical simulation and lip-sync capabilities. Users can generate vivid video clips from short story prompts. 🎟️ Limited-Time Deal: Save 10% Now.","order":800,"flag":1,"displayInput":"-","displayOutput":"$0.75 / S","imagePriceConfig":"{\"generate\":{\"standard\":{\"standard\":0.75}}}","tags":["multi_modal"],"modalities":["text","image","video"],"typeHints":["t2v"],"source":"public-provider-conf"},"vision":true},{"id":"whisper-1","name":"whisper-1","display_name":"whisper-1","type":"chat","context_length":0,"max_output_tokens":0,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"developer":"OpenAI","developerId":12,"providerId":1,"modelRatio":50,"cacheRatio":1,"completionRatio":1,"description":"无视页面的标价，这个模型请求时实际扣费跟官方一致，放心使用","descriptionEn":"Ignore the displayed price on the page; the actual charge for this model request is consistent with the official, so you can use it with confidence.","order":0,"flag":0,"displayInput":"-","displayOutput":"Transcription: $ 0.006 /Minutes","typeHints":["stt"],"source":"public-provider-conf"},"vision":false},{"id":"whisper-large-v3","name":"whisper-large","display_name":"whisper-large","type":"chat","context_length":0,"max_output_tokens":0,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"developer":"OpenAI","developerId":12,"providerId":29,"modelRatio":15.417,"cacheRatio":1,"completionRatio":1,"order":0,"flag":0,"typeHints":["stt"],"source":"public-provider-conf"},"vision":false},{"id":"yi-large","name":"yi-large","display_name":"yi-large","type":"chat","context_length":0,"max_output_tokens":0,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"developer":"零一万物","developerId":14,"providerId":31,"modelRatio":1.5,"cacheRatio":1,"completionRatio":1,"order":0,"flag":0,"source":"public-provider-conf"},"vision":false},{"id":"yi-large-rag","name":"yi-large-rag","display_name":"yi-large-rag","type":"chat","context_length":0,"max_output_tokens":0,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"developer":"零一万物","developerId":14,"providerId":31,"modelRatio":2,"cacheRatio":1,"completionRatio":1,"order":0,"flag":0,"source":"public-provider-conf"},"vision":false},{"id":"yi-large-turbo","name":"yi-large-turbo","display_name":"yi-large-turbo","type":"chat","context_length":0,"max_output_tokens":0,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"developer":"零一万物","developerId":14,"providerId":31,"modelRatio":0.9,"cacheRatio":1,"completionRatio":1,"order":0,"flag":0,"source":"public-provider-conf"},"vision":false},{"id":"yi-lightning","name":"yi-lightning","display_name":"yi-lightning","type":"chat","context_length":0,"max_output_tokens":0,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"developer":"零一万物","developerId":14,"providerId":31,"modelRatio":0.1,"cacheRatio":1,"completionRatio":1,"order":0,"flag":0,"source":"public-provider-conf"},"vision":false},{"id":"yi-medium","name":"yi-medium","display_name":"yi-medium","type":"chat","context_length":0,"max_output_tokens":0,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"developer":"零一万物","developerId":14,"providerId":31,"modelRatio":0.2,"cacheRatio":1,"completionRatio":1,"order":0,"flag":0,"source":"public-provider-conf"},"vision":false},{"id":"yi-vl-plus","name":"yi-vl-plus","display_name":"yi-vl-plus","type":"chat","context_length":0,"max_output_tokens":0,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"developer":"零一万物","developerId":14,"providerId":8,"modelRatio":0.000426,"cacheRatio":1,"completionRatio":1,"order":0,"flag":0,"source":"public-provider-conf"},"vision":false},{"id":"zai-org/GLM-4.5","name":"zai-org/GLM-4.5","display_name":"zai-org/GLM-4.5","type":"chat","context_length":0,"max_output_tokens":0,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"developer":"ChatGLM","developerId":5,"providerId":44,"modelRatio":0.25,"cacheRatio":1,"completionRatio":4,"description":"zai-org/GLM-4.5","descriptionEn":"zai-org/GLM-4.5","order":800,"flag":1,"source":"public-provider-conf"},"vision":false},{"id":"zai-org/GLM-4.5-Air","name":"zai-org/GLM-4.5-Air","display_name":"zai-org/GLM-4.5-Air","type":"chat","context_length":0,"max_output_tokens":0,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"developer":"ChatGLM","developerId":5,"providerId":44,"modelRatio":0.07,"cacheRatio":1,"completionRatio":6,"description":"zai-org/GLM-4.5-Air\n来自硅基流动","descriptionEn":"zai-org/GLM-4.5-Air\nsiliconflow","order":799,"flag":1,"source":"public-provider-conf"},"vision":false}],"metadata":{"upstream":"aihubmix-api","fetchedAt":"2025-10-03T14:35:02.898Z","modelCount":444,"source":"public-provider-conf"}},"doubao":{"id":"doubao","name":"Doubao","display_name":"Doubao","metadata":{"source":"public-provider-conf-template"},"models":[{"id":"deepseek-v3-1-250821","name":"DeepSeek V3.1","display_name":"DeepSeek V3.1","type":"chat","context_length":128000,"max_output_tokens":32000,"capabilities":{"vision":false,"function_calling":true,"reasoning":false},"metadata":{"source":"public-provider-conf-template"}},{"id":"deepseek-r1-250120","name":"DeepSeek R1","display_name":"DeepSeek R1","type":"chat","context_length":64000,"max_output_tokens":4096,"capabilities":{"vision":false,"function_calling":false,"reasoning":true},"metadata":{"source":"public-provider-conf-template"}},{"id":"deepseek-r1-distill-qwen-32b-250120","name":"DeepSeek R1 Distill Qwen 32B","display_name":"DeepSeek R1 Distill Qwen 32B","type":"chat","context_length":32000,"max_output_tokens":4096,"capabilities":{"vision":false,"function_calling":false,"reasoning":true},"metadata":{"source":"public-provider-conf-template"}},{"id":"deepseek-r1-distill-qwen-7b-250120","name":"DeepSeek R1 Distill Qwen 7B","display_name":"DeepSeek R1 Distill Qwen 7B","type":"chat","context_length":32000,"max_output_tokens":4096,"capabilities":{"vision":false,"function_calling":false,"reasoning":true},"metadata":{"source":"public-provider-conf-template"}},{"id":"deepseek-v3-250324","name":"DeepSeek V3","display_name":"DeepSeek V3","type":"chat","context_length":64000,"max_output_tokens":4096,"capabilities":{"vision":false,"function_calling":true,"reasoning":false},"metadata":{"source":"public-provider-conf-template"}},{"id":"doubao-seed-1-6-vision-250815","name":"Doubao Seed 1.6 Vision","display_name":"Doubao Seed 1.6 Vision","type":"chat","context_length":256000,"max_output_tokens":32000,"capabilities":{"vision":true,"function_calling":true,"reasoning":true},"metadata":{"source":"public-provider-conf-template"}},{"id":"doubao-seed-1-6-250615","name":"Doubao Seed 1.6","display_name":"Doubao Seed 1.6","type":"chat","context_length":256000,"max_output_tokens":32000,"capabilities":{"vision":true,"function_calling":true,"reasoning":true},"metadata":{"source":"public-provider-conf-template"}},{"id":"doubao-seed-1-6-flash-250715","name":"Doubao Seed 1.6 Flash","display_name":"Doubao Seed 1.6 Flash","type":"chat","context_length":256000,"max_output_tokens":32000,"capabilities":{"vision":true,"function_calling":true,"reasoning":true},"metadata":{"source":"public-provider-conf-template"}},{"id":"doubao-seed-1-6-flash-250615","name":"Doubao Seed 1.6 Flash (250615)","display_name":"Doubao Seed 1.6 Flash (250615)","type":"chat","context_length":256000,"max_output_tokens":32000,"capabilities":{"vision":true,"function_calling":true,"reasoning":true},"metadata":{"source":"public-provider-conf-template"}},{"id":"doubao-seed-1-6-thinking-250715","name":"Doubao Seed 1.6 Thinking","display_name":"Doubao Seed 1.6 Thinking","type":"chat","context_length":256000,"max_output_tokens":32000,"capabilities":{"vision":true,"function_calling":true,"reasoning":true},"metadata":{"source":"public-provider-conf-template"}},{"id":"doubao-seed-1-6-thinking-250615","name":"Doubao Seed 1.6 Thinking (250615)","display_name":"Doubao Seed 1.6 Thinking (250615)","type":"chat","context_length":256000,"max_output_tokens":32000,"capabilities":{"vision":true,"function_calling":true,"reasoning":true},"metadata":{"source":"public-provider-conf-template"}}]},"ollama":{"id":"ollama","name":"Ollama","display_name":"Ollama","metadata":{"source":"public-provider-conf-template"},"models":[{"id":"gpt-oss:20b","name":"GPT-OSS 20B","display_name":"GPT-OSS 20B","type":"chat","context_length":128000,"max_output_tokens":16000,"capabilities":{"vision":false,"function_calling":true,"reasoning":true},"metadata":{"source":"public-provider-conf-template"}},{"id":"gpt-oss:120b","name":"GPT-OSS 120B","display_name":"GPT-OSS 120B","type":"chat","context_length":128000,"max_output_tokens":32000,"capabilities":{"vision":false,"function_calling":true,"reasoning":true},"metadata":{"source":"public-provider-conf-template"}},{"id":"deepseek-r1:1.5b","name":"DeepSeek R1 1.5B","display_name":"DeepSeek R1 1.5B","type":"chat","context_length":65536,"max_output_tokens":32768,"capabilities":{"vision":false,"function_calling":false,"reasoning":true},"metadata":{"source":"public-provider-conf-template"}},{"id":"deepseek-r1:7b","name":"DeepSeek R1 7B","display_name":"DeepSeek R1 7B","type":"chat","context_length":65536,"max_output_tokens":32768,"capabilities":{"vision":false,"function_calling":false,"reasoning":true},"metadata":{"source":"public-provider-conf-template"}},{"id":"deepseek-r1:8b","name":"DeepSeek R1 8B","display_name":"DeepSeek R1 8B","type":"chat","context_length":65536,"max_output_tokens":32768,"capabilities":{"vision":false,"function_calling":false,"reasoning":true},"metadata":{"source":"public-provider-conf-template"}},{"id":"deepseek-r1:14b","name":"DeepSeek R1 14B","display_name":"DeepSeek R1 14B","type":"chat","context_length":65536,"max_output_tokens":32768,"capabilities":{"vision":false,"function_calling":false,"reasoning":true},"metadata":{"source":"public-provider-conf-template"}},{"id":"deepseek-r1:32b","name":"DeepSeek R1 32B","display_name":"DeepSeek R1 32B","type":"chat","context_length":65536,"max_output_tokens":32768,"capabilities":{"vision":false,"function_calling":false,"reasoning":true},"metadata":{"source":"public-provider-conf-template"}},{"id":"deepseek-r1:70b","name":"DeepSeek R1 70B","display_name":"DeepSeek R1 70B","type":"chat","context_length":131072,"max_output_tokens":32768,"capabilities":{"vision":false,"function_calling":false,"reasoning":true},"metadata":{"source":"public-provider-conf-template"}},{"id":"deepseek-r1:671b","name":"DeepSeek R1 671B","display_name":"DeepSeek R1 671B","type":"chat","context_length":131072,"max_output_tokens":65536,"capabilities":{"vision":false,"function_calling":false,"reasoning":true},"metadata":{"source":"public-provider-conf-template"}},{"id":"deepseek-v3:671b","name":"DeepSeek V3 671B","display_name":"DeepSeek V3 671B","type":"chat","context_length":131072,"max_output_tokens":32768,"capabilities":{"vision":false,"function_calling":true,"reasoning":false},"metadata":{"source":"public-provider-conf-template"}},{"id":"deepseek-v2.5:236b","name":"DeepSeek V2.5 236B","display_name":"DeepSeek V2.5 236B","type":"chat","context_length":131072,"max_output_tokens":32768,"capabilities":{"vision":false,"function_calling":true,"reasoning":false},"metadata":{"source":"public-provider-conf-template"}},{"id":"gemma3:1b","name":"Gemma3 1B","display_name":"Gemma3 1B","type":"chat","context_length":32768,"max_output_tokens":8192,"capabilities":{"vision":false,"function_calling":true,"reasoning":false},"metadata":{"source":"public-provider-conf-template"}},{"id":"gemma3:4b","name":"Gemma3 4B","display_name":"Gemma3 4B","type":"chat","context_length":32768,"max_output_tokens":8192,"capabilities":{"vision":false,"function_calling":true,"reasoning":false},"metadata":{"source":"public-provider-conf-template"}},{"id":"gemma3:12b","name":"Gemma3 12B","display_name":"Gemma3 12B","type":"chat","context_length":65536,"max_output_tokens":16384,"capabilities":{"vision":false,"function_calling":true,"reasoning":false},"metadata":{"source":"public-provider-conf-template"}},{"id":"gemma3:27b","name":"Gemma3 27B","display_name":"Gemma3 27B","type":"chat","context_length":65536,"max_output_tokens":16384,"capabilities":{"vision":false,"function_calling":true,"reasoning":false},"metadata":{"source":"public-provider-conf-template"}}]},"ppinfra":{"id":"ppinfra","models":[{"id":"deepseek/deepseek-r1-0528","context_length":128000,"max_output_tokens":16000,"name":"deepseek/deepseek-r1-0528","display_name":"deepseek/deepseek-r1-0528"},{"id":"deepseek/deepseek-v3-0324","context_length":128000,"max_output_tokens":16000,"name":"deepseek/deepseek-v3-0324","display_name":"deepseek/deepseek-v3-0324"},{"id":"deepseek/deepseek-prover-v2-671b","reasoning":true,"capabilities":{"reasoning":true},"name":"deepseek/deepseek-prover-v2-671b","display_name":"deepseek/deepseek-prover-v2-671b"},{"id":"meta-llama/llama-3.3-70b-instruct","type":"chat","context_length":131072,"max_output_tokens":8000,"capabilities":{"vision":false,"function_calling":false,"reasoning":true},"name":"meta-llama/llama-3.3-70b-instruct","display_name":"meta-llama/llama-3.3-70b-instruct"}],"name":"ppinfra","display_name":"ppinfra"},"siliconflow":{"id":"siliconflow","name":"SiliconFlow","display_name":"SiliconFlow","metadata":{"source":"public-provider-conf-template"},"models":[{"id":"deepseek-r1:32b","name":"DeepSeek R1 32B","display_name":"DeepSeek R1 32B","type":"chat","context_length":65536,"max_output_tokens":32768,"capabilities":{"vision":false,"function_calling":false,"reasoning":true},"metadata":{"source":"public-provider-conf-template"}},{"id":"deepseek-v2.5:236b","name":"DeepSeek V2.5 236B","display_name":"DeepSeek V2.5 236B","type":"chat","context_length":131072,"max_output_tokens":32768,"capabilities":{"vision":false,"function_calling":true,"reasoning":false},"metadata":{"source":"public-provider-conf-template"}},{"id":"deepseek-r1:7b","name":"DeepSeek R1 7B","display_name":"DeepSeek R1 7B","type":"chat","context_length":65536,"max_output_tokens":32768,"capabilities":{"vision":false,"function_calling":false,"reasoning":true},"metadata":{"source":"public-provider-conf-template"}},{"id":"gpt-oss:120b","name":"GPT-OSS 120B","display_name":"GPT-OSS 120B","type":"chat","context_length":128000,"max_output_tokens":32000,"capabilities":{"vision":false,"function_calling":true,"reasoning":true},"metadata":{"source":"public-provider-conf-template"}},{"id":"gemma3:1b","name":"Gemma3 1B","display_name":"Gemma3 1B","type":"chat","context_length":32768,"max_output_tokens":8192,"capabilities":{"vision":false,"function_calling":true,"reasoning":false},"metadata":{"source":"public-provider-conf-template"}},{"id":"deepseek-r1:70b","name":"DeepSeek R1 70B","display_name":"DeepSeek R1 70B","type":"chat","context_length":131072,"max_output_tokens":32768,"capabilities":{"vision":false,"function_calling":false,"reasoning":true},"metadata":{"source":"public-provider-conf-template"}},{"id":"deepseek-r1:14b","name":"DeepSeek R1 14B","display_name":"DeepSeek R1 14B","type":"chat","context_length":65536,"max_output_tokens":32768,"capabilities":{"vision":false,"function_calling":false,"reasoning":true},"metadata":{"source":"public-provider-conf-template"}},{"id":"gemma3:27b","name":"Gemma3 27B","display_name":"Gemma3 27B","type":"chat","context_length":65536,"max_output_tokens":16384,"capabilities":{"vision":false,"function_calling":true,"reasoning":false},"metadata":{"source":"public-provider-conf-template"}},{"id":"gemma3:12b","name":"Gemma3 12B","display_name":"Gemma3 12B","type":"chat","context_length":65536,"max_output_tokens":16384,"capabilities":{"vision":false,"function_calling":true,"reasoning":false},"metadata":{"source":"public-provider-conf-template"}},{"id":"gpt-oss:20b","name":"GPT-OSS 20B","display_name":"GPT-OSS 20B","type":"chat","context_length":128000,"max_output_tokens":16000,"capabilities":{"vision":false,"function_calling":true,"reasoning":true},"metadata":{"source":"public-provider-conf-template"}},{"id":"deepseek-r1:671b","name":"DeepSeek R1 671B","display_name":"DeepSeek R1 671B","type":"chat","context_length":131072,"max_output_tokens":65536,"capabilities":{"vision":false,"function_calling":false,"reasoning":true},"metadata":{"source":"public-provider-conf-template"}},{"id":"gemma3:4b","name":"Gemma3 4B","display_name":"Gemma3 4B","type":"chat","context_length":32768,"max_output_tokens":8192,"capabilities":{"vision":false,"function_calling":true,"reasoning":false},"metadata":{"source":"public-provider-conf-template"}},{"id":"deepseek-r1:8b","name":"DeepSeek R1 8B","display_name":"DeepSeek R1 8B","type":"chat","context_length":65536,"max_output_tokens":32768,"capabilities":{"vision":false,"function_calling":false,"reasoning":true},"metadata":{"source":"public-provider-conf-template"}},{"id":"deepseek-r1:1.5b","name":"DeepSeek R1 1.5B","display_name":"DeepSeek R1 1.5B","type":"chat","context_length":65536,"max_output_tokens":32768,"capabilities":{"vision":false,"function_calling":false,"reasoning":true},"metadata":{"source":"public-provider-conf-template"}},{"id":"deepseek-v3:671b","name":"DeepSeek V3 671B","display_name":"DeepSeek V3 671B","type":"chat","context_length":131072,"max_output_tokens":32768,"capabilities":{"vision":false,"function_calling":true,"reasoning":false},"metadata":{"source":"public-provider-conf-template"}}]},"tokenflux":{"id":"tokenflux","name":"Tokenflux","display_name":"Tokenflux","updated_at":"2025-10-03T14:35:07.383Z","models":[{"id":"agentica-org/deepcoder-14b-preview","name":"Agentica: Deepcoder 14B Preview","display_name":"Agentica: Deepcoder 14B Preview","type":"chat","context_length":4096,"max_output_tokens":4096,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"source":"public-provider-conf"},"vision":false},{"id":"ai21/jamba-large-1.7","name":"AI21: Jamba Large 1.7","display_name":"AI21: Jamba Large 1.7","type":"chat","context_length":4096,"max_output_tokens":4096,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"source":"public-provider-conf"},"vision":false},{"id":"ai21/jamba-mini-1.7","name":"AI21: Jamba Mini 1.7","display_name":"AI21: Jamba Mini 1.7","type":"chat","context_length":4096,"max_output_tokens":4096,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"source":"public-provider-conf"},"vision":false},{"id":"aion-labs/aion-1.0","name":"AionLabs: Aion-1.0","display_name":"AionLabs: Aion-1.0","type":"chat","context_length":4096,"max_output_tokens":4096,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"source":"public-provider-conf"},"vision":false},{"id":"aion-labs/aion-1.0-mini","name":"AionLabs: Aion-1.0-Mini","display_name":"AionLabs: Aion-1.0-Mini","type":"chat","context_length":4096,"max_output_tokens":4096,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"source":"public-provider-conf"},"vision":false},{"id":"aion-labs/aion-rp-llama-3.1-8b","name":"AionLabs: Aion-RP 1.0 (8B)","display_name":"AionLabs: Aion-RP 1.0 (8B)","type":"chat","context_length":4096,"max_output_tokens":4096,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"source":"public-provider-conf"},"vision":false},{"id":"alfredpros/codellama-7b-instruct-solidity","name":"AlfredPros: CodeLLaMa 7B Instruct Solidity","display_name":"AlfredPros: CodeLLaMa 7B Instruct Solidity","type":"completion","context_length":4096,"max_output_tokens":4096,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"source":"public-provider-conf"},"vision":false},{"id":"allenai/molmo-7b-d","name":"AllenAI: Molmo 7B D","display_name":"AllenAI: Molmo 7B D","type":"chat","context_length":4096,"max_output_tokens":4096,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"source":"public-provider-conf"},"vision":false},{"id":"allenai/olmo-2-0325-32b-instruct","name":"AllenAI: Olmo 2 32B Instruct","display_name":"AllenAI: Olmo 2 32B Instruct","type":"completion","context_length":4096,"max_output_tokens":4096,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"source":"public-provider-conf"},"vision":false},{"id":"amazon/nova-lite-v1","name":"Amazon: Nova Lite 1.0","display_name":"Amazon: Nova Lite 1.0","type":"chat","context_length":4096,"max_output_tokens":4096,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"source":"public-provider-conf"},"vision":false},{"id":"amazon/nova-micro-v1","name":"Amazon: Nova Micro 1.0","display_name":"Amazon: Nova Micro 1.0","type":"chat","context_length":4096,"max_output_tokens":4096,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"source":"public-provider-conf"},"vision":false},{"id":"amazon/nova-pro-v1","name":"Amazon: Nova Pro 1.0","display_name":"Amazon: Nova Pro 1.0","type":"chat","context_length":4096,"max_output_tokens":4096,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"source":"public-provider-conf"},"vision":false},{"id":"anthropic/claude-3-haiku","name":"Anthropic: Claude 3 Haiku","display_name":"Anthropic: Claude 3 Haiku","type":"chat","context_length":4096,"max_output_tokens":4096,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"source":"public-provider-conf"},"vision":false},{"id":"anthropic/claude-3-opus","name":"Anthropic: Claude 3 Opus","display_name":"Anthropic: Claude 3 Opus","type":"chat","context_length":4096,"max_output_tokens":4096,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"source":"public-provider-conf"},"vision":false},{"id":"anthropic/claude-3.5-haiku","name":"Anthropic: Claude 3.5 Haiku","display_name":"Anthropic: Claude 3.5 Haiku","type":"chat","context_length":4096,"max_output_tokens":4096,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"source":"public-provider-conf"},"vision":false},{"id":"anthropic/claude-3.5-haiku-20241022","name":"Anthropic: Claude 3.5 Haiku (2024-10-22)","display_name":"Anthropic: Claude 3.5 Haiku (2024-10-22)","type":"chat","context_length":4096,"max_output_tokens":4096,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"source":"public-provider-conf"},"vision":false},{"id":"anthropic/claude-3.5-sonnet","name":"Anthropic: Claude 3.5 Sonnet","display_name":"Anthropic: Claude 3.5 Sonnet","type":"chat","context_length":4096,"max_output_tokens":4096,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"source":"public-provider-conf"},"vision":false},{"id":"anthropic/claude-3.5-sonnet-20240620","name":"Anthropic: Claude 3.5 Sonnet (2024-06-20)","display_name":"Anthropic: Claude 3.5 Sonnet (2024-06-20)","type":"chat","context_length":4096,"max_output_tokens":4096,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"source":"public-provider-conf"},"vision":false},{"id":"anthropic/claude-3.7-sonnet","name":"Anthropic: Claude 3.7 Sonnet","display_name":"Anthropic: Claude 3.7 Sonnet","type":"chat","context_length":4096,"max_output_tokens":4096,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"source":"public-provider-conf"},"vision":false},{"id":"anthropic/claude-3.7-sonnet:thinking","name":"Anthropic: Claude 3.7 Sonnet (thinking)","display_name":"Anthropic: Claude 3.7 Sonnet (thinking)","type":"chat","context_length":4096,"max_output_tokens":4096,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"source":"public-provider-conf"},"vision":false},{"id":"anthropic/claude-opus-4","name":"Anthropic: Claude Opus 4","display_name":"Anthropic: Claude Opus 4","type":"chat","context_length":4096,"max_output_tokens":4096,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"source":"public-provider-conf"},"vision":false},{"id":"anthropic/claude-opus-4.1","name":"Anthropic: Claude Opus 4.1","display_name":"Anthropic: Claude Opus 4.1","type":"chat","context_length":4096,"max_output_tokens":4096,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"source":"public-provider-conf"},"vision":false},{"id":"anthropic/claude-sonnet-4","name":"Anthropic: Claude Sonnet 4","display_name":"Anthropic: Claude Sonnet 4","type":"chat","context_length":4096,"max_output_tokens":4096,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"source":"public-provider-conf"},"vision":false},{"id":"arcee-ai/afm-4.5b","name":"Arcee AI: AFM 4.5B","display_name":"Arcee AI: AFM 4.5B","type":"chat","context_length":4096,"max_output_tokens":4096,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"source":"public-provider-conf"},"vision":false},{"id":"arcee-ai/coder-large","name":"Arcee AI: Coder Large","display_name":"Arcee AI: Coder Large","type":"chat","context_length":4096,"max_output_tokens":4096,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"source":"public-provider-conf"},"vision":false},{"id":"arcee-ai/maestro-reasoning","name":"Arcee AI: Maestro Reasoning","display_name":"Arcee AI: Maestro Reasoning","type":"chat","context_length":4096,"max_output_tokens":4096,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"source":"public-provider-conf"},"vision":false},{"id":"arcee-ai/spotlight","name":"Arcee AI: Spotlight","display_name":"Arcee AI: Spotlight","type":"chat","context_length":4096,"max_output_tokens":4096,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"source":"public-provider-conf"},"vision":false},{"id":"arcee-ai/virtuoso-large","name":"Arcee AI: Virtuoso Large","display_name":"Arcee AI: Virtuoso Large","type":"chat","context_length":4096,"max_output_tokens":4096,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"source":"public-provider-conf"},"vision":false},{"id":"arliai/qwq-32b-arliai-rpr-v1","name":"ArliAI: QwQ 32B RpR v1","display_name":"ArliAI: QwQ 32B RpR v1","type":"chat","context_length":4096,"max_output_tokens":4096,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"source":"public-provider-conf"},"vision":false},{"id":"openrouter/auto","name":"Auto Router","display_name":"Auto Router","type":"chat","context_length":4096,"max_output_tokens":4096,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"source":"public-provider-conf"},"vision":false},{"id":"baidu/ernie-4.5-21b-a3b","name":"Baidu: ERNIE 4.5 21B A3B","display_name":"Baidu: ERNIE 4.5 21B A3B","type":"chat","context_length":4096,"max_output_tokens":4096,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"source":"public-provider-conf"},"vision":false},{"id":"baidu/ernie-4.5-300b-a47b","name":"Baidu: ERNIE 4.5 300B A47B","display_name":"Baidu: ERNIE 4.5 300B A47B","type":"chat","context_length":4096,"max_output_tokens":4096,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"source":"public-provider-conf"},"vision":false},{"id":"baidu/ernie-4.5-vl-28b-a3b","name":"Baidu: ERNIE 4.5 VL 28B A3B","display_name":"Baidu: ERNIE 4.5 VL 28B A3B","type":"chat","context_length":4096,"max_output_tokens":4096,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"source":"public-provider-conf"},"vision":false},{"id":"baidu/ernie-4.5-vl-424b-a47b","name":"Baidu: ERNIE 4.5 VL 424B A47B","display_name":"Baidu: ERNIE 4.5 VL 424B A47B","type":"chat","context_length":4096,"max_output_tokens":4096,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"source":"public-provider-conf"},"vision":false},{"id":"bytedance/doubao-embedding-text-240715","name":"ByteDance: Doubao Embedding","display_name":"ByteDance: Doubao Embedding","type":"embedding","context_length":4096,"max_output_tokens":4096,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"source":"public-provider-conf"},"vision":false},{"id":"bytedance/doubao-embedding-large-text-240915","name":"ByteDance: Doubao Embedding Large Text (240915)","display_name":"ByteDance: Doubao Embedding Large Text (240915)","type":"embedding","context_length":4096,"max_output_tokens":4096,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"source":"public-provider-conf"},"vision":false},{"id":"bytedance/doubao-embedding-vision-241215","name":"ByteDance: Doubao Embedding Vision","display_name":"ByteDance: Doubao Embedding Vision","type":"embedding","context_length":4096,"max_output_tokens":4096,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"source":"public-provider-conf"},"vision":false},{"id":"bytedance/doubao-embedding-vision-250328","name":"ByteDance: Doubao Embedding Vision","display_name":"ByteDance: Doubao Embedding Vision","type":"embedding","context_length":4096,"max_output_tokens":4096,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"source":"public-provider-conf"},"vision":false},{"id":"bytedance/doubao-seed-1.6","name":"ByteDance: Doubao Seed 1.6","display_name":"ByteDance: Doubao Seed 1.6","type":"chat","context_length":4096,"max_output_tokens":4096,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"source":"public-provider-conf"},"vision":false},{"id":"bytedance/doubao-seed-1.6-flash","name":"ByteDance: Doubao Seed 1.6 Flash","display_name":"ByteDance: Doubao Seed 1.6 Flash","type":"chat","context_length":4096,"max_output_tokens":4096,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"source":"public-provider-conf"},"vision":false},{"id":"bytedance/doubao-seed-1.6-thinking","name":"ByteDance: Doubao Seed 1.6 Thinking","display_name":"ByteDance: Doubao Seed 1.6 Thinking","type":"chat","context_length":4096,"max_output_tokens":4096,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"source":"public-provider-conf"},"vision":false},{"id":"bytedance/seed-oss-36b-instruct","name":"ByteDance: Seed OSS 36B Instruct","display_name":"ByteDance: Seed OSS 36B Instruct","type":"completion","context_length":4096,"max_output_tokens":4096,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"source":"public-provider-conf"},"vision":false},{"id":"bytedance/ui-tars-1.5-7b","name":"ByteDance: UI-TARS 7B","display_name":"ByteDance: UI-TARS 7B","type":"chat","context_length":4096,"max_output_tokens":4096,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"source":"public-provider-conf"},"vision":false},{"id":"deepcogito/cogito-v2-preview-llama-109b-moe","name":"Cogito V2 Preview Llama 109B","display_name":"Cogito V2 Preview Llama 109B","type":"chat","context_length":4096,"max_output_tokens":4096,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"source":"public-provider-conf"},"vision":false},{"id":"cohere/command-a","name":"Cohere: Command A","display_name":"Cohere: Command A","type":"chat","context_length":4096,"max_output_tokens":4096,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"source":"public-provider-conf"},"vision":false},{"id":"cohere/command-r-08-2024","name":"Cohere: Command R (08-2024)","display_name":"Cohere: Command R (08-2024)","type":"chat","context_length":4096,"max_output_tokens":4096,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"source":"public-provider-conf"},"vision":false},{"id":"cohere/command-r-plus-08-2024","name":"Cohere: Command R+ (08-2024)","display_name":"Cohere: Command R+ (08-2024)","type":"chat","context_length":4096,"max_output_tokens":4096,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"source":"public-provider-conf"},"vision":false},{"id":"cohere/command-r7b-12-2024","name":"Cohere: Command R7B (12-2024)","display_name":"Cohere: Command R7B (12-2024)","type":"chat","context_length":4096,"max_output_tokens":4096,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"source":"public-provider-conf"},"vision":false},{"id":"deepcogito/cogito-v2-preview-deepseek-671b","name":"Deep Cogito: Cogito V2 Preview Deepseek 671B","display_name":"Deep Cogito: Cogito V2 Preview Deepseek 671B","type":"chat","context_length":4096,"max_output_tokens":4096,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"source":"public-provider-conf"},"vision":false},{"id":"deepseek/deepseek-prover-v2","name":"DeepSeek: DeepSeek Prover V2","display_name":"DeepSeek: DeepSeek Prover V2","type":"chat","context_length":4096,"max_output_tokens":4096,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"source":"public-provider-conf"},"vision":false},{"id":"deepseek/deepseek-r1-0528-qwen3-8b","name":"DeepSeek: Deepseek R1 0528 Qwen3 8B","display_name":"DeepSeek: Deepseek R1 0528 Qwen3 8B","type":"chat","context_length":4096,"max_output_tokens":4096,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"source":"public-provider-conf"},"vision":false},{"id":"deepseek/deepseek-chat","name":"DeepSeek: DeepSeek V3","display_name":"DeepSeek: DeepSeek V3","type":"chat","context_length":4096,"max_output_tokens":4096,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"source":"public-provider-conf"},"vision":false},{"id":"deepseek/deepseek-chat-v3-0324","name":"DeepSeek: DeepSeek V3 0324","display_name":"DeepSeek: DeepSeek V3 0324","type":"chat","context_length":4096,"max_output_tokens":4096,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"source":"public-provider-conf"},"vision":false},{"id":"deepseek/deepseek-chat-v3.1","name":"DeepSeek: DeepSeek V3.1","display_name":"DeepSeek: DeepSeek V3.1","type":"chat","context_length":4096,"max_output_tokens":4096,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"source":"public-provider-conf"},"vision":false},{"id":"deepseek/deepseek-v3.1-base","name":"DeepSeek: DeepSeek V3.1 Base","display_name":"DeepSeek: DeepSeek V3.1 Base","type":"chat","context_length":4096,"max_output_tokens":4096,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"source":"public-provider-conf"},"vision":false},{"id":"deepseek/deepseek-v3.1-terminus","name":"DeepSeek: DeepSeek V3.1 Terminus","display_name":"DeepSeek: DeepSeek V3.1 Terminus","type":"chat","context_length":4096,"max_output_tokens":4096,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"source":"public-provider-conf"},"vision":false},{"id":"deepseek/deepseek-r1","name":"DeepSeek: R1","display_name":"DeepSeek: R1","type":"chat","context_length":4096,"max_output_tokens":4096,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"source":"public-provider-conf"},"vision":false},{"id":"deepseek/deepseek-r1-0528","name":"DeepSeek: R1 0528","display_name":"DeepSeek: R1 0528","type":"chat","context_length":4096,"max_output_tokens":4096,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"source":"public-provider-conf"},"vision":false},{"id":"deepseek/deepseek-r1-distill-llama-70b","name":"DeepSeek: R1 Distill Llama 70B","display_name":"DeepSeek: R1 Distill Llama 70B","type":"chat","context_length":4096,"max_output_tokens":4096,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"source":"public-provider-conf"},"vision":false},{"id":"deepseek/deepseek-r1-distill-llama-8b","name":"DeepSeek: R1 Distill Llama 8B","display_name":"DeepSeek: R1 Distill Llama 8B","type":"chat","context_length":4096,"max_output_tokens":4096,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"source":"public-provider-conf"},"vision":false},{"id":"deepseek/deepseek-r1-distill-qwen-14b","name":"DeepSeek: R1 Distill Qwen 14B","display_name":"DeepSeek: R1 Distill Qwen 14B","type":"chat","context_length":4096,"max_output_tokens":4096,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"source":"public-provider-conf"},"vision":false},{"id":"deepseek/deepseek-r1-distill-qwen-32b","name":"DeepSeek: R1 Distill Qwen 32B","display_name":"DeepSeek: R1 Distill Qwen 32B","type":"chat","context_length":4096,"max_output_tokens":4096,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"source":"public-provider-conf"},"vision":false},{"id":"cognitivecomputations/dolphin3.0-mistral-24b","name":"Dolphin3.0 Mistral 24B","display_name":"Dolphin3.0 Mistral 24B","type":"chat","context_length":4096,"max_output_tokens":4096,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"source":"public-provider-conf"},"vision":false},{"id":"cognitivecomputations/dolphin3.0-r1-mistral-24b","name":"Dolphin3.0 R1 Mistral 24B","display_name":"Dolphin3.0 R1 Mistral 24B","type":"chat","context_length":4096,"max_output_tokens":4096,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"source":"public-provider-conf"},"vision":false},{"id":"eleutherai/llemma_7b","name":"EleutherAI: Llemma 7b","display_name":"EleutherAI: Llemma 7b","type":"chat","context_length":4096,"max_output_tokens":4096,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"source":"public-provider-conf"},"vision":false},{"id":"google/gemini-2.5-flash-image-preview","name":"Gemini 2.5 Flash Image (Nano Banana)","display_name":"Gemini 2.5 Flash Image (Nano Banana)","type":"chat","context_length":4096,"max_output_tokens":4096,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"source":"public-provider-conf"},"vision":false},{"id":"alpindale/goliath-120b","name":"Goliath 120B","display_name":"Goliath 120B","type":"chat","context_length":4096,"max_output_tokens":4096,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"source":"public-provider-conf"},"vision":false},{"id":"google/gemini-flash-1.5-8b","name":"Google: Gemini 1.5 Flash 8B","display_name":"Google: Gemini 1.5 Flash 8B","type":"chat","context_length":4096,"max_output_tokens":4096,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"source":"public-provider-conf"},"vision":false},{"id":"google/gemini-2.0-flash-001","name":"Google: Gemini 2.0 Flash","display_name":"Google: Gemini 2.0 Flash","type":"chat","context_length":4096,"max_output_tokens":4096,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"source":"public-provider-conf"},"vision":false},{"id":"google/gemini-2.0-flash-lite-001","name":"Google: Gemini 2.0 Flash Lite","display_name":"Google: Gemini 2.0 Flash Lite","type":"chat","context_length":4096,"max_output_tokens":4096,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"source":"public-provider-conf"},"vision":false},{"id":"google/gemini-2.5-flash","name":"Google: Gemini 2.5 Flash","display_name":"Google: Gemini 2.5 Flash","type":"chat","context_length":4096,"max_output_tokens":4096,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"source":"public-provider-conf"},"vision":false},{"id":"google/gemini-2.5-flash-lite","name":"Google: Gemini 2.5 Flash Lite","display_name":"Google: Gemini 2.5 Flash Lite","type":"chat","context_length":4096,"max_output_tokens":4096,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"source":"public-provider-conf"},"vision":false},{"id":"google/gemini-2.5-flash-lite-preview-06-17","name":"Google: Gemini 2.5 Flash Lite Preview 06-17","display_name":"Google: Gemini 2.5 Flash Lite Preview 06-17","type":"chat","context_length":4096,"max_output_tokens":4096,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"source":"public-provider-conf"},"vision":false},{"id":"google/gemini-2.5-flash-lite-preview-09-2025","name":"Google: Gemini 2.5 Flash Lite Preview 09-2025","display_name":"Google: Gemini 2.5 Flash Lite Preview 09-2025","type":"chat","context_length":4096,"max_output_tokens":4096,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"source":"public-provider-conf"},"vision":false},{"id":"google/gemini-2.5-flash-preview-09-2025","name":"Google: Gemini 2.5 Flash Preview 09-2025","display_name":"Google: Gemini 2.5 Flash Preview 09-2025","type":"chat","context_length":4096,"max_output_tokens":4096,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"source":"public-provider-conf"},"vision":false},{"id":"google/gemini-2.5-pro","name":"Google: Gemini 2.5 Pro","display_name":"Google: Gemini 2.5 Pro","type":"chat","context_length":4096,"max_output_tokens":4096,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"source":"public-provider-conf"},"vision":false},{"id":"google/gemini-2.5-pro-preview-05-06","name":"Google: Gemini 2.5 Pro Preview 05-06","display_name":"Google: Gemini 2.5 Pro Preview 05-06","type":"chat","context_length":4096,"max_output_tokens":4096,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"source":"public-provider-conf"},"vision":false},{"id":"google/gemini-2.5-pro-preview","name":"Google: Gemini 2.5 Pro Preview 06-05","display_name":"Google: Gemini 2.5 Pro Preview 06-05","type":"chat","context_length":4096,"max_output_tokens":4096,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"source":"public-provider-conf"},"vision":false},{"id":"google/gemma-2-27b-it","name":"Google: Gemma 2 27B","display_name":"Google: Gemma 2 27B","type":"chat","context_length":4096,"max_output_tokens":4096,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"source":"public-provider-conf"},"vision":false},{"id":"google/gemma-2-9b-it","name":"Google: Gemma 2 9B","display_name":"Google: Gemma 2 9B","type":"chat","context_length":4096,"max_output_tokens":4096,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"source":"public-provider-conf"},"vision":false},{"id":"google/gemma-3-12b-it","name":"Google: Gemma 3 12B","display_name":"Google: Gemma 3 12B","type":"chat","context_length":4096,"max_output_tokens":4096,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"source":"public-provider-conf"},"vision":false},{"id":"google/gemma-3-27b-it","name":"Google: Gemma 3 27B","display_name":"Google: Gemma 3 27B","type":"chat","context_length":4096,"max_output_tokens":4096,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"source":"public-provider-conf"},"vision":false},{"id":"google/gemma-3-4b-it","name":"Google: Gemma 3 4B","display_name":"Google: Gemma 3 4B","type":"chat","context_length":4096,"max_output_tokens":4096,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"source":"public-provider-conf"},"vision":false},{"id":"google/gemma-3n-e4b-it","name":"Google: Gemma 3n 4B","display_name":"Google: Gemma 3n 4B","type":"chat","context_length":4096,"max_output_tokens":4096,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"source":"public-provider-conf"},"vision":false},{"id":"inception/mercury","name":"Inception: Mercury","display_name":"Inception: Mercury","type":"chat","context_length":4096,"max_output_tokens":4096,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"source":"public-provider-conf"},"vision":false},{"id":"inception/mercury-coder","name":"Inception: Mercury Coder","display_name":"Inception: Mercury Coder","type":"chat","context_length":4096,"max_output_tokens":4096,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"source":"public-provider-conf"},"vision":false},{"id":"inflection/inflection-3-pi","name":"Inflection: Inflection 3 Pi","display_name":"Inflection: Inflection 3 Pi","type":"chat","context_length":4096,"max_output_tokens":4096,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"source":"public-provider-conf"},"vision":false},{"id":"inflection/inflection-3-productivity","name":"Inflection: Inflection 3 Productivity","display_name":"Inflection: Inflection 3 Productivity","type":"chat","context_length":4096,"max_output_tokens":4096,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"source":"public-provider-conf"},"vision":false},{"id":"liquid/lfm-3b","name":"Liquid: LFM 3B","display_name":"Liquid: LFM 3B","type":"chat","context_length":4096,"max_output_tokens":4096,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"source":"public-provider-conf"},"vision":false},{"id":"liquid/lfm-7b","name":"Liquid: LFM 7B","display_name":"Liquid: LFM 7B","type":"chat","context_length":4096,"max_output_tokens":4096,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"source":"public-provider-conf"},"vision":false},{"id":"meta-llama/llama-guard-3-8b","name":"Llama Guard 3 8B","display_name":"Llama Guard 3 8B","type":"chat","context_length":4096,"max_output_tokens":4096,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"source":"public-provider-conf"},"vision":false},{"id":"anthracite-org/magnum-v2-72b","name":"Magnum v2 72B","display_name":"Magnum v2 72B","type":"chat","context_length":4096,"max_output_tokens":4096,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"source":"public-provider-conf"},"vision":false},{"id":"anthracite-org/magnum-v4-72b","name":"Magnum v4 72B","display_name":"Magnum v4 72B","type":"chat","context_length":4096,"max_output_tokens":4096,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"source":"public-provider-conf"},"vision":false},{"id":"mancer/weaver","name":"Mancer: Weaver (alpha)","display_name":"Mancer: Weaver (alpha)","type":"chat","context_length":4096,"max_output_tokens":4096,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"source":"public-provider-conf"},"vision":false},{"id":"meituan/longcat-flash-chat","name":"Meituan: LongCat Flash Chat","display_name":"Meituan: LongCat Flash Chat","type":"chat","context_length":4096,"max_output_tokens":4096,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"source":"public-provider-conf"},"vision":false},{"id":"meta-llama/llama-3-70b-instruct","name":"Meta: Llama 3 70B Instruct","display_name":"Meta: Llama 3 70B Instruct","type":"completion","context_length":4096,"max_output_tokens":4096,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"source":"public-provider-conf"},"vision":false},{"id":"meta-llama/llama-3-8b-instruct","name":"Meta: Llama 3 8B Instruct","display_name":"Meta: Llama 3 8B Instruct","type":"completion","context_length":4096,"max_output_tokens":4096,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"source":"public-provider-conf"},"vision":false},{"id":"meta-llama/llama-3.1-405b","name":"Meta: Llama 3.1 405B (base)","display_name":"Meta: Llama 3.1 405B (base)","type":"chat","context_length":4096,"max_output_tokens":4096,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"source":"public-provider-conf"},"vision":false},{"id":"meta-llama/llama-3.1-405b-instruct","name":"Meta: Llama 3.1 405B Instruct","display_name":"Meta: Llama 3.1 405B Instruct","type":"completion","context_length":4096,"max_output_tokens":4096,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"source":"public-provider-conf"},"vision":false},{"id":"meta-llama/llama-3.1-70b-instruct","name":"Meta: Llama 3.1 70B Instruct","display_name":"Meta: Llama 3.1 70B Instruct","type":"completion","context_length":4096,"max_output_tokens":4096,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"source":"public-provider-conf"},"vision":false},{"id":"meta-llama/llama-3.1-8b-instruct","name":"Meta: Llama 3.1 8B Instruct","display_name":"Meta: Llama 3.1 8B Instruct","type":"completion","context_length":4096,"max_output_tokens":4096,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"source":"public-provider-conf"},"vision":false},{"id":"meta-llama/llama-3.2-11b-vision-instruct","name":"Meta: Llama 3.2 11B Vision Instruct","display_name":"Meta: Llama 3.2 11B Vision Instruct","type":"completion","context_length":4096,"max_output_tokens":4096,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"source":"public-provider-conf"},"vision":false},{"id":"meta-llama/llama-3.2-1b-instruct","name":"Meta: Llama 3.2 1B Instruct","display_name":"Meta: Llama 3.2 1B Instruct","type":"completion","context_length":4096,"max_output_tokens":4096,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"source":"public-provider-conf"},"vision":false},{"id":"meta-llama/llama-3.2-3b-instruct","name":"Meta: Llama 3.2 3B Instruct","display_name":"Meta: Llama 3.2 3B Instruct","type":"completion","context_length":4096,"max_output_tokens":4096,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"source":"public-provider-conf"},"vision":false},{"id":"meta-llama/llama-3.2-90b-vision-instruct","name":"Meta: Llama 3.2 90B Vision Instruct","display_name":"Meta: Llama 3.2 90B Vision Instruct","type":"completion","context_length":4096,"max_output_tokens":4096,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"source":"public-provider-conf"},"vision":false},{"id":"meta-llama/llama-3.3-70b-instruct","name":"Meta: Llama 3.3 70B Instruct","display_name":"Meta: Llama 3.3 70B Instruct","type":"completion","context_length":4096,"max_output_tokens":4096,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"source":"public-provider-conf"},"vision":false},{"id":"meta-llama/llama-4-maverick","name":"Meta: Llama 4 Maverick","display_name":"Meta: Llama 4 Maverick","type":"chat","context_length":4096,"max_output_tokens":4096,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"source":"public-provider-conf"},"vision":false},{"id":"meta-llama/llama-4-scout","name":"Meta: Llama 4 Scout","display_name":"Meta: Llama 4 Scout","type":"chat","context_length":4096,"max_output_tokens":4096,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"source":"public-provider-conf"},"vision":false},{"id":"meta-llama/llama-guard-4-12b","name":"Meta: Llama Guard 4 12B","display_name":"Meta: Llama Guard 4 12B","type":"chat","context_length":4096,"max_output_tokens":4096,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"source":"public-provider-conf"},"vision":false},{"id":"meta-llama/llama-guard-2-8b","name":"Meta: LlamaGuard 2 8B","display_name":"Meta: LlamaGuard 2 8B","type":"chat","context_length":4096,"max_output_tokens":4096,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"source":"public-provider-conf"},"vision":false},{"id":"microsoft/mai-ds-r1","name":"Microsoft: MAI DS R1","display_name":"Microsoft: MAI DS R1","type":"chat","context_length":4096,"max_output_tokens":4096,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"source":"public-provider-conf"},"vision":false},{"id":"microsoft/phi-4","name":"Microsoft: Phi 4","display_name":"Microsoft: Phi 4","type":"chat","context_length":4096,"max_output_tokens":4096,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"source":"public-provider-conf"},"vision":false},{"id":"microsoft/phi-4-multimodal-instruct","name":"Microsoft: Phi 4 Multimodal Instruct","display_name":"Microsoft: Phi 4 Multimodal Instruct","type":"completion","context_length":4096,"max_output_tokens":4096,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"source":"public-provider-conf"},"vision":false},{"id":"microsoft/phi-4-reasoning-plus","name":"Microsoft: Phi 4 Reasoning Plus","display_name":"Microsoft: Phi 4 Reasoning Plus","type":"chat","context_length":4096,"max_output_tokens":4096,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"source":"public-provider-conf"},"vision":false},{"id":"microsoft/phi-3-medium-128k-instruct","name":"Microsoft: Phi-3 Medium 128K Instruct","display_name":"Microsoft: Phi-3 Medium 128K Instruct","type":"completion","context_length":4096,"max_output_tokens":4096,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"source":"public-provider-conf"},"vision":false},{"id":"microsoft/phi-3-mini-128k-instruct","name":"Microsoft: Phi-3 Mini 128K Instruct","display_name":"Microsoft: Phi-3 Mini 128K Instruct","type":"completion","context_length":4096,"max_output_tokens":4096,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"source":"public-provider-conf"},"vision":false},{"id":"microsoft/phi-3.5-mini-128k-instruct","name":"Microsoft: Phi-3.5 Mini 128K Instruct","display_name":"Microsoft: Phi-3.5 Mini 128K Instruct","type":"completion","context_length":4096,"max_output_tokens":4096,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"source":"public-provider-conf"},"vision":false},{"id":"minimax/minimax-m1","name":"MiniMax: MiniMax M1","display_name":"MiniMax: MiniMax M1","type":"chat","context_length":4096,"max_output_tokens":4096,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"source":"public-provider-conf"},"vision":false},{"id":"minimax/minimax-01","name":"MiniMax: MiniMax-01","display_name":"MiniMax: MiniMax-01","type":"chat","context_length":4096,"max_output_tokens":4096,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"source":"public-provider-conf"},"vision":false},{"id":"mistralai/mistral-large","name":"Mistral Large","display_name":"Mistral Large","type":"chat","context_length":4096,"max_output_tokens":4096,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"source":"public-provider-conf"},"vision":false},{"id":"mistralai/mistral-large-2407","name":"Mistral Large 2407","display_name":"Mistral Large 2407","type":"chat","context_length":4096,"max_output_tokens":4096,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"source":"public-provider-conf"},"vision":false},{"id":"mistralai/mistral-large-2411","name":"Mistral Large 2411","display_name":"Mistral Large 2411","type":"chat","context_length":4096,"max_output_tokens":4096,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"source":"public-provider-conf"},"vision":false},{"id":"mistralai/mistral-small","name":"Mistral Small","display_name":"Mistral Small","type":"chat","context_length":4096,"max_output_tokens":4096,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"source":"public-provider-conf"},"vision":false},{"id":"mistralai/mistral-tiny","name":"Mistral Tiny","display_name":"Mistral Tiny","type":"chat","context_length":4096,"max_output_tokens":4096,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"source":"public-provider-conf"},"vision":false},{"id":"mistralai/codestral-2501","name":"Mistral: Codestral 2501","display_name":"Mistral: Codestral 2501","type":"chat","context_length":4096,"max_output_tokens":4096,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"source":"public-provider-conf"},"vision":false},{"id":"mistralai/codestral-2508","name":"Mistral: Codestral 2508","display_name":"Mistral: Codestral 2508","type":"chat","context_length":4096,"max_output_tokens":4096,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"source":"public-provider-conf"},"vision":false},{"id":"mistralai/devstral-medium","name":"Mistral: Devstral Medium","display_name":"Mistral: Devstral Medium","type":"chat","context_length":4096,"max_output_tokens":4096,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"source":"public-provider-conf"},"vision":false},{"id":"mistralai/devstral-small","name":"Mistral: Devstral Small 1.1","display_name":"Mistral: Devstral Small 1.1","type":"chat","context_length":4096,"max_output_tokens":4096,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"source":"public-provider-conf"},"vision":false},{"id":"mistralai/devstral-small-2505","name":"Mistral: Devstral Small 2505","display_name":"Mistral: Devstral Small 2505","type":"chat","context_length":4096,"max_output_tokens":4096,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"source":"public-provider-conf"},"vision":false},{"id":"mistralai/magistral-medium-2506","name":"Mistral: Magistral Medium 2506","display_name":"Mistral: Magistral Medium 2506","type":"chat","context_length":4096,"max_output_tokens":4096,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"source":"public-provider-conf"},"vision":false},{"id":"mistralai/magistral-medium-2506:thinking","name":"Mistral: Magistral Medium 2506 (thinking)","display_name":"Mistral: Magistral Medium 2506 (thinking)","type":"chat","context_length":4096,"max_output_tokens":4096,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"source":"public-provider-conf"},"vision":false},{"id":"mistralai/magistral-small-2506","name":"Mistral: Magistral Small 2506","display_name":"Mistral: Magistral Small 2506","type":"chat","context_length":4096,"max_output_tokens":4096,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"source":"public-provider-conf"},"vision":false},{"id":"mistralai/ministral-3b","name":"Mistral: Ministral 3B","display_name":"Mistral: Ministral 3B","type":"chat","context_length":4096,"max_output_tokens":4096,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"source":"public-provider-conf"},"vision":false},{"id":"mistralai/ministral-8b","name":"Mistral: Ministral 8B","display_name":"Mistral: Ministral 8B","type":"chat","context_length":4096,"max_output_tokens":4096,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"source":"public-provider-conf"},"vision":false},{"id":"mistralai/mistral-7b-instruct","name":"Mistral: Mistral 7B Instruct","display_name":"Mistral: Mistral 7B Instruct","type":"completion","context_length":4096,"max_output_tokens":4096,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"source":"public-provider-conf"},"vision":false},{"id":"mistralai/mistral-7b-instruct-v0.1","name":"Mistral: Mistral 7B Instruct v0.1","display_name":"Mistral: Mistral 7B Instruct v0.1","type":"completion","context_length":4096,"max_output_tokens":4096,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"source":"public-provider-conf"},"vision":false},{"id":"mistralai/mistral-7b-instruct-v0.3","name":"Mistral: Mistral 7B Instruct v0.3","display_name":"Mistral: Mistral 7B Instruct v0.3","type":"completion","context_length":4096,"max_output_tokens":4096,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"source":"public-provider-conf"},"vision":false},{"id":"mistralai/mistral-medium-3","name":"Mistral: Mistral Medium 3","display_name":"Mistral: Mistral Medium 3","type":"chat","context_length":4096,"max_output_tokens":4096,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"source":"public-provider-conf"},"vision":false},{"id":"mistralai/mistral-medium-3.1","name":"Mistral: Mistral Medium 3.1","display_name":"Mistral: Mistral Medium 3.1","type":"chat","context_length":4096,"max_output_tokens":4096,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"source":"public-provider-conf"},"vision":false},{"id":"mistralai/mistral-nemo","name":"Mistral: Mistral Nemo","display_name":"Mistral: Mistral Nemo","type":"chat","context_length":4096,"max_output_tokens":4096,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"source":"public-provider-conf"},"vision":false},{"id":"mistralai/mistral-small-24b-instruct-2501","name":"Mistral: Mistral Small 3","display_name":"Mistral: Mistral Small 3","type":"completion","context_length":4096,"max_output_tokens":4096,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"source":"public-provider-conf"},"vision":false},{"id":"mistralai/mistral-small-3.1-24b-instruct","name":"Mistral: Mistral Small 3.1 24B","display_name":"Mistral: Mistral Small 3.1 24B","type":"completion","context_length":4096,"max_output_tokens":4096,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"source":"public-provider-conf"},"vision":false},{"id":"mistralai/mistral-small-3.2-24b-instruct","name":"Mistral: Mistral Small 3.2 24B","display_name":"Mistral: Mistral Small 3.2 24B","type":"completion","context_length":4096,"max_output_tokens":4096,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"source":"public-provider-conf"},"vision":false},{"id":"mistralai/mixtral-8x22b-instruct","name":"Mistral: Mixtral 8x22B Instruct","display_name":"Mistral: Mixtral 8x22B Instruct","type":"completion","context_length":4096,"max_output_tokens":4096,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"source":"public-provider-conf"},"vision":false},{"id":"mistralai/mixtral-8x7b-instruct","name":"Mistral: Mixtral 8x7B Instruct","display_name":"Mistral: Mixtral 8x7B Instruct","type":"completion","context_length":4096,"max_output_tokens":4096,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"source":"public-provider-conf"},"vision":false},{"id":"mistralai/pixtral-12b","name":"Mistral: Pixtral 12B","display_name":"Mistral: Pixtral 12B","type":"chat","context_length":4096,"max_output_tokens":4096,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"source":"public-provider-conf"},"vision":false},{"id":"mistralai/pixtral-large-2411","name":"Mistral: Pixtral Large 2411","display_name":"Mistral: Pixtral Large 2411","type":"chat","context_length":4096,"max_output_tokens":4096,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"source":"public-provider-conf"},"vision":false},{"id":"mistralai/mistral-saba","name":"Mistral: Saba","display_name":"Mistral: Saba","type":"chat","context_length":4096,"max_output_tokens":4096,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"source":"public-provider-conf"},"vision":false},{"id":"moonshotai/kimi-dev-72b","name":"MoonshotAI: Kimi Dev 72B","display_name":"MoonshotAI: Kimi Dev 72B","type":"chat","context_length":4096,"max_output_tokens":4096,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"source":"public-provider-conf"},"vision":false},{"id":"moonshotai/kimi-k2","name":"MoonshotAI: Kimi K2 0711","display_name":"MoonshotAI: Kimi K2 0711","type":"chat","context_length":4096,"max_output_tokens":4096,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"source":"public-provider-conf"},"vision":false},{"id":"moonshotai/kimi-k2-0905","name":"MoonshotAI: Kimi K2 0905","display_name":"MoonshotAI: Kimi K2 0905","type":"chat","context_length":4096,"max_output_tokens":4096,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"source":"public-provider-conf"},"vision":false},{"id":"moonshotai/kimi-vl-a3b-thinking","name":"MoonshotAI: Kimi VL A3B Thinking","display_name":"MoonshotAI: Kimi VL A3B Thinking","type":"chat","context_length":4096,"max_output_tokens":4096,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"source":"public-provider-conf"},"vision":false},{"id":"morph/morph-v3-fast","name":"Morph: Morph V3 Fast","display_name":"Morph: Morph V3 Fast","type":"chat","context_length":4096,"max_output_tokens":4096,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"source":"public-provider-conf"},"vision":false},{"id":"morph/morph-v3-large","name":"Morph: Morph V3 Large","display_name":"Morph: Morph V3 Large","type":"chat","context_length":4096,"max_output_tokens":4096,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"source":"public-provider-conf"},"vision":false},{"id":"gryphe/mythomax-l2-13b","name":"MythoMax 13B","display_name":"MythoMax 13B","type":"chat","context_length":4096,"max_output_tokens":4096,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"source":"public-provider-conf"},"vision":false},{"id":"neversleep/llama-3-lumimaid-70b","name":"NeverSleep: Llama 3 Lumimaid 70B","display_name":"NeverSleep: Llama 3 Lumimaid 70B","type":"chat","context_length":4096,"max_output_tokens":4096,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"source":"public-provider-conf"},"vision":false},{"id":"neversleep/llama-3.1-lumimaid-8b","name":"NeverSleep: Lumimaid v0.2 8B","display_name":"NeverSleep: Lumimaid v0.2 8B","type":"chat","context_length":4096,"max_output_tokens":4096,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"source":"public-provider-conf"},"vision":false},{"id":"neversleep/noromaid-20b","name":"Noromaid 20B","display_name":"Noromaid 20B","type":"chat","context_length":4096,"max_output_tokens":4096,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"source":"public-provider-conf"},"vision":false},{"id":"nousresearch/deephermes-3-llama-3-8b-preview","name":"Nous: DeepHermes 3 Llama 3 8B Preview","display_name":"Nous: DeepHermes 3 Llama 3 8B Preview","type":"chat","context_length":4096,"max_output_tokens":4096,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"source":"public-provider-conf"},"vision":false},{"id":"nousresearch/deephermes-3-mistral-24b-preview","name":"Nous: DeepHermes 3 Mistral 24B Preview","display_name":"Nous: DeepHermes 3 Mistral 24B Preview","type":"chat","context_length":4096,"max_output_tokens":4096,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"source":"public-provider-conf"},"vision":false},{"id":"nousresearch/hermes-3-llama-3.1-405b","name":"Nous: Hermes 3 405B Instruct","display_name":"Nous: Hermes 3 405B Instruct","type":"chat","context_length":4096,"max_output_tokens":4096,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"source":"public-provider-conf"},"vision":false},{"id":"nousresearch/hermes-3-llama-3.1-70b","name":"Nous: Hermes 3 70B Instruct","display_name":"Nous: Hermes 3 70B Instruct","type":"chat","context_length":4096,"max_output_tokens":4096,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"source":"public-provider-conf"},"vision":false},{"id":"nousresearch/hermes-4-405b","name":"Nous: Hermes 4 405B","display_name":"Nous: Hermes 4 405B","type":"chat","context_length":4096,"max_output_tokens":4096,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"source":"public-provider-conf"},"vision":false},{"id":"nousresearch/hermes-4-70b","name":"Nous: Hermes 4 70B","display_name":"Nous: Hermes 4 70B","type":"chat","context_length":4096,"max_output_tokens":4096,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"source":"public-provider-conf"},"vision":false},{"id":"nousresearch/hermes-2-pro-llama-3-8b","name":"NousResearch: Hermes 2 Pro - Llama-3 8B","display_name":"NousResearch: Hermes 2 Pro - Llama-3 8B","type":"chat","context_length":4096,"max_output_tokens":4096,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"source":"public-provider-conf"},"vision":false},{"id":"nvidia/llama-3.1-nemotron-70b-instruct","name":"NVIDIA: Llama 3.1 Nemotron 70B Instruct","display_name":"NVIDIA: Llama 3.1 Nemotron 70B Instruct","type":"completion","context_length":4096,"max_output_tokens":4096,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"source":"public-provider-conf"},"vision":false},{"id":"nvidia/llama-3.1-nemotron-ultra-253b-v1","name":"NVIDIA: Llama 3.1 Nemotron Ultra 253B v1","display_name":"NVIDIA: Llama 3.1 Nemotron Ultra 253B v1","type":"chat","context_length":4096,"max_output_tokens":4096,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"source":"public-provider-conf"},"vision":false},{"id":"nvidia/nemotron-nano-9b-v2","name":"NVIDIA: Nemotron Nano 9B V2","display_name":"NVIDIA: Nemotron Nano 9B V2","type":"chat","context_length":4096,"max_output_tokens":4096,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"source":"public-provider-conf"},"vision":false},{"id":"openai/chatgpt-4o-latest","name":"OpenAI: ChatGPT-4o","display_name":"OpenAI: ChatGPT-4o","type":"chat","context_length":4096,"max_output_tokens":4096,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"source":"public-provider-conf"},"vision":false},{"id":"openai/codex-mini","name":"OpenAI: Codex Mini","display_name":"OpenAI: Codex Mini","type":"chat","context_length":4096,"max_output_tokens":4096,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"source":"public-provider-conf"},"vision":false},{"id":"openai/gpt-3.5-turbo","name":"OpenAI: GPT-3.5 Turbo","display_name":"OpenAI: GPT-3.5 Turbo","type":"chat","context_length":4096,"max_output_tokens":4096,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"source":"public-provider-conf"},"vision":false},{"id":"openai/gpt-3.5-turbo-0613","name":"OpenAI: GPT-3.5 Turbo (older v0613)","display_name":"OpenAI: GPT-3.5 Turbo (older v0613)","type":"chat","context_length":4096,"max_output_tokens":4096,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"source":"public-provider-conf"},"vision":false},{"id":"openai/gpt-3.5-turbo-16k","name":"OpenAI: GPT-3.5 Turbo 16k","display_name":"OpenAI: GPT-3.5 Turbo 16k","type":"chat","context_length":4096,"max_output_tokens":4096,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"source":"public-provider-conf"},"vision":false},{"id":"openai/gpt-3.5-turbo-instruct","name":"OpenAI: GPT-3.5 Turbo Instruct","display_name":"OpenAI: GPT-3.5 Turbo Instruct","type":"completion","context_length":4096,"max_output_tokens":4096,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"source":"public-provider-conf"},"vision":false},{"id":"openai/gpt-4","name":"OpenAI: GPT-4","display_name":"OpenAI: GPT-4","type":"chat","context_length":4096,"max_output_tokens":4096,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"source":"public-provider-conf"},"vision":false},{"id":"openai/gpt-4-0314","name":"OpenAI: GPT-4 (older v0314)","display_name":"OpenAI: GPT-4 (older v0314)","type":"chat","context_length":4096,"max_output_tokens":4096,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"source":"public-provider-conf"},"vision":false},{"id":"openai/gpt-4-turbo","name":"OpenAI: GPT-4 Turbo","display_name":"OpenAI: GPT-4 Turbo","type":"chat","context_length":4096,"max_output_tokens":4096,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"source":"public-provider-conf"},"vision":false},{"id":"openai/gpt-4-1106-preview","name":"OpenAI: GPT-4 Turbo (older v1106)","display_name":"OpenAI: GPT-4 Turbo (older v1106)","type":"chat","context_length":4096,"max_output_tokens":4096,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"source":"public-provider-conf"},"vision":false},{"id":"openai/gpt-4-turbo-preview","name":"OpenAI: GPT-4 Turbo Preview","display_name":"OpenAI: GPT-4 Turbo Preview","type":"chat","context_length":4096,"max_output_tokens":4096,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"source":"public-provider-conf"},"vision":false},{"id":"openai/gpt-4.1","name":"OpenAI: GPT-4.1","display_name":"OpenAI: GPT-4.1","type":"chat","context_length":4096,"max_output_tokens":4096,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"source":"public-provider-conf"},"vision":false},{"id":"openai/gpt-4.1-mini","name":"OpenAI: GPT-4.1 Mini","display_name":"OpenAI: GPT-4.1 Mini","type":"chat","context_length":4096,"max_output_tokens":4096,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"source":"public-provider-conf"},"vision":false},{"id":"openai/gpt-4.1-nano","name":"OpenAI: GPT-4.1 Nano","display_name":"OpenAI: GPT-4.1 Nano","type":"chat","context_length":4096,"max_output_tokens":4096,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"source":"public-provider-conf"},"vision":false},{"id":"openai/gpt-4o","name":"OpenAI: GPT-4o","display_name":"OpenAI: GPT-4o","type":"chat","context_length":4096,"max_output_tokens":4096,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"source":"public-provider-conf"},"vision":false},{"id":"openai/gpt-4o-2024-05-13","name":"OpenAI: GPT-4o (2024-05-13)","display_name":"OpenAI: GPT-4o (2024-05-13)","type":"chat","context_length":4096,"max_output_tokens":4096,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"source":"public-provider-conf"},"vision":false},{"id":"openai/gpt-4o-2024-08-06","name":"OpenAI: GPT-4o (2024-08-06)","display_name":"OpenAI: GPT-4o (2024-08-06)","type":"chat","context_length":4096,"max_output_tokens":4096,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"source":"public-provider-conf"},"vision":false},{"id":"openai/gpt-4o-2024-11-20","name":"OpenAI: GPT-4o (2024-11-20)","display_name":"OpenAI: GPT-4o (2024-11-20)","type":"chat","context_length":4096,"max_output_tokens":4096,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"source":"public-provider-conf"},"vision":false},{"id":"openai/gpt-4o:extended","name":"OpenAI: GPT-4o (extended)","display_name":"OpenAI: GPT-4o (extended)","type":"chat","context_length":4096,"max_output_tokens":4096,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"source":"public-provider-conf"},"vision":false},{"id":"openai/gpt-4o-audio-preview","name":"OpenAI: GPT-4o Audio","display_name":"OpenAI: GPT-4o Audio","type":"chat","context_length":4096,"max_output_tokens":4096,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"source":"public-provider-conf"},"vision":false},{"id":"openai/gpt-4o-search-preview","name":"OpenAI: GPT-4o Search Preview","display_name":"OpenAI: GPT-4o Search Preview","type":"chat","context_length":4096,"max_output_tokens":4096,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"source":"public-provider-conf"},"vision":false},{"id":"openai/gpt-4o-mini","name":"OpenAI: GPT-4o-mini","display_name":"OpenAI: GPT-4o-mini","type":"chat","context_length":4096,"max_output_tokens":4096,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"source":"public-provider-conf"},"vision":false},{"id":"openai/gpt-4o-mini-2024-07-18","name":"OpenAI: GPT-4o-mini (2024-07-18)","display_name":"OpenAI: GPT-4o-mini (2024-07-18)","type":"chat","context_length":4096,"max_output_tokens":4096,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"source":"public-provider-conf"},"vision":false},{"id":"openai/gpt-4o-mini-search-preview","name":"OpenAI: GPT-4o-mini Search Preview","display_name":"OpenAI: GPT-4o-mini Search Preview","type":"chat","context_length":4096,"max_output_tokens":4096,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"source":"public-provider-conf"},"vision":false},{"id":"openai/gpt-5","name":"OpenAI: GPT-5","display_name":"OpenAI: GPT-5","type":"chat","context_length":4096,"max_output_tokens":4096,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"source":"public-provider-conf"},"vision":false},{"id":"openai/gpt-5-chat","name":"OpenAI: GPT-5 Chat","display_name":"OpenAI: GPT-5 Chat","type":"chat","context_length":4096,"max_output_tokens":4096,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"source":"public-provider-conf"},"vision":false},{"id":"openai/gpt-5-codex","name":"OpenAI: GPT-5 Codex","display_name":"OpenAI: GPT-5 Codex","type":"chat","context_length":4096,"max_output_tokens":4096,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"source":"public-provider-conf"},"vision":false},{"id":"openai/gpt-5-mini","name":"OpenAI: GPT-5 Mini","display_name":"OpenAI: GPT-5 Mini","type":"chat","context_length":4096,"max_output_tokens":4096,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"source":"public-provider-conf"},"vision":false},{"id":"openai/gpt-5-nano","name":"OpenAI: GPT-5 Nano","display_name":"OpenAI: GPT-5 Nano","type":"chat","context_length":4096,"max_output_tokens":4096,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"source":"public-provider-conf"},"vision":false},{"id":"openai/gpt-oss-120b","name":"OpenAI: gpt-oss-120b","display_name":"OpenAI: gpt-oss-120b","type":"chat","context_length":4096,"max_output_tokens":4096,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"source":"public-provider-conf"},"vision":false},{"id":"openai/gpt-oss-20b","name":"OpenAI: gpt-oss-20b","display_name":"OpenAI: gpt-oss-20b","type":"chat","context_length":4096,"max_output_tokens":4096,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"source":"public-provider-conf"},"vision":false},{"id":"openai/o1","name":"OpenAI: o1","display_name":"OpenAI: o1","type":"chat","context_length":4096,"max_output_tokens":4096,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"source":"public-provider-conf"},"vision":false},{"id":"openai/o1-mini","name":"OpenAI: o1-mini","display_name":"OpenAI: o1-mini","type":"chat","context_length":4096,"max_output_tokens":4096,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"source":"public-provider-conf"},"vision":false},{"id":"openai/o1-mini-2024-09-12","name":"OpenAI: o1-mini (2024-09-12)","display_name":"OpenAI: o1-mini (2024-09-12)","type":"chat","context_length":4096,"max_output_tokens":4096,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"source":"public-provider-conf"},"vision":false},{"id":"openai/o1-pro","name":"OpenAI: o1-pro","display_name":"OpenAI: o1-pro","type":"chat","context_length":4096,"max_output_tokens":4096,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"source":"public-provider-conf"},"vision":false},{"id":"openai/o3","name":"OpenAI: o3","display_name":"OpenAI: o3","type":"chat","context_length":4096,"max_output_tokens":4096,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"source":"public-provider-conf"},"vision":false},{"id":"openai/o3-mini","name":"OpenAI: o3 Mini","display_name":"OpenAI: o3 Mini","type":"chat","context_length":4096,"max_output_tokens":4096,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"source":"public-provider-conf"},"vision":false},{"id":"openai/o3-mini-high","name":"OpenAI: o3 Mini High","display_name":"OpenAI: o3 Mini High","type":"chat","context_length":4096,"max_output_tokens":4096,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"source":"public-provider-conf"},"vision":false},{"id":"openai/o3-pro","name":"OpenAI: o3 Pro","display_name":"OpenAI: o3 Pro","type":"chat","context_length":4096,"max_output_tokens":4096,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"source":"public-provider-conf"},"vision":false},{"id":"openai/o4-mini","name":"OpenAI: o4 Mini","display_name":"OpenAI: o4 Mini","type":"chat","context_length":4096,"max_output_tokens":4096,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"source":"public-provider-conf"},"vision":false},{"id":"openai/o4-mini-high","name":"OpenAI: o4 Mini High","display_name":"OpenAI: o4 Mini High","type":"chat","context_length":4096,"max_output_tokens":4096,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"source":"public-provider-conf"},"vision":false},{"id":"opengvlab/internvl3-78b","name":"OpenGVLab: InternVL3 78B","display_name":"OpenGVLab: InternVL3 78B","type":"chat","context_length":4096,"max_output_tokens":4096,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"source":"public-provider-conf"},"vision":false},{"id":"perplexity/r1-1776","name":"Perplexity: R1 1776","display_name":"Perplexity: R1 1776","type":"chat","context_length":4096,"max_output_tokens":4096,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"source":"public-provider-conf"},"vision":false},{"id":"perplexity/sonar","name":"Perplexity: Sonar","display_name":"Perplexity: Sonar","type":"chat","context_length":4096,"max_output_tokens":4096,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"source":"public-provider-conf"},"vision":false},{"id":"perplexity/sonar-deep-research","name":"Perplexity: Sonar Deep Research","display_name":"Perplexity: Sonar Deep Research","type":"chat","context_length":4096,"max_output_tokens":4096,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"source":"public-provider-conf"},"vision":false},{"id":"perplexity/sonar-pro","name":"Perplexity: Sonar Pro","display_name":"Perplexity: Sonar Pro","type":"chat","context_length":4096,"max_output_tokens":4096,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"source":"public-provider-conf"},"vision":false},{"id":"perplexity/sonar-reasoning","name":"Perplexity: Sonar Reasoning","display_name":"Perplexity: Sonar Reasoning","type":"chat","context_length":4096,"max_output_tokens":4096,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"source":"public-provider-conf"},"vision":false},{"id":"perplexity/sonar-reasoning-pro","name":"Perplexity: Sonar Reasoning Pro","display_name":"Perplexity: Sonar Reasoning Pro","type":"chat","context_length":4096,"max_output_tokens":4096,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"source":"public-provider-conf"},"vision":false},{"id":"qwen/qwen-plus-2025-07-28","name":"Qwen: Qwen Plus 0728","display_name":"Qwen: Qwen Plus 0728","type":"chat","context_length":4096,"max_output_tokens":4096,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"source":"public-provider-conf"},"vision":false},{"id":"qwen/qwen-plus-2025-07-28:thinking","name":"Qwen: Qwen Plus 0728 (thinking)","display_name":"Qwen: Qwen Plus 0728 (thinking)","type":"chat","context_length":4096,"max_output_tokens":4096,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"source":"public-provider-conf"},"vision":false},{"id":"qwen/qwen-vl-max","name":"Qwen: Qwen VL Max","display_name":"Qwen: Qwen VL Max","type":"chat","context_length":4096,"max_output_tokens":4096,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"source":"public-provider-conf"},"vision":false},{"id":"qwen/qwen-vl-plus","name":"Qwen: Qwen VL Plus","display_name":"Qwen: Qwen VL Plus","type":"chat","context_length":4096,"max_output_tokens":4096,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"source":"public-provider-conf"},"vision":false},{"id":"qwen/qwen-max","name":"Qwen: Qwen-Max","display_name":"Qwen: Qwen-Max","type":"chat","context_length":4096,"max_output_tokens":4096,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"source":"public-provider-conf"},"vision":false},{"id":"qwen/qwen-plus","name":"Qwen: Qwen-Plus","display_name":"Qwen: Qwen-Plus","type":"chat","context_length":4096,"max_output_tokens":4096,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"source":"public-provider-conf"},"vision":false},{"id":"qwen/qwen-turbo","name":"Qwen: Qwen-Turbo","display_name":"Qwen: Qwen-Turbo","type":"chat","context_length":4096,"max_output_tokens":4096,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"source":"public-provider-conf"},"vision":false},{"id":"qwen/qwen2.5-vl-32b-instruct","name":"Qwen: Qwen2.5 VL 32B Instruct","display_name":"Qwen: Qwen2.5 VL 32B Instruct","type":"completion","context_length":4096,"max_output_tokens":4096,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"source":"public-provider-conf"},"vision":false},{"id":"qwen/qwen2.5-vl-72b-instruct","name":"Qwen: Qwen2.5 VL 72B Instruct","display_name":"Qwen: Qwen2.5 VL 72B Instruct","type":"completion","context_length":4096,"max_output_tokens":4096,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"source":"public-provider-conf"},"vision":false},{"id":"qwen/qwen-2.5-vl-7b-instruct","name":"Qwen: Qwen2.5-VL 7B Instruct","display_name":"Qwen: Qwen2.5-VL 7B Instruct","type":"completion","context_length":4096,"max_output_tokens":4096,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"source":"public-provider-conf"},"vision":false},{"id":"qwen/qwen3-14b","name":"Qwen: Qwen3 14B","display_name":"Qwen: Qwen3 14B","type":"chat","context_length":4096,"max_output_tokens":4096,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"source":"public-provider-conf"},"vision":false},{"id":"qwen/qwen3-235b-a22b","name":"Qwen: Qwen3 235B A22B","display_name":"Qwen: Qwen3 235B A22B","type":"chat","context_length":4096,"max_output_tokens":4096,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"source":"public-provider-conf"},"vision":false},{"id":"qwen/qwen3-235b-a22b-2507","name":"Qwen: Qwen3 235B A22B Instruct 2507","display_name":"Qwen: Qwen3 235B A22B Instruct 2507","type":"chat","context_length":4096,"max_output_tokens":4096,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"source":"public-provider-conf"},"vision":false},{"id":"qwen/qwen3-235b-a22b-thinking-2507","name":"Qwen: Qwen3 235B A22B Thinking 2507","display_name":"Qwen: Qwen3 235B A22B Thinking 2507","type":"chat","context_length":4096,"max_output_tokens":4096,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"source":"public-provider-conf"},"vision":false},{"id":"qwen/qwen3-30b-a3b","name":"Qwen: Qwen3 30B A3B","display_name":"Qwen: Qwen3 30B A3B","type":"chat","context_length":4096,"max_output_tokens":4096,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"source":"public-provider-conf"},"vision":false},{"id":"qwen/qwen3-30b-a3b-instruct-2507","name":"Qwen: Qwen3 30B A3B Instruct 2507","display_name":"Qwen: Qwen3 30B A3B Instruct 2507","type":"completion","context_length":4096,"max_output_tokens":4096,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"source":"public-provider-conf"},"vision":false},{"id":"qwen/qwen3-30b-a3b-thinking-2507","name":"Qwen: Qwen3 30B A3B Thinking 2507","display_name":"Qwen: Qwen3 30B A3B Thinking 2507","type":"chat","context_length":4096,"max_output_tokens":4096,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"source":"public-provider-conf"},"vision":false},{"id":"qwen/qwen3-32b","name":"Qwen: Qwen3 32B","display_name":"Qwen: Qwen3 32B","type":"chat","context_length":4096,"max_output_tokens":4096,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"source":"public-provider-conf"},"vision":false},{"id":"qwen/qwen3-8b","name":"Qwen: Qwen3 8B","display_name":"Qwen: Qwen3 8B","type":"chat","context_length":4096,"max_output_tokens":4096,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"source":"public-provider-conf"},"vision":false},{"id":"qwen/qwen3-coder-30b-a3b-instruct","name":"Qwen: Qwen3 Coder 30B A3B Instruct","display_name":"Qwen: Qwen3 Coder 30B A3B Instruct","type":"completion","context_length":4096,"max_output_tokens":4096,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"source":"public-provider-conf"},"vision":false},{"id":"qwen/qwen3-coder","name":"Qwen: Qwen3 Coder 480B A35B","display_name":"Qwen: Qwen3 Coder 480B A35B","type":"chat","context_length":4096,"max_output_tokens":4096,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"source":"public-provider-conf"},"vision":false},{"id":"qwen/qwen3-coder-480b-a35b-instruct","name":"Qwen: Qwen3 Coder 480B A35B Instruct","display_name":"Qwen: Qwen3 Coder 480B A35B Instruct","type":"completion","context_length":4096,"max_output_tokens":4096,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"source":"public-provider-conf"},"vision":false},{"id":"qwen/qwen3-coder-flash","name":"Qwen: Qwen3 Coder Flash","display_name":"Qwen: Qwen3 Coder Flash","type":"chat","context_length":4096,"max_output_tokens":4096,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"source":"public-provider-conf"},"vision":false},{"id":"qwen/qwen3-coder-plus","name":"Qwen: Qwen3 Coder Plus","display_name":"Qwen: Qwen3 Coder Plus","type":"chat","context_length":4096,"max_output_tokens":4096,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"source":"public-provider-conf"},"vision":false},{"id":"qwen/qwen3-max","name":"Qwen: Qwen3 Max","display_name":"Qwen: Qwen3 Max","type":"chat","context_length":4096,"max_output_tokens":4096,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"source":"public-provider-conf"},"vision":false},{"id":"qwen/qwen3-next-80b-a3b-instruct","name":"Qwen: Qwen3 Next 80B A3B Instruct","display_name":"Qwen: Qwen3 Next 80B A3B Instruct","type":"completion","context_length":4096,"max_output_tokens":4096,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"source":"public-provider-conf"},"vision":false},{"id":"qwen/qwen3-next-80b-a3b-thinking","name":"Qwen: Qwen3 Next 80B A3B Thinking","display_name":"Qwen: Qwen3 Next 80B A3B Thinking","type":"chat","context_length":4096,"max_output_tokens":4096,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"source":"public-provider-conf"},"vision":false},{"id":"qwen/qwen3-vl-235b-a22b-instruct","name":"Qwen: Qwen3 VL 235B A22B Instruct","display_name":"Qwen: Qwen3 VL 235B A22B Instruct","type":"completion","context_length":4096,"max_output_tokens":4096,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"source":"public-provider-conf"},"vision":false},{"id":"qwen/qwen3-vl-235b-a22b-thinking","name":"Qwen: Qwen3 VL 235B A22B Thinking","display_name":"Qwen: Qwen3 VL 235B A22B Thinking","type":"chat","context_length":4096,"max_output_tokens":4096,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"source":"public-provider-conf"},"vision":false},{"id":"qwen/qwq-32b","name":"Qwen: QwQ 32B","display_name":"Qwen: QwQ 32B","type":"chat","context_length":4096,"max_output_tokens":4096,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"source":"public-provider-conf"},"vision":false},{"id":"qwen/text-embedding-v3","name":"Qwen: Text Embedding v3","display_name":"Qwen: Text Embedding v3","type":"embedding","context_length":4096,"max_output_tokens":4096,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"source":"public-provider-conf"},"vision":false},{"id":"qwen/text-embedding-v4","name":"Qwen: Text Embedding v4","display_name":"Qwen: Text Embedding v4","type":"embedding","context_length":4096,"max_output_tokens":4096,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"source":"public-provider-conf"},"vision":false},{"id":"qwen/qwen-2.5-72b-instruct","name":"Qwen2.5 72B Instruct","display_name":"Qwen2.5 72B Instruct","type":"completion","context_length":4096,"max_output_tokens":4096,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"source":"public-provider-conf"},"vision":false},{"id":"qwen/qwen-2.5-7b-instruct","name":"Qwen2.5 7B Instruct","display_name":"Qwen2.5 7B Instruct","type":"completion","context_length":4096,"max_output_tokens":4096,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"source":"public-provider-conf"},"vision":false},{"id":"qwen/qwen-2.5-coder-32b-instruct","name":"Qwen2.5 Coder 32B Instruct","display_name":"Qwen2.5 Coder 32B Instruct","type":"completion","context_length":4096,"max_output_tokens":4096,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"source":"public-provider-conf"},"vision":false},{"id":"undi95/remm-slerp-l2-13b","name":"ReMM SLERP 13B","display_name":"ReMM SLERP 13B","type":"chat","context_length":4096,"max_output_tokens":4096,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"source":"public-provider-conf"},"vision":false},{"id":"sao10k/l3-lunaris-8b","name":"Sao10K: Llama 3 8B Lunaris","display_name":"Sao10K: Llama 3 8B Lunaris","type":"chat","context_length":4096,"max_output_tokens":4096,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"source":"public-provider-conf"},"vision":false},{"id":"sao10k/l3-euryale-70b","name":"Sao10k: Llama 3 Euryale 70B v2.1","display_name":"Sao10k: Llama 3 Euryale 70B v2.1","type":"chat","context_length":4096,"max_output_tokens":4096,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"source":"public-provider-conf"},"vision":false},{"id":"sao10k/l3.1-euryale-70b","name":"Sao10K: Llama 3.1 Euryale 70B v2.2","display_name":"Sao10K: Llama 3.1 Euryale 70B v2.2","type":"chat","context_length":4096,"max_output_tokens":4096,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"source":"public-provider-conf"},"vision":false},{"id":"sao10k/l3.3-euryale-70b","name":"Sao10K: Llama 3.3 Euryale 70B","display_name":"Sao10K: Llama 3.3 Euryale 70B","type":"chat","context_length":4096,"max_output_tokens":4096,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"source":"public-provider-conf"},"vision":false},{"id":"shisa-ai/shisa-v2-llama3.3-70b","name":"Shisa AI: Shisa V2 Llama 3.3 70B","display_name":"Shisa AI: Shisa V2 Llama 3.3 70B","type":"chat","context_length":4096,"max_output_tokens":4096,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"source":"public-provider-conf"},"vision":false},{"id":"raifle/sorcererlm-8x22b","name":"SorcererLM 8x22B","display_name":"SorcererLM 8x22B","type":"chat","context_length":4096,"max_output_tokens":4096,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"source":"public-provider-conf"},"vision":false},{"id":"stepfun-ai/step3","name":"StepFun: Step3","display_name":"StepFun: Step3","type":"chat","context_length":4096,"max_output_tokens":4096,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"source":"public-provider-conf"},"vision":false},{"id":"switchpoint/router","name":"Switchpoint Router","display_name":"Switchpoint Router","type":"chat","context_length":4096,"max_output_tokens":4096,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"source":"public-provider-conf"},"vision":false},{"id":"tencent/hunyuan-a13b-instruct","name":"Tencent: Hunyuan A13B Instruct","display_name":"Tencent: Hunyuan A13B Instruct","type":"completion","context_length":4096,"max_output_tokens":4096,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"source":"public-provider-conf"},"vision":false},{"id":"thedrummer/anubis-70b-v1.1","name":"TheDrummer: Anubis 70B V1.1","display_name":"TheDrummer: Anubis 70B V1.1","type":"chat","context_length":4096,"max_output_tokens":4096,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"source":"public-provider-conf"},"vision":false},{"id":"thedrummer/anubis-pro-105b-v1","name":"TheDrummer: Anubis Pro 105B V1","display_name":"TheDrummer: Anubis Pro 105B V1","type":"chat","context_length":4096,"max_output_tokens":4096,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"source":"public-provider-conf"},"vision":false},{"id":"thedrummer/rocinante-12b","name":"TheDrummer: Rocinante 12B","display_name":"TheDrummer: Rocinante 12B","type":"chat","context_length":4096,"max_output_tokens":4096,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"source":"public-provider-conf"},"vision":false},{"id":"thedrummer/skyfall-36b-v2","name":"TheDrummer: Skyfall 36B V2","display_name":"TheDrummer: Skyfall 36B V2","type":"chat","context_length":4096,"max_output_tokens":4096,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"source":"public-provider-conf"},"vision":false},{"id":"thedrummer/unslopnemo-12b","name":"TheDrummer: UnslopNemo 12B","display_name":"TheDrummer: UnslopNemo 12B","type":"chat","context_length":4096,"max_output_tokens":4096,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"source":"public-provider-conf"},"vision":false},{"id":"thudm/glm-4.1v-9b-thinking","name":"THUDM: GLM 4.1V 9B Thinking","display_name":"THUDM: GLM 4.1V 9B Thinking","type":"chat","context_length":4096,"max_output_tokens":4096,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"source":"public-provider-conf"},"vision":false},{"id":"thudm/glm-z1-32b","name":"THUDM: GLM Z1 32B","display_name":"THUDM: GLM Z1 32B","type":"chat","context_length":4096,"max_output_tokens":4096,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"source":"public-provider-conf"},"vision":false},{"id":"tngtech/deepseek-r1t-chimera","name":"TNG: DeepSeek R1T Chimera","display_name":"TNG: DeepSeek R1T Chimera","type":"chat","context_length":4096,"max_output_tokens":4096,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"source":"public-provider-conf"},"vision":false},{"id":"tngtech/deepseek-r1t2-chimera","name":"TNG: DeepSeek R1T2 Chimera","display_name":"TNG: DeepSeek R1T2 Chimera","type":"chat","context_length":4096,"max_output_tokens":4096,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"source":"public-provider-conf"},"vision":false},{"id":"alibaba/tongyi-deepresearch-30b-a3b","name":"Tongyi DeepResearch 30B A3B","display_name":"Tongyi DeepResearch 30B A3B","type":"chat","context_length":4096,"max_output_tokens":4096,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"source":"public-provider-conf"},"vision":false},{"id":"microsoft/wizardlm-2-8x22b","name":"WizardLM-2 8x22B","display_name":"WizardLM-2 8x22B","type":"chat","context_length":4096,"max_output_tokens":4096,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"source":"public-provider-conf"},"vision":false},{"id":"x-ai/grok-3","name":"xAI: Grok 3","display_name":"xAI: Grok 3","type":"chat","context_length":4096,"max_output_tokens":4096,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"source":"public-provider-conf"},"vision":false},{"id":"x-ai/grok-3-beta","name":"xAI: Grok 3 Beta","display_name":"xAI: Grok 3 Beta","type":"chat","context_length":4096,"max_output_tokens":4096,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"source":"public-provider-conf"},"vision":false},{"id":"x-ai/grok-3-mini","name":"xAI: Grok 3 Mini","display_name":"xAI: Grok 3 Mini","type":"chat","context_length":4096,"max_output_tokens":4096,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"source":"public-provider-conf"},"vision":false},{"id":"x-ai/grok-3-mini-beta","name":"xAI: Grok 3 Mini Beta","display_name":"xAI: Grok 3 Mini Beta","type":"chat","context_length":4096,"max_output_tokens":4096,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"source":"public-provider-conf"},"vision":false},{"id":"x-ai/grok-4","name":"xAI: Grok 4","display_name":"xAI: Grok 4","type":"chat","context_length":4096,"max_output_tokens":4096,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"source":"public-provider-conf"},"vision":false},{"id":"x-ai/grok-4-fast","name":"xAI: Grok 4 Fast","display_name":"xAI: Grok 4 Fast","type":"chat","context_length":4096,"max_output_tokens":4096,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"source":"public-provider-conf"},"vision":false},{"id":"x-ai/grok-code-fast-1","name":"xAI: Grok Code Fast 1","display_name":"xAI: Grok Code Fast 1","type":"chat","context_length":4096,"max_output_tokens":4096,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"source":"public-provider-conf"},"vision":false},{"id":"z-ai/glm-4-32b","name":"Z.AI: GLM 4 32B","display_name":"Z.AI: GLM 4 32B","type":"chat","context_length":4096,"max_output_tokens":4096,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"source":"public-provider-conf"},"vision":false},{"id":"z-ai/glm-4.5","name":"Z.AI: GLM 4.5","display_name":"Z.AI: GLM 4.5","type":"chat","context_length":4096,"max_output_tokens":4096,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"source":"public-provider-conf"},"vision":false},{"id":"z-ai/glm-4.5-air","name":"Z.AI: GLM 4.5 Air","display_name":"Z.AI: GLM 4.5 Air","type":"chat","context_length":4096,"max_output_tokens":4096,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"source":"public-provider-conf"},"vision":false},{"id":"z-ai/glm-4.5v","name":"Z.AI: GLM 4.5V","display_name":"Z.AI: GLM 4.5V","type":"chat","context_length":4096,"max_output_tokens":4096,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"source":"public-provider-conf"},"vision":false}],"metadata":{"source":"public-provider-conf"}}},"updated_at":"2025-10-03T14:35:07.409Z"}