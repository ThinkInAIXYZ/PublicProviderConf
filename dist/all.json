{"providers":{"moonshotai-cn":{"id":"moonshotai-cn","api":"https://api.moonshot.cn/v1","name":"Moonshot AI (China)","doc":"https://platform.moonshot.cn/docs/api/chat","display_name":"Moonshot AI (China)","models":[{"id":"kimi-k2-0905-preview","name":"Kimi K2 0905","attachment":false,"reasoning":false,"temperature":true,"tool_call":true,"knowledge":"2024-10","release_date":"2025-09-05","last_updated":"2025-09-05","modalities":{"input":["text"],"output":["text"]},"open_weights":true,"cost":{"input":0.6,"output":2.5,"cache_read":0.15},"limit":{"context":262144,"output":262144},"display_name":"Kimi K2 0905"},{"id":"kimi-k2-0711-preview","name":"Kimi K2 0711","attachment":false,"reasoning":false,"temperature":true,"tool_call":true,"knowledge":"2024-10","release_date":"2025-07-14","last_updated":"2025-07-14","modalities":{"input":["text"],"output":["text"]},"open_weights":true,"cost":{"input":0.6,"output":2.5,"cache_read":0.15},"limit":{"context":131072,"output":16384},"display_name":"Kimi K2 0711"},{"id":"kimi-k2-turbo-preview","name":"Kimi K2 Turbo","attachment":false,"reasoning":false,"temperature":true,"tool_call":true,"knowledge":"2024-10","release_date":"2025-09-05","last_updated":"2025-09-05","modalities":{"input":["text"],"output":["text"]},"open_weights":true,"cost":{"input":2.4,"output":10,"cache_read":0.6},"limit":{"context":262144,"output":262144},"display_name":"Kimi K2 Turbo"}]},"lucidquery":{"id":"lucidquery","api":"https://lucidquery.com/api/v1","name":"LucidQuery AI","doc":"https://lucidquery.com/api/docs","display_name":"LucidQuery AI","models":[{"id":"lucidquery-nexus-coder","name":"LucidQuery Nexus Coder","attachment":true,"reasoning":true,"temperature":false,"tool_call":true,"knowledge":"2025-08-01","release_date":"2025-09-01","last_updated":"2025-09-01","modalities":{"input":["text"],"output":["text"]},"open_weights":false,"cost":{"input":2,"output":5},"limit":{"context":250000,"output":60000},"display_name":"LucidQuery Nexus Coder"},{"id":"lucidnova-rf1-100b","name":"LucidNova RF1 100B","attachment":true,"reasoning":true,"temperature":false,"tool_call":true,"knowledge":"2025-09-16","release_date":"2024-12-28","last_updated":"2025-09-10","modalities":{"input":["text"],"output":["text"]},"open_weights":false,"cost":{"input":2,"output":5},"limit":{"context":120000,"output":8000},"display_name":"LucidNova RF1 100B"}]},"moonshotai":{"id":"moonshotai","api":"https://api.moonshot.ai/v1","name":"Moonshot AI","doc":"https://platform.moonshot.ai/docs/api/chat","display_name":"Moonshot AI","models":[{"id":"kimi-k2-turbo-preview","name":"Kimi K2 Turbo","attachment":false,"reasoning":false,"temperature":true,"tool_call":true,"knowledge":"2024-10","release_date":"2025-09-05","last_updated":"2025-09-05","modalities":{"input":["text"],"output":["text"]},"open_weights":true,"cost":{"input":2.4,"output":10,"cache_read":0.6},"limit":{"context":262144,"output":262144},"display_name":"Kimi K2 Turbo"},{"id":"kimi-k2-0711-preview","name":"Kimi K2 0711","attachment":false,"reasoning":false,"temperature":true,"tool_call":true,"knowledge":"2024-10","release_date":"2025-07-14","last_updated":"2025-07-14","modalities":{"input":["text"],"output":["text"]},"open_weights":true,"cost":{"input":0.6,"output":2.5,"cache_read":0.15},"limit":{"context":131072,"output":16384},"display_name":"Kimi K2 0711"},{"id":"kimi-k2-0905-preview","name":"Kimi K2 0905","attachment":false,"reasoning":false,"temperature":true,"tool_call":true,"knowledge":"2024-10","release_date":"2025-09-05","last_updated":"2025-09-05","modalities":{"input":["text"],"output":["text"]},"open_weights":true,"cost":{"input":0.6,"output":2.5,"cache_read":0.15},"limit":{"context":262144,"output":262144},"display_name":"Kimi K2 0905"}]},"zai-coding-plan":{"id":"zai-coding-plan","api":"https://api.z.ai/api/coding/paas/v4","name":"Z.AI Coding Plan","doc":"https://docs.z.ai/devpack/overview","display_name":"Z.AI Coding Plan","models":[{"id":"glm-4.5-flash","name":"GLM-4.5-Flash","attachment":false,"reasoning":true,"temperature":true,"tool_call":true,"knowledge":"2025-04","release_date":"2025-07-28","last_updated":"2025-07-28","modalities":{"input":["text"],"output":["text"]},"open_weights":true,"cost":{"input":0,"output":0,"cache_read":0,"cache_write":0},"limit":{"context":131072,"output":98304},"display_name":"GLM-4.5-Flash"},{"id":"glm-4.5","name":"GLM-4.5","attachment":false,"reasoning":true,"temperature":true,"tool_call":true,"knowledge":"2025-04","release_date":"2025-07-28","last_updated":"2025-07-28","modalities":{"input":["text"],"output":["text"]},"open_weights":true,"cost":{"input":0,"output":0,"cache_read":0,"cache_write":0},"limit":{"context":131072,"output":98304},"display_name":"GLM-4.5"},{"id":"glm-4.5-air","name":"GLM-4.5-Air","attachment":false,"reasoning":true,"temperature":true,"tool_call":true,"knowledge":"2025-04","release_date":"2025-07-28","last_updated":"2025-07-28","modalities":{"input":["text"],"output":["text"]},"open_weights":true,"cost":{"input":0,"output":0,"cache_read":0,"cache_write":0},"limit":{"context":131072,"output":98304},"display_name":"GLM-4.5-Air"},{"id":"glm-4.5v","name":"GLM 4.5V","attachment":true,"reasoning":true,"temperature":true,"tool_call":true,"knowledge":"2025-04","release_date":"2025-08-11","last_updated":"2025-08-11","modalities":{"input":["text","image","video"],"output":["text"]},"open_weights":true,"cost":{"input":0,"output":0},"limit":{"context":64000,"output":16384},"display_name":"GLM 4.5V"},{"id":"glm-4.6","name":"GLM-4.6","attachment":false,"reasoning":true,"temperature":true,"tool_call":true,"knowledge":"2025-04","release_date":"2025-09-30","last_updated":"2025-09-30","modalities":{"input":["text"],"output":["text"]},"open_weights":true,"cost":{"input":0,"output":0,"cache_read":0,"cache_write":0},"limit":{"context":204800,"output":131072},"display_name":"GLM-4.6"}]},"alibaba":{"id":"alibaba","api":"https://dashscope-intl.aliyuncs.com/compatible-mode/v1","name":"alibaba","doc":"https://www.alibabacloud.com/help/en/model-studio/models","display_name":"alibaba","models":[{"id":"qwen3-coder-plus","name":"Qwen3 Coder Plus","attachment":false,"reasoning":false,"temperature":true,"tool_call":true,"knowledge":"2025-04","release_date":"2025-07-23","last_updated":"2025-07-23","modalities":{"input":["text"],"output":["text"]},"open_weights":true,"cost":{"input":1,"output":5},"limit":{"context":1048576,"output":65536},"display_name":"Qwen3 Coder Plus"},{"id":"qwen-turbo-latest","type":"chat","context_length":1000000,"max_output_tokens":16384,"capabilities":{"vision":false,"function_calling":true,"reasoning":false},"search_strategy":"turbo","name":"qwen-turbo-latest","display_name":"qwen-turbo-latest"},{"id":"qwen-turbo-2025-07-15","type":"chat","context_length":131072,"max_output_tokens":16384,"capabilities":{"vision":false,"function_calling":true,"reasoning":false},"search_strategy":"turbo","name":"qwen-turbo-2025-07-15","display_name":"qwen-turbo-2025-07-15"},{"id":"qwen-turbo","type":"chat","context_length":131072,"max_output_tokens":16384,"capabilities":{"vision":false,"function_calling":true,"reasoning":false},"search_strategy":"turbo","name":"qwen-turbo","display_name":"qwen-turbo"},{"id":"qwen-flash","type":"chat","context_length":1000000,"max_output_tokens":32768,"capabilities":{"vision":false,"function_calling":true,"reasoning":false},"search_strategy":"turbo","name":"qwen-flash","display_name":"qwen-flash"},{"id":"qwen-flash-2025-07-28","type":"chat","context_length":1000000,"max_output_tokens":32768,"capabilities":{"vision":false,"function_calling":true,"reasoning":false},"search_strategy":"turbo","name":"qwen-flash-2025-07-28","display_name":"qwen-flash-2025-07-28"},{"id":"qwen-plus-latest","type":"chat","context_length":1000000,"max_output_tokens":32768,"capabilities":{"vision":false,"function_calling":true,"reasoning":false},"search_strategy":"turbo","name":"qwen-plus-latest","display_name":"qwen-plus-latest"},{"id":"qwen-plus-2025-07-14","type":"chat","context_length":131072,"max_output_tokens":8192,"capabilities":{"vision":false,"function_calling":true,"reasoning":false},"search_strategy":"turbo","name":"qwen-plus-2025-07-14","display_name":"qwen-plus-2025-07-14"},{"id":"qwen-plus-2025-07-28","type":"chat","context_length":1000000,"max_output_tokens":32768,"capabilities":{"vision":false,"function_calling":true,"reasoning":false},"search_strategy":"turbo","name":"qwen-plus-2025-07-28","display_name":"qwen-plus-2025-07-28"},{"id":"qwen-plus","type":"chat","context_length":131072,"max_output_tokens":16384,"capabilities":{"vision":false,"function_calling":true,"reasoning":false},"search_strategy":"turbo","name":"qwen-plus","display_name":"qwen-plus"},{"id":"qwen-max-latest","type":"chat","context_length":131072,"max_output_tokens":8192,"capabilities":{"vision":false,"function_calling":true,"reasoning":false},"search_strategy":"turbo","name":"qwen-max-latest","display_name":"qwen-max-latest"},{"id":"qwen-max","type":"chat","context_length":32768,"max_output_tokens":8192,"capabilities":{"vision":false,"function_calling":true,"reasoning":false},"search_strategy":"turbo","name":"qwen-max","display_name":"qwen-max"},{"id":"qwen3-max-2025-09-23","type":"chat","context_length":262144,"max_output_tokens":65536,"capabilities":{"vision":false,"function_calling":true,"reasoning":false},"search_strategy":"turbo","name":"qwen3-max-2025-09-23","display_name":"qwen3-max-2025-09-23"},{"id":"qwen3-max-preview","type":"chat","context_length":262144,"max_output_tokens":65536,"capabilities":{"vision":false,"function_calling":true,"reasoning":false},"search_strategy":"turbo","name":"qwen3-max-preview","display_name":"qwen3-max-preview"},{"id":"qwen3-235b-a22b-thinking-2507","type":"chat","context_length":40960,"max_output_tokens":8192,"capabilities":{"vision":false,"function_calling":true,"reasoning":true},"thinking_budget":81920,"name":"qwen3-235b-a22b-thinking-2507","display_name":"qwen3-235b-a22b-thinking-2507"},{"id":"qwen3-235b-a22b","type":"chat","context_length":40960,"max_output_tokens":8192,"capabilities":{"vision":false,"function_calling":true,"reasoning":true},"thinking_budget":81920,"name":"qwen3-235b-a22b","display_name":"qwen3-235b-a22b"},{"id":"qwen3-30b-a3b-thinking-2507","type":"chat","context_length":40960,"max_output_tokens":8192,"capabilities":{"vision":false,"function_calling":true,"reasoning":true},"thinking_budget":81920,"name":"qwen3-30b-a3b-thinking-2507","display_name":"qwen3-30b-a3b-thinking-2507"},{"id":"qwen3-32b","type":"chat","context_length":40960,"max_output_tokens":8192,"capabilities":{"vision":false,"function_calling":true,"reasoning":true},"thinking_budget":38912,"name":"qwen3-32b","display_name":"qwen3-32b"},{"id":"qwen3-30b-a3b","type":"chat","context_length":40960,"max_output_tokens":8192,"capabilities":{"vision":false,"function_calling":true,"reasoning":true},"thinking_budget":38912,"name":"qwen3-30b-a3b","display_name":"qwen3-30b-a3b"},{"id":"qwen3-14b","type":"chat","context_length":40960,"max_output_tokens":8192,"capabilities":{"vision":false,"function_calling":true,"reasoning":true},"thinking_budget":38912,"name":"qwen3-14b","display_name":"qwen3-14b"},{"id":"qwen3-8b","type":"chat","context_length":40960,"max_output_tokens":8192,"capabilities":{"vision":false,"function_calling":true,"reasoning":true},"thinking_budget":38912,"name":"qwen3-8b","display_name":"qwen3-8b"},{"id":"qwen3-4b","type":"chat","context_length":40960,"max_output_tokens":8192,"capabilities":{"vision":false,"function_calling":true,"reasoning":true},"thinking_budget":38912,"name":"qwen3-4b","display_name":"qwen3-4b"},{"id":"qwen3-1.7b","type":"chat","context_length":40960,"max_output_tokens":8192,"capabilities":{"vision":false,"function_calling":true,"reasoning":true},"thinking_budget":20000,"name":"qwen3-1.7b","display_name":"qwen3-1.7b"},{"id":"qwen3-0.6b","type":"chat","context_length":40960,"max_output_tokens":8192,"capabilities":{"vision":false,"function_calling":true,"reasoning":true},"thinking_budget":20000,"name":"qwen3-0.6b","display_name":"qwen3-0.6b"},{"id":"qwen3-vl-plus","type":"chat","context_length":262144,"max_output_tokens":32768,"capabilities":{"vision":true,"function_calling":false,"reasoning":true},"thinking_budget":81920,"name":"qwen3-vl-plus","display_name":"qwen3-vl-plus"},{"id":"qwq-plus","type":"chat","context_length":131072,"max_output_tokens":8192,"capabilities":{"vision":false,"function_calling":false,"reasoning":true},"search_strategy":"turbo","name":"qwq-plus","display_name":"qwq-plus"},{"id":"qwq-plus-latest","type":"chat","context_length":131072,"max_output_tokens":8192,"capabilities":{"vision":false,"function_calling":false,"reasoning":true},"name":"qwq-plus-latest","display_name":"qwq-plus-latest"},{"id":"qwen3-next-80b-a3b-thinking","type":"chat","context_length":131072,"max_output_tokens":32768,"capabilities":{"vision":false,"function_calling":false,"reasoning":true},"thinking_budget":81920,"name":"qwen3-next-80b-a3b-thinking","display_name":"qwen3-next-80b-a3b-thinking"},{"id":"qwen3-next-80b-a3b-instruct","type":"chat","context_length":131072,"max_output_tokens":32768,"capabilities":{"vision":false,"function_calling":true,"reasoning":false},"name":"qwen3-next-80b-a3b-instruct","display_name":"qwen3-next-80b-a3b-instruct"}]},"xai":{"id":"xai","name":"xAI","doc":"https://docs.x.ai/docs/models","display_name":"xAI","models":[{"id":"grok-4-fast-non-reasoning","name":"Grok 4 Fast (Non-Reasoning)","attachment":true,"reasoning":false,"temperature":true,"tool_call":true,"knowledge":"2025-07","release_date":"2025-09-19","last_updated":"2025-09-19","modalities":{"input":["text","image"],"output":["text"]},"open_weights":false,"cost":{"input":0.2,"output":0.5,"cache_read":0.05},"limit":{"context":2000000,"output":30000},"display_name":"Grok 4 Fast (Non-Reasoning)"},{"id":"grok-3-fast","name":"Grok 3 Fast","attachment":false,"reasoning":false,"temperature":true,"tool_call":true,"knowledge":"2024-11","release_date":"2025-02-17","last_updated":"2025-02-17","modalities":{"input":["text"],"output":["text"]},"open_weights":false,"cost":{"input":5,"output":25,"cache_read":1.25},"limit":{"context":131072,"output":8192},"display_name":"Grok 3 Fast"},{"id":"grok-4","name":"Grok 4","attachment":false,"reasoning":true,"temperature":true,"tool_call":true,"knowledge":"2025-07","release_date":"2025-07-09","last_updated":"2025-07-09","modalities":{"input":["text"],"output":["text"]},"open_weights":false,"cost":{"input":3,"output":15,"reasoning":15,"cache_read":0.75},"limit":{"context":256000,"output":64000},"display_name":"Grok 4"},{"id":"grok-2-vision","name":"Grok 2 Vision","attachment":true,"reasoning":false,"temperature":true,"tool_call":true,"knowledge":"2024-08","release_date":"2024-08-20","last_updated":"2024-08-20","modalities":{"input":["text","image"],"output":["text"]},"open_weights":false,"cost":{"input":2,"output":10,"cache_read":2},"limit":{"context":8192,"output":4096},"display_name":"Grok 2 Vision"},{"id":"grok-code-fast-1","name":"Grok Code Fast 1","attachment":false,"reasoning":true,"temperature":true,"tool_call":true,"knowledge":"2023-10","release_date":"2025-08-28","last_updated":"2025-08-28","modalities":{"input":["text"],"output":["text"]},"open_weights":false,"cost":{"input":0.2,"output":1.5,"cache_read":0.02},"limit":{"context":256000,"output":10000},"display_name":"Grok Code Fast 1"},{"id":"grok-2","name":"Grok 2","attachment":false,"reasoning":false,"temperature":true,"tool_call":true,"knowledge":"2024-08","release_date":"2024-08-20","last_updated":"2024-08-20","modalities":{"input":["text"],"output":["text"]},"open_weights":false,"cost":{"input":2,"output":10,"cache_read":2},"limit":{"context":131072,"output":8192},"display_name":"Grok 2"},{"id":"grok-3-mini-fast-latest","name":"Grok 3 Mini Fast Latest","attachment":false,"reasoning":true,"temperature":true,"tool_call":true,"knowledge":"2024-11","release_date":"2025-02-17","last_updated":"2025-02-17","modalities":{"input":["text"],"output":["text"]},"open_weights":false,"cost":{"input":0.6,"output":4,"reasoning":4,"cache_read":0.15},"limit":{"context":131072,"output":8192},"display_name":"Grok 3 Mini Fast Latest"},{"id":"grok-2-vision-1212","name":"Grok 2 Vision (1212)","attachment":true,"reasoning":false,"temperature":true,"tool_call":true,"knowledge":"2024-08","release_date":"2024-08-20","last_updated":"2024-12-12","modalities":{"input":["text","image"],"output":["text"]},"open_weights":false,"cost":{"input":2,"output":10,"cache_read":2},"limit":{"context":8192,"output":4096},"display_name":"Grok 2 Vision (1212)"},{"id":"grok-3","name":"Grok 3","attachment":false,"reasoning":false,"temperature":true,"tool_call":true,"knowledge":"2024-11","release_date":"2025-02-17","last_updated":"2025-02-17","modalities":{"input":["text"],"output":["text"]},"open_weights":false,"cost":{"input":3,"output":15,"cache_read":0.75},"limit":{"context":131072,"output":8192},"display_name":"Grok 3"},{"id":"grok-4-fast","name":"Grok 4 Fast","attachment":true,"reasoning":true,"temperature":true,"tool_call":true,"knowledge":"2025-07","release_date":"2025-09-19","last_updated":"2025-09-19","modalities":{"input":["text","image"],"output":["text"]},"open_weights":false,"cost":{"input":0.2,"output":0.5,"cache_read":0.05},"limit":{"context":2000000,"output":30000},"display_name":"Grok 4 Fast"},{"id":"grok-2-latest","name":"Grok 2 Latest","attachment":false,"reasoning":false,"temperature":true,"tool_call":true,"knowledge":"2024-08","release_date":"2024-08-20","last_updated":"2024-12-12","modalities":{"input":["text"],"output":["text"]},"open_weights":false,"cost":{"input":2,"output":10,"cache_read":2},"limit":{"context":131072,"output":8192},"display_name":"Grok 2 Latest"},{"id":"grok-2-1212","name":"Grok 2 (1212)","attachment":false,"reasoning":false,"temperature":true,"tool_call":true,"knowledge":"2024-08","release_date":"2024-12-12","last_updated":"2024-12-12","modalities":{"input":["text"],"output":["text"]},"open_weights":false,"cost":{"input":2,"output":10,"cache_read":2},"limit":{"context":131072,"output":8192},"display_name":"Grok 2 (1212)"},{"id":"grok-3-fast-latest","name":"Grok 3 Fast Latest","attachment":false,"reasoning":false,"temperature":true,"tool_call":true,"knowledge":"2024-11","release_date":"2025-02-17","last_updated":"2025-02-17","modalities":{"input":["text"],"output":["text"]},"open_weights":false,"cost":{"input":5,"output":25,"cache_read":1.25},"limit":{"context":131072,"output":8192},"display_name":"Grok 3 Fast Latest"},{"id":"grok-3-latest","name":"Grok 3 Latest","attachment":false,"reasoning":false,"temperature":true,"tool_call":true,"knowledge":"2024-11","release_date":"2025-02-17","last_updated":"2025-02-17","modalities":{"input":["text"],"output":["text"]},"open_weights":false,"cost":{"input":3,"output":15,"cache_read":0.75},"limit":{"context":131072,"output":8192},"display_name":"Grok 3 Latest"},{"id":"grok-2-vision-latest","name":"Grok 2 Vision Latest","attachment":true,"reasoning":false,"temperature":true,"tool_call":true,"knowledge":"2024-08","release_date":"2024-08-20","last_updated":"2024-12-12","modalities":{"input":["text","image"],"output":["text"]},"open_weights":false,"cost":{"input":2,"output":10,"cache_read":2},"limit":{"context":8192,"output":4096},"display_name":"Grok 2 Vision Latest"},{"id":"grok-vision-beta","name":"Grok Vision Beta","attachment":true,"reasoning":false,"temperature":true,"tool_call":true,"knowledge":"2024-08","release_date":"2024-11-01","last_updated":"2024-11-01","modalities":{"input":["text","image"],"output":["text"]},"open_weights":false,"cost":{"input":5,"output":15,"cache_read":5},"limit":{"context":8192,"output":4096},"display_name":"Grok Vision Beta"},{"id":"grok-3-mini","name":"Grok 3 Mini","attachment":false,"reasoning":true,"temperature":true,"tool_call":true,"knowledge":"2024-11","release_date":"2025-02-17","last_updated":"2025-02-17","modalities":{"input":["text"],"output":["text"]},"open_weights":false,"cost":{"input":0.3,"output":0.5,"reasoning":0.5,"cache_read":0.075},"limit":{"context":131072,"output":8192},"display_name":"Grok 3 Mini"},{"id":"grok-beta","name":"Grok Beta","attachment":false,"reasoning":false,"temperature":true,"tool_call":true,"knowledge":"2024-08","release_date":"2024-11-01","last_updated":"2024-11-01","modalities":{"input":["text"],"output":["text"]},"open_weights":false,"cost":{"input":5,"output":15,"cache_read":5},"limit":{"context":131072,"output":4096},"display_name":"Grok Beta"},{"id":"grok-3-mini-latest","name":"Grok 3 Mini Latest","attachment":false,"reasoning":true,"temperature":true,"tool_call":true,"knowledge":"2024-11","release_date":"2025-02-17","last_updated":"2025-02-17","modalities":{"input":["text"],"output":["text"]},"open_weights":false,"cost":{"input":0.3,"output":0.5,"reasoning":0.5,"cache_read":0.075},"limit":{"context":131072,"output":8192},"display_name":"Grok 3 Mini Latest"},{"id":"grok-3-mini-fast","name":"Grok 3 Mini Fast","attachment":false,"reasoning":true,"temperature":true,"tool_call":true,"knowledge":"2024-11","release_date":"2025-02-17","last_updated":"2025-02-17","modalities":{"input":["text"],"output":["text"]},"open_weights":false,"cost":{"input":0.6,"output":4,"reasoning":4,"cache_read":0.15},"limit":{"context":131072,"output":8192},"display_name":"Grok 3 Mini Fast"}]},"nvidia":{"id":"nvidia","api":"https://integrate.api.nvidia.com/v1","name":"Nvidia","doc":"https://docs.api.nvidia.com/nim/","display_name":"Nvidia","models":[{"id":"moonshotai/kimi-k2-instruct","name":"Kimi K2 Instruct","attachment":false,"reasoning":true,"temperature":true,"tool_call":true,"knowledge":"2024-01","release_date":"2025-01-01","last_updated":"2025-09-05","modalities":{"input":["text"],"output":["text"]},"open_weights":false,"cost":{"input":0,"output":0},"limit":{"context":128000,"output":8192},"display_name":"Kimi K2 Instruct"},{"id":"nvidia/cosmos-nemotron-34b","name":"Cosmos Nemotron 34B","attachment":false,"reasoning":true,"temperature":true,"tool_call":false,"knowledge":"2024-01","release_date":"2024-01-01","last_updated":"2025-09-05","modalities":{"input":["text","image","video"],"output":["text"]},"open_weights":false,"cost":{"input":0,"output":0},"limit":{"context":131072,"output":8192},"display_name":"Cosmos Nemotron 34B"},{"id":"nvidia/parakeet-tdt-0.6b-v2","name":"Parakeet TDT 0.6B v2","attachment":false,"reasoning":false,"temperature":false,"tool_call":false,"knowledge":"2024-01","release_date":"2024-01-01","last_updated":"2025-09-05","modalities":{"input":["audio"],"output":["text"]},"open_weights":false,"cost":{"input":0,"output":0},"limit":{"context":0,"output":4096},"display_name":"Parakeet TDT 0.6B v2"},{"id":"nvidia/nemoretriever-ocr-v1","name":"NeMo Retriever OCR v1","attachment":false,"reasoning":false,"temperature":false,"tool_call":false,"knowledge":"2024-01","release_date":"2024-01-01","last_updated":"2025-09-05","modalities":{"input":["image"],"output":["text"]},"open_weights":false,"cost":{"input":0,"output":0},"limit":{"context":0,"output":4096},"display_name":"NeMo Retriever OCR v1"},{"id":"nvidia/llama-3.1-nemotron-ultra-253b-v1","name":"Llama-3.1-Nemotron-Ultra-253B-v1","attachment":false,"reasoning":true,"temperature":true,"tool_call":true,"knowledge":"2024-07","release_date":"2024-07-01","last_updated":"2025-09-05","modalities":{"input":["text"],"output":["text"]},"open_weights":false,"cost":{"input":0,"output":0},"limit":{"context":131072,"output":8192},"display_name":"Llama-3.1-Nemotron-Ultra-253B-v1"},{"id":"google/gemma-3-27b-it","name":"Gemma-3-27B-IT","attachment":true,"reasoning":true,"temperature":true,"tool_call":true,"knowledge":"2024-12","release_date":"2024-12-01","last_updated":"2025-09-05","modalities":{"input":["text","image"],"output":["text"]},"open_weights":false,"cost":{"input":0,"output":0},"limit":{"context":131072,"output":8192},"display_name":"Gemma-3-27B-IT"},{"id":"microsoft/phi-4-mini-instruct","name":"Phi-4-Mini","attachment":true,"reasoning":true,"temperature":true,"tool_call":true,"knowledge":"2024-12","release_date":"2024-12-01","last_updated":"2025-09-05","modalities":{"input":["text","image","audio"],"output":["text"]},"open_weights":false,"cost":{"input":0,"output":0},"limit":{"context":131072,"output":8192},"display_name":"Phi-4-Mini"},{"id":"openai/whisper-large-v3","name":"Whisper Large v3","attachment":false,"reasoning":false,"temperature":false,"tool_call":false,"knowledge":"2023-09","release_date":"2023-09-01","last_updated":"2025-09-05","modalities":{"input":["audio"],"output":["text"]},"open_weights":true,"cost":{"input":0,"output":0},"limit":{"context":0,"output":4096},"display_name":"Whisper Large v3"},{"id":"openai/gpt-oss-120b","name":"GPT-OSS-120B","attachment":true,"reasoning":true,"temperature":true,"tool_call":false,"knowledge":"2024-01","release_date":"2024-01-01","last_updated":"2025-09-05","modalities":{"input":["text"],"output":["text"]},"open_weights":false,"cost":{"input":0,"output":0},"limit":{"context":128000,"output":8192},"display_name":"GPT-OSS-120B"},{"id":"qwen/qwen3-235b-a22b","name":"Qwen3-235B-A22B","attachment":false,"reasoning":true,"temperature":true,"tool_call":true,"knowledge":"2024-12","release_date":"2024-12-01","last_updated":"2025-09-05","modalities":{"input":["text"],"output":["text"]},"open_weights":false,"cost":{"input":0,"output":0},"limit":{"context":131072,"output":8192},"display_name":"Qwen3-235B-A22B"},{"id":"qwen/qwen3-coder-480b-a35b-instruct","name":"Qwen3 Coder 480B A35B Instruct","attachment":false,"reasoning":false,"temperature":true,"tool_call":true,"knowledge":"2025-04","release_date":"2025-07-23","last_updated":"2025-07-23","modalities":{"input":["text"],"output":["text"]},"open_weights":false,"cost":{"input":0,"output":0},"limit":{"context":262144,"output":66536},"display_name":"Qwen3 Coder 480B A35B Instruct"},{"id":"deepseek-ai/deepseek-v3.1","name":"DeepSeek V3.1","attachment":false,"reasoning":true,"temperature":true,"tool_call":true,"knowledge":"2024-07","release_date":"2025-08-20","last_updated":"2025-08-26","modalities":{"input":["text"],"output":["text"]},"open_weights":false,"cost":{"input":0,"output":0},"limit":{"context":128000,"output":8192},"display_name":"DeepSeek V3.1"},{"id":"black-forest-labs/flux.1-dev","name":"FLUX.1-dev","attachment":false,"reasoning":false,"temperature":true,"tool_call":false,"knowledge":"2024-08","release_date":"2024-08-01","last_updated":"2025-09-05","modalities":{"input":["text"],"output":["image"]},"open_weights":false,"cost":{"input":0,"output":0},"limit":{"context":4096,"output":0},"display_name":"FLUX.1-dev"}]},"upstage":{"id":"upstage","api":"https://api.upstage.ai","name":"Upstage","doc":"https://developers.upstage.ai/docs/apis/chat","display_name":"Upstage","models":[{"id":"solar-mini","name":"solar-mini","attachment":false,"reasoning":false,"temperature":true,"tool_call":true,"knowledge":"2024-09","release_date":"2024-06-12","last_updated":"2025-04-22","modalities":{"input":["text"],"output":["text"]},"open_weights":false,"cost":{"input":0.15,"output":0.15},"limit":{"context":32768,"output":4096},"display_name":"solar-mini"},{"id":"solar-pro2","name":"solar-pro2","attachment":false,"reasoning":true,"temperature":true,"tool_call":true,"knowledge":"2025-03","release_date":"2025-05-20","last_updated":"2025-05-20","modalities":{"input":["text"],"output":["text"]},"open_weights":false,"cost":{"input":0.25,"output":0.25},"limit":{"context":65536,"output":8192},"display_name":"solar-pro2"}]},"groq":{"id":"groq","name":"Groq","doc":"https://console.groq.com/docs/models","display_name":"Groq","models":[{"id":"llama-3.1-8b-instant","name":"Llama 3.1 8B Instant","attachment":false,"reasoning":false,"temperature":true,"tool_call":true,"knowledge":"2023-12","release_date":"2024-07-23","last_updated":"2024-07-23","modalities":{"input":["text"],"output":["text"]},"open_weights":true,"cost":{"input":0.05,"output":0.08},"limit":{"context":131072,"output":8192},"display_name":"Llama 3.1 8B Instant"},{"id":"mistral-saba-24b","name":"Mistral Saba 24B","attachment":false,"reasoning":false,"temperature":true,"tool_call":true,"knowledge":"2024-08","release_date":"2025-02-06","last_updated":"2025-02-06","modalities":{"input":["text"],"output":["text"]},"open_weights":false,"cost":{"input":0.79,"output":0.79},"limit":{"context":32768,"output":32768},"display_name":"Mistral Saba 24B"},{"id":"llama3-8b-8192","name":"Llama 3 8B","attachment":false,"reasoning":false,"temperature":true,"tool_call":true,"knowledge":"2023-03","release_date":"2024-04-18","last_updated":"2024-04-18","modalities":{"input":["text"],"output":["text"]},"open_weights":true,"cost":{"input":0.05,"output":0.08},"limit":{"context":8192,"output":8192},"display_name":"Llama 3 8B"},{"id":"qwen-qwq-32b","name":"Qwen QwQ 32B","attachment":false,"reasoning":true,"temperature":true,"tool_call":true,"knowledge":"2024-09","release_date":"2024-11-27","last_updated":"2024-11-27","modalities":{"input":["text"],"output":["text"]},"open_weights":true,"cost":{"input":0.29,"output":0.39},"limit":{"context":131072,"output":16384},"display_name":"Qwen QwQ 32B"},{"id":"llama3-70b-8192","name":"Llama 3 70B","attachment":false,"reasoning":false,"temperature":true,"tool_call":true,"knowledge":"2023-03","release_date":"2024-04-18","last_updated":"2024-04-18","modalities":{"input":["text"],"output":["text"]},"open_weights":true,"cost":{"input":0.59,"output":0.79},"limit":{"context":8192,"output":8192},"display_name":"Llama 3 70B"},{"id":"deepseek-r1-distill-llama-70b","name":"DeepSeek R1 Distill Llama 70B","attachment":false,"reasoning":true,"temperature":true,"tool_call":true,"knowledge":"2024-07","release_date":"2025-01-20","last_updated":"2025-01-20","modalities":{"input":["text"],"output":["text"]},"open_weights":true,"cost":{"input":0.75,"output":0.99},"limit":{"context":131072,"output":8192},"display_name":"DeepSeek R1 Distill Llama 70B"},{"id":"llama-guard-3-8b","name":"Llama Guard 3 8B","attachment":false,"reasoning":false,"temperature":true,"tool_call":false,"release_date":"2024-07-23","last_updated":"2024-07-23","modalities":{"input":["text"],"output":["text"]},"open_weights":true,"cost":{"input":0.2,"output":0.2},"limit":{"context":8192,"output":8192},"display_name":"Llama Guard 3 8B"},{"id":"gemma2-9b-it","name":"Gemma 2 9B","attachment":false,"reasoning":false,"temperature":true,"tool_call":true,"knowledge":"2024-06","release_date":"2024-06-27","last_updated":"2024-06-27","modalities":{"input":["text"],"output":["text"]},"open_weights":true,"cost":{"input":0.2,"output":0.2},"limit":{"context":8192,"output":8192},"display_name":"Gemma 2 9B"},{"id":"llama-3.3-70b-versatile","name":"Llama 3.3 70B Versatile","attachment":false,"reasoning":false,"temperature":true,"tool_call":true,"knowledge":"2023-12","release_date":"2024-12-06","last_updated":"2024-12-06","modalities":{"input":["text"],"output":["text"]},"open_weights":true,"cost":{"input":0.59,"output":0.79},"limit":{"context":131072,"output":32768},"display_name":"Llama 3.3 70B Versatile"},{"id":"moonshotai/kimi-k2-instruct-0905","name":"Kimi K2 Instruct 0905","attachment":false,"reasoning":false,"temperature":true,"tool_call":true,"knowledge":"2024-10","release_date":"2025-09-05","last_updated":"2025-09-05","modalities":{"input":["text"],"output":["text"]},"open_weights":true,"cost":{"input":1,"output":3},"limit":{"context":262144,"output":16384},"display_name":"Kimi K2 Instruct 0905"},{"id":"moonshotai/kimi-k2-instruct","name":"Kimi K2 Instruct","attachment":false,"reasoning":false,"temperature":true,"tool_call":true,"knowledge":"2024-10","release_date":"2025-07-14","last_updated":"2025-07-14","modalities":{"input":["text"],"output":["text"]},"open_weights":true,"cost":{"input":1,"output":3},"limit":{"context":131072,"output":16384},"display_name":"Kimi K2 Instruct"},{"id":"openai/gpt-oss-20b","name":"GPT OSS 20B","attachment":false,"reasoning":true,"temperature":true,"tool_call":true,"release_date":"2025-08-05","last_updated":"2025-08-05","modalities":{"input":["text"],"output":["text"]},"open_weights":true,"cost":{"input":0.1,"output":0.5},"limit":{"context":131072,"output":32768},"display_name":"GPT OSS 20B"},{"id":"openai/gpt-oss-120b","name":"GPT OSS 120B","attachment":false,"reasoning":true,"temperature":true,"tool_call":true,"release_date":"2025-08-05","last_updated":"2025-08-05","modalities":{"input":["text"],"output":["text"]},"open_weights":true,"cost":{"input":0.15,"output":0.75},"limit":{"context":131072,"output":32768},"display_name":"GPT OSS 120B"},{"id":"qwen/qwen3-32b","name":"Qwen3 32B","attachment":false,"reasoning":true,"temperature":true,"tool_call":true,"knowledge":"2024-11-08","release_date":"2024-12-23","last_updated":"2024-12-23","modalities":{"input":["text"],"output":["text"]},"open_weights":true,"cost":{"input":0.29,"output":0.59},"limit":{"context":131072,"output":16384},"display_name":"Qwen3 32B"},{"id":"meta-llama/llama-4-scout-17b-16e-instruct","name":"Llama 4 Scout 17B","attachment":false,"reasoning":false,"temperature":true,"tool_call":true,"knowledge":"2024-08","release_date":"2025-04-05","last_updated":"2025-04-05","modalities":{"input":["text","image"],"output":["text"]},"open_weights":true,"cost":{"input":0.11,"output":0.34},"limit":{"context":131072,"output":8192},"display_name":"Llama 4 Scout 17B"},{"id":"meta-llama/llama-4-maverick-17b-128e-instruct","name":"Llama 4 Maverick 17B","attachment":false,"reasoning":false,"temperature":true,"tool_call":true,"knowledge":"2024-08","release_date":"2025-04-05","last_updated":"2025-04-05","modalities":{"input":["text","image"],"output":["text"]},"open_weights":true,"cost":{"input":0.2,"output":0.6},"limit":{"context":131072,"output":8192},"display_name":"Llama 4 Maverick 17B"},{"id":"meta-llama/llama-guard-4-12b","name":"Llama Guard 4 12B","attachment":false,"reasoning":false,"temperature":true,"tool_call":false,"release_date":"2025-04-05","last_updated":"2025-04-05","modalities":{"input":["text","image"],"output":["text"]},"open_weights":true,"cost":{"input":0.2,"output":0.2},"limit":{"context":131072,"output":128},"display_name":"Llama Guard 4 12B"}]},"github-copilot":{"id":"github-copilot","api":"https://api.githubcopilot.com","name":"GitHub Copilot","doc":"https://docs.github.com/en/copilot","display_name":"GitHub Copilot","models":[{"id":"gemini-2.0-flash-001","name":"Gemini 2.0 Flash","attachment":true,"reasoning":false,"temperature":true,"tool_call":true,"knowledge":"2024-06","release_date":"2024-12-11","last_updated":"2024-12-11","modalities":{"input":["text","image","audio","video"],"output":["text"]},"open_weights":false,"limit":{"context":1000000,"output":8192},"display_name":"Gemini 2.0 Flash"},{"id":"claude-opus-4","name":"Claude Opus 4","attachment":true,"reasoning":true,"temperature":false,"tool_call":false,"knowledge":"2025-03-31","release_date":"2025-05-22","last_updated":"2025-05-22","modalities":{"input":["text","image"],"output":["text"]},"open_weights":false,"limit":{"context":80000,"output":16000},"display_name":"Claude Opus 4"},{"id":"grok-code-fast-1","name":"Grok Code Fast 1","attachment":false,"reasoning":true,"temperature":true,"tool_call":true,"knowledge":"2025-08","release_date":"2025-08-27","last_updated":"2025-08-27","modalities":{"input":["text"],"output":["text"]},"open_weights":false,"limit":{"context":256000,"output":10000},"display_name":"Grok Code Fast 1"},{"id":"claude-3.5-sonnet","name":"Claude Sonnet 3.5","attachment":true,"reasoning":false,"temperature":true,"tool_call":true,"knowledge":"2024-04","release_date":"2024-10-22","last_updated":"2024-10-22","modalities":{"input":["text","image"],"output":["text"]},"open_weights":false,"limit":{"context":90000,"output":8192},"display_name":"Claude Sonnet 3.5"},{"id":"o3-mini","name":"o3-mini","attachment":false,"reasoning":true,"temperature":false,"tool_call":false,"knowledge":"2024-10","release_date":"2024-12-20","last_updated":"2025-01-29","modalities":{"input":["text"],"output":["text"]},"open_weights":false,"limit":{"context":128000,"output":65536},"display_name":"o3-mini"},{"id":"gpt-5-codex","name":"GPT-5-Codex","attachment":false,"reasoning":true,"temperature":false,"tool_call":true,"knowledge":"2024-09-30","release_date":"2025-09-15","last_updated":"2025-09-15","modalities":{"input":["text","image"],"output":["text"]},"open_weights":false,"limit":{"context":128000,"output":64000},"display_name":"GPT-5-Codex"},{"id":"gpt-4o","name":"GPT-4o","attachment":true,"reasoning":false,"temperature":true,"tool_call":true,"knowledge":"2023-09","release_date":"2024-05-13","last_updated":"2024-05-13","modalities":{"input":["text","image"],"output":["text"]},"open_weights":false,"limit":{"context":128000,"output":16384},"display_name":"GPT-4o"},{"id":"gpt-4.1","name":"GPT-4.1","attachment":true,"reasoning":false,"temperature":true,"tool_call":true,"knowledge":"2024-04","release_date":"2025-04-14","last_updated":"2025-04-14","modalities":{"input":["text","image"],"output":["text"]},"open_weights":false,"limit":{"context":128000,"output":16384},"display_name":"GPT-4.1"},{"id":"o4-mini","name":"o4-mini (Preview)","attachment":false,"reasoning":true,"temperature":false,"tool_call":false,"knowledge":"2024-10","release_date":"2025-04-16","last_updated":"2025-04-16","modalities":{"input":["text"],"output":["text"]},"open_weights":false,"limit":{"context":128000,"output":65536},"display_name":"o4-mini (Preview)"},{"id":"claude-opus-41","name":"Claude Opus 4.1","attachment":true,"reasoning":true,"temperature":true,"tool_call":false,"knowledge":"2025-03-31","release_date":"2025-08-05","last_updated":"2025-08-05","modalities":{"input":["text","image"],"output":["text"]},"open_weights":false,"limit":{"context":80000,"output":16000},"display_name":"Claude Opus 4.1"},{"id":"gpt-5-mini","name":"GPT-5-mini","attachment":true,"reasoning":true,"temperature":true,"tool_call":true,"knowledge":"2024-06","release_date":"2025-08-13","last_updated":"2025-08-13","modalities":{"input":["text","image"],"output":["text"]},"open_weights":false,"limit":{"context":128000,"output":64000},"display_name":"GPT-5-mini"},{"id":"claude-3.7-sonnet","name":"Claude Sonnet 3.7","attachment":true,"reasoning":false,"temperature":true,"tool_call":true,"knowledge":"2024-04","release_date":"2025-02-19","last_updated":"2025-02-19","modalities":{"input":["text","image"],"output":["text"]},"open_weights":false,"limit":{"context":200000,"output":16384},"display_name":"Claude Sonnet 3.7"},{"id":"gemini-2.5-pro","name":"Gemini 2.5 Pro","attachment":true,"reasoning":false,"temperature":true,"tool_call":true,"knowledge":"2025-01","release_date":"2025-03-20","last_updated":"2025-06-05","modalities":{"input":["text","image","audio","video"],"output":["text"]},"open_weights":false,"limit":{"context":128000,"output":64000},"display_name":"Gemini 2.5 Pro"},{"id":"o3","name":"o3 (Preview)","attachment":true,"reasoning":true,"temperature":false,"tool_call":true,"knowledge":"2024-05","release_date":"2025-04-16","last_updated":"2025-04-16","modalities":{"input":["text","image"],"output":["text"]},"open_weights":false,"limit":{"context":128000,"output":16384},"display_name":"o3 (Preview)"},{"id":"claude-sonnet-4","name":"Claude Sonnet 4","attachment":true,"reasoning":true,"temperature":true,"tool_call":true,"knowledge":"2025-03-31","release_date":"2025-05-22","last_updated":"2025-05-22","modalities":{"input":["text","image"],"output":["text"]},"open_weights":false,"limit":{"context":128000,"output":16000},"display_name":"Claude Sonnet 4"},{"id":"gpt-5","name":"GPT-5","attachment":true,"reasoning":true,"temperature":true,"tool_call":true,"knowledge":"2024-10","release_date":"2025-08-07","last_updated":"2025-08-07","modalities":{"input":["text","image"],"output":["text"]},"open_weights":false,"limit":{"context":128000,"output":64000},"display_name":"GPT-5"},{"id":"claude-3.7-sonnet-thought","name":"Claude Sonnet 3.7 Thinking","attachment":true,"reasoning":true,"temperature":true,"tool_call":true,"knowledge":"2024-04","release_date":"2025-02-19","last_updated":"2025-02-19","modalities":{"input":["text","image"],"output":["text"]},"open_weights":false,"limit":{"context":200000,"output":16384},"display_name":"Claude Sonnet 3.7 Thinking"},{"id":"claude-sonnet-4.5","name":"Claude Sonnet 4.5 (Preview)","attachment":true,"reasoning":true,"temperature":true,"tool_call":true,"knowledge":"2025-03-31","release_date":"2025-09-29","last_updated":"2025-09-29","modalities":{"input":["text","image"],"output":["text"]},"open_weights":false,"limit":{"context":128000,"output":16000},"display_name":"Claude Sonnet 4.5 (Preview)"}]},"mistral":{"id":"mistral","name":"Mistral","doc":"https://docs.mistral.ai/getting-started/models/","display_name":"Mistral","models":[{"id":"devstral-medium-2507","name":"Devstral Medium","attachment":false,"reasoning":false,"temperature":true,"tool_call":true,"knowledge":"2025-05","release_date":"2025-07-10","last_updated":"2025-07-10","modalities":{"input":["text"],"output":["text"]},"open_weights":true,"cost":{"input":0.4,"output":2},"limit":{"context":128000,"output":128000},"display_name":"Devstral Medium"},{"id":"open-mixtral-8x22b","name":"Mixtral 8x22B","attachment":false,"reasoning":false,"temperature":true,"tool_call":true,"knowledge":"2024-04","release_date":"2024-04-17","last_updated":"2024-04-17","modalities":{"input":["text"],"output":["text"]},"open_weights":true,"cost":{"input":2,"output":6},"limit":{"context":64000,"output":64000},"display_name":"Mixtral 8x22B"},{"id":"ministral-8b-latest","name":"Ministral 8B","attachment":false,"reasoning":false,"temperature":true,"tool_call":true,"knowledge":"2024-10","release_date":"2024-10-01","last_updated":"2024-10-04","modalities":{"input":["text"],"output":["text"]},"open_weights":true,"cost":{"input":0.1,"output":0.1},"limit":{"context":128000,"output":128000},"display_name":"Ministral 8B"},{"id":"pixtral-large-latest","name":"Pixtral Large","attachment":true,"reasoning":false,"temperature":true,"tool_call":true,"knowledge":"2024-11","release_date":"2024-11-01","last_updated":"2024-11-04","modalities":{"input":["text","image"],"output":["text"]},"open_weights":true,"cost":{"input":2,"output":6},"limit":{"context":128000,"output":128000},"display_name":"Pixtral Large"},{"id":"ministral-3b-latest","name":"Ministral 3B","attachment":false,"reasoning":false,"temperature":true,"tool_call":true,"knowledge":"2024-10","release_date":"2024-10-01","last_updated":"2024-10-04","modalities":{"input":["text"],"output":["text"]},"open_weights":true,"cost":{"input":0.04,"output":0.04},"limit":{"context":128000,"output":128000},"display_name":"Ministral 3B"},{"id":"pixtral-12b","name":"Pixtral 12B","attachment":true,"reasoning":false,"temperature":true,"tool_call":true,"knowledge":"2024-09","release_date":"2024-09-01","last_updated":"2024-09-01","modalities":{"input":["text","image"],"output":["text"]},"open_weights":true,"cost":{"input":0.15,"output":0.15},"limit":{"context":128000,"output":128000},"display_name":"Pixtral 12B"},{"id":"mistral-medium-2505","name":"Mistral Medium 3","attachment":true,"reasoning":false,"temperature":true,"tool_call":true,"knowledge":"2025-05","release_date":"2025-05-07","last_updated":"2025-05-07","modalities":{"input":["text","image"],"output":["text"]},"open_weights":false,"cost":{"input":0.4,"output":2},"limit":{"context":131072,"output":131072},"display_name":"Mistral Medium 3"},{"id":"devstral-small-2505","name":"Devstral Small 2505","attachment":false,"reasoning":false,"temperature":true,"tool_call":true,"knowledge":"2025-05","release_date":"2025-05-07","last_updated":"2025-05-07","modalities":{"input":["text"],"output":["text"]},"open_weights":true,"cost":{"input":0.1,"output":0.3},"limit":{"context":128000,"output":128000},"display_name":"Devstral Small 2505"},{"id":"mistral-medium-2508","name":"Mistral Medium 3.1","attachment":true,"reasoning":false,"temperature":true,"tool_call":true,"knowledge":"2025-05","release_date":"2025-08-12","last_updated":"2025-08-12","modalities":{"input":["text","image"],"output":["text"]},"open_weights":false,"cost":{"input":0.4,"output":2},"limit":{"context":262144,"output":262144},"display_name":"Mistral Medium 3.1"},{"id":"mistral-small-latest","name":"Mistral Small","attachment":false,"reasoning":false,"temperature":true,"tool_call":true,"knowledge":"2025-03","release_date":"2024-09-01","last_updated":"2024-09-04","modalities":{"input":["text","image"],"output":["text"]},"open_weights":true,"cost":{"input":0.1,"output":0.3},"limit":{"context":128000,"output":16384},"display_name":"Mistral Small"},{"id":"magistral-small","name":"Magistral Small","attachment":false,"reasoning":true,"temperature":true,"tool_call":true,"knowledge":"2025-06","release_date":"2025-03-17","last_updated":"2025-03-17","modalities":{"input":["text"],"output":["text"]},"open_weights":true,"cost":{"input":0.5,"output":1.5},"limit":{"context":128000,"output":128000},"display_name":"Magistral Small"},{"id":"devstral-small-2507","name":"Devstral Small","attachment":false,"reasoning":false,"temperature":true,"tool_call":true,"knowledge":"2025-05","release_date":"2025-07-10","last_updated":"2025-07-10","modalities":{"input":["text"],"output":["text"]},"open_weights":true,"cost":{"input":0.1,"output":0.3},"limit":{"context":128000,"output":128000},"display_name":"Devstral Small"},{"id":"codestral-latest","name":"Codestral","attachment":false,"reasoning":false,"temperature":true,"tool_call":true,"knowledge":"2024-10","release_date":"2024-05-29","last_updated":"2025-01-04","modalities":{"input":["text"],"output":["text"]},"open_weights":true,"cost":{"input":0.3,"output":0.9},"limit":{"context":256000,"output":4096},"display_name":"Codestral"},{"id":"open-mixtral-8x7b","name":"Mixtral 8x7B","attachment":false,"reasoning":false,"temperature":true,"tool_call":true,"knowledge":"2024-01","release_date":"2023-12-11","last_updated":"2023-12-11","modalities":{"input":["text"],"output":["text"]},"open_weights":true,"cost":{"input":0.7,"output":0.7},"limit":{"context":32000,"output":32000},"display_name":"Mixtral 8x7B"},{"id":"mistral-nemo","name":"Mistral Nemo","attachment":false,"reasoning":false,"temperature":true,"tool_call":true,"knowledge":"2024-07","release_date":"2024-07-01","last_updated":"2024-07-01","modalities":{"input":["text"],"output":["text"]},"open_weights":true,"cost":{"input":0.15,"output":0.15},"limit":{"context":128000,"output":128000},"display_name":"Mistral Nemo"},{"id":"open-mistral-7b","name":"Mistral 7B","attachment":false,"reasoning":false,"temperature":true,"tool_call":true,"knowledge":"2023-12","release_date":"2023-09-27","last_updated":"2023-09-27","modalities":{"input":["text"],"output":["text"]},"open_weights":true,"cost":{"input":0.25,"output":0.25},"limit":{"context":8000,"output":8000},"display_name":"Mistral 7B"},{"id":"mistral-large-latest","name":"Mistral Large","attachment":false,"reasoning":false,"temperature":true,"tool_call":true,"knowledge":"2024-11","release_date":"2024-11-01","last_updated":"2024-11-04","modalities":{"input":["text"],"output":["text"]},"open_weights":true,"cost":{"input":2,"output":6},"limit":{"context":131072,"output":16384},"display_name":"Mistral Large"},{"id":"mistral-medium-latest","name":"Mistral Medium","attachment":false,"reasoning":false,"temperature":true,"tool_call":true,"knowledge":"2025-05","release_date":"2025-05-07","last_updated":"2025-05-10","modalities":{"input":["text","image"],"output":["text"]},"open_weights":true,"cost":{"input":0.4,"output":2},"limit":{"context":128000,"output":16384},"display_name":"Mistral Medium"},{"id":"magistral-medium-latest","name":"Magistral Medium","attachment":false,"reasoning":true,"temperature":true,"tool_call":true,"knowledge":"2025-06","release_date":"2025-03-17","last_updated":"2025-03-20","modalities":{"input":["text"],"output":["text"]},"open_weights":true,"cost":{"input":2,"output":5},"limit":{"context":128000,"output":16384},"display_name":"Magistral Medium"}]},"vercel":{"id":"vercel","name":"Vercel AI Gateway","doc":"https://github.com/vercel/ai/tree/5eb85cc45a259553501f535b8ac79a77d0e79223/packages/gateway","display_name":"Vercel AI Gateway","models":[{"id":"moonshotai/kimi-k2","name":"Kimi K2 Instruct","attachment":false,"reasoning":false,"temperature":true,"tool_call":true,"knowledge":"2024-10","release_date":"2025-07-14","last_updated":"2025-07-14","modalities":{"input":["text"],"output":["text"]},"open_weights":true,"cost":{"input":1,"output":3},"limit":{"context":131072,"output":16384},"display_name":"Kimi K2 Instruct"},{"id":"xai/grok-3-mini-fast","name":"Grok 3 Mini Fast","attachment":false,"reasoning":true,"temperature":true,"tool_call":true,"knowledge":"2024-11","release_date":"2025-02-17","last_updated":"2025-02-17","modalities":{"input":["text"],"output":["text"]},"open_weights":false,"cost":{"input":0.6,"output":4,"reasoning":4,"cache_read":0.15},"limit":{"context":131072,"output":8192},"display_name":"Grok 3 Mini Fast"},{"id":"xai/grok-3-mini","name":"Grok 3 Mini","attachment":false,"reasoning":true,"temperature":true,"tool_call":true,"knowledge":"2024-11","release_date":"2025-02-17","last_updated":"2025-02-17","modalities":{"input":["text"],"output":["text"]},"open_weights":false,"cost":{"input":0.3,"output":0.5,"reasoning":0.5,"cache_read":0.075},"limit":{"context":131072,"output":8192},"display_name":"Grok 3 Mini"},{"id":"xai/grok-4-fast","name":"Grok 4 Fast","attachment":true,"reasoning":true,"temperature":true,"tool_call":true,"knowledge":"2025-07","release_date":"2025-09-19","last_updated":"2025-09-19","modalities":{"input":["text","image"],"output":["text"]},"open_weights":false,"cost":{"input":0.2,"output":0.5,"cache_read":0.05},"limit":{"context":2000000,"output":30000},"display_name":"Grok 4 Fast"},{"id":"xai/grok-3","name":"Grok 3","attachment":false,"reasoning":false,"temperature":true,"tool_call":true,"knowledge":"2024-11","release_date":"2025-02-17","last_updated":"2025-02-17","modalities":{"input":["text"],"output":["text"]},"open_weights":false,"cost":{"input":3,"output":15,"cache_read":0.75},"limit":{"context":131072,"output":8192},"display_name":"Grok 3"},{"id":"xai/grok-2","name":"Grok 2","attachment":false,"reasoning":false,"temperature":true,"tool_call":true,"knowledge":"2024-08","release_date":"2024-08-20","last_updated":"2024-08-20","modalities":{"input":["text"],"output":["text"]},"open_weights":false,"cost":{"input":2,"output":10,"cache_read":2},"limit":{"context":131072,"output":8192},"display_name":"Grok 2"},{"id":"xai/grok-code-fast-1","name":"Grok Code Fast 1","attachment":false,"reasoning":true,"temperature":true,"tool_call":true,"knowledge":"2023-10","release_date":"2025-08-28","last_updated":"2025-08-28","modalities":{"input":["text"],"output":["text"]},"open_weights":false,"cost":{"input":0.2,"output":1.5,"cache_read":0.02},"limit":{"context":256000,"output":10000},"display_name":"Grok Code Fast 1"},{"id":"xai/grok-2-vision","name":"Grok 2 Vision","attachment":true,"reasoning":false,"temperature":true,"tool_call":true,"knowledge":"2024-08","release_date":"2024-08-20","last_updated":"2024-08-20","modalities":{"input":["text","image"],"output":["text"]},"open_weights":false,"cost":{"input":2,"output":10,"cache_read":2},"limit":{"context":8192,"output":4096},"display_name":"Grok 2 Vision"},{"id":"xai/grok-4","name":"Grok 4","attachment":false,"reasoning":true,"temperature":true,"tool_call":true,"knowledge":"2025-07","release_date":"2025-07-09","last_updated":"2025-07-09","modalities":{"input":["text"],"output":["text"]},"open_weights":false,"cost":{"input":3,"output":15,"reasoning":15,"cache_read":0.75},"limit":{"context":256000,"output":64000},"display_name":"Grok 4"},{"id":"xai/grok-3-fast","name":"Grok 3 Fast","attachment":false,"reasoning":false,"temperature":true,"tool_call":true,"knowledge":"2024-11","release_date":"2025-02-17","last_updated":"2025-02-17","modalities":{"input":["text"],"output":["text"]},"open_weights":false,"cost":{"input":5,"output":25,"cache_read":1.25},"limit":{"context":131072,"output":8192},"display_name":"Grok 3 Fast"},{"id":"xai/grok-4-fast-non-reasoning","name":"Grok 4 Fast (Non-Reasoning)","attachment":true,"reasoning":false,"temperature":true,"tool_call":true,"knowledge":"2025-07","release_date":"2025-09-19","last_updated":"2025-09-19","modalities":{"input":["text","image"],"output":["text"]},"open_weights":false,"cost":{"input":0.2,"output":0.5,"cache_read":0.05},"limit":{"context":2000000,"output":30000},"display_name":"Grok 4 Fast (Non-Reasoning)"},{"id":"mistral/codestral","name":"Codestral","attachment":false,"reasoning":false,"temperature":true,"tool_call":true,"knowledge":"2024-10","release_date":"2024-05-29","last_updated":"2025-01-04","modalities":{"input":["text"],"output":["text"]},"open_weights":true,"cost":{"input":0.3,"output":0.9},"limit":{"context":256000,"output":4096},"display_name":"Codestral"},{"id":"mistral/magistral-medium","name":"Magistral Medium","attachment":false,"reasoning":true,"temperature":true,"tool_call":true,"knowledge":"2025-06","release_date":"2025-03-17","last_updated":"2025-03-20","modalities":{"input":["text"],"output":["text"]},"open_weights":true,"cost":{"input":2,"output":5},"limit":{"context":128000,"output":16384},"display_name":"Magistral Medium"},{"id":"mistral/mistral-large","name":"Mistral Large","attachment":false,"reasoning":false,"temperature":true,"tool_call":true,"knowledge":"2024-11","release_date":"2024-11-01","last_updated":"2024-11-04","modalities":{"input":["text"],"output":["text"]},"open_weights":true,"cost":{"input":2,"output":6},"limit":{"context":131072,"output":16384},"display_name":"Mistral Large"},{"id":"mistral/pixtral-large","name":"Pixtral Large","attachment":true,"reasoning":false,"temperature":true,"tool_call":true,"knowledge":"2024-11","release_date":"2024-11-01","last_updated":"2024-11-04","modalities":{"input":["text","image"],"output":["text"]},"open_weights":true,"cost":{"input":2,"output":6},"limit":{"context":128000,"output":128000},"display_name":"Pixtral Large"},{"id":"mistral/ministral-8b","name":"Ministral 8B","attachment":false,"reasoning":false,"temperature":true,"tool_call":true,"knowledge":"2024-10","release_date":"2024-10-01","last_updated":"2024-10-04","modalities":{"input":["text"],"output":["text"]},"open_weights":true,"cost":{"input":0.1,"output":0.1},"limit":{"context":128000,"output":128000},"display_name":"Ministral 8B"},{"id":"mistral/ministral-3b","name":"Ministral 3B","attachment":false,"reasoning":false,"temperature":true,"tool_call":true,"knowledge":"2024-10","release_date":"2024-10-01","last_updated":"2024-10-04","modalities":{"input":["text"],"output":["text"]},"open_weights":true,"cost":{"input":0.04,"output":0.04},"limit":{"context":128000,"output":128000},"display_name":"Ministral 3B"},{"id":"mistral/magistral-small","name":"Magistral Small","attachment":false,"reasoning":true,"temperature":true,"tool_call":true,"knowledge":"2025-06","release_date":"2025-03-17","last_updated":"2025-03-17","modalities":{"input":["text"],"output":["text"]},"open_weights":true,"cost":{"input":0.5,"output":1.5},"limit":{"context":128000,"output":128000},"display_name":"Magistral Small"},{"id":"mistral/mistral-small","name":"Mistral Small","attachment":false,"reasoning":false,"temperature":true,"tool_call":true,"knowledge":"2025-03","release_date":"2024-09-01","last_updated":"2024-09-04","modalities":{"input":["text","image"],"output":["text"]},"open_weights":true,"cost":{"input":0.1,"output":0.3},"limit":{"context":128000,"output":16384},"display_name":"Mistral Small"},{"id":"mistral/pixtral-12b","name":"Pixtral 12B","attachment":true,"reasoning":false,"temperature":true,"tool_call":true,"knowledge":"2024-09","release_date":"2024-09-01","last_updated":"2024-09-01","modalities":{"input":["text","image"],"output":["text"]},"open_weights":true,"cost":{"input":0.15,"output":0.15},"limit":{"context":128000,"output":128000},"display_name":"Pixtral 12B"},{"id":"mistral/mixtral-8x22b-instruct","name":"Mixtral 8x22B","attachment":false,"reasoning":false,"temperature":true,"tool_call":true,"knowledge":"2024-04","release_date":"2024-04-17","last_updated":"2024-04-17","modalities":{"input":["text"],"output":["text"]},"open_weights":true,"cost":{"input":2,"output":6},"limit":{"context":64000,"output":64000},"display_name":"Mixtral 8x22B"},{"id":"vercel/v0-1.0-md","name":"v0-1.0-md","attachment":true,"reasoning":true,"temperature":true,"tool_call":true,"release_date":"2025-05-22","last_updated":"2025-05-22","modalities":{"input":["text","image"],"output":["text"]},"open_weights":false,"cost":{"input":3,"output":15},"limit":{"context":128000,"output":32000},"display_name":"v0-1.0-md"},{"id":"vercel/v0-1.5-md","name":"v0-1.5-md","attachment":true,"reasoning":true,"temperature":true,"tool_call":true,"release_date":"2025-06-09","last_updated":"2025-06-09","modalities":{"input":["text","image"],"output":["text"]},"open_weights":false,"cost":{"input":3,"output":15},"limit":{"context":128000,"output":32000},"display_name":"v0-1.5-md"},{"id":"deepseek/deepseek-r1-distill-llama-70b","name":"DeepSeek R1 Distill Llama 70B","attachment":false,"reasoning":true,"temperature":true,"tool_call":true,"knowledge":"2024-07","release_date":"2025-01-20","last_updated":"2025-01-20","modalities":{"input":["text"],"output":["text"]},"open_weights":true,"cost":{"input":0.75,"output":0.99},"limit":{"context":131072,"output":8192},"display_name":"DeepSeek R1 Distill Llama 70B"},{"id":"deepseek/deepseek-r1","name":"DeepSeek-R1","attachment":false,"reasoning":true,"temperature":true,"tool_call":true,"knowledge":"2024-07","release_date":"2025-01-20","last_updated":"2025-05-29","modalities":{"input":["text"],"output":["text"]},"open_weights":false,"cost":{"input":1.35,"output":5.4},"limit":{"context":128000,"output":32768},"display_name":"DeepSeek-R1"},{"id":"google/gemini-2.5-pro","name":"Gemini 2.5 Pro","attachment":true,"reasoning":true,"temperature":true,"tool_call":true,"knowledge":"2025-01","release_date":"2025-03-20","last_updated":"2025-06-05","modalities":{"input":["text","image","audio","video","pdf"],"output":["text"]},"open_weights":false,"cost":{"input":1.25,"output":10,"cache_read":0.31},"limit":{"context":1048576,"output":65536},"display_name":"Gemini 2.5 Pro"},{"id":"google/gemini-2.0-flash","name":"Gemini 2.0 Flash","attachment":true,"reasoning":false,"temperature":true,"tool_call":true,"knowledge":"2024-06","release_date":"2024-12-11","last_updated":"2024-12-11","modalities":{"input":["text","image","audio","video","pdf"],"output":["text"]},"open_weights":false,"cost":{"input":0.1,"output":0.4,"cache_read":0.025},"limit":{"context":1048576,"output":8192},"display_name":"Gemini 2.0 Flash"},{"id":"google/gemini-2.0-flash-lite","name":"Gemini 2.0 Flash Lite","attachment":true,"reasoning":false,"temperature":true,"tool_call":true,"knowledge":"2024-06","release_date":"2024-12-11","last_updated":"2024-12-11","modalities":{"input":["text","image","audio","video","pdf"],"output":["text"]},"open_weights":false,"cost":{"input":0.075,"output":0.3},"limit":{"context":1048576,"output":8192},"display_name":"Gemini 2.0 Flash Lite"},{"id":"google/gemini-2.5-flash","name":"Gemini 2.5 Flash","attachment":true,"reasoning":true,"temperature":true,"tool_call":true,"knowledge":"2025-01","release_date":"2025-03-20","last_updated":"2025-06-05","modalities":{"input":["text","image","audio","video","pdf"],"output":["text"]},"open_weights":false,"cost":{"input":0.3,"output":2.5,"cache_read":0.075,"input_audio":1},"limit":{"context":1048576,"output":65536},"display_name":"Gemini 2.5 Flash"},{"id":"openai/gpt-oss-20b","name":"GPT OSS 20B","attachment":false,"reasoning":true,"temperature":true,"tool_call":true,"release_date":"2025-08-05","last_updated":"2025-08-05","modalities":{"input":["text"],"output":["text"]},"open_weights":true,"cost":{"input":0.07,"output":0.3},"limit":{"context":131072,"output":32768},"display_name":"GPT OSS 20B"},{"id":"openai/gpt-oss-120b","name":"GPT OSS 120B","attachment":false,"reasoning":true,"temperature":true,"tool_call":true,"release_date":"2025-08-05","last_updated":"2025-08-05","modalities":{"input":["text"],"output":["text"]},"open_weights":true,"cost":{"input":0.1,"output":0.5},"limit":{"context":131072,"output":32768},"display_name":"GPT OSS 120B"},{"id":"openai/gpt-5","name":"GPT-5","attachment":true,"reasoning":true,"temperature":false,"tool_call":true,"knowledge":"2024-09-30","release_date":"2025-08-07","last_updated":"2025-08-07","modalities":{"input":["text","image"],"output":["text"]},"open_weights":false,"cost":{"input":1.25,"output":10,"cache_read":0.13},"limit":{"context":400000,"output":128000},"display_name":"GPT-5"},{"id":"openai/gpt-4o-mini","name":"GPT-4o mini","attachment":true,"reasoning":false,"temperature":true,"tool_call":true,"knowledge":"2023-09","release_date":"2024-07-18","last_updated":"2024-07-18","modalities":{"input":["text","image"],"output":["text"]},"open_weights":false,"cost":{"input":0.15,"output":0.6,"cache_read":0.08},"limit":{"context":128000,"output":16384},"display_name":"GPT-4o mini"},{"id":"openai/o3","name":"o3","attachment":true,"reasoning":true,"temperature":false,"tool_call":true,"knowledge":"2024-05","release_date":"2025-04-16","last_updated":"2025-04-16","modalities":{"input":["text","image"],"output":["text"]},"open_weights":false,"cost":{"input":2,"output":8,"cache_read":0.5},"limit":{"context":200000,"output":100000},"display_name":"o3"},{"id":"openai/gpt-5-mini","name":"GPT-5 Mini","attachment":true,"reasoning":true,"temperature":false,"tool_call":true,"knowledge":"2024-05-30","release_date":"2025-08-07","last_updated":"2025-08-07","modalities":{"input":["text","image"],"output":["text"]},"open_weights":false,"cost":{"input":0.25,"output":2,"cache_read":0.03},"limit":{"context":400000,"output":128000},"display_name":"GPT-5 Mini"},{"id":"openai/o1","name":"o1","attachment":true,"reasoning":true,"temperature":false,"tool_call":true,"knowledge":"2023-09","release_date":"2024-12-05","last_updated":"2024-12-05","modalities":{"input":["text","image"],"output":["text"]},"open_weights":false,"cost":{"input":15,"output":60,"cache_read":7.5},"limit":{"context":200000,"output":100000},"display_name":"o1"},{"id":"openai/o4-mini","name":"o4-mini","attachment":true,"reasoning":true,"temperature":false,"tool_call":true,"knowledge":"2024-05","release_date":"2025-04-16","last_updated":"2025-04-16","modalities":{"input":["text","image"],"output":["text"]},"open_weights":false,"cost":{"input":1.1,"output":4.4,"cache_read":0.28},"limit":{"context":200000,"output":100000},"display_name":"o4-mini"},{"id":"openai/gpt-4.1","name":"GPT-4.1","attachment":true,"reasoning":false,"temperature":true,"tool_call":true,"knowledge":"2024-04","release_date":"2025-04-14","last_updated":"2025-04-14","modalities":{"input":["text","image"],"output":["text"]},"open_weights":false,"cost":{"input":2,"output":8,"cache_read":0.5},"limit":{"context":1047576,"output":32768},"display_name":"GPT-4.1"},{"id":"openai/gpt-4o","name":"GPT-4o","attachment":true,"reasoning":false,"temperature":true,"tool_call":true,"knowledge":"2023-09","release_date":"2024-05-13","last_updated":"2024-08-06","modalities":{"input":["text","image"],"output":["text"]},"open_weights":false,"cost":{"input":2.5,"output":10,"cache_read":1.25},"limit":{"context":128000,"output":16384},"display_name":"GPT-4o"},{"id":"openai/gpt-5-codex","name":"GPT-5-Codex","attachment":false,"reasoning":true,"temperature":false,"tool_call":true,"knowledge":"2024-09-30","release_date":"2025-09-15","last_updated":"2025-09-15","modalities":{"input":["text","image"],"output":["text"]},"open_weights":false,"limit":{"context":400000,"output":128000},"display_name":"GPT-5-Codex"},{"id":"openai/gpt-5-nano","name":"GPT-5 Nano","attachment":true,"reasoning":true,"temperature":false,"tool_call":true,"knowledge":"2024-05-30","release_date":"2025-08-07","last_updated":"2025-08-07","modalities":{"input":["text","image"],"output":["text"]},"open_weights":false,"cost":{"input":0.05,"output":0.4,"cache_read":0.01},"limit":{"context":400000,"output":128000},"display_name":"GPT-5 Nano"},{"id":"openai/o3-mini","name":"o3-mini","attachment":false,"reasoning":true,"temperature":false,"tool_call":true,"knowledge":"2024-05","release_date":"2024-12-20","last_updated":"2025-01-29","modalities":{"input":["text"],"output":["text"]},"open_weights":false,"cost":{"input":1.1,"output":4.4,"cache_read":0.55},"limit":{"context":200000,"output":100000},"display_name":"o3-mini"},{"id":"openai/gpt-4-turbo","name":"GPT-4 Turbo","attachment":true,"reasoning":false,"temperature":true,"tool_call":true,"knowledge":"2023-12","release_date":"2023-11-06","last_updated":"2024-04-09","modalities":{"input":["text","image"],"output":["text"]},"open_weights":false,"cost":{"input":10,"output":30},"limit":{"context":128000,"output":4096},"display_name":"GPT-4 Turbo"},{"id":"openai/gpt-4.1-mini","name":"GPT-4.1 mini","attachment":true,"reasoning":false,"temperature":true,"tool_call":true,"knowledge":"2024-04","release_date":"2025-04-14","last_updated":"2025-04-14","modalities":{"input":["text","image"],"output":["text"]},"open_weights":false,"cost":{"input":0.4,"output":1.6,"cache_read":0.1},"limit":{"context":1047576,"output":32768},"display_name":"GPT-4.1 mini"},{"id":"openai/gpt-4.1-nano","name":"GPT-4.1 nano","attachment":true,"reasoning":false,"temperature":true,"tool_call":true,"knowledge":"2024-04","release_date":"2025-04-14","last_updated":"2025-04-14","modalities":{"input":["text","image"],"output":["text"]},"open_weights":false,"cost":{"input":0.1,"output":0.4,"cache_read":0.03},"limit":{"context":1047576,"output":32768},"display_name":"GPT-4.1 nano"},{"id":"amazon/nova-micro","name":"Nova Micro","attachment":false,"reasoning":false,"temperature":true,"tool_call":true,"knowledge":"2024-10","release_date":"2024-12-03","last_updated":"2024-12-03","modalities":{"input":["text"],"output":["text"]},"open_weights":false,"cost":{"input":0.035,"output":0.14,"cache_read":0.00875},"limit":{"context":128000,"output":8192},"display_name":"Nova Micro"},{"id":"amazon/nova-pro","name":"Nova Pro","attachment":true,"reasoning":false,"temperature":true,"tool_call":true,"knowledge":"2024-10","release_date":"2024-12-03","last_updated":"2024-12-03","modalities":{"input":["text","image","video"],"output":["text"]},"open_weights":false,"cost":{"input":0.8,"output":3.2,"cache_read":0.2},"limit":{"context":300000,"output":8192},"display_name":"Nova Pro"},{"id":"amazon/nova-lite","name":"Nova Lite","attachment":true,"reasoning":false,"temperature":true,"tool_call":true,"knowledge":"2024-10","release_date":"2024-12-03","last_updated":"2024-12-03","modalities":{"input":["text","image","video"],"output":["text"]},"open_weights":false,"cost":{"input":0.06,"output":0.24,"cache_read":0.015},"limit":{"context":300000,"output":8192},"display_name":"Nova Lite"},{"id":"morph/morph-v3-fast","name":"Morph v3 Fast","attachment":false,"reasoning":false,"temperature":false,"tool_call":false,"release_date":"2024-08-15","last_updated":"2024-08-15","modalities":{"input":["text"],"output":["text"]},"open_weights":false,"cost":{"input":0.8,"output":1.2},"limit":{"context":16000,"output":16000},"display_name":"Morph v3 Fast"},{"id":"morph/morph-v3-large","name":"Morph v3 Large","attachment":false,"reasoning":false,"temperature":false,"tool_call":false,"release_date":"2024-08-15","last_updated":"2024-08-15","modalities":{"input":["text"],"output":["text"]},"open_weights":false,"cost":{"input":0.9,"output":1.9},"limit":{"context":32000,"output":32000},"display_name":"Morph v3 Large"},{"id":"meta/llama-4-scout","name":"Llama-4-Scout-17B-16E-Instruct-FP8","attachment":true,"reasoning":false,"temperature":true,"tool_call":true,"knowledge":"2024-08","release_date":"2025-04-05","last_updated":"2025-04-05","modalities":{"input":["text","image"],"output":["text"]},"open_weights":true,"cost":{"input":0,"output":0},"limit":{"context":128000,"output":4096},"display_name":"Llama-4-Scout-17B-16E-Instruct-FP8"},{"id":"meta/llama-3.3-70b","name":"Llama-3.3-70B-Instruct","attachment":true,"reasoning":false,"temperature":true,"tool_call":true,"knowledge":"2023-12","release_date":"2024-12-06","last_updated":"2024-12-06","modalities":{"input":["text"],"output":["text"]},"open_weights":true,"cost":{"input":0,"output":0},"limit":{"context":128000,"output":4096},"display_name":"Llama-3.3-70B-Instruct"},{"id":"meta/llama-4-maverick","name":"Llama-4-Maverick-17B-128E-Instruct-FP8","attachment":true,"reasoning":false,"temperature":true,"tool_call":true,"knowledge":"2024-08","release_date":"2025-04-05","last_updated":"2025-04-05","modalities":{"input":["text","image"],"output":["text"]},"open_weights":true,"cost":{"input":0,"output":0},"limit":{"context":128000,"output":4096},"display_name":"Llama-4-Maverick-17B-128E-Instruct-FP8"},{"id":"anthropic/claude-3.7-sonnet","name":"Claude Sonnet 3.7","attachment":true,"reasoning":true,"temperature":true,"tool_call":true,"knowledge":"2024-10-31","release_date":"2025-02-19","last_updated":"2025-02-19","modalities":{"input":["text","image"],"output":["text"]},"open_weights":false,"cost":{"input":3,"output":15,"cache_read":0.3,"cache_write":3.75},"limit":{"context":200000,"output":64000},"display_name":"Claude Sonnet 3.7"},{"id":"anthropic/claude-3-5-haiku","name":"Claude Haiku 3.5","attachment":true,"reasoning":false,"temperature":true,"tool_call":true,"knowledge":"2024-07-31","release_date":"2024-10-22","last_updated":"2024-10-22","modalities":{"input":["text","image"],"output":["text"]},"open_weights":false,"cost":{"input":0.8,"output":4,"cache_read":0.08,"cache_write":1},"limit":{"context":200000,"output":8192},"display_name":"Claude Haiku 3.5"},{"id":"anthropic/claude-4.5-sonnet","name":"Claude Sonnet 4.5","attachment":true,"reasoning":true,"temperature":true,"tool_call":true,"knowledge":"2025-07-31","release_date":"2025-09-29","last_updated":"2025-09-29","modalities":{"input":["text","image"],"output":["text"]},"open_weights":false,"cost":{"input":3,"output":15,"cache_read":0.3,"cache_write":3.75},"limit":{"context":200000,"output":64000},"display_name":"Claude Sonnet 4.5"},{"id":"anthropic/claude-3.5-sonnet","name":"Claude Sonnet 3.5 v2","attachment":true,"reasoning":false,"temperature":true,"tool_call":true,"knowledge":"2024-04-30","release_date":"2024-10-22","last_updated":"2024-10-22","modalities":{"input":["text","image"],"output":["text"]},"open_weights":false,"cost":{"input":3,"output":15,"cache_read":0.3,"cache_write":3.75},"limit":{"context":200000,"output":8192},"display_name":"Claude Sonnet 3.5 v2"},{"id":"anthropic/claude-4-1-opus","name":"Claude Opus 4","attachment":true,"reasoning":true,"temperature":true,"tool_call":true,"knowledge":"2025-03-31","release_date":"2025-05-22","last_updated":"2025-05-22","modalities":{"input":["text","image"],"output":["text"]},"open_weights":false,"cost":{"input":15,"output":75,"cache_read":1.5,"cache_write":18.75},"limit":{"context":200000,"output":32000},"display_name":"Claude Opus 4"},{"id":"anthropic/claude-4-sonnet","name":"Claude Sonnet 4","attachment":true,"reasoning":true,"temperature":true,"tool_call":true,"knowledge":"2025-03-31","release_date":"2025-05-22","last_updated":"2025-05-22","modalities":{"input":["text","image"],"output":["text"]},"open_weights":false,"cost":{"input":3,"output":15,"cache_read":0.3,"cache_write":3.75},"limit":{"context":200000,"output":64000},"display_name":"Claude Sonnet 4"},{"id":"anthropic/claude-3-opus","name":"Claude Opus 3","attachment":true,"reasoning":false,"temperature":true,"tool_call":true,"knowledge":"2023-08-31","release_date":"2024-02-29","last_updated":"2024-02-29","modalities":{"input":["text","image"],"output":["text"]},"open_weights":false,"cost":{"input":15,"output":75,"cache_read":1.5,"cache_write":18.75},"limit":{"context":200000,"output":4096},"display_name":"Claude Opus 3"},{"id":"anthropic/claude-3-haiku","name":"Claude Haiku 3","attachment":true,"reasoning":false,"temperature":true,"tool_call":true,"knowledge":"2023-08-31","release_date":"2024-03-13","last_updated":"2024-03-13","modalities":{"input":["text","image"],"output":["text"]},"open_weights":false,"cost":{"input":0.25,"output":1.25,"cache_read":0.03,"cache_write":0.3},"limit":{"context":200000,"output":4096},"display_name":"Claude Haiku 3"},{"id":"anthropic/claude-4-opus","name":"Claude Opus 4","attachment":true,"reasoning":true,"temperature":true,"tool_call":true,"knowledge":"2025-03-31","release_date":"2025-05-22","last_updated":"2025-05-22","modalities":{"input":["text","image"],"output":["text"]},"open_weights":false,"cost":{"input":15,"output":75,"cache_read":1.5,"cache_write":18.75},"limit":{"context":200000,"output":32000},"display_name":"Claude Opus 4"},{"id":"cerebras/qwen3-coder","name":"Qwen 3 Coder 480B","attachment":false,"reasoning":false,"temperature":true,"tool_call":true,"knowledge":"2025-04","release_date":"2025-07-23","last_updated":"2025-07-23","modalities":{"input":["text"],"output":["text"]},"open_weights":true,"cost":{"input":2,"output":2},"limit":{"context":131000,"output":32000},"display_name":"Qwen 3 Coder 480B"}]},"deepseek":{"id":"deepseek","api":"https://api.deepseek.com","name":"DeepSeek","doc":"https://platform.deepseek.com/api-docs/pricing","display_name":"DeepSeek","models":[{"id":"deepseek-chat","name":"DeepSeek Chat","attachment":true,"reasoning":false,"temperature":true,"tool_call":true,"knowledge":"2024-07","release_date":"2024-12-26","last_updated":"2025-08-21","modalities":{"input":["text"],"output":["text"]},"open_weights":false,"cost":{"input":0.57,"output":1.68,"cache_read":0.07},"limit":{"context":128000,"output":8192},"display_name":"DeepSeek Chat"},{"id":"deepseek-reasoner","name":"DeepSeek Reasoner","attachment":true,"reasoning":true,"temperature":true,"tool_call":true,"knowledge":"2024-07","release_date":"2025-01-20","last_updated":"2025-08-21","modalities":{"input":["text"],"output":["text"]},"open_weights":false,"cost":{"input":0.57,"output":1.68,"cache_read":0.07},"limit":{"context":128000,"output":128000},"display_name":"DeepSeek Reasoner"}]},"alibaba-cn":{"id":"alibaba-cn","api":"https://dashscope.aliyuncs.com/compatible-mode/v1","name":"Alibaba (China)","doc":"https://www.alibabacloud.com/help/en/model-studio/models","display_name":"Alibaba (China)","models":[{"id":"qwen3-coder-plus","name":"Qwen3 Coder Plus","attachment":false,"reasoning":false,"temperature":true,"tool_call":true,"knowledge":"2025-04","release_date":"2025-07-23","last_updated":"2025-07-23","modalities":{"input":["text"],"output":["text"]},"open_weights":true,"cost":{"input":1,"output":5},"limit":{"context":1048576,"output":65536},"display_name":"Qwen3 Coder Plus"}]},"google-vertex-anthropic":{"id":"google-vertex-anthropic","name":"Vertex","doc":"https://cloud.google.com/vertex-ai/generative-ai/docs/partner-models/claude","display_name":"Vertex","models":[{"id":"claude-3-5-sonnet@20241022","name":"Claude Sonnet 3.5 v2","attachment":true,"reasoning":false,"temperature":true,"tool_call":true,"knowledge":"2024-04-30","release_date":"2024-10-22","last_updated":"2024-10-22","modalities":{"input":["text","image"],"output":["text"]},"open_weights":false,"cost":{"input":3,"output":15,"cache_read":0.3,"cache_write":3.75},"limit":{"context":200000,"output":8192},"display_name":"Claude Sonnet 3.5 v2"},{"id":"claude-3-5-haiku@20241022","name":"Claude Haiku 3.5","attachment":true,"reasoning":false,"temperature":true,"tool_call":true,"knowledge":"2024-07-31","release_date":"2024-10-22","last_updated":"2024-10-22","modalities":{"input":["text","image"],"output":["text"]},"open_weights":false,"cost":{"input":0.8,"output":4,"cache_read":0.08,"cache_write":1},"limit":{"context":200000,"output":8192},"display_name":"Claude Haiku 3.5"},{"id":"claude-sonnet-4@20250514","name":"Claude Sonnet 4","attachment":true,"reasoning":true,"temperature":true,"tool_call":true,"knowledge":"2025-03-31","release_date":"2025-05-22","last_updated":"2025-05-22","modalities":{"input":["text","image"],"output":["text"]},"open_weights":false,"cost":{"input":3,"output":15,"cache_read":0.3,"cache_write":3.75},"limit":{"context":200000,"output":64000},"display_name":"Claude Sonnet 4"},{"id":"claude-opus-4-1@20250805","name":"Claude Opus 4.1","attachment":true,"reasoning":true,"temperature":true,"tool_call":true,"knowledge":"2025-03-31","release_date":"2025-08-05","last_updated":"2025-08-05","modalities":{"input":["text","image"],"output":["text"]},"open_weights":false,"cost":{"input":15,"output":75,"cache_read":1.5,"cache_write":18.75},"limit":{"context":200000,"output":32000},"display_name":"Claude Opus 4.1"},{"id":"claude-3-7-sonnet@20250219","name":"Claude Sonnet 3.7","attachment":true,"reasoning":true,"temperature":true,"tool_call":true,"knowledge":"2024-10-31","release_date":"2025-02-19","last_updated":"2025-02-19","modalities":{"input":["text","image"],"output":["text"]},"open_weights":false,"cost":{"input":3,"output":15,"cache_read":0.3,"cache_write":3.75},"limit":{"context":200000,"output":64000},"display_name":"Claude Sonnet 3.7"},{"id":"claude-opus-4@20250514","name":"Claude Opus 4","attachment":true,"reasoning":true,"temperature":true,"tool_call":true,"knowledge":"2025-03-31","release_date":"2025-05-22","last_updated":"2025-05-22","modalities":{"input":["text","image"],"output":["text"]},"open_weights":false,"cost":{"input":15,"output":75,"cache_read":1.5,"cache_write":18.75},"limit":{"context":200000,"output":32000},"display_name":"Claude Opus 4"}]},"venice":{"id":"venice","api":"https://api.venice.ai/api/v1","name":"Venice AI","doc":"https://docs.venice.ai","display_name":"Venice AI","models":[{"id":"dolphin-2.9.2-qwen2-72b","name":"Dolphin 72B","attachment":false,"reasoning":false,"temperature":true,"tool_call":false,"knowledge":"2021-09","release_date":"2025-05-21","last_updated":"2025-05-21","modalities":{"input":["text"],"output":["text"]},"open_weights":true,"cost":{"input":0.7,"output":2.8},"limit":{"context":32768,"output":8192},"display_name":"Dolphin 72B"},{"id":"mistral-31-24b","name":"Venice Medium","attachment":false,"reasoning":false,"temperature":true,"tool_call":true,"knowledge":"2023-10","release_date":"2025-07-15","last_updated":"2025-07-15","modalities":{"input":["text","image"],"output":["text"]},"open_weights":true,"cost":{"input":0.5,"output":2},"limit":{"context":131072,"output":8192},"display_name":"Venice Medium"},{"id":"venice-uncensored","name":"Venice Uncensored 1.1","attachment":false,"reasoning":false,"temperature":true,"tool_call":false,"knowledge":"2023-10","release_date":"2025-07-15","last_updated":"2025-07-15","modalities":{"input":["text"],"output":["text"]},"open_weights":true,"cost":{"input":0.5,"output":2},"limit":{"context":32768,"output":8192},"display_name":"Venice Uncensored 1.1"},{"id":"qwen-2.5-vl","name":"Qwen 2.5 VL 72B","attachment":false,"reasoning":false,"temperature":true,"tool_call":false,"knowledge":"2023-10","release_date":"2025-06-09","last_updated":"2025-06-09","modalities":{"input":["text","image"],"output":["text"]},"open_weights":true,"cost":{"input":0.7,"output":2.8},"limit":{"context":32768,"output":8192},"display_name":"Qwen 2.5 VL 72B"},{"id":"qwen3-235b","name":"Venice Large","attachment":false,"reasoning":true,"temperature":true,"tool_call":true,"knowledge":"2024-10","release_date":"2025-07-27","last_updated":"2025-07-27","modalities":{"input":["text"],"output":["text"]},"open_weights":true,"cost":{"input":1.5,"output":6},"limit":{"context":131072,"output":8192},"display_name":"Venice Large"},{"id":"qwen-2.5-qwq-32b","name":"Venice Reasoning","attachment":false,"reasoning":true,"temperature":true,"tool_call":false,"knowledge":"2023-10","release_date":"2025-07-08","last_updated":"2025-07-08","modalities":{"input":["text"],"output":["text"]},"open_weights":true,"cost":{"input":0.5,"output":2},"limit":{"context":32768,"output":8192},"display_name":"Venice Reasoning"},{"id":"deepseek-coder-v2-lite","name":"DeepSeek Coder V2 Lite","attachment":false,"reasoning":false,"temperature":true,"tool_call":false,"knowledge":"2021-09","release_date":"2025-06-22","last_updated":"2025-06-22","modalities":{"input":["text"],"output":["text"]},"open_weights":true,"cost":{"input":0.5,"output":2},"limit":{"context":131072,"output":8192},"display_name":"DeepSeek Coder V2 Lite"},{"id":"qwen3-4b","name":"Venice Small","attachment":false,"reasoning":true,"temperature":true,"tool_call":true,"knowledge":"2024-07","release_date":"2025-07-27","last_updated":"2025-07-27","modalities":{"input":["text"],"output":["text"]},"open_weights":true,"cost":{"input":0.15,"output":0.6},"limit":{"context":32768,"output":8192},"display_name":"Venice Small"},{"id":"llama-3.3-70b","name":"Llama 3.3 70B","attachment":false,"reasoning":false,"temperature":true,"tool_call":true,"knowledge":"2023-12","release_date":"2025-06-09","last_updated":"2025-06-09","modalities":{"input":["text"],"output":["text"]},"open_weights":true,"cost":{"input":0.7,"output":2.8},"limit":{"context":65536,"output":8192},"display_name":"Llama 3.3 70B"},{"id":"qwen-2.5-coder-32b","name":"Qwen 2.5 Coder 32B","attachment":false,"reasoning":false,"temperature":true,"tool_call":false,"knowledge":"2023-10","release_date":"2025-06-14","last_updated":"2025-06-14","modalities":{"input":["text"],"output":["text"]},"open_weights":true,"cost":{"input":0.5,"output":2},"limit":{"context":32768,"output":8192},"display_name":"Qwen 2.5 Coder 32B"},{"id":"deepseek-r1-671b","name":"DeepSeek R1 671B","attachment":false,"reasoning":true,"temperature":true,"tool_call":false,"knowledge":"2023-10","release_date":"2025-06-05","last_updated":"2025-06-05","modalities":{"input":["text"],"output":["text"]},"open_weights":true,"cost":{"input":3.5,"output":14},"limit":{"context":131072,"output":8192},"display_name":"DeepSeek R1 671B"},{"id":"llama-3.2-3b","name":"Llama 3.2 3B","attachment":false,"reasoning":false,"temperature":true,"tool_call":true,"knowledge":"2023-12","release_date":"2025-05-23","last_updated":"2025-05-23","modalities":{"input":["text"],"output":["text"]},"open_weights":true,"cost":{"input":0.15,"output":0.6},"limit":{"context":131072,"output":8192},"display_name":"Llama 3.2 3B"},{"id":"llama-3.1-405b","name":"Llama 3.1 405B","attachment":false,"reasoning":false,"temperature":true,"tool_call":false,"knowledge":"2023-12","release_date":"2025-06-30","last_updated":"2025-06-30","modalities":{"input":["text"],"output":["text"]},"open_weights":true,"cost":{"input":1.5,"output":6},"limit":{"context":65536,"output":8192},"display_name":"Llama 3.1 405B"}]},"chutes":{"id":"chutes","api":"https://llm.chutes.ai/v1","name":"Chutes","doc":"https://llm.chutes.ai/v1/models","display_name":"Chutes","models":[{"id":"moonshotai/Kimi-Dev-72B","name":"Kimi Dev 72B","attachment":false,"reasoning":false,"temperature":true,"tool_call":true,"release_date":"2024-12-01","last_updated":"2024-12-01","modalities":{"input":["text"],"output":["text"]},"open_weights":false,"cost":{"input":0.06664,"output":0.266688},"limit":{"context":131072,"output":131072},"display_name":"Kimi Dev 72B"},{"id":"moonshotai/Kimi-K2-Instruct-75k","name":"Kimi K2 Instruct","attachment":false,"reasoning":false,"temperature":true,"tool_call":true,"release_date":"2025-08-01","last_updated":"2025-08-01","modalities":{"input":["text"],"output":["text"]},"open_weights":false,"cost":{"input":0.15,"output":0.59},"limit":{"context":75000,"output":75000},"display_name":"Kimi K2 Instruct"},{"id":"moonshotai/Kimi-K2-Instruct-0905","name":"Kimi K2 Instruct 0905","attachment":false,"reasoning":false,"temperature":true,"tool_call":true,"release_date":"2024-09-05","last_updated":"2024-09-05","modalities":{"input":["text"],"output":["text"]},"open_weights":false,"cost":{"input":0.296176,"output":1.18528},"limit":{"context":262144,"output":262144},"display_name":"Kimi K2 Instruct 0905"},{"id":"moonshotai/Kimi-VL-A3B-Thinking","name":"Kimi VL A3B Thinking","attachment":false,"reasoning":true,"temperature":true,"tool_call":true,"release_date":"2024-12-01","last_updated":"2024-12-01","modalities":{"input":["text","image"],"output":["text"]},"open_weights":false,"cost":{"input":0.02499,"output":0.100008},"limit":{"context":131072,"output":131072},"display_name":"Kimi VL A3B Thinking"},{"id":"meituan-longcat/LongCat-Flash-Chat-FP8","name":"LongCat Flash Chat FP8","attachment":false,"reasoning":false,"temperature":true,"tool_call":true,"release_date":"2025-09-10","last_updated":"2025-09-10","modalities":{"input":["text"],"output":["text"]},"open_weights":true,"cost":{"input":0.25,"output":1},"limit":{"context":131072,"output":131072},"display_name":"LongCat Flash Chat FP8"},{"id":"tngtech/DeepSeek-R1T-Chimera","name":"DeepSeek R1T Chimera","attachment":false,"reasoning":true,"temperature":true,"tool_call":false,"knowledge":"2025-04","release_date":"2025-04-26","last_updated":"2025-04-26","modalities":{"input":["text"],"output":["text"]},"open_weights":true,"cost":{"input":0.18,"output":0.72},"limit":{"context":163840,"output":163840},"display_name":"DeepSeek R1T Chimera"},{"id":"tngtech/DeepSeek-TNG-R1T2-Chimera","name":"DeepSeek TNG R1T2 Chimera","attachment":false,"reasoning":true,"temperature":true,"tool_call":false,"knowledge":"2025-07","release_date":"2025-07-08","last_updated":"2025-07-08","modalities":{"input":["text"],"output":["text"]},"open_weights":true,"cost":{"input":0.2,"output":0.8},"limit":{"context":163840,"output":163840},"display_name":"DeepSeek TNG R1T2 Chimera"},{"id":"openai/gpt-oss-120b","name":"GPT OSS 120B","attachment":false,"reasoning":true,"temperature":true,"tool_call":true,"release_date":"2025-08-05","last_updated":"2025-08-05","modalities":{"input":["text"],"output":["text"]},"open_weights":true,"cost":{"input":0.1,"output":0.41},"limit":{"context":131072,"output":32768},"display_name":"GPT OSS 120B"},{"id":"chutesai/Devstral-Small-2505","name":"Devstral Small (2505)","attachment":false,"reasoning":false,"temperature":true,"tool_call":true,"release_date":"2025-05-21","last_updated":"2025-05-21","modalities":{"input":["text"],"output":["text"]},"open_weights":true,"cost":{"input":0.02,"output":0.08},"limit":{"context":32768,"output":32768},"display_name":"Devstral Small (2505)"},{"id":"chutesai/Mistral-Small-3.2-24B-Instruct-2506","name":"Mistral Small 3.2 24B Instruct (2506)","attachment":false,"reasoning":false,"temperature":true,"tool_call":true,"release_date":"2025-06-20","last_updated":"2025-06-20","modalities":{"input":["text"],"output":["text"]},"open_weights":true,"cost":{"input":0.02,"output":0.08},"limit":{"context":131072,"output":131072},"display_name":"Mistral Small 3.2 24B Instruct (2506)"},{"id":"Qwen/Qwen3-30B-A3B","name":"Qwen3 30B A3B","attachment":false,"reasoning":true,"temperature":true,"tool_call":true,"knowledge":"2025-04","release_date":"2025-04-28","last_updated":"2025-04-28","modalities":{"input":["text"],"output":["text"]},"open_weights":true,"cost":{"input":0.02,"output":0.08},"limit":{"context":40960,"output":40960},"display_name":"Qwen3 30B A3B"},{"id":"Qwen/Qwen3-30B-A3B-Thinking-2507","name":"Qwen3 30B A3B Thinking 2507","attachment":false,"reasoning":true,"temperature":true,"tool_call":true,"knowledge":"2025-04","release_date":"2025-07-30","last_updated":"2025-07-30","modalities":{"input":["text"],"output":["text"]},"open_weights":true,"cost":{"input":0.08,"output":0.29},"limit":{"context":262144,"output":262144},"display_name":"Qwen3 30B A3B Thinking 2507"},{"id":"Qwen/Qwen3-235B-A22B-Instruct-2507","name":"Qwen3 235B A22B Instruct 2507","attachment":false,"reasoning":false,"temperature":true,"tool_call":true,"knowledge":"2025-04","release_date":"2025-04-28","last_updated":"2025-07-21","modalities":{"input":["text"],"output":["text"]},"open_weights":true,"cost":{"input":0.078,"output":0.312},"limit":{"context":262144,"output":131072},"display_name":"Qwen3 235B A22B Instruct 2507"},{"id":"Qwen/Qwen3-Coder-30B-A3B-Instruct","name":"Qwen3 Coder 30B A3B Instruct","attachment":false,"reasoning":false,"temperature":true,"tool_call":true,"knowledge":"2025-04","release_date":"2025-07-25","last_updated":"2025-07-25","modalities":{"input":["text"],"output":["text"]},"open_weights":true,"cost":{"input":0,"output":0},"limit":{"context":262144,"output":262144},"display_name":"Qwen3 Coder 30B A3B Instruct"},{"id":"Qwen/Qwen3-Coder-480B-A35B-Instruct-FP8","name":"Qwen3 Coder 480B A35B Instruct (FP8)","attachment":false,"reasoning":false,"temperature":true,"tool_call":true,"release_date":"2025-08-01","last_updated":"2025-08-01","modalities":{"input":["text"],"output":["text"]},"open_weights":false,"cost":{"input":0.2,"output":0.8},"limit":{"context":262144,"output":262144},"display_name":"Qwen3 Coder 480B A35B Instruct (FP8)"},{"id":"Qwen/Qwen3-30B-A3B-Instruct-2507","name":"Qwen3 30B A3B Instruct 2507","attachment":false,"reasoning":false,"temperature":true,"tool_call":true,"knowledge":"2025-04","release_date":"2025-07-25","last_updated":"2025-07-25","modalities":{"input":["text"],"output":["text"]},"open_weights":true,"cost":{"input":0.05,"output":0.2},"limit":{"context":262144,"output":262144},"display_name":"Qwen3 30B A3B Instruct 2507"},{"id":"Qwen/Qwen3-235B-A22B-Thinking-2507","name":"Qwen3-235B-A22B-Thinking-2507","attachment":false,"reasoning":true,"temperature":true,"tool_call":true,"knowledge":"2025-04","release_date":"2025-07-25","last_updated":"2025-07-25","modalities":{"input":["text"],"output":["text"]},"open_weights":true,"cost":{"input":0.078,"output":0.312},"limit":{"context":262144,"output":262144},"display_name":"Qwen3-235B-A22B-Thinking-2507"},{"id":"Qwen/Qwen3-Next-80B-A3B-Instruct","name":"Qwen3 Next 80B A3B Instruct","attachment":false,"reasoning":false,"temperature":true,"tool_call":true,"knowledge":"2025-04","release_date":"2025-09-11","last_updated":"2025-09-11","modalities":{"input":["text"],"output":["text"]},"open_weights":true,"cost":{"input":0.1,"output":0.8},"limit":{"context":262144,"output":262144},"display_name":"Qwen3 Next 80B A3B Instruct"},{"id":"Qwen/Qwen3-Next-80B-A3B-Thinking","name":"Qwen3 Next 80B A3B Thinking","attachment":false,"reasoning":true,"temperature":true,"tool_call":true,"knowledge":"2025-04","release_date":"2025-09-11","last_updated":"2025-09-11","modalities":{"input":["text"],"output":["text"]},"open_weights":true,"cost":{"input":0.1,"output":0.8},"limit":{"context":262144,"output":262144},"display_name":"Qwen3 Next 80B A3B Thinking"},{"id":"zai-org/GLM-4.5-turbo","name":"GLM 4.5 Turbo","attachment":false,"reasoning":true,"temperature":true,"tool_call":true,"knowledge":"2025-04","release_date":"2025-07-28","last_updated":"2025-07-28","modalities":{"input":["text"],"output":["text"]},"open_weights":true,"cost":{"input":1,"output":3},"limit":{"context":131072,"output":131072},"display_name":"GLM 4.5 Turbo"},{"id":"zai-org/GLM-4.6-FP8","name":"GLM 4.6 FP8","attachment":false,"reasoning":true,"temperature":true,"tool_call":true,"knowledge":"2025-04","release_date":"2025-09-30","last_updated":"2025-09-30","modalities":{"input":["text"],"output":["text"]},"open_weights":true,"cost":{"input":0.39,"output":1.55},"limit":{"context":204800,"output":131072},"display_name":"GLM 4.6 FP8"},{"id":"zai-org/GLM-4.5-FP8","name":"GLM 4.5 FP8","attachment":false,"reasoning":true,"temperature":true,"tool_call":true,"knowledge":"2025-04","release_date":"2025-07-28","last_updated":"2025-07-28","modalities":{"input":["text"],"output":["text"]},"open_weights":true,"cost":{"input":0,"output":0},"limit":{"context":131072,"output":131072},"display_name":"GLM 4.5 FP8"},{"id":"zai-org/GLM-4.5-Air","name":"GLM 4.5 Air","attachment":false,"reasoning":true,"temperature":true,"tool_call":true,"knowledge":"2025-04","release_date":"2025-07-28","last_updated":"2025-07-28","modalities":{"input":["text"],"output":["text"]},"open_weights":true,"cost":{"input":0,"output":0},"limit":{"context":131072,"output":98304},"display_name":"GLM 4.5 Air"},{"id":"deepseek-ai/DeepSeek-R1-0528-Qwen3-8B","name":"DeepSeek R1 0528 Qwen3 8B","attachment":false,"reasoning":true,"temperature":true,"tool_call":true,"knowledge":"2025-05","release_date":"2025-05-29","last_updated":"2025-05-29","modalities":{"input":["text"],"output":["text"]},"open_weights":true,"cost":{"input":0.02,"output":0.07},"limit":{"context":131072,"output":131072},"display_name":"DeepSeek R1 0528 Qwen3 8B"},{"id":"deepseek-ai/DeepSeek-R1-0528","name":"DeepSeek R1 (0528)","attachment":false,"reasoning":true,"temperature":true,"tool_call":true,"release_date":"2025-08-01","last_updated":"2025-08-01","modalities":{"input":["text"],"output":["text"]},"open_weights":false,"cost":{"input":0.18,"output":0.72},"limit":{"context":75000,"output":163840},"display_name":"DeepSeek R1 (0528)"},{"id":"deepseek-ai/DeepSeek-V3.1-Terminus","name":"DeepSeek V3.1 Terminus","attachment":false,"reasoning":true,"temperature":true,"tool_call":true,"knowledge":"2025-07","release_date":"2025-09-22","last_updated":"2025-09-22","modalities":{"input":["text"],"output":["text"]},"open_weights":true,"cost":{"input":0.25,"output":1},"limit":{"context":131072,"output":65536},"display_name":"DeepSeek V3.1 Terminus"},{"id":"deepseek-ai/DeepSeek-V3.1-turbo","name":"DeepSeek V3.1 Turbo","attachment":false,"reasoning":false,"temperature":true,"tool_call":true,"release_date":"2025-08-21","last_updated":"2025-08-21","modalities":{"input":["text"],"output":["text"]},"open_weights":false,"cost":{"input":1,"output":3},"limit":{"context":128000,"output":128000},"display_name":"DeepSeek V3.1 Turbo"},{"id":"deepseek-ai/DeepSeek-V3.1:THINKING","name":"DeepSeek V3.1 Reasoning","attachment":false,"reasoning":true,"temperature":true,"tool_call":true,"release_date":"2025-08-21","last_updated":"2025-08-21","modalities":{"input":["text"],"output":["text"]},"open_weights":false,"cost":{"input":0.2,"output":0.8},"limit":{"context":163840,"output":163840},"display_name":"DeepSeek V3.1 Reasoning"},{"id":"deepseek-ai/DeepSeek-R1-Distill-Llama-70B","name":"DeepSeek R1 Distill Llama 70B","attachment":false,"reasoning":true,"temperature":true,"tool_call":false,"knowledge":"2024-10","release_date":"2025-01-23","last_updated":"2025-01-23","modalities":{"input":["text"],"output":["text"]},"open_weights":true,"cost":{"input":0.03,"output":0.14},"limit":{"context":131072,"output":131072},"display_name":"DeepSeek R1 Distill Llama 70B"},{"id":"deepseek-ai/DeepSeek-V3.1","name":"DeepSeek V3.1","attachment":false,"reasoning":false,"temperature":true,"tool_call":true,"release_date":"2025-08-21","last_updated":"2025-08-21","modalities":{"input":["text"],"output":["text"]},"open_weights":false,"cost":{"input":0.2,"output":0.8},"limit":{"context":163840,"output":163840},"display_name":"DeepSeek V3.1"},{"id":"deepseek-ai/DeepSeek-V3-0324","name":"DeepSeek V3 (0324)","attachment":false,"reasoning":false,"temperature":true,"tool_call":true,"release_date":"2025-08-01","last_updated":"2025-08-01","modalities":{"input":["text"],"output":["text"]},"open_weights":false,"cost":{"input":0.18,"output":0.72},"limit":{"context":75000,"output":163840},"display_name":"DeepSeek V3 (0324)"}]},"cortecs":{"id":"cortecs","api":"https://api.cortecs.ai/v1","name":"Cortecs","doc":"https://api.cortecs.ai/v1/models","display_name":"Cortecs","models":[{"id":"nova-pro-v1","name":"Nova Pro 1.0","attachment":false,"reasoning":false,"temperature":true,"tool_call":true,"knowledge":"2024-04","release_date":"2024-12-03","last_updated":"2024-12-03","modalities":{"input":["text","image"],"output":["text"]},"open_weights":false,"cost":{"input":0.824,"output":3.295},"limit":{"context":300000,"output":5000},"display_name":"Nova Pro 1.0"},{"id":"deepseek-v3-0324","name":"DeepSeek V3 0324","attachment":false,"reasoning":false,"temperature":true,"tool_call":true,"knowledge":"2024-07","release_date":"2025-03-24","last_updated":"2025-03-24","modalities":{"input":["text"],"output":["text"]},"open_weights":true,"cost":{"input":0.447,"output":1.342},"limit":{"context":128000,"output":128000},"display_name":"DeepSeek V3 0324"},{"id":"kimi-k2-instruct","name":"Kimi K2 Instruct","attachment":false,"reasoning":false,"temperature":true,"tool_call":true,"knowledge":"2024-07","release_date":"2025-07-11","last_updated":"2025-09-05","modalities":{"input":["text"],"output":["text"]},"open_weights":true,"cost":{"input":0.447,"output":2.147},"limit":{"context":131000,"output":131000},"display_name":"Kimi K2 Instruct"},{"id":"gpt-4.1","name":"GPT 4.1","attachment":false,"reasoning":false,"temperature":true,"tool_call":true,"knowledge":"2024-06","release_date":"2025-04-14","last_updated":"2025-04-14","modalities":{"input":["text","image"],"output":["text"]},"open_weights":false,"cost":{"input":1.91,"output":7.64},"limit":{"context":1047576,"output":32768},"display_name":"GPT 4.1"},{"id":"gemini-2.5-pro","name":"Gemini 2.5 Pro","attachment":false,"reasoning":false,"temperature":true,"tool_call":true,"knowledge":"2025-01","release_date":"2025-03-20","last_updated":"2025-06-17","modalities":{"input":["text","image"],"output":["text"]},"open_weights":false,"cost":{"input":1.3416,"output":8.944},"limit":{"context":1048576,"output":65535},"display_name":"Gemini 2.5 Pro"},{"id":"gpt-oss-120b","name":"GPT Oss 120b","attachment":false,"reasoning":false,"temperature":true,"tool_call":true,"knowledge":"2024-01","release_date":"2025-08-05","last_updated":"2025-08-05","modalities":{"input":["text"],"output":["text"]},"open_weights":true,"cost":{"input":0,"output":0},"limit":{"context":128000,"output":128000},"display_name":"GPT Oss 120b"},{"id":"qwen3-coder-480b-a35b-instruct","name":"Qwen3 Coder 480B A35B Instruct","attachment":false,"reasoning":false,"temperature":true,"tool_call":true,"knowledge":"2025-01","release_date":"2025-07-25","last_updated":"2025-07-25","modalities":{"input":["text"],"output":["text"]},"open_weights":true,"cost":{"input":0.358,"output":1.61},"limit":{"context":262000,"output":262000},"display_name":"Qwen3 Coder 480B A35B Instruct"},{"id":"claude-sonnet-4","name":"Claude Sonnet 4","attachment":false,"reasoning":false,"temperature":true,"tool_call":true,"knowledge":"2025-03","release_date":"2025-05-22","last_updated":"2025-05-22","modalities":{"input":["text","image"],"output":["text"]},"open_weights":false,"cost":{"input":2.683,"output":13.416},"limit":{"context":200000,"output":64000},"display_name":"Claude Sonnet 4"},{"id":"llama-3.1-405b-instruct","name":"Llama 3.1 405B Instruct","attachment":false,"reasoning":false,"temperature":true,"tool_call":true,"knowledge":"2023-12","release_date":"2024-07-23","last_updated":"2024-07-23","modalities":{"input":["text"],"output":["text"]},"open_weights":true,"cost":{"input":0,"output":0},"limit":{"context":128000,"output":128000},"display_name":"Llama 3.1 405B Instruct"},{"id":"qwen3-32b","name":"Qwen3 32B","attachment":false,"reasoning":false,"temperature":true,"tool_call":true,"knowledge":"2024-12","release_date":"2025-04-29","last_updated":"2025-04-29","modalities":{"input":["text"],"output":["text"]},"open_weights":true,"cost":{"input":0.08,"output":0.268},"limit":{"context":16384,"output":16384},"display_name":"Qwen3 32B"}]},"github-models":{"id":"github-models","api":"https://models.github.ai/inference","name":"GitHub Models","doc":"https://docs.github.com/en/github-models","display_name":"GitHub Models","models":[{"id":"core42/jais-30b-chat","name":"JAIS 30b Chat","attachment":false,"reasoning":true,"temperature":true,"tool_call":true,"knowledge":"2023-03","release_date":"2023-08-30","last_updated":"2023-08-30","modalities":{"input":["text"],"output":["text"]},"open_weights":true,"cost":{"input":0,"output":0},"limit":{"context":8192,"output":2048},"display_name":"JAIS 30b Chat"},{"id":"xai/grok-3","name":"Grok 3","attachment":false,"reasoning":true,"temperature":true,"tool_call":true,"knowledge":"2024-10","release_date":"2024-12-09","last_updated":"2024-12-09","modalities":{"input":["text"],"output":["text"]},"open_weights":false,"cost":{"input":0,"output":0},"limit":{"context":128000,"output":8192},"display_name":"Grok 3"},{"id":"xai/grok-3-mini","name":"Grok 3 Mini","attachment":false,"reasoning":true,"temperature":true,"tool_call":true,"knowledge":"2024-10","release_date":"2024-12-09","last_updated":"2024-12-09","modalities":{"input":["text"],"output":["text"]},"open_weights":false,"cost":{"input":0,"output":0},"limit":{"context":128000,"output":8192},"display_name":"Grok 3 Mini"},{"id":"cohere/cohere-command-r-08-2024","name":"Cohere Command R 08-2024","attachment":false,"reasoning":true,"temperature":true,"tool_call":true,"knowledge":"2024-03","release_date":"2024-08-01","last_updated":"2024-08-01","modalities":{"input":["text"],"output":["text"]},"open_weights":false,"cost":{"input":0,"output":0},"limit":{"context":128000,"output":4096},"display_name":"Cohere Command R 08-2024"},{"id":"cohere/cohere-command-a","name":"Cohere Command A","attachment":false,"reasoning":true,"temperature":true,"tool_call":true,"knowledge":"2024-03","release_date":"2024-11-01","last_updated":"2024-11-01","modalities":{"input":["text"],"output":["text"]},"open_weights":false,"cost":{"input":0,"output":0},"limit":{"context":128000,"output":4096},"display_name":"Cohere Command A"},{"id":"cohere/cohere-command-r-plus-08-2024","name":"Cohere Command R+ 08-2024","attachment":false,"reasoning":true,"temperature":true,"tool_call":true,"knowledge":"2024-03","release_date":"2024-08-01","last_updated":"2024-08-01","modalities":{"input":["text"],"output":["text"]},"open_weights":false,"cost":{"input":0,"output":0},"limit":{"context":128000,"output":4096},"display_name":"Cohere Command R+ 08-2024"},{"id":"cohere/cohere-command-r","name":"Cohere Command R","attachment":false,"reasoning":true,"temperature":true,"tool_call":true,"knowledge":"2024-03","release_date":"2024-03-11","last_updated":"2024-08-01","modalities":{"input":["text"],"output":["text"]},"open_weights":false,"cost":{"input":0,"output":0},"limit":{"context":128000,"output":4096},"display_name":"Cohere Command R"},{"id":"cohere/cohere-command-r-plus","name":"Cohere Command R+","attachment":false,"reasoning":true,"temperature":true,"tool_call":true,"knowledge":"2024-03","release_date":"2024-04-04","last_updated":"2024-08-01","modalities":{"input":["text"],"output":["text"]},"open_weights":false,"cost":{"input":0,"output":0},"limit":{"context":128000,"output":4096},"display_name":"Cohere Command R+"},{"id":"deepseek/deepseek-r1-0528","name":"DeepSeek-R1-0528","attachment":false,"reasoning":true,"temperature":true,"tool_call":true,"knowledge":"2024-06","release_date":"2025-05-28","last_updated":"2025-05-28","modalities":{"input":["text"],"output":["text"]},"open_weights":true,"cost":{"input":0,"output":0},"limit":{"context":65536,"output":8192},"display_name":"DeepSeek-R1-0528"},{"id":"deepseek/deepseek-r1","name":"DeepSeek-R1","attachment":false,"reasoning":true,"temperature":true,"tool_call":true,"knowledge":"2024-06","release_date":"2025-01-20","last_updated":"2025-01-20","modalities":{"input":["text"],"output":["text"]},"open_weights":true,"cost":{"input":0,"output":0},"limit":{"context":65536,"output":8192},"display_name":"DeepSeek-R1"},{"id":"deepseek/deepseek-v3-0324","name":"DeepSeek-V3-0324","attachment":false,"reasoning":true,"temperature":true,"tool_call":true,"knowledge":"2024-06","release_date":"2025-03-24","last_updated":"2025-03-24","modalities":{"input":["text"],"output":["text"]},"open_weights":true,"cost":{"input":0,"output":0},"limit":{"context":128000,"output":8192},"display_name":"DeepSeek-V3-0324"},{"id":"mistral-ai/mistral-medium-2505","name":"Mistral Medium 3 (25.05)","attachment":false,"reasoning":true,"temperature":true,"tool_call":true,"knowledge":"2024-09","release_date":"2025-05-01","last_updated":"2025-05-01","modalities":{"input":["text","image"],"output":["text"]},"open_weights":false,"cost":{"input":0,"output":0},"limit":{"context":128000,"output":32768},"display_name":"Mistral Medium 3 (25.05)"},{"id":"mistral-ai/ministral-3b","name":"Ministral 3B","attachment":false,"reasoning":true,"temperature":true,"tool_call":true,"knowledge":"2024-03","release_date":"2024-10-22","last_updated":"2024-10-22","modalities":{"input":["text"],"output":["text"]},"open_weights":true,"cost":{"input":0,"output":0},"limit":{"context":128000,"output":8192},"display_name":"Ministral 3B"},{"id":"mistral-ai/mistral-nemo","name":"Mistral Nemo","attachment":false,"reasoning":true,"temperature":true,"tool_call":true,"knowledge":"2024-03","release_date":"2024-07-18","last_updated":"2024-07-18","modalities":{"input":["text"],"output":["text"]},"open_weights":true,"cost":{"input":0,"output":0},"limit":{"context":128000,"output":8192},"display_name":"Mistral Nemo"},{"id":"mistral-ai/mistral-large-2411","name":"Mistral Large 24.11","attachment":false,"reasoning":true,"temperature":true,"tool_call":true,"knowledge":"2024-09","release_date":"2024-11-01","last_updated":"2024-11-01","modalities":{"input":["text"],"output":["text"]},"open_weights":false,"cost":{"input":0,"output":0},"limit":{"context":128000,"output":32768},"display_name":"Mistral Large 24.11"},{"id":"mistral-ai/codestral-2501","name":"Codestral 25.01","attachment":false,"reasoning":true,"temperature":true,"tool_call":true,"knowledge":"2024-03","release_date":"2025-01-01","last_updated":"2025-01-01","modalities":{"input":["text"],"output":["text"]},"open_weights":false,"cost":{"input":0,"output":0},"limit":{"context":32000,"output":8192},"display_name":"Codestral 25.01"},{"id":"mistral-ai/mistral-small-2503","name":"Mistral Small 3.1","attachment":false,"reasoning":true,"temperature":true,"tool_call":true,"knowledge":"2024-09","release_date":"2025-03-01","last_updated":"2025-03-01","modalities":{"input":["text","image"],"output":["text"]},"open_weights":false,"cost":{"input":0,"output":0},"limit":{"context":128000,"output":32768},"display_name":"Mistral Small 3.1"},{"id":"microsoft/phi-3-medium-128k-instruct","name":"Phi-3-medium instruct (128k)","attachment":false,"reasoning":true,"temperature":true,"tool_call":true,"knowledge":"2023-10","release_date":"2024-04-23","last_updated":"2024-04-23","modalities":{"input":["text"],"output":["text"]},"open_weights":true,"cost":{"input":0,"output":0},"limit":{"context":128000,"output":4096},"display_name":"Phi-3-medium instruct (128k)"},{"id":"microsoft/phi-3-mini-4k-instruct","name":"Phi-3-mini instruct (4k)","attachment":false,"reasoning":true,"temperature":true,"tool_call":true,"knowledge":"2023-10","release_date":"2024-04-23","last_updated":"2024-04-23","modalities":{"input":["text"],"output":["text"]},"open_weights":true,"cost":{"input":0,"output":0},"limit":{"context":4096,"output":1024},"display_name":"Phi-3-mini instruct (4k)"},{"id":"microsoft/phi-3-small-128k-instruct","name":"Phi-3-small instruct (128k)","attachment":false,"reasoning":true,"temperature":true,"tool_call":true,"knowledge":"2023-10","release_date":"2024-04-23","last_updated":"2024-04-23","modalities":{"input":["text"],"output":["text"]},"open_weights":true,"cost":{"input":0,"output":0},"limit":{"context":128000,"output":4096},"display_name":"Phi-3-small instruct (128k)"},{"id":"microsoft/phi-3.5-vision-instruct","name":"Phi-3.5-vision instruct (128k)","attachment":false,"reasoning":true,"temperature":true,"tool_call":true,"knowledge":"2023-10","release_date":"2024-08-20","last_updated":"2024-08-20","modalities":{"input":["text","image"],"output":["text"]},"open_weights":true,"cost":{"input":0,"output":0},"limit":{"context":128000,"output":4096},"display_name":"Phi-3.5-vision instruct (128k)"},{"id":"microsoft/phi-4","name":"Phi-4","attachment":false,"reasoning":true,"temperature":true,"tool_call":true,"knowledge":"2023-10","release_date":"2024-12-11","last_updated":"2024-12-11","modalities":{"input":["text"],"output":["text"]},"open_weights":true,"cost":{"input":0,"output":0},"limit":{"context":16000,"output":4096},"display_name":"Phi-4"},{"id":"microsoft/phi-4-mini-reasoning","name":"Phi-4-mini-reasoning","attachment":false,"reasoning":true,"temperature":true,"tool_call":true,"knowledge":"2023-10","release_date":"2024-12-11","last_updated":"2024-12-11","modalities":{"input":["text"],"output":["text"]},"open_weights":true,"cost":{"input":0,"output":0},"limit":{"context":128000,"output":4096},"display_name":"Phi-4-mini-reasoning"},{"id":"microsoft/phi-3-small-8k-instruct","name":"Phi-3-small instruct (8k)","attachment":false,"reasoning":true,"temperature":true,"tool_call":true,"knowledge":"2023-10","release_date":"2024-04-23","last_updated":"2024-04-23","modalities":{"input":["text"],"output":["text"]},"open_weights":true,"cost":{"input":0,"output":0},"limit":{"context":8192,"output":2048},"display_name":"Phi-3-small instruct (8k)"},{"id":"microsoft/phi-3.5-mini-instruct","name":"Phi-3.5-mini instruct (128k)","attachment":false,"reasoning":true,"temperature":true,"tool_call":true,"knowledge":"2023-10","release_date":"2024-08-20","last_updated":"2024-08-20","modalities":{"input":["text"],"output":["text"]},"open_weights":true,"cost":{"input":0,"output":0},"limit":{"context":128000,"output":4096},"display_name":"Phi-3.5-mini instruct (128k)"},{"id":"microsoft/phi-4-multimodal-instruct","name":"Phi-4-multimodal-instruct","attachment":false,"reasoning":true,"temperature":true,"tool_call":true,"knowledge":"2023-10","release_date":"2024-12-11","last_updated":"2024-12-11","modalities":{"input":["text","image","audio"],"output":["text"]},"open_weights":true,"cost":{"input":0,"output":0},"limit":{"context":128000,"output":4096},"display_name":"Phi-4-multimodal-instruct"},{"id":"microsoft/phi-3-mini-128k-instruct","name":"Phi-3-mini instruct (128k)","attachment":false,"reasoning":true,"temperature":true,"tool_call":true,"knowledge":"2023-10","release_date":"2024-04-23","last_updated":"2024-04-23","modalities":{"input":["text"],"output":["text"]},"open_weights":true,"cost":{"input":0,"output":0},"limit":{"context":128000,"output":4096},"display_name":"Phi-3-mini instruct (128k)"},{"id":"microsoft/phi-3.5-moe-instruct","name":"Phi-3.5-MoE instruct (128k)","attachment":false,"reasoning":true,"temperature":true,"tool_call":true,"knowledge":"2023-10","release_date":"2024-08-20","last_updated":"2024-08-20","modalities":{"input":["text"],"output":["text"]},"open_weights":true,"cost":{"input":0,"output":0},"limit":{"context":128000,"output":4096},"display_name":"Phi-3.5-MoE instruct (128k)"},{"id":"microsoft/phi-4-mini-instruct","name":"Phi-4-mini-instruct","attachment":false,"reasoning":true,"temperature":true,"tool_call":true,"knowledge":"2023-10","release_date":"2024-12-11","last_updated":"2024-12-11","modalities":{"input":["text"],"output":["text"]},"open_weights":true,"cost":{"input":0,"output":0},"limit":{"context":128000,"output":4096},"display_name":"Phi-4-mini-instruct"},{"id":"microsoft/phi-3-medium-4k-instruct","name":"Phi-3-medium instruct (4k)","attachment":false,"reasoning":true,"temperature":true,"tool_call":true,"knowledge":"2023-10","release_date":"2024-04-23","last_updated":"2024-04-23","modalities":{"input":["text"],"output":["text"]},"open_weights":true,"cost":{"input":0,"output":0},"limit":{"context":4096,"output":1024},"display_name":"Phi-3-medium instruct (4k)"},{"id":"microsoft/phi-4-reasoning","name":"Phi-4-Reasoning","attachment":false,"reasoning":true,"temperature":true,"tool_call":true,"knowledge":"2023-10","release_date":"2024-12-11","last_updated":"2024-12-11","modalities":{"input":["text"],"output":["text"]},"open_weights":true,"cost":{"input":0,"output":0},"limit":{"context":128000,"output":4096},"display_name":"Phi-4-Reasoning"},{"id":"microsoft/mai-ds-r1","name":"MAI-DS-R1","attachment":false,"reasoning":true,"temperature":true,"tool_call":true,"knowledge":"2024-06","release_date":"2025-01-20","last_updated":"2025-01-20","modalities":{"input":["text"],"output":["text"]},"open_weights":false,"cost":{"input":0,"output":0},"limit":{"context":65536,"output":8192},"display_name":"MAI-DS-R1"},{"id":"openai/gpt-4.1-nano","name":"GPT-4.1-nano","attachment":true,"reasoning":false,"temperature":true,"tool_call":true,"knowledge":"2024-04","release_date":"2025-04-14","last_updated":"2025-04-14","modalities":{"input":["text","image"],"output":["text"]},"open_weights":false,"cost":{"input":0,"output":0},"limit":{"context":128000,"output":16384},"display_name":"GPT-4.1-nano"},{"id":"openai/gpt-4.1-mini","name":"GPT-4.1-mini","attachment":true,"reasoning":false,"temperature":true,"tool_call":true,"knowledge":"2024-04","release_date":"2025-04-14","last_updated":"2025-04-14","modalities":{"input":["text","image"],"output":["text"]},"open_weights":false,"cost":{"input":0,"output":0},"limit":{"context":128000,"output":16384},"display_name":"GPT-4.1-mini"},{"id":"openai/o1-preview","name":"OpenAI o1-preview","attachment":false,"reasoning":true,"temperature":false,"tool_call":false,"knowledge":"2023-10","release_date":"2024-09-12","last_updated":"2024-09-12","modalities":{"input":["text"],"output":["text"]},"open_weights":false,"cost":{"input":0,"output":0},"limit":{"context":128000,"output":32768},"display_name":"OpenAI o1-preview"},{"id":"openai/o3-mini","name":"OpenAI o3-mini","attachment":false,"reasoning":true,"temperature":false,"tool_call":false,"knowledge":"2024-04","release_date":"2025-01-31","last_updated":"2025-01-31","modalities":{"input":["text"],"output":["text"]},"open_weights":false,"cost":{"input":0,"output":0},"limit":{"context":200000,"output":100000},"display_name":"OpenAI o3-mini"},{"id":"openai/gpt-4o","name":"GPT-4o","attachment":true,"reasoning":false,"temperature":true,"tool_call":true,"knowledge":"2023-10","release_date":"2024-05-13","last_updated":"2024-05-13","modalities":{"input":["text","image","audio"],"output":["text"]},"open_weights":false,"cost":{"input":0,"output":0},"limit":{"context":128000,"output":16384},"display_name":"GPT-4o"},{"id":"openai/gpt-4.1","name":"GPT-4.1","attachment":true,"reasoning":false,"temperature":true,"tool_call":true,"knowledge":"2024-04","release_date":"2025-04-14","last_updated":"2025-04-14","modalities":{"input":["text","image"],"output":["text"]},"open_weights":false,"cost":{"input":0,"output":0},"limit":{"context":128000,"output":16384},"display_name":"GPT-4.1"},{"id":"openai/o4-mini","name":"OpenAI o4-mini","attachment":false,"reasoning":true,"temperature":false,"tool_call":false,"knowledge":"2024-04","release_date":"2025-01-31","last_updated":"2025-01-31","modalities":{"input":["text","image"],"output":["text"]},"open_weights":false,"cost":{"input":0,"output":0},"limit":{"context":200000,"output":100000},"display_name":"OpenAI o4-mini"},{"id":"openai/o1","name":"OpenAI o1","attachment":false,"reasoning":true,"temperature":false,"tool_call":false,"knowledge":"2023-10","release_date":"2024-09-12","last_updated":"2024-12-17","modalities":{"input":["text","image"],"output":["text"]},"open_weights":false,"cost":{"input":0,"output":0},"limit":{"context":200000,"output":100000},"display_name":"OpenAI o1"},{"id":"openai/o1-mini","name":"OpenAI o1-mini","attachment":false,"reasoning":true,"temperature":false,"tool_call":false,"knowledge":"2023-10","release_date":"2024-09-12","last_updated":"2024-12-17","modalities":{"input":["text"],"output":["text"]},"open_weights":false,"cost":{"input":0,"output":0},"limit":{"context":128000,"output":65536},"display_name":"OpenAI o1-mini"},{"id":"openai/o3","name":"OpenAI o3","attachment":false,"reasoning":true,"temperature":false,"tool_call":false,"knowledge":"2024-04","release_date":"2025-01-31","last_updated":"2025-01-31","modalities":{"input":["text","image"],"output":["text"]},"open_weights":false,"cost":{"input":0,"output":0},"limit":{"context":200000,"output":100000},"display_name":"OpenAI o3"},{"id":"openai/gpt-4o-mini","name":"GPT-4o mini","attachment":true,"reasoning":false,"temperature":true,"tool_call":true,"knowledge":"2023-10","release_date":"2024-07-18","last_updated":"2024-07-18","modalities":{"input":["text","image","audio"],"output":["text"]},"open_weights":false,"cost":{"input":0,"output":0},"limit":{"context":128000,"output":16384},"display_name":"GPT-4o mini"},{"id":"meta/llama-3.2-11b-vision-instruct","name":"Llama-3.2-11B-Vision-Instruct","attachment":false,"reasoning":true,"temperature":true,"tool_call":true,"knowledge":"2023-12","release_date":"2024-09-25","last_updated":"2024-09-25","modalities":{"input":["text","image","audio"],"output":["text"]},"open_weights":true,"cost":{"input":0,"output":0},"limit":{"context":128000,"output":8192},"display_name":"Llama-3.2-11B-Vision-Instruct"},{"id":"meta/meta-llama-3.1-405b-instruct","name":"Meta-Llama-3.1-405B-Instruct","attachment":false,"reasoning":true,"temperature":true,"tool_call":true,"knowledge":"2023-12","release_date":"2024-07-23","last_updated":"2024-07-23","modalities":{"input":["text"],"output":["text"]},"open_weights":true,"cost":{"input":0,"output":0},"limit":{"context":128000,"output":32768},"display_name":"Meta-Llama-3.1-405B-Instruct"},{"id":"meta/llama-4-maverick-17b-128e-instruct-fp8","name":"Llama 4 Maverick 17B 128E Instruct FP8","attachment":false,"reasoning":true,"temperature":true,"tool_call":true,"knowledge":"2024-12","release_date":"2025-01-31","last_updated":"2025-01-31","modalities":{"input":["text","image"],"output":["text"]},"open_weights":true,"cost":{"input":0,"output":0},"limit":{"context":128000,"output":8192},"display_name":"Llama 4 Maverick 17B 128E Instruct FP8"},{"id":"meta/meta-llama-3-70b-instruct","name":"Meta-Llama-3-70B-Instruct","attachment":false,"reasoning":true,"temperature":true,"tool_call":true,"knowledge":"2023-12","release_date":"2024-04-18","last_updated":"2024-04-18","modalities":{"input":["text"],"output":["text"]},"open_weights":true,"cost":{"input":0,"output":0},"limit":{"context":8192,"output":2048},"display_name":"Meta-Llama-3-70B-Instruct"},{"id":"meta/meta-llama-3.1-70b-instruct","name":"Meta-Llama-3.1-70B-Instruct","attachment":false,"reasoning":true,"temperature":true,"tool_call":true,"knowledge":"2023-12","release_date":"2024-07-23","last_updated":"2024-07-23","modalities":{"input":["text"],"output":["text"]},"open_weights":true,"cost":{"input":0,"output":0},"limit":{"context":128000,"output":32768},"display_name":"Meta-Llama-3.1-70B-Instruct"},{"id":"meta/llama-3.3-70b-instruct","name":"Llama-3.3-70B-Instruct","attachment":false,"reasoning":true,"temperature":true,"tool_call":true,"knowledge":"2023-12","release_date":"2024-12-06","last_updated":"2024-12-06","modalities":{"input":["text"],"output":["text"]},"open_weights":true,"cost":{"input":0,"output":0},"limit":{"context":128000,"output":32768},"display_name":"Llama-3.3-70B-Instruct"},{"id":"meta/llama-3.2-90b-vision-instruct","name":"Llama-3.2-90B-Vision-Instruct","attachment":false,"reasoning":true,"temperature":true,"tool_call":true,"knowledge":"2023-12","release_date":"2024-09-25","last_updated":"2024-09-25","modalities":{"input":["text","image","audio"],"output":["text"]},"open_weights":true,"cost":{"input":0,"output":0},"limit":{"context":128000,"output":8192},"display_name":"Llama-3.2-90B-Vision-Instruct"},{"id":"meta/meta-llama-3-8b-instruct","name":"Meta-Llama-3-8B-Instruct","attachment":false,"reasoning":true,"temperature":true,"tool_call":true,"knowledge":"2023-12","release_date":"2024-04-18","last_updated":"2024-04-18","modalities":{"input":["text"],"output":["text"]},"open_weights":true,"cost":{"input":0,"output":0},"limit":{"context":8192,"output":2048},"display_name":"Meta-Llama-3-8B-Instruct"},{"id":"meta/llama-4-scout-17b-16e-instruct","name":"Llama 4 Scout 17B 16E Instruct","attachment":false,"reasoning":true,"temperature":true,"tool_call":true,"knowledge":"2024-12","release_date":"2025-01-31","last_updated":"2025-01-31","modalities":{"input":["text","image"],"output":["text"]},"open_weights":true,"cost":{"input":0,"output":0},"limit":{"context":128000,"output":8192},"display_name":"Llama 4 Scout 17B 16E Instruct"},{"id":"meta/meta-llama-3.1-8b-instruct","name":"Meta-Llama-3.1-8B-Instruct","attachment":false,"reasoning":true,"temperature":true,"tool_call":true,"knowledge":"2023-12","release_date":"2024-07-23","last_updated":"2024-07-23","modalities":{"input":["text"],"output":["text"]},"open_weights":true,"cost":{"input":0,"output":0},"limit":{"context":128000,"output":32768},"display_name":"Meta-Llama-3.1-8B-Instruct"},{"id":"ai21-labs/ai21-jamba-1.5-large","name":"AI21 Jamba 1.5 Large","attachment":false,"reasoning":true,"temperature":true,"tool_call":true,"knowledge":"2024-03","release_date":"2024-08-29","last_updated":"2024-08-29","modalities":{"input":["text"],"output":["text"]},"open_weights":false,"cost":{"input":0,"output":0},"limit":{"context":256000,"output":4096},"display_name":"AI21 Jamba 1.5 Large"},{"id":"ai21-labs/ai21-jamba-1.5-mini","name":"AI21 Jamba 1.5 Mini","attachment":false,"reasoning":true,"temperature":true,"tool_call":true,"knowledge":"2024-03","release_date":"2024-08-29","last_updated":"2024-08-29","modalities":{"input":["text"],"output":["text"]},"open_weights":false,"cost":{"input":0,"output":0},"limit":{"context":256000,"output":4096},"display_name":"AI21 Jamba 1.5 Mini"}]},"togetherai":{"id":"togetherai","name":"Together AI","doc":"https://docs.together.ai/docs/serverless-models","display_name":"Together AI","models":[{"id":"moonshotai/Kimi-K2-Instruct","name":"Kimi K2 Instruct","attachment":false,"reasoning":false,"temperature":true,"tool_call":true,"knowledge":"2024-10","release_date":"2025-07-14","last_updated":"2025-07-14","modalities":{"input":["text"],"output":["text"]},"open_weights":true,"cost":{"input":1,"output":3},"limit":{"context":131072,"output":32768},"display_name":"Kimi K2 Instruct"},{"id":"openai/gpt-oss-120b","name":"GPT OSS 120B","attachment":false,"reasoning":true,"temperature":true,"tool_call":true,"release_date":"2025-08-05","last_updated":"2025-08-05","modalities":{"input":["text"],"output":["text"]},"open_weights":true,"cost":{"input":0.15,"output":0.6},"limit":{"context":131072,"output":131072},"display_name":"GPT OSS 120B"},{"id":"meta-llama/Llama-3.3-70B-Instruct-Turbo","name":"Llama 3.3 70B","attachment":false,"reasoning":false,"temperature":true,"tool_call":true,"knowledge":"2023-12","release_date":"2024-12-06","last_updated":"2024-12-06","modalities":{"input":["text"],"output":["text"]},"open_weights":true,"cost":{"input":0.88,"output":0.88},"limit":{"context":131072,"output":66536},"display_name":"Llama 3.3 70B"},{"id":"Qwen/Qwen3-Coder-480B-A35B-Instruct-FP8","name":"Qwen3 Coder 480B A35B Instruct","attachment":false,"reasoning":false,"temperature":true,"tool_call":true,"knowledge":"2025-04","release_date":"2025-07-23","last_updated":"2025-07-23","modalities":{"input":["text"],"output":["text"]},"open_weights":true,"cost":{"input":2,"output":2},"limit":{"context":262144,"output":66536},"display_name":"Qwen3 Coder 480B A35B Instruct"},{"id":"deepseek-ai/DeepSeek-R1","name":"DeepSeek R1","attachment":false,"reasoning":true,"temperature":true,"tool_call":false,"knowledge":"2024-07","release_date":"2024-12-26","last_updated":"2025-03-24","modalities":{"input":["text"],"output":["text"]},"open_weights":true,"cost":{"input":3,"output":7},"limit":{"context":163839,"output":12288},"display_name":"DeepSeek R1"},{"id":"deepseek-ai/DeepSeek-V3","name":"DeepSeek V3","attachment":false,"reasoning":true,"temperature":true,"tool_call":true,"knowledge":"2024-07","release_date":"2025-01-20","last_updated":"2025-05-29","modalities":{"input":["text"],"output":["text"]},"open_weights":true,"cost":{"input":1.25,"output":1.25},"limit":{"context":131072,"output":12288},"display_name":"DeepSeek V3"}]},"azure":{"id":"azure","name":"Azure","doc":"https://learn.microsoft.com/en-us/azure/ai-services/openai/concepts/models","display_name":"Azure","models":[{"id":"gpt-4.1-nano","name":"GPT-4.1 nano","attachment":true,"reasoning":false,"temperature":true,"tool_call":true,"knowledge":"2024-05","release_date":"2025-04-14","last_updated":"2025-04-14","modalities":{"input":["text","image"],"output":["text"]},"open_weights":false,"cost":{"input":0.1,"output":0.4,"cache_read":0.03},"limit":{"context":1047576,"output":32768},"display_name":"GPT-4.1 nano"},{"id":"gpt-4","name":"GPT-4","attachment":false,"reasoning":false,"temperature":true,"tool_call":true,"knowledge":"2023-11","release_date":"2023-03-14","last_updated":"2023-03-14","modalities":{"input":["text"],"output":["text"]},"open_weights":false,"cost":{"input":60,"output":120},"limit":{"context":8192,"output":8192},"display_name":"GPT-4"},{"id":"gpt-4-32k","name":"GPT-4 32K","attachment":false,"reasoning":false,"temperature":true,"tool_call":true,"knowledge":"2023-11","release_date":"2023-03-14","last_updated":"2023-03-14","modalities":{"input":["text"],"output":["text"]},"open_weights":false,"cost":{"input":60,"output":120},"limit":{"context":32768,"output":32768},"display_name":"GPT-4 32K"},{"id":"gpt-4.1-mini","name":"GPT-4.1 mini","attachment":true,"reasoning":false,"temperature":true,"tool_call":true,"knowledge":"2024-05","release_date":"2025-04-14","last_updated":"2025-04-14","modalities":{"input":["text","image"],"output":["text"]},"open_weights":false,"cost":{"input":0.4,"output":1.6,"cache_read":0.1},"limit":{"context":1047576,"output":32768},"display_name":"GPT-4.1 mini"},{"id":"gpt-5-chat","name":"GPT-5 Chat","attachment":true,"reasoning":true,"temperature":false,"tool_call":false,"knowledge":"2024-10-24","release_date":"2025-08-07","last_updated":"2025-08-07","modalities":{"input":["text","image"],"output":["text"]},"open_weights":false,"cost":{"input":1.25,"output":10,"cache_read":0.13},"limit":{"context":128000,"output":16384},"display_name":"GPT-5 Chat"},{"id":"gpt-3.5-turbo-0125","name":"GPT-3.5 Turbo 0125","attachment":false,"reasoning":false,"temperature":true,"tool_call":false,"knowledge":"2021-08","release_date":"2024-01-25","last_updated":"2024-01-25","modalities":{"input":["text"],"output":["text"]},"open_weights":false,"cost":{"input":0.5,"output":1.5},"limit":{"context":16384,"output":16384},"display_name":"GPT-3.5 Turbo 0125"},{"id":"gpt-4-turbo","name":"GPT-4 Turbo","attachment":true,"reasoning":false,"temperature":true,"tool_call":true,"knowledge":"2023-11","release_date":"2023-11-06","last_updated":"2024-04-09","modalities":{"input":["text","image"],"output":["text"]},"open_weights":false,"cost":{"input":10,"output":30},"limit":{"context":128000,"output":4096},"display_name":"GPT-4 Turbo"},{"id":"gpt-3.5-turbo-0613","name":"GPT-3.5 Turbo 0613","attachment":false,"reasoning":false,"temperature":true,"tool_call":false,"knowledge":"2021-08","release_date":"2023-06-13","last_updated":"2023-06-13","modalities":{"input":["text"],"output":["text"]},"open_weights":false,"cost":{"input":3,"output":4},"limit":{"context":16384,"output":16384},"display_name":"GPT-3.5 Turbo 0613"},{"id":"o1-preview","name":"o1-preview","attachment":false,"reasoning":true,"temperature":false,"tool_call":true,"knowledge":"2023-09","release_date":"2024-09-12","last_updated":"2024-09-12","modalities":{"input":["text"],"output":["text"]},"open_weights":false,"cost":{"input":16.5,"output":66,"cache_read":8.25},"limit":{"context":128000,"output":32768},"display_name":"o1-preview"},{"id":"o3-mini","name":"o3-mini","attachment":false,"reasoning":true,"temperature":false,"tool_call":true,"knowledge":"2024-05","release_date":"2024-12-20","last_updated":"2025-01-29","modalities":{"input":["text"],"output":["text"]},"open_weights":false,"cost":{"input":1.1,"output":4.4,"cache_read":0.55},"limit":{"context":200000,"output":100000},"display_name":"o3-mini"},{"id":"gpt-5-nano","name":"GPT-5 Nano","attachment":true,"reasoning":true,"temperature":false,"tool_call":true,"knowledge":"2024-05-30","release_date":"2025-08-07","last_updated":"2025-08-07","modalities":{"input":["text","image"],"output":["text"]},"open_weights":false,"cost":{"input":0.05,"output":0.4,"cache_read":0.01},"limit":{"context":272000,"output":128000},"display_name":"GPT-5 Nano"},{"id":"gpt-5-codex","name":"GPT-5-Codex","attachment":false,"reasoning":true,"temperature":false,"tool_call":true,"knowledge":"2024-09-30","release_date":"2025-09-15","last_updated":"2025-09-15","modalities":{"input":["text","image"],"output":["text"]},"open_weights":false,"limit":{"context":400000,"output":128000},"display_name":"GPT-5-Codex"},{"id":"gpt-4o","name":"GPT-4o","attachment":true,"reasoning":false,"temperature":true,"tool_call":true,"knowledge":"2023-09","release_date":"2024-05-13","last_updated":"2024-05-13","modalities":{"input":["text","image"],"output":["text"]},"open_weights":false,"cost":{"input":2.5,"output":10,"cache_read":1.25},"limit":{"context":128000,"output":16384},"display_name":"GPT-4o"},{"id":"gpt-3.5-turbo-0301","name":"GPT-3.5 Turbo 0301","attachment":false,"reasoning":false,"temperature":true,"tool_call":false,"knowledge":"2021-08","release_date":"2023-03-01","last_updated":"2023-03-01","modalities":{"input":["text"],"output":["text"]},"open_weights":false,"cost":{"input":1.5,"output":2},"limit":{"context":4096,"output":4096},"display_name":"GPT-3.5 Turbo 0301"},{"id":"gpt-4.1","name":"GPT-4.1","attachment":true,"reasoning":false,"temperature":true,"tool_call":true,"knowledge":"2024-05","release_date":"2025-04-14","last_updated":"2025-04-14","modalities":{"input":["text","image"],"output":["text"]},"open_weights":false,"cost":{"input":2,"output":8,"cache_read":0.5},"limit":{"context":1047576,"output":32768},"display_name":"GPT-4.1"},{"id":"o4-mini","name":"o4-mini","attachment":true,"reasoning":true,"temperature":false,"tool_call":true,"knowledge":"2024-05","release_date":"2025-04-16","last_updated":"2025-04-16","modalities":{"input":["text","image"],"output":["text"]},"open_weights":false,"cost":{"input":1.1,"output":4.4,"cache_read":0.28},"limit":{"context":200000,"output":100000},"display_name":"o4-mini"},{"id":"o1","name":"o1","attachment":false,"reasoning":true,"temperature":false,"tool_call":true,"knowledge":"2023-09","release_date":"2024-12-05","last_updated":"2024-12-05","modalities":{"input":["text","image"],"output":["text"]},"open_weights":false,"cost":{"input":15,"output":60,"cache_read":7.5},"limit":{"context":200000,"output":100000},"display_name":"o1"},{"id":"gpt-5-mini","name":"GPT-5 Mini","attachment":true,"reasoning":true,"temperature":false,"tool_call":true,"knowledge":"2024-05-30","release_date":"2025-08-07","last_updated":"2025-08-07","modalities":{"input":["text","image"],"output":["text"]},"open_weights":false,"cost":{"input":0.25,"output":2,"cache_read":0.03},"limit":{"context":272000,"output":128000},"display_name":"GPT-5 Mini"},{"id":"o1-mini","name":"o1-mini","attachment":false,"reasoning":true,"temperature":false,"tool_call":true,"knowledge":"2023-09","release_date":"2024-09-12","last_updated":"2024-09-12","modalities":{"input":["text"],"output":["text"]},"open_weights":false,"cost":{"input":1.1,"output":4.4,"cache_read":0.55},"limit":{"context":128000,"output":65536},"display_name":"o1-mini"},{"id":"gpt-3.5-turbo-instruct","name":"GPT-3.5 Turbo Instruct","attachment":false,"reasoning":false,"temperature":true,"tool_call":false,"knowledge":"2021-08","release_date":"2023-09-21","last_updated":"2023-09-21","modalities":{"input":["text"],"output":["text"]},"open_weights":false,"cost":{"input":1.5,"output":2},"limit":{"context":4096,"output":4096},"display_name":"GPT-3.5 Turbo Instruct"},{"id":"o3","name":"o3","attachment":true,"reasoning":true,"temperature":false,"tool_call":true,"knowledge":"2024-05","release_date":"2025-04-16","last_updated":"2025-04-16","modalities":{"input":["text","image"],"output":["text"]},"open_weights":false,"cost":{"input":2,"output":8,"cache_read":0.5},"limit":{"context":200000,"output":100000},"display_name":"o3"},{"id":"codex-mini","name":"Codex Mini","attachment":true,"reasoning":true,"temperature":false,"tool_call":true,"knowledge":"2024-04","release_date":"2025-05-16","last_updated":"2025-05-16","modalities":{"input":["text"],"output":["text"]},"open_weights":false,"cost":{"input":1.5,"output":6,"cache_read":0.375},"limit":{"context":200000,"output":100000},"display_name":"Codex Mini"},{"id":"gpt-4-turbo-vision","name":"GPT-4 Turbo Vision","attachment":true,"reasoning":false,"temperature":true,"tool_call":true,"knowledge":"2023-11","release_date":"2023-11-06","last_updated":"2024-04-09","modalities":{"input":["text","image"],"output":["text"]},"open_weights":false,"cost":{"input":10,"output":30},"limit":{"context":128000,"output":4096},"display_name":"GPT-4 Turbo Vision"},{"id":"gpt-4o-mini","name":"GPT-4o mini","attachment":true,"reasoning":false,"temperature":true,"tool_call":true,"knowledge":"2023-09","release_date":"2024-07-18","last_updated":"2024-07-18","modalities":{"input":["text","image"],"output":["text"]},"open_weights":false,"cost":{"input":0.15,"output":0.6,"cache_read":0.08},"limit":{"context":128000,"output":16384},"display_name":"GPT-4o mini"},{"id":"gpt-5","name":"GPT-5","attachment":true,"reasoning":true,"temperature":false,"tool_call":true,"knowledge":"2024-09-30","release_date":"2025-08-07","last_updated":"2025-08-07","modalities":{"input":["text","image"],"output":["text"]},"open_weights":false,"cost":{"input":1.25,"output":10,"cache_read":0.13},"limit":{"context":272000,"output":128000},"display_name":"GPT-5"},{"id":"gpt-3.5-turbo-1106","name":"GPT-3.5 Turbo 1106","attachment":false,"reasoning":false,"temperature":true,"tool_call":false,"knowledge":"2021-08","release_date":"2023-11-06","last_updated":"2023-11-06","modalities":{"input":["text"],"output":["text"]},"open_weights":false,"cost":{"input":1,"output":2},"limit":{"context":16384,"output":16384},"display_name":"GPT-3.5 Turbo 1106"}]},"baseten":{"id":"baseten","api":"https://inference.baseten.co/v1","name":"Baseten","doc":"https://docs.baseten.co/development/model-apis/overview","display_name":"Baseten","models":[{"id":"moonshotai/Kimi-K2-Instruct-0905","name":"Kimi K2 Instruct 0905","attachment":false,"reasoning":false,"temperature":true,"tool_call":true,"knowledge":"2025-08","release_date":"2025-09-05","last_updated":"2025-09-05","modalities":{"input":["text"],"output":["text"]},"open_weights":true,"cost":{"input":0.6,"output":2.5},"limit":{"context":262144,"output":262144},"display_name":"Kimi K2 Instruct 0905"},{"id":"Qwen3/Qwen3-Coder-480B-A35B-Instruct","name":"Qwen3 Coder 480B A35B Instruct","attachment":false,"reasoning":false,"temperature":true,"tool_call":true,"knowledge":"2025-04","release_date":"2025-07-23","last_updated":"2025-07-23","modalities":{"input":["text"],"output":["text"]},"open_weights":true,"cost":{"input":0.38,"output":1.53},"limit":{"context":262144,"output":66536},"display_name":"Qwen3 Coder 480B A35B Instruct"}]},"huggingface":{"id":"huggingface","api":"https://router.huggingface.co/v1","name":"Hugging Face","doc":"https://huggingface.co/docs/inference-providers","display_name":"Hugging Face","models":[{"id":"moonshotai/Kimi-K2-Instruct","name":"Kimi-K2-Instruct","attachment":false,"reasoning":false,"temperature":true,"tool_call":true,"knowledge":"2024-10","release_date":"2025-07-14","last_updated":"2025-07-14","modalities":{"input":["text"],"output":["text"]},"open_weights":true,"cost":{"input":1,"output":3},"limit":{"context":131072,"output":16384},"display_name":"Kimi-K2-Instruct"},{"id":"moonshotai/Kimi-K2-Instruct-0905","name":"Kimi-K2-Instruct-0905","attachment":false,"reasoning":false,"temperature":true,"tool_call":true,"knowledge":"2024-10","release_date":"2025-09-04","last_updated":"2025-09-04","modalities":{"input":["text"],"output":["text"]},"open_weights":true,"cost":{"input":1,"output":3},"limit":{"context":262144,"output":16384},"display_name":"Kimi-K2-Instruct-0905"},{"id":"Qwen/Qwen3-Coder-480B-A35B-Instruct","name":"Qwen3-Coder-480B-A35B-Instruct","attachment":false,"reasoning":false,"temperature":true,"tool_call":true,"knowledge":"2025-04","release_date":"2025-07-23","last_updated":"2025-07-23","modalities":{"input":["text"],"output":["text"]},"open_weights":true,"cost":{"input":2,"output":2},"limit":{"context":262144,"output":66536},"display_name":"Qwen3-Coder-480B-A35B-Instruct"},{"id":"Qwen/Qwen3-235B-A22B-Thinking-2507","name":"Qwen3-235B-A22B-Thinking-2507","attachment":false,"reasoning":true,"temperature":true,"tool_call":true,"knowledge":"2025-04","release_date":"2025-07-25","last_updated":"2025-07-25","modalities":{"input":["text"],"output":["text"]},"open_weights":true,"cost":{"input":0.3,"output":3},"limit":{"context":262144,"output":131072},"display_name":"Qwen3-235B-A22B-Thinking-2507"},{"id":"Qwen/Qwen3-Next-80B-A3B-Instruct","name":"Qwen3-Next-80B-A3B-Instruct","attachment":false,"reasoning":false,"temperature":true,"tool_call":true,"knowledge":"2025-04","release_date":"2025-09-11","last_updated":"2025-09-11","modalities":{"input":["text"],"output":["text"]},"open_weights":true,"cost":{"input":0.25,"output":1},"limit":{"context":262144,"output":66536},"display_name":"Qwen3-Next-80B-A3B-Instruct"},{"id":"Qwen/Qwen3-Next-80B-A3B-Thinking","name":"Qwen3-Next-80B-A3B-Thinking","attachment":false,"reasoning":false,"temperature":true,"tool_call":true,"knowledge":"2025-04","release_date":"2025-09-11","last_updated":"2025-09-11","modalities":{"input":["text"],"output":["text"]},"open_weights":true,"cost":{"input":0.3,"output":2},"limit":{"context":262144,"output":131072},"display_name":"Qwen3-Next-80B-A3B-Thinking"},{"id":"zai-org/GLM-4.5","name":"GLM-4.5","attachment":false,"reasoning":true,"temperature":true,"tool_call":true,"knowledge":"2025-04","release_date":"2025-07-28","last_updated":"2025-07-28","modalities":{"input":["text"],"output":["text"]},"open_weights":true,"cost":{"input":0.6,"output":2.2},"limit":{"context":131072,"output":98304},"display_name":"GLM-4.5"},{"id":"zai-org/GLM-4.6","name":"GLM-4.6","attachment":false,"reasoning":true,"temperature":true,"tool_call":true,"knowledge":"2025-04","release_date":"2025-09-30","last_updated":"2025-09-30","modalities":{"input":["text"],"output":["text"]},"open_weights":true,"cost":{"input":0.6,"output":2.2,"cache_read":0.11},"limit":{"context":200000,"output":128000},"display_name":"GLM-4.6"},{"id":"zai-org/GLM-4.5-Air","name":"GLM-4.5-Air","attachment":false,"reasoning":true,"temperature":true,"tool_call":true,"knowledge":"2025-04","release_date":"2025-07-28","last_updated":"2025-07-28","modalities":{"input":["text"],"output":["text"]},"open_weights":true,"cost":{"input":0.2,"output":1.1},"limit":{"context":128000,"output":96000},"display_name":"GLM-4.5-Air"},{"id":"deepseek-ai/Deepseek-V3-0324","name":"DeepSeek-V3-0324","attachment":false,"reasoning":false,"temperature":true,"tool_call":true,"knowledge":"2024-10","release_date":"2025-03-24","last_updated":"2025-03-24","modalities":{"input":["text"],"output":["text"]},"open_weights":true,"cost":{"input":1.25,"output":1.25},"limit":{"context":16384,"output":8192},"display_name":"DeepSeek-V3-0324"},{"id":"deepseek-ai/DeepSeek-R1-0528","name":"DeepSeek-R1-0528","attachment":false,"reasoning":true,"temperature":true,"tool_call":true,"knowledge":"2025-05","release_date":"2025-05-28","last_updated":"2025-05-28","modalities":{"input":["text"],"output":["text"]},"open_weights":true,"cost":{"input":3,"output":5},"limit":{"context":163840,"output":163840},"display_name":"DeepSeek-R1-0528"}]},"opencode":{"id":"opencode","api":"https://opencode.ai/zen/v1","name":"opencode zen","doc":"https://opencode.ai/docs","display_name":"opencode zen","models":[{"id":"qwen3-coder","name":"Qwen3 Coder","attachment":false,"reasoning":false,"temperature":true,"tool_call":true,"knowledge":"2025-04","release_date":"2025-07-23","last_updated":"2025-07-23","modalities":{"input":["text"],"output":["text"]},"open_weights":true,"cost":{"input":0.45,"output":1.8},"limit":{"context":262144,"output":65536},"display_name":"Qwen3 Coder"},{"id":"claude-opus-4-1","name":"Claude Opus 4.1","attachment":true,"reasoning":true,"temperature":true,"tool_call":true,"knowledge":"2025-03-31","release_date":"2025-08-05","last_updated":"2025-08-05","modalities":{"input":["text","image"],"output":["text"]},"open_weights":false,"cost":{"input":15,"output":75,"reasoning":75,"cache_read":1.5,"cache_write":18.75},"limit":{"context":200000,"output":32000},"provider":{"npm":"@ai-sdk/anthropic"},"display_name":"Claude Opus 4.1"},{"id":"kimi-k2","name":"Kimi K2","attachment":false,"reasoning":false,"temperature":true,"tool_call":true,"knowledge":"2024-10","release_date":"2025-09-05","last_updated":"2025-09-05","modalities":{"input":["text"],"output":["text"]},"open_weights":true,"cost":{"input":0.6,"output":2.5,"cache_read":0.36},"limit":{"context":262144,"output":262144},"display_name":"Kimi K2"},{"id":"claude-sonnet-4-5","name":"Claude Sonnet 4.5","attachment":true,"reasoning":true,"temperature":true,"tool_call":true,"knowledge":"2025-07-31","release_date":"2025-09-29","last_updated":"2025-09-29","modalities":{"input":["text","image"],"output":["text"]},"open_weights":false,"cost":{"input":3,"output":15,"cache_read":0.3,"cache_write":3.75},"limit":{"context":1000000,"output":64000},"provider":{"npm":"@ai-sdk/anthropic"},"display_name":"Claude Sonnet 4.5"},{"id":"gpt-5-codex","name":"GPT-5-Codex","attachment":true,"reasoning":true,"temperature":false,"tool_call":true,"knowledge":"2024-09-30","release_date":"2025-08-07","last_updated":"2025-08-07","modalities":{"input":["text","image"],"output":["text"]},"open_weights":false,"cost":{"input":1.25,"output":10,"reasoning":10,"cache_read":0.125},"limit":{"context":400000,"output":128000},"provider":{"npm":"@ai-sdk/openai"},"display_name":"GPT-5-Codex"},{"id":"claude-3-5-haiku","name":"Claude Haiku 3.5","attachment":true,"reasoning":false,"temperature":true,"tool_call":true,"knowledge":"2024-07-31","release_date":"2024-10-22","last_updated":"2024-10-22","modalities":{"input":["text","image"],"output":["text"]},"open_weights":false,"cost":{"input":0.8,"output":4,"cache_read":0.08,"cache_write":1},"limit":{"context":200000,"output":8192},"provider":{"npm":"@ai-sdk/anthropic"},"display_name":"Claude Haiku 3.5"},{"id":"glm-4.6","name":"GLM-4.6","attachment":false,"reasoning":true,"temperature":true,"tool_call":true,"knowledge":"2025-04","release_date":"2025-09-30","last_updated":"2025-09-30","modalities":{"input":["text"],"output":["text"]},"open_weights":true,"cost":{"input":0.6,"output":2.2,"cache_read":0.11,"cache_write":0},"limit":{"context":204800,"output":131072},"experimental":true,"display_name":"GLM-4.6"},{"id":"grok-code","name":"Grok Code Fast 1","attachment":true,"reasoning":true,"temperature":true,"tool_call":true,"release_date":"2025-08-20","last_updated":"2025-08-20","modalities":{"input":["text"],"output":["text"]},"open_weights":false,"cost":{"input":0,"output":0,"cache_read":0,"cache_write":0},"limit":{"context":256000,"output":256000},"display_name":"Grok Code Fast 1"},{"id":"code-supernova","name":"Code Supernova 1M","attachment":true,"reasoning":true,"temperature":true,"tool_call":true,"release_date":"2025-09-19","last_updated":"2025-09-19","modalities":{"input":["text","image"],"output":["text"]},"open_weights":false,"cost":{"input":0,"output":0,"cache_read":0,"cache_write":0},"limit":{"context":1000000,"output":1000000},"display_name":"Code Supernova 1M"},{"id":"qwen3-max","name":"Qwen3 Max","attachment":false,"reasoning":true,"temperature":true,"tool_call":true,"knowledge":"2025-04","release_date":"2025-09-05","last_updated":"2025-09-05","modalities":{"input":["text"],"output":["text"]},"open_weights":true,"cost":{"input":1.6,"output":6.4},"limit":{"context":262144,"output":65536},"experimental":true,"display_name":"Qwen3 Max"},{"id":"claude-sonnet-4","name":"Claude Sonnet 4","attachment":true,"reasoning":true,"temperature":true,"tool_call":true,"knowledge":"2025-03-31","release_date":"2025-05-22","last_updated":"2025-05-22","modalities":{"input":["text","image"],"output":["text"]},"open_weights":false,"cost":{"input":3,"output":15,"cache_read":0.3,"cache_write":3.75},"limit":{"context":1000000,"output":64000},"provider":{"npm":"@ai-sdk/anthropic"},"display_name":"Claude Sonnet 4"},{"id":"gpt-5","name":"GPT-5","attachment":true,"reasoning":true,"temperature":false,"tool_call":true,"knowledge":"2024-09-30","release_date":"2025-08-07","last_updated":"2025-08-07","modalities":{"input":["text","image"],"output":["text"]},"open_weights":false,"cost":{"input":1.25,"output":10,"reasoning":10,"cache_read":0.125},"limit":{"context":400000,"output":128000},"provider":{"npm":"@ai-sdk/openai"},"display_name":"GPT-5"}]},"fastrouter":{"id":"fastrouter","api":"https://go.fastrouter.ai/api/v1","name":"FastRouter","doc":"https://fastrouter.ai/models","display_name":"FastRouter","models":[{"id":"moonshotai/kimi-k2","name":"Kimi K2","attachment":false,"reasoning":false,"temperature":true,"tool_call":true,"knowledge":"2024-10","release_date":"2025-07-11","last_updated":"2025-07-11","modalities":{"input":["text"],"output":["text"]},"open_weights":true,"cost":{"input":0.55,"output":2.2},"limit":{"context":131072,"output":32768},"display_name":"Kimi K2"},{"id":"x-ai/grok-4","name":"Grok 4","attachment":false,"reasoning":true,"temperature":true,"tool_call":true,"knowledge":"2025-07","release_date":"2025-07-09","last_updated":"2025-07-09","modalities":{"input":["text"],"output":["text"]},"open_weights":false,"cost":{"input":3,"output":15,"cache_read":0.75,"cache_write":15},"limit":{"context":256000,"output":64000},"display_name":"Grok 4"},{"id":"google/gemini-2.5-flash","name":"Gemini 2.5 Flash","attachment":true,"reasoning":true,"temperature":true,"tool_call":true,"knowledge":"2025-01","release_date":"2025-06-17","last_updated":"2025-06-17","modalities":{"input":["text","image","pdf"],"output":["text"]},"open_weights":false,"cost":{"input":0.3,"output":2.5,"cache_read":0.0375},"limit":{"context":1048576,"output":65536},"display_name":"Gemini 2.5 Flash"},{"id":"google/gemini-2.5-pro","name":"Gemini 2.5 Pro","attachment":true,"reasoning":true,"temperature":true,"tool_call":true,"knowledge":"2025-01","release_date":"2025-06-17","last_updated":"2025-06-17","modalities":{"input":["text","image","pdf"],"output":["text"]},"open_weights":false,"cost":{"input":1.25,"output":10,"cache_read":0.31},"limit":{"context":1048576,"output":65536},"display_name":"Gemini 2.5 Pro"},{"id":"openai/gpt-5-nano","name":"GPT-5 Nano","attachment":true,"reasoning":true,"temperature":true,"tool_call":true,"knowledge":"2024-10-01","release_date":"2025-08-07","last_updated":"2025-08-07","modalities":{"input":["text","image"],"output":["text"]},"open_weights":false,"cost":{"input":0.05,"output":0.4,"cache_read":0.005},"limit":{"context":400000,"output":128000},"display_name":"GPT-5 Nano"},{"id":"openai/gpt-4.1","name":"GPT-4.1","attachment":true,"reasoning":false,"temperature":true,"tool_call":true,"knowledge":"2024-04","release_date":"2025-04-14","last_updated":"2025-04-14","modalities":{"input":["text","image"],"output":["text"]},"open_weights":false,"cost":{"input":2,"output":8,"cache_read":0.5},"limit":{"context":1047576,"output":32768},"display_name":"GPT-4.1"},{"id":"openai/gpt-5-mini","name":"GPT-5 Mini","attachment":true,"reasoning":true,"temperature":true,"tool_call":true,"knowledge":"2024-10-01","release_date":"2025-08-07","last_updated":"2025-08-07","modalities":{"input":["text","image"],"output":["text"]},"open_weights":false,"cost":{"input":0.25,"output":2,"cache_read":0.025},"limit":{"context":400000,"output":128000},"display_name":"GPT-5 Mini"},{"id":"openai/gpt-oss-20b","name":"GPT OSS 20B","attachment":false,"reasoning":true,"temperature":true,"tool_call":true,"release_date":"2025-08-05","last_updated":"2025-08-05","modalities":{"input":["text"],"output":["text"]},"open_weights":true,"cost":{"input":0.05,"output":0.2},"limit":{"context":131072,"output":65536},"display_name":"GPT OSS 20B"},{"id":"openai/gpt-oss-120b","name":"GPT OSS 120B","attachment":false,"reasoning":true,"temperature":true,"tool_call":true,"release_date":"2025-08-05","last_updated":"2025-08-05","modalities":{"input":["text"],"output":["text"]},"open_weights":true,"cost":{"input":0.15,"output":0.6},"limit":{"context":131072,"output":32768},"display_name":"GPT OSS 120B"},{"id":"openai/gpt-5","name":"GPT-5","attachment":true,"reasoning":true,"temperature":true,"tool_call":true,"knowledge":"2024-10-01","release_date":"2025-08-07","last_updated":"2025-08-07","modalities":{"input":["text","image"],"output":["text"]},"open_weights":false,"cost":{"input":1.25,"output":10,"cache_read":0.125},"limit":{"context":400000,"output":128000},"display_name":"GPT-5"},{"id":"qwen/qwen3-coder","name":"Qwen3 Coder","attachment":false,"reasoning":false,"temperature":true,"tool_call":true,"knowledge":"2025-04","release_date":"2025-07-23","last_updated":"2025-07-23","modalities":{"input":["text"],"output":["text"]},"open_weights":true,"cost":{"input":0.3,"output":1.2},"limit":{"context":262144,"output":66536},"display_name":"Qwen3 Coder"},{"id":"anthropic/claude-opus-4.1","name":"Claude Opus 4.1","attachment":true,"reasoning":true,"temperature":true,"tool_call":true,"knowledge":"2025-03-31","release_date":"2025-08-05","last_updated":"2025-08-05","modalities":{"input":["text","image"],"output":["text"]},"open_weights":false,"cost":{"input":15,"output":75,"cache_read":1.5,"cache_write":18.75},"limit":{"context":200000,"output":32000},"display_name":"Claude Opus 4.1"},{"id":"anthropic/claude-sonnet-4","name":"Claude Sonnet 4","attachment":true,"reasoning":true,"temperature":true,"tool_call":true,"knowledge":"2025-03-31","release_date":"2025-05-22","last_updated":"2025-05-22","modalities":{"input":["text","image"],"output":["text"]},"open_weights":false,"cost":{"input":3,"output":15,"cache_read":0.3,"cache_write":3.75},"limit":{"context":200000,"output":64000},"display_name":"Claude Sonnet 4"},{"id":"deepseek-ai/deepseek-r1-distill-llama-70b","name":"DeepSeek R1 Distill Llama 70B","attachment":false,"reasoning":true,"temperature":true,"tool_call":false,"knowledge":"2024-10","release_date":"2025-01-23","last_updated":"2025-01-23","modalities":{"input":["text"],"output":["text"]},"open_weights":true,"cost":{"input":0.03,"output":0.14},"limit":{"context":131072,"output":131072},"display_name":"DeepSeek R1 Distill Llama 70B"}]},"google":{"id":"google","name":"Google","doc":"https://ai.google.dev/gemini-api/docs/pricing","display_name":"Google","models":[{"id":"gemini-2.5-flash-preview-05-20","name":"Gemini 2.5 Flash Preview 05-20","attachment":true,"reasoning":true,"temperature":true,"tool_call":true,"knowledge":"2025-01","release_date":"2025-05-20","last_updated":"2025-05-20","modalities":{"input":["text","image","audio","video","pdf"],"output":["text"]},"open_weights":false,"cost":{"input":0.15,"output":0.6,"cache_read":0.0375},"limit":{"context":1048576,"output":65536},"display_name":"Gemini 2.5 Flash Preview 05-20"},{"id":"gemini-flash-lite-latest","name":"Gemini Flash-Lite Latest","attachment":true,"reasoning":true,"temperature":true,"tool_call":true,"knowledge":"2025-01","release_date":"2025-09-25","last_updated":"2025-09-25","modalities":{"input":["text","image","audio","video","pdf"],"output":["text"]},"open_weights":false,"cost":{"input":0.1,"output":0.4,"cache_read":0.025},"limit":{"context":1048576,"output":65536},"display_name":"Gemini Flash-Lite Latest"},{"id":"gemini-2.5-flash","name":"Gemini 2.5 Flash","attachment":true,"reasoning":true,"temperature":true,"tool_call":true,"knowledge":"2025-01","release_date":"2025-03-20","last_updated":"2025-06-05","modalities":{"input":["text","image","audio","video","pdf"],"output":["text"]},"open_weights":false,"cost":{"input":0.3,"output":2.5,"cache_read":0.075,"input_audio":1},"limit":{"context":1048576,"output":65536},"display_name":"Gemini 2.5 Flash"},{"id":"gemini-flash-latest","name":"Gemini Flash Latest","attachment":true,"reasoning":true,"temperature":true,"tool_call":true,"knowledge":"2025-01","release_date":"2025-09-25","last_updated":"2025-09-25","modalities":{"input":["text","image","audio","video","pdf"],"output":["text"]},"open_weights":false,"cost":{"input":0.15,"output":0.6,"cache_read":0.0375},"limit":{"context":1048576,"output":65536},"display_name":"Gemini Flash Latest"},{"id":"gemini-2.5-pro-preview-05-06","name":"Gemini 2.5 Pro Preview 05-06","attachment":true,"reasoning":true,"temperature":true,"tool_call":true,"knowledge":"2025-01","release_date":"2025-05-06","last_updated":"2025-05-06","modalities":{"input":["text","image","audio","video","pdf"],"output":["text"]},"open_weights":false,"cost":{"input":1.25,"output":10,"cache_read":0.31},"limit":{"context":1048576,"output":65536},"display_name":"Gemini 2.5 Pro Preview 05-06"},{"id":"gemini-2.0-flash-lite","name":"Gemini 2.0 Flash Lite","attachment":true,"reasoning":false,"temperature":true,"tool_call":true,"knowledge":"2024-06","release_date":"2024-12-11","last_updated":"2024-12-11","modalities":{"input":["text","image","audio","video","pdf"],"output":["text"]},"open_weights":false,"cost":{"input":0.075,"output":0.3},"limit":{"context":1048576,"output":8192},"display_name":"Gemini 2.0 Flash Lite"},{"id":"gemini-live-2.5-flash-preview-native-audio","name":"Gemini Live 2.5 Flash Preview Native Audio","attachment":false,"reasoning":true,"temperature":false,"tool_call":true,"knowledge":"2025-01","release_date":"2025-06-17","last_updated":"2025-09-18","modalities":{"input":["text","audio","video"],"output":["text","audio"]},"open_weights":false,"cost":{"input":0.5,"output":2,"input_audio":3,"output_audio":12},"limit":{"context":131072,"output":65536},"experimental":true,"display_name":"Gemini Live 2.5 Flash Preview Native Audio"},{"id":"gemini-2.0-flash","name":"Gemini 2.0 Flash","attachment":true,"reasoning":false,"temperature":true,"tool_call":true,"knowledge":"2024-06","release_date":"2024-12-11","last_updated":"2024-12-11","modalities":{"input":["text","image","audio","video","pdf"],"output":["text"]},"open_weights":false,"cost":{"input":0.1,"output":0.4,"cache_read":0.025},"limit":{"context":1048576,"output":8192},"display_name":"Gemini 2.0 Flash"},{"id":"gemini-2.5-flash-lite","name":"Gemini 2.5 Flash Lite","attachment":true,"reasoning":true,"temperature":true,"tool_call":true,"knowledge":"2025-01","release_date":"2025-06-17","last_updated":"2025-06-17","modalities":{"input":["text","image","audio","video","pdf"],"output":["text"]},"open_weights":false,"cost":{"input":0.1,"output":0.4,"cache_read":0.025},"limit":{"context":1048576,"output":65536},"display_name":"Gemini 2.5 Flash Lite"},{"id":"gemini-2.5-pro-preview-06-05","name":"Gemini 2.5 Pro Preview 06-05","attachment":true,"reasoning":true,"temperature":true,"tool_call":true,"knowledge":"2025-01","release_date":"2025-06-05","last_updated":"2025-06-05","modalities":{"input":["text","image","audio","video","pdf"],"output":["text"]},"open_weights":false,"cost":{"input":1.25,"output":10,"cache_read":0.31},"limit":{"context":1048576,"output":65536},"display_name":"Gemini 2.5 Pro Preview 06-05"},{"id":"gemini-2.5-flash-lite-preview-06-17","name":"Gemini 2.5 Flash Lite Preview 06-17","attachment":true,"reasoning":true,"temperature":true,"tool_call":true,"knowledge":"2025-01","release_date":"2025-06-17","last_updated":"2025-06-17","modalities":{"input":["text","image","audio","video","pdf"],"output":["text"]},"open_weights":false,"cost":{"input":0.1,"output":0.4,"cache_read":0.025,"input_audio":0.3},"limit":{"context":1048576,"output":65536},"display_name":"Gemini 2.5 Flash Lite Preview 06-17"},{"id":"gemini-2.5-flash-preview-09-2025","name":"Gemini 2.5 Flash Preview 09-25","attachment":true,"reasoning":true,"temperature":true,"tool_call":true,"knowledge":"2025-01","release_date":"2025-09-25","last_updated":"2025-09-25","modalities":{"input":["text","image","audio","video","pdf"],"output":["text"]},"open_weights":false,"cost":{"input":0.15,"output":0.6,"cache_read":0.0375},"limit":{"context":1048576,"output":65536},"display_name":"Gemini 2.5 Flash Preview 09-25"},{"id":"gemini-2.5-flash-preview-04-17","name":"Gemini 2.5 Flash Preview 04-17","attachment":true,"reasoning":true,"temperature":true,"tool_call":true,"knowledge":"2025-01","release_date":"2025-04-17","last_updated":"2025-04-17","modalities":{"input":["text","image","audio","video","pdf"],"output":["text"]},"open_weights":false,"cost":{"input":0.15,"output":0.6,"cache_read":0.0375},"limit":{"context":1048576,"output":65536},"display_name":"Gemini 2.5 Flash Preview 04-17"},{"id":"gemini-2.5-pro","name":"Gemini 2.5 Pro","attachment":true,"reasoning":true,"temperature":true,"tool_call":true,"knowledge":"2025-01","release_date":"2025-03-20","last_updated":"2025-06-05","modalities":{"input":["text","image","audio","video","pdf"],"output":["text"]},"open_weights":false,"cost":{"input":1.25,"output":10,"cache_read":0.31},"limit":{"context":1048576,"output":65536},"display_name":"Gemini 2.5 Pro"},{"id":"gemini-1.5-flash","name":"Gemini 1.5 Flash","attachment":true,"reasoning":false,"temperature":true,"tool_call":true,"knowledge":"2024-04","release_date":"2024-05-14","last_updated":"2024-05-14","modalities":{"input":["text","image","audio","video"],"output":["text"]},"open_weights":false,"cost":{"input":0.075,"output":0.3,"cache_read":0.01875},"limit":{"context":1000000,"output":8192},"display_name":"Gemini 1.5 Flash"},{"id":"gemini-1.5-flash-8b","name":"Gemini 1.5 Flash-8B","attachment":true,"reasoning":false,"temperature":true,"tool_call":true,"knowledge":"2024-04","release_date":"2024-10-03","last_updated":"2024-10-03","modalities":{"input":["text","image","audio","video"],"output":["text"]},"open_weights":false,"cost":{"input":0.0375,"output":0.15,"cache_read":0.01},"limit":{"context":1000000,"output":8192},"display_name":"Gemini 1.5 Flash-8B"},{"id":"gemini-2.5-flash-lite-preview-09-2025","name":"Gemini 2.5 Flash Lite Preview 09-25","attachment":true,"reasoning":true,"temperature":true,"tool_call":true,"knowledge":"2025-01","release_date":"2025-09-25","last_updated":"2025-09-25","modalities":{"input":["text","image","audio","video","pdf"],"output":["text"]},"open_weights":false,"cost":{"input":0.1,"output":0.4,"cache_read":0.025},"limit":{"context":1048576,"output":65536},"display_name":"Gemini 2.5 Flash Lite Preview 09-25"},{"id":"gemini-1.5-pro","name":"Gemini 1.5 Pro","attachment":true,"reasoning":false,"temperature":true,"tool_call":true,"knowledge":"2024-04","release_date":"2024-02-15","last_updated":"2024-02-15","modalities":{"input":["text","image","audio","video"],"output":["text"]},"open_weights":false,"cost":{"input":1.25,"output":5,"cache_read":0.3125},"limit":{"context":1000000,"output":8192},"display_name":"Gemini 1.5 Pro"}]},"google-vertex":{"id":"google-vertex","name":"Vertex","doc":"https://cloud.google.com/vertex-ai/generative-ai/docs/models","display_name":"Vertex","models":[{"id":"gemini-2.5-flash-preview-05-20","name":"Gemini 2.5 Flash Preview 05-20","attachment":true,"reasoning":true,"temperature":true,"tool_call":true,"knowledge":"2025-01","release_date":"2025-05-20","last_updated":"2025-05-20","modalities":{"input":["text","image","audio","video","pdf"],"output":["text"]},"open_weights":false,"cost":{"input":0.15,"output":0.6,"cache_read":0.0375},"limit":{"context":1048576,"output":65536},"display_name":"Gemini 2.5 Flash Preview 05-20"},{"id":"gemini-2.5-flash","name":"Gemini 2.5 Flash","attachment":true,"reasoning":true,"temperature":true,"tool_call":true,"knowledge":"2025-01","release_date":"2025-06-17","last_updated":"2025-06-17","modalities":{"input":["text","image","audio","video","pdf"],"output":["text"]},"open_weights":false,"cost":{"input":0.3,"output":2.5,"cache_read":0.075,"cache_write":0.383},"limit":{"context":1048576,"output":65536},"display_name":"Gemini 2.5 Flash"},{"id":"gemini-2.5-pro-preview-05-06","name":"Gemini 2.5 Pro Preview 05-06","attachment":true,"reasoning":true,"temperature":true,"tool_call":true,"knowledge":"2025-01","release_date":"2025-05-06","last_updated":"2025-05-06","modalities":{"input":["text","image","audio","video","pdf"],"output":["text"]},"open_weights":false,"cost":{"input":1.25,"output":10,"cache_read":0.31},"limit":{"context":1048576,"output":65536},"display_name":"Gemini 2.5 Pro Preview 05-06"},{"id":"gemini-2.0-flash-lite","name":"Gemini 2.0 Flash Lite","attachment":true,"reasoning":false,"temperature":true,"tool_call":true,"knowledge":"2024-06","release_date":"2024-12-11","last_updated":"2024-12-11","modalities":{"input":["text","image","audio","video","pdf"],"output":["text"]},"open_weights":false,"cost":{"input":0.075,"output":0.3},"limit":{"context":1048576,"output":8192},"display_name":"Gemini 2.0 Flash Lite"},{"id":"gemini-2.0-flash","name":"Gemini 2.0 Flash","attachment":true,"reasoning":false,"temperature":true,"tool_call":true,"knowledge":"2024-06","release_date":"2024-12-11","last_updated":"2024-12-11","modalities":{"input":["text","image","audio","video","pdf"],"output":["text"]},"open_weights":false,"cost":{"input":0.1,"output":0.4,"cache_read":0.025},"limit":{"context":1048576,"output":8192},"display_name":"Gemini 2.0 Flash"},{"id":"gemini-2.5-pro-preview-06-05","name":"Gemini 2.5 Pro Preview 06-05","attachment":true,"reasoning":true,"temperature":true,"tool_call":true,"knowledge":"2025-01","release_date":"2025-06-05","last_updated":"2025-06-05","modalities":{"input":["text","image","audio","video","pdf"],"output":["text"]},"open_weights":false,"cost":{"input":1.25,"output":10,"cache_read":0.31},"limit":{"context":1048576,"output":65536},"display_name":"Gemini 2.5 Pro Preview 06-05"},{"id":"gemini-2.5-flash-lite-preview-06-17","name":"Gemini 2.5 Flash Lite Preview 06-17","attachment":true,"reasoning":true,"temperature":true,"tool_call":true,"knowledge":"2025-01","release_date":"2025-06-17","last_updated":"2025-06-17","modalities":{"input":["text","image","audio","video","pdf"],"output":["text"]},"open_weights":false,"cost":{"input":0.1,"output":0.4,"cache_read":0.025},"limit":{"context":65536,"output":65536},"display_name":"Gemini 2.5 Flash Lite Preview 06-17"},{"id":"gemini-2.5-flash-preview-04-17","name":"Gemini 2.5 Flash Preview 04-17","attachment":true,"reasoning":true,"temperature":true,"tool_call":true,"knowledge":"2025-01","release_date":"2025-04-17","last_updated":"2025-04-17","modalities":{"input":["text","image","audio","video","pdf"],"output":["text"]},"open_weights":false,"cost":{"input":0.15,"output":0.6,"cache_read":0.0375},"limit":{"context":1048576,"output":65536},"display_name":"Gemini 2.5 Flash Preview 04-17"},{"id":"gemini-2.5-pro","name":"Gemini 2.5 Pro","attachment":true,"reasoning":true,"temperature":true,"tool_call":true,"knowledge":"2025-01","release_date":"2025-03-20","last_updated":"2025-06-05","modalities":{"input":["text","image","audio","video","pdf"],"output":["text"]},"open_weights":false,"cost":{"input":1.25,"output":10,"cache_read":0.31},"limit":{"context":1048576,"output":65536},"display_name":"Gemini 2.5 Pro"}]},"cloudflare-workers-ai":{"id":"cloudflare-workers-ai","name":"Cloudflare Workers AI","doc":"https://developers.cloudflare.com/workers-ai/models/","display_name":"Cloudflare Workers AI","models":[{"id":"mistral-7b-instruct-v0.1-awq","name":"@hf/thebloke/mistral-7b-instruct-v0.1-awq","attachment":false,"reasoning":false,"temperature":true,"tool_call":true,"release_date":"2023-09-27","last_updated":"2023-11-09","modalities":{"input":["text"],"output":["text"]},"open_weights":true,"cost":{"input":0,"output":0},"limit":{"context":4096,"output":4096},"display_name":"@hf/thebloke/mistral-7b-instruct-v0.1-awq"},{"id":"aura-1","name":"@cf/deepgram/aura-1","attachment":false,"reasoning":false,"temperature":false,"tool_call":false,"release_date":"2025-08-27","last_updated":"2025-07-07","modalities":{"input":["text"],"output":["audio"]},"open_weights":true,"cost":{"input":0.015,"output":0.015},"limit":{"context":0,"output":0},"display_name":"@cf/deepgram/aura-1"},{"id":"mistral-7b-instruct-v0.2","name":"@hf/mistral/mistral-7b-instruct-v0.2","attachment":false,"reasoning":false,"temperature":true,"tool_call":true,"release_date":"2023-12-11","last_updated":"2025-07-24","modalities":{"input":["text"],"output":["text"]},"open_weights":true,"cost":{"input":0,"output":0},"limit":{"context":3072,"output":3072},"display_name":"@hf/mistral/mistral-7b-instruct-v0.2"},{"id":"tinyllama-1.1b-chat-v1.0","name":"@cf/tinyllama/tinyllama-1.1b-chat-v1.0","attachment":false,"reasoning":false,"temperature":true,"tool_call":true,"release_date":"2023-12-30","last_updated":"2024-03-17","modalities":{"input":["text"],"output":["text"]},"open_weights":true,"cost":{"input":0,"output":0},"limit":{"context":2048,"output":2048},"display_name":"@cf/tinyllama/tinyllama-1.1b-chat-v1.0"},{"id":"qwen1.5-0.5b-chat","name":"@cf/qwen/qwen1.5-0.5b-chat","attachment":false,"reasoning":false,"temperature":true,"tool_call":true,"release_date":"2024-01-31","last_updated":"2024-04-30","modalities":{"input":["text"],"output":["text"]},"open_weights":true,"cost":{"input":0,"output":0},"limit":{"context":32000,"output":32000},"display_name":"@cf/qwen/qwen1.5-0.5b-chat"},{"id":"llama-3.2-11b-vision-instruct","name":"@cf/meta/llama-3.2-11b-vision-instruct","attachment":false,"reasoning":false,"temperature":true,"tool_call":true,"release_date":"2024-09-18","last_updated":"2024-12-04","modalities":{"input":["text"],"output":["text"]},"open_weights":true,"cost":{"input":0.049,"output":0.68},"limit":{"context":128000,"output":128000},"display_name":"@cf/meta/llama-3.2-11b-vision-instruct"},{"id":"llama-2-13b-chat-awq","name":"@hf/thebloke/llama-2-13b-chat-awq","attachment":false,"reasoning":false,"temperature":true,"tool_call":true,"release_date":"2023-09-19","last_updated":"2023-11-09","modalities":{"input":["text"],"output":["text"]},"open_weights":true,"cost":{"input":0,"output":0},"limit":{"context":4096,"output":4096},"display_name":"@hf/thebloke/llama-2-13b-chat-awq"},{"id":"llama-3.1-8b-instruct-fp8","name":"@cf/meta/llama-3.1-8b-instruct-fp8","attachment":false,"reasoning":false,"temperature":true,"tool_call":true,"release_date":"2024-07-25","last_updated":"2024-07-25","modalities":{"input":["text"],"output":["text"]},"open_weights":true,"cost":{"input":0.15,"output":0.29},"limit":{"context":32000,"output":32000},"display_name":"@cf/meta/llama-3.1-8b-instruct-fp8"},{"id":"whisper","name":"@cf/openai/whisper","attachment":false,"reasoning":false,"temperature":false,"tool_call":false,"release_date":"2023-11-07","last_updated":"2024-08-12","modalities":{"input":["audio"],"output":["text"]},"open_weights":true,"cost":{"input":0.00045,"output":0.00045},"limit":{"context":0,"output":0},"display_name":"@cf/openai/whisper"},{"id":"stable-diffusion-xl-base-1.0","name":"@cf/stabilityai/stable-diffusion-xl-base-1.0","attachment":false,"reasoning":false,"temperature":false,"tool_call":false,"release_date":"2023-07-25","last_updated":"2023-10-30","modalities":{"input":["text"],"output":["image"]},"open_weights":true,"cost":{"input":0,"output":0},"limit":{"context":0,"output":0},"display_name":"@cf/stabilityai/stable-diffusion-xl-base-1.0"},{"id":"llama-2-7b-chat-fp16","name":"@cf/meta/llama-2-7b-chat-fp16","attachment":false,"reasoning":false,"temperature":true,"tool_call":true,"release_date":"2023-07-26","last_updated":"2023-07-26","modalities":{"input":["text"],"output":["text"]},"open_weights":true,"cost":{"input":0.56,"output":6.67},"limit":{"context":4096,"output":4096},"display_name":"@cf/meta/llama-2-7b-chat-fp16"},{"id":"resnet-50","name":"@cf/microsoft/resnet-50","attachment":false,"reasoning":false,"temperature":false,"tool_call":false,"release_date":"2022-03-16","last_updated":"2024-02-13","modalities":{"input":["image"],"output":["text"]},"open_weights":true,"cost":{"input":0.0000025,"output":0},"limit":{"context":0,"output":0},"display_name":"@cf/microsoft/resnet-50"},{"id":"stable-diffusion-v1-5-inpainting","name":"@cf/runwayml/stable-diffusion-v1-5-inpainting","attachment":false,"reasoning":false,"temperature":false,"tool_call":false,"release_date":"2024-02-27","last_updated":"2024-02-27","modalities":{"input":["text"],"output":["image"]},"open_weights":true,"cost":{"input":0,"output":0},"limit":{"context":0,"output":0},"display_name":"@cf/runwayml/stable-diffusion-v1-5-inpainting"},{"id":"sqlcoder-7b-2","name":"@cf/defog/sqlcoder-7b-2","attachment":false,"reasoning":false,"temperature":true,"tool_call":true,"release_date":"2024-02-05","last_updated":"2024-02-12","modalities":{"input":["text"],"output":["text"]},"open_weights":true,"cost":{"input":0,"output":0},"limit":{"context":10000,"output":10000},"display_name":"@cf/defog/sqlcoder-7b-2"},{"id":"llama-3-8b-instruct","name":"@cf/meta/llama-3-8b-instruct","attachment":false,"reasoning":false,"temperature":true,"tool_call":true,"release_date":"2024-04-17","last_updated":"2025-06-19","modalities":{"input":["text"],"output":["text"]},"open_weights":true,"cost":{"input":0.28,"output":0.83},"limit":{"context":7968,"output":7968},"display_name":"@cf/meta/llama-3-8b-instruct"},{"id":"llama-2-7b-chat-hf-lora","name":"@cf/meta-llama/llama-2-7b-chat-hf-lora","attachment":false,"reasoning":false,"temperature":true,"tool_call":true,"release_date":"2023-07-13","last_updated":"2024-04-17","modalities":{"input":["text"],"output":["text"]},"open_weights":true,"cost":{"input":0,"output":0},"limit":{"context":8192,"output":8192},"display_name":"@cf/meta-llama/llama-2-7b-chat-hf-lora"},{"id":"llama-3.1-8b-instruct","name":"@cf/meta/llama-3.1-8b-instruct","attachment":false,"reasoning":false,"temperature":true,"tool_call":true,"release_date":"2024-07-18","last_updated":"2024-09-25","modalities":{"input":["text"],"output":["text"]},"open_weights":true,"cost":{"input":0.28,"output":0.83},"limit":{"context":7968,"output":7968},"display_name":"@cf/meta/llama-3.1-8b-instruct"},{"id":"openchat-3.5-0106","name":"@cf/openchat/openchat-3.5-0106","attachment":false,"reasoning":false,"temperature":true,"tool_call":true,"release_date":"2024-01-07","last_updated":"2024-05-18","modalities":{"input":["text"],"output":["text"]},"open_weights":true,"cost":{"input":0,"output":0},"limit":{"context":8192,"output":8192},"display_name":"@cf/openchat/openchat-3.5-0106"},{"id":"openhermes-2.5-mistral-7b-awq","name":"@hf/thebloke/openhermes-2.5-mistral-7b-awq","attachment":false,"reasoning":false,"temperature":true,"tool_call":true,"release_date":"2023-11-02","last_updated":"2023-11-09","modalities":{"input":["text"],"output":["text"]},"open_weights":true,"cost":{"input":0,"output":0},"limit":{"context":4096,"output":4096},"display_name":"@hf/thebloke/openhermes-2.5-mistral-7b-awq"},{"id":"lucid-origin","name":"@cf/leonardo/lucid-origin","attachment":false,"reasoning":false,"temperature":false,"tool_call":false,"release_date":"2025-08-25","last_updated":"2025-08-05","modalities":{"input":["text"],"output":["image"]},"open_weights":false,"cost":{"input":0.007,"output":0.007},"limit":{"context":0,"output":0},"display_name":"@cf/leonardo/lucid-origin"},{"id":"bart-large-cnn","name":"@cf/facebook/bart-large-cnn","attachment":false,"reasoning":false,"temperature":false,"tool_call":false,"release_date":"2022-03-02","last_updated":"2024-02-13","modalities":{"input":["text"],"output":["text"]},"open_weights":true,"cost":{"input":0,"output":0},"limit":{"context":0,"output":0},"display_name":"@cf/facebook/bart-large-cnn"},{"id":"flux-1-schnell","name":"@cf/black-forest-labs/flux-1-schnell","attachment":false,"reasoning":false,"temperature":false,"tool_call":false,"release_date":"2024-07-31","last_updated":"2024-08-16","modalities":{"input":["text"],"output":["image"]},"open_weights":true,"cost":{"input":0.000053,"output":0.00011},"limit":{"context":2048,"output":0},"display_name":"@cf/black-forest-labs/flux-1-schnell"},{"id":"deepseek-r1-distill-qwen-32b","name":"@cf/deepseek-ai/deepseek-r1-distill-qwen-32b","attachment":false,"reasoning":true,"temperature":true,"tool_call":true,"release_date":"2025-01-20","last_updated":"2025-02-24","modalities":{"input":["text"],"output":["text"]},"open_weights":true,"cost":{"input":0.5,"output":4.88},"limit":{"context":80000,"output":80000},"display_name":"@cf/deepseek-ai/deepseek-r1-distill-qwen-32b"},{"id":"gemma-2b-it-lora","name":"@cf/google/gemma-2b-it-lora","attachment":false,"reasoning":false,"temperature":true,"tool_call":true,"release_date":"2024-04-02","last_updated":"2024-04-02","modalities":{"input":["text"],"output":["text"]},"open_weights":true,"cost":{"input":0,"output":0},"limit":{"context":8192,"output":8192},"display_name":"@cf/google/gemma-2b-it-lora"},{"id":"una-cybertron-7b-v2-bf16","name":"@cf/fblgit/una-cybertron-7b-v2-bf16","attachment":false,"reasoning":false,"temperature":true,"tool_call":true,"release_date":"2023-12-02","last_updated":"2024-03-08","modalities":{"input":["text"],"output":["text"]},"open_weights":true,"cost":{"input":0,"output":0},"limit":{"context":15000,"output":15000},"display_name":"@cf/fblgit/una-cybertron-7b-v2-bf16"},{"id":"m2m100-1.2b","name":"@cf/meta/m2m100-1.2b","attachment":false,"reasoning":false,"temperature":false,"tool_call":false,"release_date":"2022-03-02","last_updated":"2023-11-16","modalities":{"input":["text"],"output":["text"]},"open_weights":true,"cost":{"input":0.34,"output":0.34},"limit":{"context":0,"output":0},"display_name":"@cf/meta/m2m100-1.2b"},{"id":"llama-3.2-3b-instruct","name":"@cf/meta/llama-3.2-3b-instruct","attachment":false,"reasoning":false,"temperature":true,"tool_call":true,"release_date":"2024-09-18","last_updated":"2024-10-24","modalities":{"input":["text"],"output":["text"]},"open_weights":true,"cost":{"input":0.051,"output":0.34},"limit":{"context":128000,"output":128000},"display_name":"@cf/meta/llama-3.2-3b-instruct"},{"id":"qwen2.5-coder-32b-instruct","name":"@cf/qwen/qwen2.5-coder-32b-instruct","attachment":false,"reasoning":false,"temperature":true,"tool_call":true,"release_date":"2024-11-06","last_updated":"2025-01-12","modalities":{"input":["text"],"output":["text"]},"open_weights":true,"cost":{"input":0.66,"output":1},"limit":{"context":32768,"output":32768},"display_name":"@cf/qwen/qwen2.5-coder-32b-instruct"},{"id":"stable-diffusion-v1-5-img2img","name":"@cf/runwayml/stable-diffusion-v1-5-img2img","attachment":false,"reasoning":false,"temperature":false,"tool_call":false,"release_date":"2024-02-27","last_updated":"2024-02-27","modalities":{"input":["text"],"output":["image"]},"open_weights":true,"cost":{"input":0,"output":0},"limit":{"context":0,"output":0},"display_name":"@cf/runwayml/stable-diffusion-v1-5-img2img"},{"id":"gemma-7b-it-lora","name":"@cf/google/gemma-7b-it-lora","attachment":false,"reasoning":false,"temperature":true,"tool_call":true,"release_date":"2024-04-02","last_updated":"2024-04-02","modalities":{"input":["text"],"output":["text"]},"open_weights":true,"cost":{"input":0,"output":0},"limit":{"context":3500,"output":3500},"display_name":"@cf/google/gemma-7b-it-lora"},{"id":"qwen1.5-14b-chat-awq","name":"@cf/qwen/qwen1.5-14b-chat-awq","attachment":false,"reasoning":false,"temperature":true,"tool_call":true,"release_date":"2024-02-03","last_updated":"2024-04-30","modalities":{"input":["text"],"output":["text"]},"open_weights":true,"cost":{"input":0,"output":0},"limit":{"context":7500,"output":7500},"display_name":"@cf/qwen/qwen1.5-14b-chat-awq"},{"id":"qwen1.5-1.8b-chat","name":"@cf/qwen/qwen1.5-1.8b-chat","attachment":false,"reasoning":false,"temperature":true,"tool_call":true,"release_date":"2024-01-30","last_updated":"2024-04-30","modalities":{"input":["text"],"output":["text"]},"open_weights":true,"cost":{"input":0,"output":0},"limit":{"context":32000,"output":32000},"display_name":"@cf/qwen/qwen1.5-1.8b-chat"},{"id":"mistral-small-3.1-24b-instruct","name":"@cf/mistralai/mistral-small-3.1-24b-instruct","attachment":false,"reasoning":false,"temperature":true,"tool_call":true,"release_date":"2025-03-11","last_updated":"2025-07-28","modalities":{"input":["text"],"output":["text"]},"open_weights":true,"cost":{"input":0.35,"output":0.56},"limit":{"context":128000,"output":128000},"display_name":"@cf/mistralai/mistral-small-3.1-24b-instruct"},{"id":"gemma-7b-it","name":"@hf/google/gemma-7b-it","attachment":false,"reasoning":false,"temperature":true,"tool_call":true,"release_date":"2024-02-13","last_updated":"2024-08-14","modalities":{"input":["text"],"output":["text"]},"open_weights":true,"cost":{"input":0,"output":0},"limit":{"context":8192,"output":8192},"display_name":"@hf/google/gemma-7b-it"},{"id":"llamaguard-7b-awq","name":"@hf/thebloke/llamaguard-7b-awq","attachment":false,"reasoning":false,"temperature":true,"tool_call":true,"release_date":"2023-12-11","last_updated":"2023-12-11","modalities":{"input":["text"],"output":["text"]},"open_weights":true,"cost":{"input":0,"output":0},"limit":{"context":4096,"output":4096},"display_name":"@hf/thebloke/llamaguard-7b-awq"},{"id":"hermes-2-pro-mistral-7b","name":"@hf/nousresearch/hermes-2-pro-mistral-7b","attachment":false,"reasoning":false,"temperature":true,"tool_call":true,"release_date":"2024-03-11","last_updated":"2024-09-08","modalities":{"input":["text"],"output":["text"]},"open_weights":true,"cost":{"input":0,"output":0},"limit":{"context":24000,"output":24000},"display_name":"@hf/nousresearch/hermes-2-pro-mistral-7b"},{"id":"falcon-7b-instruct","name":"@cf/tiiuae/falcon-7b-instruct","attachment":false,"reasoning":false,"temperature":true,"tool_call":true,"release_date":"2023-04-25","last_updated":"2024-10-12","modalities":{"input":["text"],"output":["text"]},"open_weights":true,"cost":{"input":0,"output":0},"limit":{"context":4096,"output":4096},"display_name":"@cf/tiiuae/falcon-7b-instruct"},{"id":"llama-3.3-70b-instruct-fp8-fast","name":"@cf/meta/llama-3.3-70b-instruct-fp8-fast","attachment":false,"reasoning":false,"temperature":true,"tool_call":true,"release_date":"2024-12-06","last_updated":"2024-12-06","modalities":{"input":["text"],"output":["text"]},"open_weights":true,"cost":{"input":0.29,"output":2.25},"limit":{"context":24000,"output":24000},"display_name":"@cf/meta/llama-3.3-70b-instruct-fp8-fast"},{"id":"llama-3-8b-instruct-awq","name":"@cf/meta/llama-3-8b-instruct-awq","attachment":false,"reasoning":false,"temperature":true,"tool_call":true,"release_date":"2024-05-09","last_updated":"2024-05-09","modalities":{"input":["text"],"output":["text"]},"open_weights":true,"cost":{"input":0.12,"output":0.27},"limit":{"context":8192,"output":8192},"display_name":"@cf/meta/llama-3-8b-instruct-awq"},{"id":"phoenix-1.0","name":"@cf/leonardo/phoenix-1.0","attachment":false,"reasoning":false,"temperature":false,"tool_call":false,"release_date":"2025-08-25","last_updated":"2025-08-25","modalities":{"input":["text"],"output":["image"]},"open_weights":false,"cost":{"input":0.0058,"output":0.0058},"limit":{"context":0,"output":0},"display_name":"@cf/leonardo/phoenix-1.0"},{"id":"phi-2","name":"@cf/microsoft/phi-2","attachment":false,"reasoning":false,"temperature":true,"tool_call":true,"release_date":"2023-12-13","last_updated":"2024-04-29","modalities":{"input":["text"],"output":["text"]},"open_weights":true,"cost":{"input":0,"output":0},"limit":{"context":2048,"output":2048},"display_name":"@cf/microsoft/phi-2"},{"id":"dreamshaper-8-lcm","name":"@cf/lykon/dreamshaper-8-lcm","attachment":true,"reasoning":false,"temperature":false,"tool_call":false,"release_date":"2023-12-06","last_updated":"2023-12-07","modalities":{"input":["text"],"output":["image"]},"open_weights":true,"cost":{"input":0,"output":0},"limit":{"context":0,"output":0},"display_name":"@cf/lykon/dreamshaper-8-lcm"},{"id":"discolm-german-7b-v1-awq","name":"@cf/thebloke/discolm-german-7b-v1-awq","attachment":false,"reasoning":false,"temperature":true,"tool_call":true,"release_date":"2024-01-18","last_updated":"2024-01-24","modalities":{"input":["text"],"output":["text"]},"open_weights":true,"cost":{"input":0,"output":0},"limit":{"context":4096,"output":4096},"display_name":"@cf/thebloke/discolm-german-7b-v1-awq"},{"id":"llama-2-7b-chat-int8","name":"@cf/meta/llama-2-7b-chat-int8","attachment":false,"reasoning":false,"temperature":true,"tool_call":true,"release_date":"2023-09-25","last_updated":"2023-09-25","modalities":{"input":["text"],"output":["text"]},"open_weights":true,"limit":{"context":8192,"output":8192},"display_name":"@cf/meta/llama-2-7b-chat-int8"},{"id":"llama-3.2-1b-instruct","name":"@cf/meta/llama-3.2-1b-instruct","attachment":false,"reasoning":false,"temperature":true,"tool_call":true,"release_date":"2024-09-18","last_updated":"2024-10-24","modalities":{"input":["text"],"output":["text"]},"open_weights":true,"cost":{"input":0.027,"output":0.2},"limit":{"context":60000,"output":60000},"display_name":"@cf/meta/llama-3.2-1b-instruct"},{"id":"whisper-large-v3-turbo","name":"@cf/openai/whisper-large-v3-turbo","attachment":false,"reasoning":false,"temperature":false,"tool_call":false,"release_date":"2024-10-01","last_updated":"2024-10-04","modalities":{"input":["audio"],"output":["text"]},"open_weights":true,"cost":{"input":0.00051,"output":0.00051},"limit":{"context":0,"output":0},"display_name":"@cf/openai/whisper-large-v3-turbo"},{"id":"llama-4-scout-17b-16e-instruct","name":"@cf/meta/llama-4-scout-17b-16e-instruct","attachment":false,"reasoning":false,"temperature":true,"tool_call":true,"release_date":"2025-04-02","last_updated":"2025-05-23","modalities":{"input":["text"],"output":["text"]},"open_weights":true,"cost":{"input":0.27,"output":0.85},"limit":{"context":131000,"output":131000},"display_name":"@cf/meta/llama-4-scout-17b-16e-instruct"},{"id":"starling-lm-7b-beta","name":"@hf/nexusflow/starling-lm-7b-beta","attachment":false,"reasoning":false,"temperature":true,"tool_call":true,"release_date":"2024-03-19","last_updated":"2024-04-03","modalities":{"input":["text"],"output":["text"]},"open_weights":true,"cost":{"input":0,"output":0},"limit":{"context":4096,"output":4096},"display_name":"@hf/nexusflow/starling-lm-7b-beta"},{"id":"deepseek-coder-6.7b-base-awq","name":"@hf/thebloke/deepseek-coder-6.7b-base-awq","attachment":false,"reasoning":false,"temperature":true,"tool_call":true,"release_date":"2023-11-05","last_updated":"2023-11-09","modalities":{"input":["text"],"output":["text"]},"open_weights":true,"cost":{"input":0,"output":0},"limit":{"context":4096,"output":4096},"display_name":"@hf/thebloke/deepseek-coder-6.7b-base-awq"},{"id":"gemma-3-12b-it","name":"@cf/google/gemma-3-12b-it","attachment":false,"reasoning":false,"temperature":true,"tool_call":true,"release_date":"2025-03-01","last_updated":"2025-03-21","modalities":{"input":["text"],"output":["text"]},"open_weights":true,"cost":{"input":0.35,"output":0.56},"limit":{"context":80000,"output":80000},"display_name":"@cf/google/gemma-3-12b-it"},{"id":"llama-guard-3-8b","name":"@cf/meta/llama-guard-3-8b","attachment":false,"reasoning":false,"temperature":true,"tool_call":false,"release_date":"2024-07-22","last_updated":"2024-10-11","modalities":{"input":["text"],"output":["text"]},"open_weights":true,"cost":{"input":0.48,"output":0.03},"limit":{"context":0,"output":0},"display_name":"@cf/meta/llama-guard-3-8b"},{"id":"neural-chat-7b-v3-1-awq","name":"@hf/thebloke/neural-chat-7b-v3-1-awq","attachment":false,"reasoning":false,"temperature":true,"tool_call":true,"release_date":"2023-11-15","last_updated":"2023-11-17","modalities":{"input":["text"],"output":["text"]},"open_weights":true,"cost":{"input":0,"output":0},"limit":{"context":4096,"output":4096},"display_name":"@hf/thebloke/neural-chat-7b-v3-1-awq"},{"id":"whisper-tiny-en","name":"@cf/openai/whisper-tiny-en","attachment":false,"reasoning":false,"temperature":false,"tool_call":false,"release_date":"2022-09-26","last_updated":"2024-01-22","modalities":{"input":["audio"],"output":["text"]},"open_weights":true,"cost":{"input":0,"output":0},"limit":{"context":0,"output":0},"display_name":"@cf/openai/whisper-tiny-en"},{"id":"stable-diffusion-xl-lightning","name":"@cf/bytedance/stable-diffusion-xl-lightning","attachment":false,"reasoning":false,"temperature":false,"tool_call":false,"release_date":"2024-02-20","last_updated":"2024-04-03","modalities":{"input":["text"],"output":["image"]},"open_weights":true,"cost":{"input":0,"output":0},"limit":{"context":0,"output":0},"display_name":"@cf/bytedance/stable-diffusion-xl-lightning"},{"id":"mistral-7b-instruct-v0.1","name":"@cf/mistral/mistral-7b-instruct-v0.1","attachment":false,"reasoning":false,"temperature":true,"tool_call":true,"release_date":"2023-09-27","last_updated":"2025-07-24","modalities":{"input":["text"],"output":["text"]},"open_weights":true,"cost":{"input":0.11,"output":0.19},"limit":{"context":2824,"output":2824},"display_name":"@cf/mistral/mistral-7b-instruct-v0.1"},{"id":"llava-1.5-7b-hf","name":"@cf/llava-hf/llava-1.5-7b-hf","attachment":true,"reasoning":false,"temperature":true,"tool_call":false,"release_date":"2023-12-05","last_updated":"2025-06-06","modalities":{"input":["image","text"],"output":["text"]},"open_weights":true,"cost":{"input":0,"output":0},"limit":{"context":0,"output":0},"display_name":"@cf/llava-hf/llava-1.5-7b-hf"},{"id":"gpt-oss-20b","name":"@cf/openai/gpt-oss-20b","attachment":false,"reasoning":false,"temperature":false,"tool_call":false,"release_date":"2025-08-04","last_updated":"2025-08-14","modalities":{"input":["text"],"output":["text"]},"open_weights":true,"cost":{"input":0.2,"output":0.3},"limit":{"context":128000,"output":128000},"display_name":"@cf/openai/gpt-oss-20b"},{"id":"deepseek-math-7b-instruct","name":"@cf/deepseek-ai/deepseek-math-7b-instruct","attachment":false,"reasoning":false,"temperature":true,"tool_call":true,"release_date":"2024-02-05","last_updated":"2024-02-06","modalities":{"input":["text"],"output":["text"]},"open_weights":true,"cost":{"input":0,"output":0},"limit":{"context":4096,"output":4096},"display_name":"@cf/deepseek-ai/deepseek-math-7b-instruct"},{"id":"gpt-oss-120b","name":"@cf/openai/gpt-oss-120b","attachment":false,"reasoning":false,"temperature":false,"tool_call":false,"release_date":"2025-08-04","last_updated":"2025-08-14","modalities":{"input":["text"],"output":["text"]},"open_weights":true,"cost":{"input":0.35,"output":0.75},"limit":{"context":128000,"output":128000},"display_name":"@cf/openai/gpt-oss-120b"},{"id":"melotts","name":"@cf/myshell-ai/melotts","attachment":true,"reasoning":false,"temperature":false,"tool_call":false,"release_date":"2024-07-19","last_updated":"2024-07-19","modalities":{"input":["text"],"output":["audio"]},"open_weights":true,"cost":{"input":0.0002,"output":0},"limit":{"context":0,"output":0},"display_name":"@cf/myshell-ai/melotts"},{"id":"qwen1.5-7b-chat-awq","name":"@cf/qwen/qwen1.5-7b-chat-awq","attachment":false,"reasoning":false,"temperature":true,"tool_call":true,"release_date":"2024-02-03","last_updated":"2024-04-30","modalities":{"input":["text"],"output":["text"]},"open_weights":true,"cost":{"input":0,"output":0},"limit":{"context":20000,"output":20000},"display_name":"@cf/qwen/qwen1.5-7b-chat-awq"},{"id":"llama-3.1-8b-instruct-fast","name":"@cf/meta/llama-3.1-8b-instruct-fast","attachment":false,"reasoning":false,"temperature":true,"tool_call":true,"release_date":"2024-07-18","last_updated":"2024-09-25","modalities":{"input":["text"],"output":["text"]},"open_weights":true,"limit":{"context":128000,"output":128000},"display_name":"@cf/meta/llama-3.1-8b-instruct-fast"},{"id":"nova-3","name":"@cf/deepgram/nova-3","attachment":false,"reasoning":false,"temperature":false,"tool_call":false,"release_date":"2025-06-05","last_updated":"2025-07-08","modalities":{"input":["audio"],"output":["text"]},"open_weights":true,"cost":{"input":0.0052,"output":0.0052},"limit":{"context":0,"output":0},"display_name":"@cf/deepgram/nova-3"},{"id":"llama-3.1-70b-instruct","name":"@cf/meta/llama-3.1-70b-instruct","attachment":false,"reasoning":false,"temperature":true,"tool_call":true,"release_date":"2024-07-16","last_updated":"2024-12-15","modalities":{"input":["text"],"output":["text"]},"open_weights":true,"limit":{"context":24000,"output":24000},"display_name":"@cf/meta/llama-3.1-70b-instruct"},{"id":"qwq-32b","name":"@cf/qwen/qwq-32b","attachment":false,"reasoning":false,"temperature":true,"tool_call":true,"release_date":"2025-03-05","last_updated":"2025-03-11","modalities":{"input":["text"],"output":["text"]},"open_weights":true,"cost":{"input":0.66,"output":1},"limit":{"context":24000,"output":24000},"display_name":"@cf/qwen/qwq-32b"},{"id":"zephyr-7b-beta-awq","name":"@hf/thebloke/zephyr-7b-beta-awq","attachment":false,"reasoning":false,"temperature":true,"tool_call":true,"release_date":"2023-10-27","last_updated":"2023-11-09","modalities":{"input":["text"],"output":["text"]},"open_weights":true,"cost":{"input":0,"output":0},"limit":{"context":4096,"output":4096},"display_name":"@hf/thebloke/zephyr-7b-beta-awq"},{"id":"deepseek-coder-6.7b-instruct-awq","name":"@hf/thebloke/deepseek-coder-6.7b-instruct-awq","attachment":false,"reasoning":false,"temperature":true,"tool_call":true,"release_date":"2023-11-05","last_updated":"2023-11-13","modalities":{"input":["text"],"output":["text"]},"open_weights":true,"cost":{"input":0,"output":0},"limit":{"context":4096,"output":4096},"display_name":"@hf/thebloke/deepseek-coder-6.7b-instruct-awq"},{"id":"llama-3.1-8b-instruct-awq","name":"@cf/meta/llama-3.1-8b-instruct-awq","attachment":false,"reasoning":false,"temperature":true,"tool_call":true,"release_date":"2024-07-25","last_updated":"2024-07-25","modalities":{"input":["text"],"output":["text"]},"open_weights":true,"cost":{"input":0.12,"output":0.27},"limit":{"context":8192,"output":8192},"display_name":"@cf/meta/llama-3.1-8b-instruct-awq"},{"id":"mistral-7b-instruct-v0.2-lora","name":"@cf/mistral/mistral-7b-instruct-v0.2-lora","attachment":false,"reasoning":false,"temperature":true,"tool_call":true,"release_date":"2024-04-01","last_updated":"2024-04-01","modalities":{"input":["text"],"output":["text"]},"open_weights":true,"cost":{"input":0,"output":0},"limit":{"context":15000,"output":15000},"display_name":"@cf/mistral/mistral-7b-instruct-v0.2-lora"},{"id":"uform-gen2-qwen-500m","name":"@cf/unum/uform-gen2-qwen-500m","attachment":false,"reasoning":false,"temperature":false,"tool_call":false,"release_date":"2024-02-15","last_updated":"2024-04-24","modalities":{"input":["image","text"],"output":["text"]},"open_weights":true,"cost":{"input":0,"output":0},"limit":{"context":0,"output":0},"display_name":"@cf/unum/uform-gen2-qwen-500m"}]},"inception":{"id":"inception","api":"https://api.inceptionlabs.ai/v1/","name":"Inception","doc":"https://platform.inceptionlabs.ai/docs","display_name":"Inception","models":[{"id":"mercury-coder","name":"Mercury Coder","attachment":false,"reasoning":false,"temperature":true,"tool_call":true,"knowledge":"2023-10","release_date":"2025-02-26","last_updated":"2025-07-31","modalities":{"input":["text"],"output":["text"]},"open_weights":false,"cost":{"input":0.25,"output":1,"cache_read":0.25,"cache_write":1},"limit":{"context":128000,"output":16384},"display_name":"Mercury Coder"},{"id":"mercury","name":"Mercury","attachment":false,"reasoning":false,"temperature":true,"tool_call":true,"knowledge":"2023-10","release_date":"2025-06-26","last_updated":"2025-07-31","modalities":{"input":["text"],"output":["text"]},"open_weights":false,"cost":{"input":0.25,"output":1,"cache_read":0.25,"cache_write":1},"limit":{"context":128000,"output":16384},"display_name":"Mercury"}]},"wandb":{"id":"wandb","api":"https://api.inference.wandb.ai/v1","name":"Weights & Biases","doc":"https://weave-docs.wandb.ai/guides/integrations/inference/","display_name":"Weights & Biases","models":[{"id":"moonshotai/Kimi-K2-Instruct","name":"Kimi-K2-Instruct","attachment":false,"reasoning":false,"temperature":true,"tool_call":true,"knowledge":"2024-10","release_date":"2025-07-14","last_updated":"2025-07-14","modalities":{"input":["text"],"output":["text"]},"open_weights":true,"cost":{"input":1.35,"output":4},"limit":{"context":128000,"output":16384},"display_name":"Kimi-K2-Instruct"},{"id":"microsoft/Phi-4-mini-instruct","name":"Phi-4-mini-instruct","attachment":false,"reasoning":true,"temperature":true,"tool_call":true,"knowledge":"2023-10","release_date":"2024-12-11","last_updated":"2024-12-11","modalities":{"input":["text"],"output":["text"]},"open_weights":true,"cost":{"input":0.08,"output":0.35},"limit":{"context":128000,"output":4096},"display_name":"Phi-4-mini-instruct"},{"id":"meta-llama/Llama-3.1-8B-Instruct","name":"Meta-Llama-3.1-8B-Instruct","attachment":false,"reasoning":true,"temperature":true,"tool_call":true,"knowledge":"2023-12","release_date":"2024-07-23","last_updated":"2024-07-23","modalities":{"input":["text"],"output":["text"]},"open_weights":true,"cost":{"input":0.22,"output":0.22},"limit":{"context":128000,"output":32768},"display_name":"Meta-Llama-3.1-8B-Instruct"},{"id":"meta-llama/Llama-3.3-70B-Instruct","name":"Llama-3.3-70B-Instruct","attachment":false,"reasoning":true,"temperature":true,"tool_call":true,"knowledge":"2023-12","release_date":"2024-12-06","last_updated":"2024-12-06","modalities":{"input":["text"],"output":["text"]},"open_weights":true,"cost":{"input":0.71,"output":0.71},"limit":{"context":128000,"output":32768},"display_name":"Llama-3.3-70B-Instruct"},{"id":"meta-llama/Llama-4-Scout-17B-16E-Instruct","name":"Llama 4 Scout 17B 16E Instruct","attachment":false,"reasoning":true,"temperature":true,"tool_call":true,"knowledge":"2024-12","release_date":"2025-01-31","last_updated":"2025-01-31","modalities":{"input":["text","image"],"output":["text"]},"open_weights":true,"cost":{"input":0.17,"output":0.66},"limit":{"context":64000,"output":8192},"display_name":"Llama 4 Scout 17B 16E Instruct"},{"id":"Qwen/Qwen3-235B-A22B-Instruct-2507","name":"Qwen3 235B A22B Instruct 2507","attachment":false,"reasoning":false,"temperature":true,"tool_call":true,"knowledge":"2025-04","release_date":"2025-04-28","last_updated":"2025-07-21","modalities":{"input":["text"],"output":["text"]},"open_weights":true,"cost":{"input":0.1,"output":0.1},"limit":{"context":262144,"output":131072},"display_name":"Qwen3 235B A22B Instruct 2507"},{"id":"Qwen/Qwen3-Coder-480B-A35B-Instruct","name":"Qwen3-Coder-480B-A35B-Instruct","attachment":false,"reasoning":false,"temperature":true,"tool_call":true,"knowledge":"2025-04","release_date":"2025-07-23","last_updated":"2025-07-23","modalities":{"input":["text"],"output":["text"]},"open_weights":true,"cost":{"input":1,"output":1.5},"limit":{"context":262144,"output":66536},"display_name":"Qwen3-Coder-480B-A35B-Instruct"},{"id":"Qwen/Qwen3-235B-A22B-Thinking-2507","name":"Qwen3-235B-A22B-Thinking-2507","attachment":false,"reasoning":true,"temperature":true,"tool_call":true,"knowledge":"2025-04","release_date":"2025-07-25","last_updated":"2025-07-25","modalities":{"input":["text"],"output":["text"]},"open_weights":true,"cost":{"input":0.1,"output":0.1},"limit":{"context":262144,"output":131072},"display_name":"Qwen3-235B-A22B-Thinking-2507"},{"id":"deepseek-ai/DeepSeek-R1-0528","name":"DeepSeek-R1-0528","attachment":false,"reasoning":true,"temperature":true,"tool_call":true,"knowledge":"2025-05","release_date":"2025-05-28","last_updated":"2025-05-28","modalities":{"input":["text"],"output":["text"]},"open_weights":true,"cost":{"input":1.35,"output":5.4},"limit":{"context":161000,"output":163840},"display_name":"DeepSeek-R1-0528"},{"id":"deepseek-ai/DeepSeek-V3-0324","name":"DeepSeek-V3-0324","attachment":false,"reasoning":false,"temperature":true,"tool_call":true,"knowledge":"2024-10","release_date":"2025-03-24","last_updated":"2025-03-24","modalities":{"input":["text"],"output":["text"]},"open_weights":true,"cost":{"input":1.14,"output":2.75},"limit":{"context":161000,"output":8192},"display_name":"DeepSeek-V3-0324"}]},"openai":{"id":"openai","name":"openai","doc":"https://platform.openai.com/docs/models","display_name":"openai","models":[{"id":"gpt-4.1-nano","name":"GPT-4.1 nano","attachment":true,"reasoning":false,"temperature":true,"tool_call":true,"knowledge":"2024-04","release_date":"2025-04-14","last_updated":"2025-04-14","modalities":{"input":["text","image"],"output":["text"]},"open_weights":false,"cost":{"input":0.1,"output":0.4,"cache_read":0.03},"limit":{"context":1047576,"output":32768},"display_name":"GPT-4.1 nano"},{"id":"gpt-4","name":"GPT-4","attachment":true,"reasoning":false,"temperature":true,"tool_call":true,"knowledge":"2023-11","release_date":"2023-11-06","last_updated":"2024-04-09","modalities":{"input":["text"],"output":["text"]},"open_weights":false,"cost":{"input":30,"output":60},"limit":{"context":8192,"output":8192},"display_name":"GPT-4"},{"id":"o1-pro","name":"o1-pro","attachment":true,"reasoning":true,"temperature":false,"tool_call":true,"knowledge":"2023-09","release_date":"2025-03-19","last_updated":"2025-03-19","modalities":{"input":["text","image"],"output":["text"]},"open_weights":false,"cost":{"input":150,"output":600},"limit":{"context":200000,"output":100000},"display_name":"o1-pro"},{"id":"gpt-4o-2024-05-13","name":"GPT-4o (2024-05-13)","attachment":true,"reasoning":false,"temperature":true,"tool_call":true,"knowledge":"2023-09","release_date":"2024-05-13","last_updated":"2024-05-13","modalities":{"input":["text","image"],"output":["text"]},"open_weights":false,"cost":{"input":5,"output":15},"limit":{"context":128000,"output":4096},"display_name":"GPT-4o (2024-05-13)"},{"id":"gpt-4o-2024-08-06","name":"GPT-4o (2024-08-06)","attachment":true,"reasoning":false,"temperature":true,"tool_call":true,"knowledge":"2023-09","release_date":"2024-08-06","last_updated":"2024-08-06","modalities":{"input":["text","image"],"output":["text"]},"open_weights":false,"cost":{"input":2.5,"output":10,"cache_read":1.25},"limit":{"context":128000,"output":16384},"display_name":"GPT-4o (2024-08-06)"},{"id":"gpt-4.1-mini","name":"GPT-4.1 mini","attachment":true,"reasoning":false,"temperature":true,"tool_call":true,"knowledge":"2024-04","release_date":"2025-04-14","last_updated":"2025-04-14","modalities":{"input":["text","image"],"output":["text"]},"open_weights":false,"cost":{"input":0.4,"output":1.6,"cache_read":0.1},"limit":{"context":1047576,"output":32768},"display_name":"GPT-4.1 mini"},{"id":"o3-deep-research","name":"o3-deep-research","attachment":true,"reasoning":true,"temperature":false,"tool_call":true,"knowledge":"2024-05","release_date":"2024-06-26","last_updated":"2024-06-26","modalities":{"input":["text","image"],"output":["text"]},"open_weights":false,"cost":{"input":10,"output":40,"cache_read":2.5},"limit":{"context":200000,"output":100000},"display_name":"o3-deep-research"},{"id":"gpt-3.5-turbo","name":"GPT-3.5-turbo","attachment":false,"reasoning":false,"temperature":true,"tool_call":false,"knowledge":"2021-09-01","release_date":"2023-03-01","last_updated":"2023-11-06","modalities":{"input":["text"],"output":["text"]},"open_weights":false,"cost":{"input":0.5,"output":1.5,"cache_read":1.25},"limit":{"context":16385,"output":4096},"display_name":"GPT-3.5-turbo"},{"id":"gpt-4-turbo","name":"GPT-4 Turbo","attachment":true,"reasoning":false,"temperature":true,"tool_call":true,"knowledge":"2023-12","release_date":"2023-11-06","last_updated":"2024-04-09","modalities":{"input":["text","image"],"output":["text"]},"open_weights":false,"cost":{"input":10,"output":30},"limit":{"context":128000,"output":4096},"display_name":"GPT-4 Turbo"},{"id":"o1-preview","name":"o1-preview","attachment":false,"reasoning":true,"temperature":true,"tool_call":false,"knowledge":"2023-09","release_date":"2024-09-12","last_updated":"2024-09-12","modalities":{"input":["text"],"output":["text"]},"open_weights":false,"cost":{"input":15,"output":60,"cache_read":7.5},"limit":{"context":128000,"output":32768},"display_name":"o1-preview"},{"id":"o3-mini","name":"o3-mini","attachment":false,"reasoning":true,"temperature":false,"tool_call":true,"knowledge":"2024-05","release_date":"2024-12-20","last_updated":"2025-01-29","modalities":{"input":["text"],"output":["text"]},"open_weights":false,"cost":{"input":1.1,"output":4.4,"cache_read":0.55},"limit":{"context":200000,"output":100000},"display_name":"o3-mini"},{"id":"codex-mini-latest","name":"Codex Mini","attachment":true,"reasoning":true,"temperature":false,"tool_call":true,"knowledge":"2024-04","release_date":"2025-05-16","last_updated":"2025-05-16","modalities":{"input":["text"],"output":["text"]},"open_weights":false,"cost":{"input":1.5,"output":6,"cache_read":0.375},"limit":{"context":200000,"output":100000},"display_name":"Codex Mini"},{"id":"gpt-5-nano","name":"gpt-5-nano","attachment":true,"reasoning":true,"temperature":false,"tool_call":true,"knowledge":"2024-05-30","release_date":"2025-08-07","last_updated":"2025-08-07","modalities":{"input":["text","image"],"output":["text"]},"open_weights":false,"cost":{"input":0.05,"output":0.4,"cache_read":0.01},"limit":{"context":400000,"output":128000},"display_name":"gpt-5-nano","type":"chat","context_length":272000,"reasoning_effort":"medium"},{"id":"gpt-5-codex","name":"GPT-5-Codex","attachment":false,"reasoning":true,"temperature":false,"tool_call":true,"knowledge":"2024-09-30","release_date":"2025-09-15","last_updated":"2025-09-15","modalities":{"input":["text","image"],"output":["text"]},"open_weights":false,"limit":{"context":400000,"output":128000},"display_name":"GPT-5-Codex"},{"id":"gpt-4o","name":"GPT-4o","attachment":true,"reasoning":false,"temperature":true,"tool_call":true,"knowledge":"2023-09","release_date":"2024-05-13","last_updated":"2024-08-06","modalities":{"input":["text","image"],"output":["text"]},"open_weights":false,"cost":{"input":2.5,"output":10,"cache_read":1.25},"limit":{"context":128000,"output":16384},"display_name":"GPT-4o"},{"id":"gpt-4.1","name":"GPT-4.1","attachment":true,"reasoning":false,"temperature":true,"tool_call":true,"knowledge":"2024-04","release_date":"2025-04-14","last_updated":"2025-04-14","modalities":{"input":["text","image"],"output":["text"]},"open_weights":false,"cost":{"input":2,"output":8,"cache_read":0.5},"limit":{"context":1047576,"output":32768},"display_name":"GPT-4.1"},{"id":"o4-mini","name":"o4-mini","attachment":true,"reasoning":true,"temperature":false,"tool_call":true,"knowledge":"2024-05","release_date":"2025-04-16","last_updated":"2025-04-16","modalities":{"input":["text","image"],"output":["text"]},"open_weights":false,"cost":{"input":1.1,"output":4.4,"cache_read":0.28},"limit":{"context":200000,"output":100000},"display_name":"o4-mini"},{"id":"o1","name":"o1","attachment":true,"reasoning":true,"temperature":false,"tool_call":true,"knowledge":"2023-09","release_date":"2024-12-05","last_updated":"2024-12-05","modalities":{"input":["text","image"],"output":["text"]},"open_weights":false,"cost":{"input":15,"output":60,"cache_read":7.5},"limit":{"context":200000,"output":100000},"display_name":"o1"},{"id":"gpt-5-mini","name":"gpt-5-mini","attachment":true,"reasoning":true,"temperature":false,"tool_call":true,"knowledge":"2024-05-30","release_date":"2025-08-07","last_updated":"2025-08-07","modalities":{"input":["text","image"],"output":["text"]},"open_weights":false,"cost":{"input":0.25,"output":2,"cache_read":0.03},"limit":{"context":400000,"output":128000},"display_name":"gpt-5-mini","type":"chat","context_length":272000,"reasoning_effort":"medium"},{"id":"o1-mini","name":"o1-mini","attachment":false,"reasoning":true,"temperature":false,"tool_call":false,"knowledge":"2023-09","release_date":"2024-09-12","last_updated":"2024-09-12","modalities":{"input":["text"],"output":["text"]},"open_weights":false,"cost":{"input":1.1,"output":4.4,"cache_read":0.55},"limit":{"context":128000,"output":65536},"display_name":"o1-mini"},{"id":"o3-pro","name":"o3-pro","attachment":true,"reasoning":true,"temperature":false,"tool_call":true,"knowledge":"2024-05","release_date":"2025-06-10","last_updated":"2025-06-10","modalities":{"input":["text","image"],"output":["text"]},"open_weights":false,"cost":{"input":20,"output":80},"limit":{"context":200000,"output":100000},"display_name":"o3-pro"},{"id":"gpt-4o-2024-11-20","name":"GPT-4o (2024-11-20)","attachment":true,"reasoning":false,"temperature":true,"tool_call":true,"knowledge":"2023-09","release_date":"2024-11-20","last_updated":"2024-11-20","modalities":{"input":["text","image"],"output":["text"]},"open_weights":false,"cost":{"input":2.5,"output":10,"cache_read":1.25},"limit":{"context":128000,"output":16384},"display_name":"GPT-4o (2024-11-20)"},{"id":"o3","name":"o3","attachment":true,"reasoning":true,"temperature":false,"tool_call":true,"knowledge":"2024-05","release_date":"2025-04-16","last_updated":"2025-04-16","modalities":{"input":["text","image"],"output":["text"]},"open_weights":false,"cost":{"input":2,"output":8,"cache_read":0.5},"limit":{"context":200000,"output":100000},"display_name":"o3"},{"id":"o4-mini-deep-research","name":"o4-mini-deep-research","attachment":true,"reasoning":true,"temperature":false,"tool_call":true,"knowledge":"2024-05","release_date":"2024-06-26","last_updated":"2024-06-26","modalities":{"input":["text","image"],"output":["text"]},"open_weights":false,"cost":{"input":2,"output":8,"cache_read":0.5},"limit":{"context":200000,"output":100000},"display_name":"o4-mini-deep-research"},{"id":"gpt-5-chat-latest","name":"gpt-5-chat-latest","attachment":true,"reasoning":true,"temperature":true,"tool_call":false,"knowledge":"2024-09-30","release_date":"2025-08-07","last_updated":"2025-08-07","modalities":{"input":["text","image"],"output":["text"]},"open_weights":false,"cost":{"input":1.25,"output":10},"limit":{"context":400000,"output":128000},"display_name":"gpt-5-chat-latest","type":"chat","context_length":272000,"max_output_tokens":16384,"reasoning_effort":"medium"},{"id":"gpt-4o-mini","name":"GPT-4o mini","attachment":true,"reasoning":false,"temperature":true,"tool_call":true,"knowledge":"2023-09","release_date":"2024-07-18","last_updated":"2024-07-18","modalities":{"input":["text","image"],"output":["text"]},"open_weights":false,"cost":{"input":0.15,"output":0.6,"cache_read":0.08},"limit":{"context":128000,"output":16384},"display_name":"GPT-4o mini"},{"id":"gpt-5","name":"gpt-5","attachment":true,"reasoning":true,"temperature":false,"tool_call":true,"knowledge":"2024-09-30","release_date":"2025-08-07","last_updated":"2025-08-07","modalities":{"input":["text","image"],"output":["text"]},"open_weights":false,"cost":{"input":1.25,"output":10,"cache_read":0.13},"limit":{"context":400000,"output":128000},"display_name":"gpt-5","type":"chat","context_length":272000,"reasoning_effort":"medium"},{"id":"gpt-5-chat","type":"chat","context_length":272000,"max_output_tokens":16384,"reasoning_effort":"medium","name":"gpt-5-chat","display_name":"gpt-5-chat"}]},"zhipuai-coding-plan":{"id":"zhipuai-coding-plan","api":"https://open.bigmodel.cn/api/coding/paas/v4","name":"Zhipu AI Coding Plan","doc":"https://docs.bigmodel.cn/cn/coding-plan/overview","display_name":"Zhipu AI Coding Plan","models":[{"id":"glm-4.6","name":"GLM-4.6","attachment":false,"reasoning":true,"temperature":true,"tool_call":true,"knowledge":"2025-04","release_date":"2025-09-30","last_updated":"2025-09-30","modalities":{"input":["text"],"output":["text"]},"open_weights":true,"cost":{"input":0,"output":0,"cache_read":0,"cache_write":0},"limit":{"context":204800,"output":131072},"display_name":"GLM-4.6"},{"id":"glm-4.5v","name":"GLM 4.5V","attachment":true,"reasoning":true,"temperature":true,"tool_call":true,"knowledge":"2025-04","release_date":"2025-08-11","last_updated":"2025-08-11","modalities":{"input":["text","image","video"],"output":["text"]},"open_weights":true,"cost":{"input":0,"output":0},"limit":{"context":64000,"output":16384},"display_name":"GLM 4.5V"},{"id":"glm-4.5-air","name":"GLM-4.5-Air","attachment":false,"reasoning":true,"temperature":true,"tool_call":true,"knowledge":"2025-04","release_date":"2025-07-28","last_updated":"2025-07-28","modalities":{"input":["text"],"output":["text"]},"open_weights":true,"cost":{"input":0,"output":0,"cache_read":0,"cache_write":0},"limit":{"context":131072,"output":98304},"display_name":"GLM-4.5-Air"},{"id":"glm-4.5","name":"GLM-4.5","attachment":false,"reasoning":true,"temperature":true,"tool_call":true,"knowledge":"2025-04","release_date":"2025-07-28","last_updated":"2025-07-28","modalities":{"input":["text"],"output":["text"]},"open_weights":true,"cost":{"input":0,"output":0,"cache_read":0,"cache_write":0},"limit":{"context":131072,"output":98304},"display_name":"GLM-4.5"},{"id":"glm-4.5-flash","name":"GLM-4.5-Flash","attachment":false,"reasoning":true,"temperature":true,"tool_call":true,"knowledge":"2025-04","release_date":"2025-07-28","last_updated":"2025-07-28","modalities":{"input":["text"],"output":["text"]},"open_weights":true,"cost":{"input":0,"output":0,"cache_read":0,"cache_write":0},"limit":{"context":131072,"output":98304},"display_name":"GLM-4.5-Flash"}]},"perplexity":{"id":"perplexity","name":"Perplexity","doc":"https://docs.perplexity.ai","display_name":"Perplexity","models":[{"id":"sonar-reasoning","name":"Sonar Reasoning","attachment":false,"reasoning":true,"temperature":true,"tool_call":false,"knowledge":"2025-09-01","release_date":"2024-01-01","last_updated":"2025-09-01","modalities":{"input":["text"],"output":["text"]},"open_weights":false,"cost":{"input":1,"output":5},"limit":{"context":128000,"output":4096},"display_name":"Sonar Reasoning"},{"id":"sonar","name":"Sonar","attachment":false,"reasoning":false,"temperature":true,"tool_call":false,"knowledge":"2025-09-01","release_date":"2024-01-01","last_updated":"2025-09-01","modalities":{"input":["text"],"output":["text"]},"open_weights":false,"cost":{"input":1,"output":1},"limit":{"context":128000,"output":4096},"display_name":"Sonar"},{"id":"sonar-pro","name":"Sonar Pro","attachment":true,"reasoning":false,"temperature":true,"tool_call":false,"knowledge":"2025-09-01","release_date":"2024-01-01","last_updated":"2025-09-01","modalities":{"input":["text","image"],"output":["text"]},"open_weights":false,"cost":{"input":3,"output":15},"limit":{"context":200000,"output":8192},"display_name":"Sonar Pro"},{"id":"sonar-reasoning-pro","name":"Sonar Reasoning Pro","attachment":true,"reasoning":true,"temperature":true,"tool_call":false,"knowledge":"2025-09-01","release_date":"2024-01-01","last_updated":"2025-09-01","modalities":{"input":["text","image"],"output":["text"]},"open_weights":false,"cost":{"input":2,"output":8},"limit":{"context":128000,"output":4096},"display_name":"Sonar Reasoning Pro"}]},"openrouter":{"id":"openrouter","api":"https://openrouter.ai/api/v1","name":"openrouter","doc":"https://openrouter.ai/models","display_name":"openrouter","models":[{"id":"moonshotai/kimi-k2","name":"Kimi K2","attachment":false,"reasoning":false,"temperature":true,"tool_call":true,"knowledge":"2024-10","release_date":"2025-07-11","last_updated":"2025-07-11","modalities":{"input":["text"],"output":["text"]},"open_weights":true,"cost":{"input":0.55,"output":2.2},"limit":{"context":131072,"output":32768},"display_name":"Kimi K2"},{"id":"moonshotai/kimi-k2-0905","name":"Kimi K2 Instruct 0905","attachment":false,"reasoning":false,"temperature":true,"tool_call":true,"knowledge":"2024-10","release_date":"2025-09-05","last_updated":"2025-09-05","modalities":{"input":["text"],"output":["text"]},"open_weights":true,"cost":{"input":0.6,"output":2.5},"limit":{"context":262144,"output":16384},"display_name":"Kimi K2 Instruct 0905"},{"id":"moonshotai/kimi-dev-72b:free","name":"Kimi Dev 72b (free)","attachment":false,"reasoning":false,"temperature":true,"tool_call":true,"knowledge":"2025-06","release_date":"2025-06-16","last_updated":"2025-06-16","modalities":{"input":["text"],"output":["text"]},"open_weights":true,"cost":{"input":0,"output":0},"limit":{"context":131072,"output":131072},"display_name":"Kimi Dev 72b (free)"},{"id":"moonshotai/kimi-k2:free","name":"Kimi K2 (free)","attachment":false,"reasoning":false,"temperature":true,"tool_call":true,"knowledge":"2025-04","release_date":"2025-07-11","last_updated":"2025-07-11","modalities":{"input":["text"],"output":["text"]},"open_weights":true,"cost":{"input":0,"output":0},"limit":{"context":32800,"output":32800},"display_name":"Kimi K2 (free)"},{"id":"thudm/glm-z1-32b:free","name":"GLM Z1 32B (free)","attachment":false,"reasoning":true,"temperature":true,"tool_call":true,"knowledge":"2025-04","release_date":"2025-04-17","last_updated":"2025-04-17","modalities":{"input":["text"],"output":["text"]},"open_weights":true,"cost":{"input":0,"output":0},"limit":{"context":32768,"output":32768},"display_name":"GLM Z1 32B (free)"},{"id":"nousresearch/hermes-4-70b","name":"Hermes 4 70B","attachment":false,"reasoning":true,"temperature":true,"tool_call":true,"knowledge":"2023-12","release_date":"2025-08-25","last_updated":"2025-08-25","modalities":{"input":["text"],"output":["text"]},"open_weights":true,"cost":{"input":0.13,"output":0.4},"limit":{"context":131072,"output":131072},"display_name":"Hermes 4 70B"},{"id":"nousresearch/hermes-4-405b","name":"Hermes 4 405B","attachment":false,"reasoning":true,"temperature":true,"tool_call":true,"knowledge":"2023-12","release_date":"2025-08-25","last_updated":"2025-08-25","modalities":{"input":["text"],"output":["text"]},"open_weights":true,"cost":{"input":1,"output":3},"limit":{"context":131072,"output":131072},"display_name":"Hermes 4 405B"},{"id":"nousresearch/deephermes-3-llama-3-8b-preview","name":"DeepHermes 3 Llama 3 8B Preview","attachment":false,"reasoning":true,"temperature":true,"tool_call":true,"knowledge":"2024-04","release_date":"2025-02-28","last_updated":"2025-02-28","modalities":{"input":["text"],"output":["text"]},"open_weights":true,"cost":{"input":0,"output":0},"limit":{"context":131072,"output":8192},"display_name":"DeepHermes 3 Llama 3 8B Preview"},{"id":"x-ai/grok-4","name":"Grok 4","attachment":false,"reasoning":true,"temperature":true,"tool_call":true,"knowledge":"2025-07","release_date":"2025-07-09","last_updated":"2025-07-09","modalities":{"input":["text"],"output":["text"]},"open_weights":false,"cost":{"input":3,"output":15,"cache_read":0.75,"cache_write":15},"limit":{"context":256000,"output":64000},"display_name":"Grok 4"},{"id":"x-ai/grok-code-fast-1","name":"Grok Code Fast 1","attachment":false,"reasoning":true,"temperature":true,"tool_call":true,"knowledge":"2025-08","release_date":"2025-08-26","last_updated":"2025-08-26","modalities":{"input":["text"],"output":["text"]},"open_weights":false,"cost":{"input":0.2,"output":1.5,"cache_read":0.02},"limit":{"context":256000,"output":10000},"display_name":"Grok Code Fast 1"},{"id":"x-ai/grok-4-fast:free","name":"Grok 4 Fast (free)","attachment":false,"reasoning":true,"temperature":true,"tool_call":true,"knowledge":"2024-11","release_date":"2025-08-19","last_updated":"2025-08-19","modalities":{"input":["text","image"],"output":["text"]},"open_weights":false,"cost":{"input":0,"output":0,"cache_read":0,"cache_write":0},"limit":{"context":2000000,"output":2000000},"display_name":"Grok 4 Fast (free)"},{"id":"x-ai/grok-3","name":"Grok 3","attachment":false,"reasoning":false,"temperature":true,"tool_call":true,"knowledge":"2024-11","release_date":"2025-02-17","last_updated":"2025-02-17","modalities":{"input":["text"],"output":["text"]},"open_weights":false,"cost":{"input":3,"output":15,"cache_read":0.75,"cache_write":15},"limit":{"context":131072,"output":8192},"display_name":"Grok 3"},{"id":"x-ai/grok-4-fast","name":"Grok 4 Fast","attachment":false,"reasoning":true,"temperature":true,"tool_call":true,"knowledge":"2024-11","release_date":"2025-08-19","last_updated":"2025-08-19","modalities":{"input":["text","image"],"output":["text"]},"open_weights":false,"cost":{"input":0.2,"output":0.5,"cache_read":0.05,"cache_write":0.05},"limit":{"context":2000000,"output":30000},"display_name":"Grok 4 Fast"},{"id":"x-ai/grok-3-beta","name":"Grok 3 Beta","attachment":false,"reasoning":false,"temperature":true,"tool_call":true,"knowledge":"2024-11","release_date":"2025-02-17","last_updated":"2025-02-17","modalities":{"input":["text"],"output":["text"]},"open_weights":false,"cost":{"input":3,"output":15,"cache_read":0.75,"cache_write":15},"limit":{"context":131072,"output":8192},"display_name":"Grok 3 Beta"},{"id":"x-ai/grok-3-mini-beta","name":"Grok 3 Mini Beta","attachment":false,"reasoning":true,"temperature":true,"tool_call":true,"knowledge":"2024-11","release_date":"2025-02-17","last_updated":"2025-02-17","modalities":{"input":["text"],"output":["text"]},"open_weights":false,"cost":{"input":0.3,"output":0.5,"cache_read":0.075,"cache_write":0.5},"limit":{"context":131072,"output":8192},"display_name":"Grok 3 Mini Beta"},{"id":"x-ai/grok-3-mini","name":"Grok 3 Mini","attachment":false,"reasoning":true,"temperature":true,"tool_call":true,"knowledge":"2024-11","release_date":"2025-02-17","last_updated":"2025-02-17","modalities":{"input":["text"],"output":["text"]},"open_weights":false,"cost":{"input":0.3,"output":0.5,"cache_read":0.075,"cache_write":0.5},"limit":{"context":131072,"output":8192},"display_name":"Grok 3 Mini"},{"id":"cognitivecomputations/dolphin3.0-mistral-24b","name":"Dolphin3.0 Mistral 24B","attachment":false,"reasoning":false,"temperature":true,"tool_call":true,"knowledge":"2024-10","release_date":"2025-02-13","last_updated":"2025-02-13","modalities":{"input":["text"],"output":["text"]},"open_weights":true,"cost":{"input":0,"output":0},"limit":{"context":32768,"output":8192},"display_name":"Dolphin3.0 Mistral 24B"},{"id":"cognitivecomputations/dolphin3.0-r1-mistral-24b","name":"Dolphin3.0 R1 Mistral 24B","attachment":false,"reasoning":true,"temperature":true,"tool_call":true,"knowledge":"2024-10","release_date":"2025-02-13","last_updated":"2025-02-13","modalities":{"input":["text"],"output":["text"]},"open_weights":true,"cost":{"input":0,"output":0},"limit":{"context":32768,"output":8192},"display_name":"Dolphin3.0 R1 Mistral 24B"},{"id":"deepseek/deepseek-chat-v3.1","name":"DeepSeek-V3.1","attachment":false,"reasoning":true,"temperature":true,"tool_call":true,"knowledge":"2025-07","release_date":"2025-08-21","last_updated":"2025-08-21","modalities":{"input":["text"],"output":["text"]},"open_weights":true,"cost":{"input":0.2,"output":0.8},"limit":{"context":163840,"output":163840},"display_name":"DeepSeek-V3.1"},{"id":"deepseek/deepseek-r1:free","name":"R1 (free)","attachment":false,"reasoning":true,"temperature":true,"tool_call":true,"knowledge":"2025-01","release_date":"2025-01-20","last_updated":"2025-01-20","modalities":{"input":["text"],"output":["text"]},"open_weights":true,"cost":{"input":0,"output":0},"limit":{"context":163840,"output":163840},"display_name":"R1 (free)"},{"id":"deepseek/deepseek-v3-base:free","name":"DeepSeek V3 Base (free)","attachment":false,"reasoning":false,"temperature":true,"tool_call":false,"knowledge":"2025-03","release_date":"2025-03-29","last_updated":"2025-03-29","modalities":{"input":["text"],"output":["text"]},"open_weights":true,"cost":{"input":0,"output":0},"limit":{"context":163840,"output":163840},"display_name":"DeepSeek V3 Base (free)"},{"id":"deepseek/deepseek-v3.1-terminus","name":"DeepSeek V3.1 Terminus","attachment":false,"reasoning":true,"temperature":true,"tool_call":true,"knowledge":"2025-07","release_date":"2025-09-22","last_updated":"2025-09-22","modalities":{"input":["text"],"output":["text"]},"open_weights":true,"cost":{"input":0.27,"output":1},"limit":{"context":131072,"output":65536},"display_name":"DeepSeek V3.1 Terminus"},{"id":"deepseek/deepseek-r1-0528-qwen3-8b:free","name":"Deepseek R1 0528 Qwen3 8B (free)","attachment":false,"reasoning":true,"temperature":true,"tool_call":true,"knowledge":"2025-05","release_date":"2025-05-29","last_updated":"2025-05-29","modalities":{"input":["text"],"output":["text"]},"open_weights":true,"cost":{"input":0,"output":0},"limit":{"context":131072,"output":131072},"display_name":"Deepseek R1 0528 Qwen3 8B (free)"},{"id":"deepseek/deepseek-chat-v3-0324","name":"DeepSeek V3 0324","attachment":false,"reasoning":false,"temperature":true,"tool_call":false,"knowledge":"2024-10","release_date":"2025-03-24","last_updated":"2025-03-24","modalities":{"input":["text"],"output":["text"]},"open_weights":true,"cost":{"input":0,"output":0},"limit":{"context":16384,"output":8192},"display_name":"DeepSeek V3 0324"},{"id":"deepseek/deepseek-r1-0528:free","name":"R1 0528 (free)","attachment":false,"reasoning":true,"temperature":true,"tool_call":true,"knowledge":"2025-05","release_date":"2025-05-28","last_updated":"2025-05-28","modalities":{"input":["text"],"output":["text"]},"open_weights":true,"cost":{"input":0,"output":0},"limit":{"context":163840,"output":163840},"display_name":"R1 0528 (free)"},{"id":"deepseek/deepseek-r1-distill-llama-70b","name":"DeepSeek R1 Distill Llama 70B","attachment":false,"reasoning":true,"temperature":true,"tool_call":false,"knowledge":"2024-10","release_date":"2025-01-23","last_updated":"2025-01-23","modalities":{"input":["text"],"output":["text"]},"open_weights":true,"cost":{"input":0,"output":0},"limit":{"context":8192,"output":8192},"display_name":"DeepSeek R1 Distill Llama 70B"},{"id":"deepseek/deepseek-r1-distill-qwen-14b","name":"DeepSeek R1 Distill Qwen 14B","attachment":false,"reasoning":true,"temperature":true,"tool_call":false,"knowledge":"2024-10","release_date":"2025-01-29","last_updated":"2025-01-29","modalities":{"input":["text"],"output":["text"]},"open_weights":true,"cost":{"input":0,"output":0},"limit":{"context":64000,"output":8192},"display_name":"DeepSeek R1 Distill Qwen 14B"},{"id":"featherless/qwerky-72b","name":"Qwerky 72B","attachment":false,"reasoning":false,"temperature":true,"tool_call":false,"knowledge":"2024-10","release_date":"2025-03-20","last_updated":"2025-03-20","modalities":{"input":["text"],"output":["text"]},"open_weights":true,"cost":{"input":0,"output":0},"limit":{"context":32768,"output":8192},"display_name":"Qwerky 72B"},{"id":"tngtech/deepseek-r1t2-chimera:free","name":"DeepSeek R1T2 Chimera (free)","attachment":false,"reasoning":true,"temperature":true,"tool_call":false,"knowledge":"2025-07","release_date":"2025-07-08","last_updated":"2025-07-08","modalities":{"input":["text"],"output":["text"]},"open_weights":true,"cost":{"input":0,"output":0},"limit":{"context":163840,"output":163840},"display_name":"DeepSeek R1T2 Chimera (free)"},{"id":"google/gemini-2.0-flash-001","name":"Gemini 2.0 Flash","attachment":true,"reasoning":false,"temperature":true,"tool_call":true,"knowledge":"2024-06","release_date":"2024-12-11","last_updated":"2024-12-11","modalities":{"input":["text","image","audio","video","pdf"],"output":["text"]},"open_weights":false,"cost":{"input":0.1,"output":0.4,"cache_read":0.025},"limit":{"context":1048576,"output":8192},"display_name":"Gemini 2.0 Flash"},{"id":"google/gemma-2-9b-it:free","name":"Gemma 2 9B (free)","attachment":false,"reasoning":false,"temperature":true,"tool_call":true,"knowledge":"2024-06","release_date":"2024-06-28","last_updated":"2024-06-28","modalities":{"input":["text"],"output":["text"]},"open_weights":true,"cost":{"input":0,"output":0},"limit":{"context":8192,"output":8192},"display_name":"Gemma 2 9B (free)"},{"id":"google/gemini-2.5-flash","name":"Gemini 2.5 Flash","attachment":true,"reasoning":true,"temperature":true,"tool_call":true,"knowledge":"2025-01","release_date":"2025-07-17","last_updated":"2025-07-17","modalities":{"input":["text","image","audio","video","pdf"],"output":["text"]},"open_weights":false,"cost":{"input":0.3,"output":2.5,"cache_read":0.0375},"limit":{"context":1048576,"output":65536},"display_name":"Gemini 2.5 Flash"},{"id":"google/gemini-2.5-pro-preview-05-06","name":"Gemini 2.5 Pro Preview 05-06","attachment":true,"reasoning":true,"temperature":true,"tool_call":true,"knowledge":"2025-01","release_date":"2025-05-06","last_updated":"2025-05-06","modalities":{"input":["text","image","audio","video","pdf"],"output":["text"]},"open_weights":false,"cost":{"input":1.25,"output":10,"cache_read":0.31},"limit":{"context":1048576,"output":65536},"display_name":"Gemini 2.5 Pro Preview 05-06"},{"id":"google/gemma-3n-e4b-it","name":"Gemma 3n E4B IT","attachment":true,"reasoning":false,"temperature":true,"tool_call":false,"knowledge":"2024-10","release_date":"2025-05-20","last_updated":"2025-05-20","modalities":{"input":["text","image","audio"],"output":["text"]},"open_weights":true,"cost":{"input":0,"output":0},"limit":{"context":8192,"output":8192},"display_name":"Gemma 3n E4B IT"},{"id":"google/gemini-2.5-pro-preview-06-05","name":"Gemini 2.5 Pro Preview 06-05","attachment":true,"reasoning":true,"temperature":true,"tool_call":true,"knowledge":"2025-01","release_date":"2025-06-05","last_updated":"2025-06-05","modalities":{"input":["text","image","audio","video","pdf"],"output":["text"]},"open_weights":false,"cost":{"input":1.25,"output":10,"cache_read":0.31},"limit":{"context":1048576,"output":65536},"display_name":"Gemini 2.5 Pro Preview 06-05"},{"id":"google/gemini-2.5-pro","name":"Gemini 2.5 Pro","attachment":true,"reasoning":true,"temperature":true,"tool_call":true,"knowledge":"2025-01","release_date":"2025-03-20","last_updated":"2025-06-05","modalities":{"input":["text","image","audio","video","pdf"],"output":["text"]},"open_weights":false,"cost":{"input":1.25,"output":10,"cache_read":0.31},"limit":{"context":1048576,"output":65536},"display_name":"Gemini 2.5 Pro"},{"id":"google/gemma-3-12b-it","name":"Gemma 3 12B IT","attachment":true,"reasoning":false,"temperature":true,"tool_call":true,"knowledge":"2024-10","release_date":"2025-03-13","last_updated":"2025-03-13","modalities":{"input":["text","image"],"output":["text"]},"open_weights":true,"cost":{"input":0,"output":0},"limit":{"context":96000,"output":8192},"display_name":"Gemma 3 12B IT"},{"id":"google/gemma-3n-e4b-it:free","name":"Gemma 3n 4B (free)","attachment":true,"reasoning":false,"temperature":true,"tool_call":true,"knowledge":"2025-05","release_date":"2025-05-20","last_updated":"2025-05-20","modalities":{"input":["text","image","audio"],"output":["text"]},"open_weights":true,"cost":{"input":0,"output":0},"limit":{"context":8192,"output":8192},"display_name":"Gemma 3n 4B (free)"},{"id":"google/gemini-2.0-flash-exp:free","name":"Gemini 2.0 Flash Experimental (free)","attachment":true,"reasoning":false,"temperature":true,"tool_call":true,"knowledge":"2024-12","release_date":"2024-12-11","last_updated":"2024-12-11","modalities":{"input":["text","image"],"output":["text"]},"open_weights":false,"cost":{"input":0,"output":0},"limit":{"context":1048576,"output":1048576},"display_name":"Gemini 2.0 Flash Experimental (free)"},{"id":"google/gemma-3-27b-it","name":"Gemma 3 27B IT","attachment":true,"reasoning":false,"temperature":true,"tool_call":true,"knowledge":"2024-10","release_date":"2025-03-12","last_updated":"2025-03-12","modalities":{"input":["text","image"],"output":["text"]},"open_weights":true,"cost":{"input":0,"output":0},"limit":{"context":96000,"output":8192},"display_name":"Gemma 3 27B IT"},{"id":"microsoft/mai-ds-r1:free","name":"MAI DS R1 (free)","attachment":false,"reasoning":true,"temperature":true,"tool_call":true,"knowledge":"2025-04","release_date":"2025-04-21","last_updated":"2025-04-21","modalities":{"input":["text"],"output":["text"]},"open_weights":true,"cost":{"input":0,"output":0},"limit":{"context":163840,"output":163840},"display_name":"MAI DS R1 (free)"},{"id":"openai/gpt-4.1-mini","name":"GPT-4.1 Mini","attachment":true,"reasoning":false,"temperature":true,"tool_call":true,"knowledge":"2024-04","release_date":"2025-04-14","last_updated":"2025-04-14","modalities":{"input":["text","image"],"output":["text"]},"open_weights":false,"cost":{"input":0.4,"output":1.6,"cache_read":0.1},"limit":{"context":1047576,"output":32768},"display_name":"GPT-4.1 Mini"},{"id":"openai/gpt-5-chat","name":"GPT-5 Chat (latest)","attachment":true,"reasoning":true,"temperature":true,"tool_call":false,"knowledge":"2024-09-30","release_date":"2025-08-07","last_updated":"2025-08-07","modalities":{"input":["text","image"],"output":["text"]},"open_weights":false,"cost":{"input":1.25,"output":10},"limit":{"context":400000,"output":128000},"display_name":"GPT-5 Chat (latest)"},{"id":"openai/gpt-5-nano","name":"GPT-5 Nano","attachment":true,"reasoning":true,"temperature":true,"tool_call":true,"knowledge":"2024-10-01","release_date":"2025-08-07","last_updated":"2025-08-07","modalities":{"input":["text","image"],"output":["text"]},"open_weights":false,"cost":{"input":0.05,"output":0.4},"limit":{"context":400000,"output":128000},"display_name":"GPT-5 Nano"},{"id":"openai/gpt-5-codex","name":"GPT-5 Codex","attachment":true,"reasoning":true,"temperature":true,"tool_call":true,"knowledge":"2024-10-01","release_date":"2025-09-15","last_updated":"2025-09-15","modalities":{"input":["text","image"],"output":["text"]},"open_weights":false,"cost":{"input":1.25,"output":10,"cache_read":0.125},"limit":{"context":400000,"output":128000},"display_name":"GPT-5 Codex"},{"id":"openai/gpt-4.1","name":"GPT-4.1","attachment":true,"reasoning":false,"temperature":true,"tool_call":true,"knowledge":"2024-04","release_date":"2025-04-14","last_updated":"2025-04-14","modalities":{"input":["text","image"],"output":["text"]},"open_weights":false,"cost":{"input":2,"output":8,"cache_read":0.5},"limit":{"context":1047576,"output":32768},"display_name":"GPT-4.1"},{"id":"openai/o4-mini","name":"o4 Mini","attachment":true,"reasoning":true,"temperature":true,"tool_call":true,"knowledge":"2024-06","release_date":"2025-04-16","last_updated":"2025-04-16","modalities":{"input":["text","image"],"output":["text"]},"open_weights":false,"cost":{"input":1.1,"output":4.4,"cache_read":0.28},"limit":{"context":200000,"output":100000},"display_name":"o4 Mini"},{"id":"openai/gpt-5-mini","name":"GPT-5 Mini","attachment":true,"reasoning":true,"temperature":true,"tool_call":true,"knowledge":"2024-10-01","release_date":"2025-08-07","last_updated":"2025-08-07","modalities":{"input":["text","image"],"output":["text"]},"open_weights":false,"cost":{"input":0.25,"output":2},"limit":{"context":400000,"output":128000},"display_name":"GPT-5 Mini"},{"id":"openai/gpt-oss-20b","name":"GPT OSS 20B","attachment":false,"reasoning":true,"temperature":true,"tool_call":true,"release_date":"2025-08-05","last_updated":"2025-08-05","modalities":{"input":["text"],"output":["text"]},"open_weights":true,"cost":{"input":0.05,"output":0.2},"limit":{"context":131072,"output":32768},"display_name":"GPT OSS 20B"},{"id":"openai/gpt-oss-120b","name":"GPT OSS 120B","attachment":false,"reasoning":true,"temperature":true,"tool_call":true,"release_date":"2025-08-05","last_updated":"2025-08-05","modalities":{"input":["text"],"output":["text"]},"open_weights":true,"cost":{"input":0.072,"output":0.28},"limit":{"context":131072,"output":32768},"display_name":"GPT OSS 120B"},{"id":"openai/gpt-4o-mini","name":"GPT-4o-mini","attachment":true,"reasoning":false,"temperature":true,"tool_call":true,"knowledge":"2024-10","release_date":"2024-07-18","last_updated":"2024-07-18","modalities":{"input":["text","image"],"output":["text"]},"open_weights":false,"cost":{"input":0.15,"output":0.6,"cache_read":0.08},"limit":{"context":128000,"output":16384},"display_name":"GPT-4o-mini"},{"id":"openai/gpt-5","name":"GPT-5","attachment":true,"reasoning":true,"temperature":true,"tool_call":true,"knowledge":"2024-10-01","release_date":"2025-08-07","last_updated":"2025-08-07","modalities":{"input":["text","image"],"output":["text"]},"open_weights":false,"cost":{"input":1.25,"output":10},"limit":{"context":400000,"output":128000},"display_name":"GPT-5"},{"id":"openrouter/horizon-alpha","name":"Horizon Alpha","attachment":true,"reasoning":false,"temperature":false,"tool_call":true,"knowledge":"2025-07","release_date":"2025-07-30","last_updated":"2025-07-30","modalities":{"input":["text","image"],"output":["text"]},"open_weights":false,"cost":{"input":0,"output":0},"limit":{"context":256000,"output":128000},"display_name":"Horizon Alpha"},{"id":"openrouter/sonoma-sky-alpha","name":"Sonoma Sky Alpha","attachment":true,"reasoning":false,"temperature":false,"tool_call":true,"release_date":"2024-09-05","last_updated":"2024-09-05","modalities":{"input":["text","image"],"output":["text"]},"open_weights":false,"cost":{"input":0,"output":0},"limit":{"context":2000000,"output":2000000},"display_name":"Sonoma Sky Alpha"},{"id":"openrouter/cypher-alpha:free","name":"Cypher Alpha (free)","attachment":false,"reasoning":false,"temperature":true,"tool_call":true,"knowledge":"2025-07","release_date":"2025-07-01","last_updated":"2025-07-01","modalities":{"input":["text"],"output":["text"]},"open_weights":false,"cost":{"input":0,"output":0},"limit":{"context":1000000,"output":1000000},"display_name":"Cypher Alpha (free)"},{"id":"openrouter/sonoma-dusk-alpha","name":"Sonoma Dusk Alpha","attachment":true,"reasoning":false,"temperature":false,"tool_call":true,"release_date":"2024-09-05","last_updated":"2024-09-05","modalities":{"input":["text","image"],"output":["text"]},"open_weights":false,"cost":{"input":0,"output":0},"limit":{"context":2000000,"output":2000000},"display_name":"Sonoma Dusk Alpha"},{"id":"openrouter/horizon-beta","name":"Horizon Beta","attachment":true,"reasoning":false,"temperature":false,"tool_call":true,"knowledge":"2025-07","release_date":"2025-08-01","last_updated":"2025-08-01","modalities":{"input":["text","image"],"output":["text"]},"open_weights":false,"cost":{"input":0,"output":0},"limit":{"context":256000,"output":128000},"display_name":"Horizon Beta"},{"id":"z-ai/glm-4.5","name":"GLM 4.5","attachment":false,"reasoning":true,"temperature":true,"tool_call":true,"knowledge":"2025-04","release_date":"2025-07-28","last_updated":"2025-07-28","modalities":{"input":["text"],"output":["text"]},"open_weights":true,"cost":{"input":0.6,"output":2.2},"limit":{"context":128000,"output":96000},"display_name":"GLM 4.5"},{"id":"z-ai/glm-4.5-air","name":"GLM 4.5 Air","attachment":false,"reasoning":true,"temperature":true,"tool_call":true,"knowledge":"2025-04","release_date":"2025-07-28","last_updated":"2025-07-28","modalities":{"input":["text"],"output":["text"]},"open_weights":true,"cost":{"input":0.2,"output":1.1},"limit":{"context":128000,"output":96000},"display_name":"GLM 4.5 Air"},{"id":"z-ai/glm-4.5v","name":"GLM 4.5V","attachment":true,"reasoning":true,"temperature":true,"tool_call":true,"knowledge":"2025-04","release_date":"2025-08-11","last_updated":"2025-08-11","modalities":{"input":["text","image","video"],"output":["text"]},"open_weights":true,"cost":{"input":0.6,"output":1.8},"limit":{"context":64000,"output":16384},"display_name":"GLM 4.5V"},{"id":"z-ai/glm-4.6","name":"GLM 4.6","attachment":false,"reasoning":true,"temperature":true,"tool_call":true,"knowledge":"2025-09","release_date":"2025-09-30","last_updated":"2025-09-30","modalities":{"input":["text"],"output":["text"]},"open_weights":true,"cost":{"input":0.6,"output":2.2,"cache_read":0.11},"limit":{"context":200000,"output":128000},"display_name":"GLM 4.6"},{"id":"z-ai/glm-4.5-air:free","name":"GLM 4.5 Air (free)","attachment":false,"reasoning":true,"temperature":true,"tool_call":false,"knowledge":"2025-04","release_date":"2025-07-28","last_updated":"2025-07-28","modalities":{"input":["text"],"output":["text"]},"open_weights":true,"cost":{"input":0,"output":0},"limit":{"context":128000,"output":96000},"display_name":"GLM 4.5 Air (free)"},{"id":"qwen/qwen3-coder","name":"Qwen3 Coder","attachment":false,"reasoning":false,"temperature":true,"tool_call":true,"knowledge":"2025-04","release_date":"2025-07-23","last_updated":"2025-07-23","modalities":{"input":["text"],"output":["text"]},"open_weights":true,"cost":{"input":0.3,"output":1.2},"limit":{"context":262144,"output":66536},"display_name":"Qwen3 Coder"},{"id":"qwen/qwen3-32b:free","name":"Qwen3 32B (free)","attachment":false,"reasoning":true,"temperature":true,"tool_call":true,"knowledge":"2025-04","release_date":"2025-04-28","last_updated":"2025-04-28","modalities":{"input":["text"],"output":["text"]},"open_weights":true,"cost":{"input":0,"output":0},"limit":{"context":40960,"output":40960},"display_name":"Qwen3 32B (free)"},{"id":"qwen/qwen3-next-80b-a3b-instruct","name":"Qwen3 Next 80B A3B Instruct","attachment":false,"reasoning":false,"temperature":true,"tool_call":true,"knowledge":"2025-04","release_date":"2025-09-11","last_updated":"2025-09-11","modalities":{"input":["text"],"output":["text"]},"open_weights":true,"cost":{"input":0.14,"output":1.4},"limit":{"context":262144,"output":262144},"display_name":"Qwen3 Next 80B A3B Instruct"},{"id":"qwen/qwen-2.5-coder-32b-instruct","name":"Qwen2.5 Coder 32B Instruct","attachment":false,"reasoning":false,"temperature":true,"tool_call":false,"knowledge":"2024-10","release_date":"2024-11-11","last_updated":"2024-11-11","modalities":{"input":["text"],"output":["text"]},"open_weights":true,"cost":{"input":0,"output":0},"limit":{"context":32768,"output":8192},"display_name":"Qwen2.5 Coder 32B Instruct"},{"id":"qwen/qwen3-235b-a22b:free","name":"Qwen3 235B A22B (free)","attachment":false,"reasoning":true,"temperature":true,"tool_call":true,"knowledge":"2025-04","release_date":"2025-04-28","last_updated":"2025-04-28","modalities":{"input":["text"],"output":["text"]},"open_weights":true,"cost":{"input":0,"output":0},"limit":{"context":131072,"output":131072},"display_name":"Qwen3 235B A22B (free)"},{"id":"qwen/qwq-32b:free","name":"QwQ 32B (free)","attachment":false,"reasoning":true,"temperature":true,"tool_call":true,"knowledge":"2025-03","release_date":"2025-03-05","last_updated":"2025-03-05","modalities":{"input":["text"],"output":["text"]},"open_weights":true,"cost":{"input":0,"output":0},"limit":{"context":32768,"output":32768},"display_name":"QwQ 32B (free)"},{"id":"qwen/qwen3-30b-a3b:free","name":"Qwen3 30B A3B (free)","attachment":false,"reasoning":true,"temperature":true,"tool_call":true,"knowledge":"2025-04","release_date":"2025-04-28","last_updated":"2025-04-28","modalities":{"input":["text"],"output":["text"]},"open_weights":true,"cost":{"input":0,"output":0},"limit":{"context":40960,"output":40960},"display_name":"Qwen3 30B A3B (free)"},{"id":"qwen/qwen2.5-vl-72b-instruct","name":"Qwen2.5 VL 72B Instruct","attachment":true,"reasoning":false,"temperature":true,"tool_call":false,"knowledge":"2024-10","release_date":"2025-02-01","last_updated":"2025-02-01","modalities":{"input":["text","image"],"output":["text"]},"open_weights":true,"cost":{"input":0,"output":0},"limit":{"context":32768,"output":8192},"display_name":"Qwen2.5 VL 72B Instruct"},{"id":"qwen/qwen3-14b:free","name":"Qwen3 14B (free)","attachment":false,"reasoning":true,"temperature":true,"tool_call":true,"knowledge":"2025-04","release_date":"2025-04-28","last_updated":"2025-04-28","modalities":{"input":["text"],"output":["text"]},"open_weights":true,"cost":{"input":0,"output":0},"limit":{"context":40960,"output":40960},"display_name":"Qwen3 14B (free)"},{"id":"qwen/qwen3-30b-a3b-instruct-2507","name":"Qwen3 30B A3B Instruct 2507","attachment":false,"reasoning":false,"temperature":true,"tool_call":false,"knowledge":"2025-04","release_date":"2025-07-29","last_updated":"2025-07-29","modalities":{"input":["text"],"output":["text"]},"open_weights":true,"cost":{"input":0.2,"output":0.8},"limit":{"context":131072,"output":33000},"display_name":"Qwen3 30B A3B Instruct 2507"},{"id":"qwen/qwen3-235b-a22b-thinking-2507","name":"Qwen3 235B A22B Thinking 2507","attachment":false,"reasoning":true,"temperature":true,"tool_call":true,"knowledge":"2025-04","release_date":"2025-07-25","last_updated":"2025-07-25","modalities":{"input":["text"],"output":["text"]},"open_weights":true,"cost":{"input":0.078,"output":0.312},"limit":{"context":262144,"output":81920},"display_name":"Qwen3 235B A22B Thinking 2507"},{"id":"qwen/qwen2.5-vl-32b-instruct:free","name":"Qwen2.5 VL 32B Instruct (free)","attachment":true,"reasoning":false,"temperature":true,"tool_call":true,"knowledge":"2025-03","release_date":"2025-03-24","last_updated":"2025-03-24","modalities":{"input":["text","image","video"],"output":["text"]},"open_weights":true,"cost":{"input":0,"output":0},"limit":{"context":8192,"output":8192},"display_name":"Qwen2.5 VL 32B Instruct (free)"},{"id":"qwen/qwen2.5-vl-72b-instruct:free","name":"Qwen2.5 VL 72B Instruct (free)","attachment":true,"reasoning":false,"temperature":true,"tool_call":true,"knowledge":"2025-02","release_date":"2025-02-01","last_updated":"2025-02-01","modalities":{"input":["text","image"],"output":["text"]},"open_weights":true,"cost":{"input":0,"output":0},"limit":{"context":32768,"output":32768},"display_name":"Qwen2.5 VL 72B Instruct (free)"},{"id":"qwen/qwen3-235b-a22b-07-25:free","name":"Qwen3 235B A22B Instruct 2507 (free)","attachment":false,"reasoning":false,"temperature":true,"tool_call":true,"knowledge":"2025-04","release_date":"2025-04-28","last_updated":"2025-07-21","modalities":{"input":["text"],"output":["text"]},"open_weights":true,"cost":{"input":0,"output":0},"limit":{"context":262144,"output":131072},"display_name":"Qwen3 235B A22B Instruct 2507 (free)"},{"id":"qwen/qwen3-coder:free","name":"Qwen3 Coder 480B A35B Instruct (free)","attachment":false,"reasoning":false,"temperature":true,"tool_call":true,"knowledge":"2025-04","release_date":"2025-07-23","last_updated":"2025-07-23","modalities":{"input":["text"],"output":["text"]},"open_weights":true,"cost":{"input":0,"output":0},"limit":{"context":262144,"output":66536},"display_name":"Qwen3 Coder 480B A35B Instruct (free)"},{"id":"qwen/qwen3-235b-a22b-07-25","name":"Qwen3 235B A22B Instruct 2507","attachment":false,"reasoning":false,"temperature":true,"tool_call":true,"knowledge":"2025-04","release_date":"2025-04-28","last_updated":"2025-07-21","modalities":{"input":["text"],"output":["text"]},"open_weights":true,"cost":{"input":0.15,"output":0.85},"limit":{"context":262144,"output":131072},"display_name":"Qwen3 235B A22B Instruct 2507"},{"id":"qwen/qwen3-8b:free","name":"Qwen3 8B (free)","attachment":false,"reasoning":true,"temperature":true,"tool_call":true,"knowledge":"2025-04","release_date":"2025-04-28","last_updated":"2025-04-28","modalities":{"input":["text"],"output":["text"]},"open_weights":true,"cost":{"input":0,"output":0},"limit":{"context":40960,"output":40960},"display_name":"Qwen3 8B (free)"},{"id":"qwen/qwen3-max","name":"Qwen3 Max","attachment":false,"reasoning":true,"temperature":true,"tool_call":true,"release_date":"2025-09-05","last_updated":"2025-09-05","modalities":{"input":["text"],"output":["text"]},"open_weights":false,"cost":{"input":1.2,"output":6},"limit":{"context":262144,"output":32768},"display_name":"Qwen3 Max"},{"id":"mistralai/devstral-medium-2507","name":"Devstral Medium","attachment":false,"reasoning":false,"temperature":true,"tool_call":true,"knowledge":"2025-05","release_date":"2025-07-10","last_updated":"2025-07-10","modalities":{"input":["text"],"output":["text"]},"open_weights":true,"cost":{"input":0.4,"output":2},"limit":{"context":131072,"output":131072},"display_name":"Devstral Medium"},{"id":"mistralai/codestral-2508","name":"Codestral 2508","attachment":false,"reasoning":false,"temperature":true,"tool_call":true,"knowledge":"2025-05","release_date":"2025-08-01","last_updated":"2025-08-01","modalities":{"input":["text"],"output":["text"]},"open_weights":true,"cost":{"input":0.3,"output":0.9},"limit":{"context":256000,"output":256000},"display_name":"Codestral 2508"},{"id":"mistralai/mistral-7b-instruct:free","name":"Mistral 7B Instruct (free)","attachment":false,"reasoning":false,"temperature":true,"tool_call":true,"knowledge":"2024-05","release_date":"2024-05-27","last_updated":"2024-05-27","modalities":{"input":["text"],"output":["text"]},"open_weights":true,"cost":{"input":0,"output":0},"limit":{"context":32768,"output":32768},"display_name":"Mistral 7B Instruct (free)"},{"id":"mistralai/devstral-small-2505","name":"Devstral Small","attachment":false,"reasoning":false,"temperature":true,"tool_call":true,"knowledge":"2025-05","release_date":"2025-05-07","last_updated":"2025-05-07","modalities":{"input":["text"],"output":["text"]},"open_weights":true,"cost":{"input":0.06,"output":0.12},"limit":{"context":128000,"output":128000},"display_name":"Devstral Small"},{"id":"mistralai/mistral-small-3.2-24b-instruct","name":"Mistral Small 3.2 24B Instruct","attachment":true,"reasoning":false,"temperature":true,"tool_call":true,"knowledge":"2024-10","release_date":"2025-06-20","last_updated":"2025-06-20","modalities":{"input":["text","image"],"output":["text"]},"open_weights":true,"cost":{"input":0,"output":0},"limit":{"context":96000,"output":8192},"display_name":"Mistral Small 3.2 24B Instruct"},{"id":"mistralai/devstral-small-2505:free","name":"Devstral Small 2505 (free)","attachment":false,"reasoning":false,"temperature":true,"tool_call":true,"knowledge":"2025-05","release_date":"2025-05-21","last_updated":"2025-05-21","modalities":{"input":["text"],"output":["text"]},"open_weights":true,"cost":{"input":0,"output":0},"limit":{"context":32768,"output":32768},"display_name":"Devstral Small 2505 (free)"},{"id":"mistralai/mistral-small-3.2-24b-instruct:free","name":"Mistral Small 3.2 24B (free)","attachment":true,"reasoning":false,"temperature":true,"tool_call":true,"knowledge":"2025-06","release_date":"2025-06-20","last_updated":"2025-06-20","modalities":{"input":["text","image"],"output":["text"]},"open_weights":true,"cost":{"input":0,"output":0},"limit":{"context":96000,"output":96000},"display_name":"Mistral Small 3.2 24B (free)"},{"id":"mistralai/mistral-medium-3","name":"Mistral Medium 3","attachment":true,"reasoning":false,"temperature":true,"tool_call":true,"knowledge":"2025-05","release_date":"2025-05-07","last_updated":"2025-05-07","modalities":{"input":["text","image"],"output":["text"]},"open_weights":false,"cost":{"input":0.4,"output":2},"limit":{"context":131072,"output":131072},"display_name":"Mistral Medium 3"},{"id":"mistralai/mistral-small-3.1-24b-instruct","name":"Mistral Small 3.1 24B Instruct","attachment":true,"reasoning":false,"temperature":true,"tool_call":true,"knowledge":"2024-10","release_date":"2025-03-17","last_updated":"2025-03-17","modalities":{"input":["text","image"],"output":["text"]},"open_weights":true,"cost":{"input":0,"output":0},"limit":{"context":128000,"output":8192},"display_name":"Mistral Small 3.1 24B Instruct"},{"id":"mistralai/devstral-small-2507","name":"Devstral Small 1.1","attachment":false,"reasoning":false,"temperature":true,"tool_call":true,"knowledge":"2025-05","release_date":"2025-07-10","last_updated":"2025-07-10","modalities":{"input":["text"],"output":["text"]},"open_weights":true,"cost":{"input":0.1,"output":0.3},"limit":{"context":131072,"output":131072},"display_name":"Devstral Small 1.1"},{"id":"mistralai/mistral-medium-3.1","name":"Mistral Medium 3.1","attachment":true,"reasoning":false,"temperature":true,"tool_call":true,"knowledge":"2025-05","release_date":"2025-08-12","last_updated":"2025-08-12","modalities":{"input":["text","image"],"output":["text"]},"open_weights":false,"cost":{"input":0.4,"output":2},"limit":{"context":262144,"output":262144},"display_name":"Mistral Medium 3.1"},{"id":"mistralai/mistral-nemo:free","name":"Mistral Nemo (free)","attachment":false,"reasoning":false,"temperature":true,"tool_call":true,"knowledge":"2024-07","release_date":"2024-07-19","last_updated":"2024-07-19","modalities":{"input":["text"],"output":["text"]},"open_weights":true,"cost":{"input":0,"output":0},"limit":{"context":131072,"output":131072},"display_name":"Mistral Nemo (free)"},{"id":"rekaai/reka-flash-3","name":"Reka Flash 3","attachment":false,"reasoning":true,"temperature":true,"tool_call":true,"knowledge":"2024-10","release_date":"2025-03-12","last_updated":"2025-03-12","modalities":{"input":["text"],"output":["text"]},"open_weights":true,"cost":{"input":0,"output":0},"limit":{"context":32768,"output":8192},"display_name":"Reka Flash 3"},{"id":"meta-llama/llama-3.2-11b-vision-instruct","name":"Llama 3.2 11B Vision Instruct","attachment":true,"reasoning":false,"temperature":true,"tool_call":false,"knowledge":"2023-12","release_date":"2024-09-25","last_updated":"2024-09-25","modalities":{"input":["text","image"],"output":["text"]},"open_weights":true,"cost":{"input":0,"output":0},"limit":{"context":131072,"output":8192},"display_name":"Llama 3.2 11B Vision Instruct"},{"id":"meta-llama/llama-3.3-70b-instruct:free","name":"Llama 3.3 70B Instruct (free)","attachment":false,"reasoning":false,"temperature":true,"tool_call":true,"knowledge":"2024-12","release_date":"2024-12-06","last_updated":"2024-12-06","modalities":{"input":["text"],"output":["text"]},"open_weights":true,"cost":{"input":0,"output":0},"limit":{"context":65536,"output":65536},"display_name":"Llama 3.3 70B Instruct (free)"},{"id":"meta-llama/llama-4-scout:free","name":"Llama 4 Scout (free)","attachment":true,"reasoning":false,"temperature":true,"tool_call":true,"knowledge":"2024-08","release_date":"2025-04-05","last_updated":"2025-04-05","modalities":{"input":["text","image"],"output":["text"]},"open_weights":true,"cost":{"input":0,"output":0},"limit":{"context":64000,"output":64000},"display_name":"Llama 4 Scout (free)"},{"id":"anthropic/claude-opus-4","name":"Claude Opus 4","attachment":true,"reasoning":true,"temperature":true,"tool_call":true,"knowledge":"2025-03-31","release_date":"2025-05-22","last_updated":"2025-05-22","modalities":{"input":["text","image"],"output":["text"]},"open_weights":false,"cost":{"input":15,"output":75,"cache_read":1.5,"cache_write":18.75},"limit":{"context":200000,"output":32000},"display_name":"Claude Opus 4"},{"id":"anthropic/claude-opus-4.1","name":"Claude Opus 4.1","attachment":true,"reasoning":true,"temperature":true,"tool_call":true,"knowledge":"2025-03-31","release_date":"2025-08-05","last_updated":"2025-08-05","modalities":{"input":["text","image"],"output":["text"]},"open_weights":false,"cost":{"input":15,"output":75,"cache_read":1.5,"cache_write":18.75},"limit":{"context":200000,"output":32000},"display_name":"Claude Opus 4.1"},{"id":"anthropic/claude-3.7-sonnet","name":"Claude Sonnet 3.7","attachment":true,"reasoning":true,"temperature":true,"tool_call":true,"knowledge":"2024-01","release_date":"2025-02-19","last_updated":"2025-02-19","modalities":{"input":["text","image"],"output":["text"]},"open_weights":false,"cost":{"input":15,"output":75,"cache_read":1.5,"cache_write":18.75},"limit":{"context":200000,"output":128000},"display_name":"Claude Sonnet 3.7"},{"id":"anthropic/claude-3.5-haiku","name":"Claude Haiku 3.5","attachment":true,"reasoning":false,"temperature":true,"tool_call":true,"knowledge":"2024-07-31","release_date":"2024-10-22","last_updated":"2024-10-22","modalities":{"input":["text","image"],"output":["text"]},"open_weights":false,"cost":{"input":0.8,"output":4,"cache_read":0.08,"cache_write":1},"limit":{"context":200000,"output":8192},"display_name":"Claude Haiku 3.5"},{"id":"anthropic/claude-sonnet-4","name":"Claude Sonnet 4","attachment":true,"reasoning":true,"temperature":true,"tool_call":true,"knowledge":"2025-03-31","release_date":"2025-05-22","last_updated":"2025-05-22","modalities":{"input":["text","image"],"output":["text"]},"open_weights":false,"cost":{"input":3,"output":15,"cache_read":0.3,"cache_write":3.75},"limit":{"context":200000,"output":64000},"display_name":"Claude Sonnet 4"},{"id":"anthropic/claude-sonnet-4.5","name":"Claude Sonnet 4.5","attachment":true,"reasoning":true,"temperature":true,"tool_call":true,"knowledge":"2025-07-31","release_date":"2025-09-29","last_updated":"2025-09-29","modalities":{"input":["text","image"],"output":["text"]},"open_weights":false,"cost":{"input":3,"output":15,"cache_read":0.3,"cache_write":3.75},"limit":{"context":1000000,"output":64000},"display_name":"Claude Sonnet 4.5"},{"id":"sarvamai/sarvam-m:free","name":"Sarvam-M (free)","attachment":false,"reasoning":true,"temperature":true,"tool_call":true,"knowledge":"2025-05","release_date":"2025-05-25","last_updated":"2025-05-25","modalities":{"input":["text"],"output":["text"]},"open_weights":true,"cost":{"input":0,"output":0},"limit":{"context":32768,"output":32768},"display_name":"Sarvam-M (free)"},{"id":"deepseek-chat-v3-0324:free","type":"chat","context_length":131072,"max_output_tokens":65536,"name":"deepseek-chat-v3-0324:free","display_name":"deepseek-chat-v3-0324:free"},{"id":"deepseek-r1-0528:free","type":"chat","context_length":131072,"max_output_tokens":65536,"name":"deepseek-r1-0528:free","display_name":"deepseek-r1-0528:free"},{"id":"google/gemini-2.5-flash-image-preview","type":"image-generation","context_length":32768,"max_output_tokens":32768,"name":"google/gemini-2.5-flash-image-preview","display_name":"google/gemini-2.5-flash-image-preview"},{"id":"gpt-5","type":"chat","reasoning_effort":"medium","name":"gpt-5","display_name":"gpt-5"},{"id":"gpt-5-chat","type":"chat","reasoning_effort":"medium","name":"gpt-5-chat","display_name":"gpt-5-chat"},{"id":"gpt-5-mini","type":"chat","reasoning_effort":"medium","name":"gpt-5-mini","display_name":"gpt-5-mini"},{"id":"gpt-5-nano","type":"chat","reasoning_effort":"medium","name":"gpt-5-nano","display_name":"gpt-5-nano"},{"id":"o1","type":"chat","context_length":200000,"max_output_tokens":100000,"reasoning_effort":"medium","name":"o1","display_name":"o1"},{"id":"o1-mini","type":"chat","context_length":128000,"max_output_tokens":65536,"reasoning_effort":"medium","name":"o1-mini","display_name":"o1-mini"},{"id":"o1-preview","type":"chat","context_length":128000,"max_output_tokens":32768,"reasoning_effort":"medium","name":"o1-preview","display_name":"o1-preview"},{"id":"o1-pro","type":"chat","context_length":200000,"max_output_tokens":100000,"reasoning_effort":"medium","name":"o1-pro","display_name":"o1-pro"},{"id":"o3","type":"chat","context_length":200000,"max_output_tokens":100000,"reasoning_effort":"medium","name":"o3","display_name":"o3"},{"id":"o3-mini","type":"chat","context_length":128000,"max_output_tokens":65536,"reasoning_effort":"medium","name":"o3-mini","display_name":"o3-mini"},{"id":"o3-mini-high","type":"chat","context_length":128000,"max_output_tokens":65536,"reasoning_effort":"high","name":"o3-mini-high","display_name":"o3-mini-high"},{"id":"o3-pro","type":"chat","context_length":200000,"max_output_tokens":100000,"reasoning_effort":"medium","name":"o3-pro","display_name":"o3-pro"}]},"v0":{"id":"v0","name":"v0","doc":"https://sdk.vercel.ai/providers/ai-sdk-providers/vercel","display_name":"v0","models":[{"id":"v0-1.5-lg","name":"v0-1.5-lg","attachment":true,"reasoning":true,"temperature":true,"tool_call":true,"release_date":"2025-06-09","last_updated":"2025-06-09","modalities":{"input":["text","image"],"output":["text"]},"open_weights":false,"cost":{"input":15,"output":75},"limit":{"context":512000,"output":32000},"display_name":"v0-1.5-lg"},{"id":"v0-1.5-md","name":"v0-1.5-md","attachment":true,"reasoning":true,"temperature":true,"tool_call":true,"release_date":"2025-06-09","last_updated":"2025-06-09","modalities":{"input":["text","image"],"output":["text"]},"open_weights":false,"cost":{"input":3,"output":15},"limit":{"context":128000,"output":32000},"display_name":"v0-1.5-md"},{"id":"v0-1.0-md","name":"v0-1.0-md","attachment":true,"reasoning":true,"temperature":true,"tool_call":true,"release_date":"2025-05-22","last_updated":"2025-05-22","modalities":{"input":["text","image"],"output":["text"]},"open_weights":false,"cost":{"input":3,"output":15},"limit":{"context":128000,"output":32000},"display_name":"v0-1.0-md"}]},"synthetic":{"id":"synthetic","api":"https://api.synthetic.new/v1","name":"Synthetic","doc":"https://synthetic.new/pricing","display_name":"Synthetic","models":[{"id":"hf:Qwen/Qwen3-235B-A22B-Instruct-2507","name":"Qwen 3 235B Instruct","attachment":false,"reasoning":false,"temperature":true,"tool_call":true,"knowledge":"2025-04","release_date":"2025-04-28","last_updated":"2025-07-21","modalities":{"input":["text"],"output":["text"]},"open_weights":true,"cost":{"input":0.2,"output":0.6},"limit":{"context":256000,"output":32000},"display_name":"Qwen 3 235B Instruct"},{"id":"hf:Qwen/Qwen2.5-Coder-32B-Instruct","name":"Qwen2.5-Coder-32B-Instruct","attachment":false,"reasoning":false,"temperature":true,"tool_call":false,"knowledge":"2024-10","release_date":"2024-11-11","last_updated":"2024-11-11","modalities":{"input":["text"],"output":["text"]},"open_weights":true,"cost":{"input":0.8,"output":0.8},"limit":{"context":32768,"output":32768},"display_name":"Qwen2.5-Coder-32B-Instruct"},{"id":"hf:Qwen/Qwen3-Coder-480B-A35B-Instruct","name":"Qwen 3 Coder 480B","attachment":false,"reasoning":false,"temperature":true,"tool_call":true,"knowledge":"2025-04","release_date":"2025-07-23","last_updated":"2025-07-23","modalities":{"input":["text"],"output":["text"]},"open_weights":true,"cost":{"input":2,"output":2},"limit":{"context":256000,"output":32000},"display_name":"Qwen 3 Coder 480B"},{"id":"hf:Qwen/Qwen3-235B-A22B-Thinking-2507","name":"Qwen3 235B A22B Thinking 2507","attachment":false,"reasoning":true,"temperature":true,"tool_call":true,"knowledge":"2025-04","release_date":"2025-07-25","last_updated":"2025-07-25","modalities":{"input":["text"],"output":["text"]},"open_weights":true,"cost":{"input":0.65,"output":3},"limit":{"context":256000,"output":32000},"display_name":"Qwen3 235B A22B Thinking 2507"},{"id":"hf:meta-llama/Llama-3.1-70B-Instruct","name":"Llama-3.1-70B-Instruct","attachment":false,"reasoning":true,"temperature":true,"tool_call":true,"knowledge":"2023-12","release_date":"2024-07-23","last_updated":"2024-07-23","modalities":{"input":["text"],"output":["text"]},"open_weights":true,"cost":{"input":0.9,"output":0.9},"limit":{"context":128000,"output":32768},"display_name":"Llama-3.1-70B-Instruct"},{"id":"hf:meta-llama/Llama-3.1-8B-Instruct","name":"Llama-3.1-8B-Instruct","attachment":false,"reasoning":true,"temperature":true,"tool_call":true,"knowledge":"2023-12","release_date":"2024-07-23","last_updated":"2024-07-23","modalities":{"input":["text"],"output":["text"]},"open_weights":true,"cost":{"input":0.2,"output":0.2},"limit":{"context":128000,"output":32768},"display_name":"Llama-3.1-8B-Instruct"},{"id":"hf:meta-llama/Llama-3.3-70B-Instruct","name":"Llama-3.3-70B-Instruct","attachment":false,"reasoning":true,"temperature":true,"tool_call":true,"knowledge":"2023-12","release_date":"2024-12-06","last_updated":"2024-12-06","modalities":{"input":["text"],"output":["text"]},"open_weights":true,"cost":{"input":0.9,"output":0.9},"limit":{"context":128000,"output":32768},"display_name":"Llama-3.3-70B-Instruct"},{"id":"hf:meta-llama/Llama-4-Scout-17B-16E-Instruct","name":"Llama-4-Scout-17B-16E-Instruct","attachment":true,"reasoning":false,"temperature":true,"tool_call":true,"knowledge":"2024-08","release_date":"2025-04-05","last_updated":"2025-04-05","modalities":{"input":["text","image"],"output":["text"]},"open_weights":true,"cost":{"input":0.15,"output":0.6},"limit":{"context":328000,"output":4096},"display_name":"Llama-4-Scout-17B-16E-Instruct"},{"id":"hf:meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8","name":"Llama-4-Maverick-17B-128E-Instruct-FP8","attachment":true,"reasoning":false,"temperature":true,"tool_call":true,"knowledge":"2024-08","release_date":"2025-04-05","last_updated":"2025-04-05","modalities":{"input":["text","image"],"output":["text"]},"open_weights":true,"cost":{"input":0.22,"output":0.88},"limit":{"context":524000,"output":4096},"display_name":"Llama-4-Maverick-17B-128E-Instruct-FP8"},{"id":"hf:meta-llama/Llama-3.1-405B-Instruct","name":"Llama-3.1-405B-Instruct","attachment":false,"reasoning":true,"temperature":true,"tool_call":true,"knowledge":"2023-12","release_date":"2024-07-23","last_updated":"2024-07-23","modalities":{"input":["text"],"output":["text"]},"open_weights":true,"cost":{"input":3,"output":3},"limit":{"context":128000,"output":32768},"display_name":"Llama-3.1-405B-Instruct"},{"id":"hf:moonshotai/Kimi-K2-Instruct","name":"Kimi K2","attachment":false,"reasoning":false,"temperature":true,"tool_call":true,"knowledge":"2024-10","release_date":"2025-07-11","last_updated":"2025-07-11","modalities":{"input":["text"],"output":["text"]},"open_weights":true,"cost":{"input":0.6,"output":2.5},"limit":{"context":128000,"output":32768},"display_name":"Kimi K2"},{"id":"hf:moonshotai/Kimi-K2-Instruct-0905","name":"Kimi K2 0905","attachment":false,"reasoning":false,"temperature":true,"tool_call":true,"knowledge":"2024-10","release_date":"2025-09-05","last_updated":"2025-09-05","modalities":{"input":["text"],"output":["text"]},"open_weights":true,"cost":{"input":1.2,"output":1.2},"limit":{"context":262144,"output":32768},"display_name":"Kimi K2 0905"},{"id":"hf:zai-org/GLM-4.5","name":"GLM 4.5","attachment":false,"reasoning":true,"temperature":true,"tool_call":true,"knowledge":"2025-04","release_date":"2025-07-28","last_updated":"2025-07-28","modalities":{"input":["text"],"output":["text"]},"open_weights":true,"cost":{"input":0.55,"output":2.19},"limit":{"context":128000,"output":96000},"display_name":"GLM 4.5"},{"id":"hf:zai-org/GLM-4.6","name":"GLM 4.6","attachment":false,"reasoning":true,"temperature":true,"tool_call":true,"knowledge":"2025-04","release_date":"2025-09-30","last_updated":"2025-09-30","modalities":{"input":["text"],"output":["text"]},"open_weights":true,"cost":{"input":0.55,"output":2.19},"limit":{"context":200000,"output":96000},"display_name":"GLM 4.6"},{"id":"hf:deepseek-ai/DeepSeek-R1","name":"DeepSeek R1","attachment":false,"reasoning":true,"temperature":true,"tool_call":true,"knowledge":"2025-01","release_date":"2025-01-20","last_updated":"2025-01-20","modalities":{"input":["text"],"output":["text"]},"open_weights":true,"cost":{"input":0.55,"output":2.19},"limit":{"context":128000,"output":128000},"display_name":"DeepSeek R1"},{"id":"hf:deepseek-ai/DeepSeek-R1-0528","name":"DeepSeek R1 (0528)","attachment":false,"reasoning":true,"temperature":true,"tool_call":true,"release_date":"2025-08-01","last_updated":"2025-08-01","modalities":{"input":["text"],"output":["text"]},"open_weights":false,"cost":{"input":3,"output":8},"limit":{"context":128000,"output":128000},"display_name":"DeepSeek R1 (0528)"},{"id":"hf:deepseek-ai/DeepSeek-V3.1-Terminus","name":"DeepSeek V3.1 Terminus","attachment":false,"reasoning":true,"temperature":true,"tool_call":true,"release_date":"2025-09-22","last_updated":"2025-09-25","modalities":{"input":["text"],"output":["text"]},"open_weights":false,"cost":{"input":1.2,"output":1.2},"limit":{"context":128000,"output":128000},"display_name":"DeepSeek V3.1 Terminus"},{"id":"hf:deepseek-ai/DeepSeek-V3","name":"DeepSeek V3","attachment":false,"reasoning":true,"temperature":true,"tool_call":true,"knowledge":"2024-07","release_date":"2025-01-20","last_updated":"2025-05-29","modalities":{"input":["text"],"output":["text"]},"open_weights":true,"cost":{"input":1.25,"output":1.25},"limit":{"context":128000,"output":128000},"display_name":"DeepSeek V3"},{"id":"hf:deepseek-ai/DeepSeek-V3.1","name":"DeepSeek V3.1","attachment":false,"reasoning":true,"temperature":true,"tool_call":true,"release_date":"2025-08-21","last_updated":"2025-08-21","modalities":{"input":["text"],"output":["text"]},"open_weights":false,"cost":{"input":0.56,"output":1.68},"limit":{"context":128000,"output":128000},"display_name":"DeepSeek V3.1"},{"id":"hf:deepseek-ai/DeepSeek-V3-0324","name":"DeepSeek V3 (0324)","attachment":false,"reasoning":false,"temperature":true,"tool_call":true,"release_date":"2025-08-01","last_updated":"2025-08-01","modalities":{"input":["text"],"output":["text"]},"open_weights":false,"cost":{"input":1.2,"output":1.2},"limit":{"context":128000,"output":128000},"display_name":"DeepSeek V3 (0324)"},{"id":"hf:openai/gpt-oss-120b","name":"GPT OSS 120B","attachment":false,"reasoning":true,"temperature":true,"tool_call":true,"release_date":"2025-08-05","last_updated":"2025-08-05","modalities":{"input":["text"],"output":["text"]},"open_weights":true,"cost":{"input":0.1,"output":0.1},"limit":{"context":128000,"output":32768},"display_name":"GPT OSS 120B"}]},"deepinfra":{"id":"deepinfra","name":"Deep Infra","doc":"https://deepinfra.com/models","display_name":"Deep Infra","models":[{"id":"moonshotai/Kimi-K2-Instruct","name":"Kimi K2","attachment":false,"reasoning":false,"temperature":true,"tool_call":true,"knowledge":"2024-10","release_date":"2025-07-11","last_updated":"2025-07-11","modalities":{"input":["text"],"output":["text"]},"open_weights":true,"cost":{"input":0.5,"output":2},"limit":{"context":131072,"output":32768},"display_name":"Kimi K2"},{"id":"Qwen/Qwen3-Coder-480B-A35B-Instruct","name":"Qwen3 Coder 480B A35B Instruct","attachment":false,"reasoning":false,"temperature":true,"tool_call":true,"knowledge":"2025-04","release_date":"2025-07-23","last_updated":"2025-07-23","modalities":{"input":["text"],"output":["text"]},"open_weights":true,"cost":{"input":0.4,"output":1.6},"limit":{"context":262144,"output":66536},"display_name":"Qwen3 Coder 480B A35B Instruct"},{"id":"Qwen/Qwen3-Coder-480B-A35B-Instruct-Turbo","name":"Qwen3 Coder 480B A35B Instruct Turbo","attachment":false,"reasoning":false,"temperature":true,"tool_call":true,"knowledge":"2025-04","release_date":"2025-07-23","last_updated":"2025-07-23","modalities":{"input":["text"],"output":["text"]},"open_weights":true,"cost":{"input":0.3,"output":1.2},"limit":{"context":262144,"output":66536},"display_name":"Qwen3 Coder 480B A35B Instruct Turbo"},{"id":"zai-org/GLM-4.5","name":"GLM-4.5","attachment":false,"reasoning":false,"temperature":true,"tool_call":true,"knowledge":"2025-04","release_date":"2025-07-28","last_updated":"2025-07-28","modalities":{"input":["text"],"output":["text"]},"open_weights":true,"cost":{"input":0.6,"output":2.2},"limit":{"context":131072,"output":98304},"display_name":"GLM-4.5"}]},"zhipuai":{"id":"zhipuai","api":"https://open.bigmodel.cn/api/paas/v4","name":"Zhipu AI","doc":"https://docs.z.ai/guides/overview/pricing","display_name":"Zhipu AI","models":[{"id":"glm-4.6","name":"GLM-4.6","attachment":false,"reasoning":true,"temperature":true,"tool_call":true,"knowledge":"2025-04","release_date":"2025-09-30","last_updated":"2025-09-30","modalities":{"input":["text"],"output":["text"]},"open_weights":true,"cost":{"input":0.6,"output":2.2,"cache_read":0.11,"cache_write":0},"limit":{"context":204800,"output":131072},"display_name":"GLM-4.6"},{"id":"glm-4.5v","name":"GLM 4.5V","attachment":true,"reasoning":true,"temperature":true,"tool_call":true,"knowledge":"2025-04","release_date":"2025-08-11","last_updated":"2025-08-11","modalities":{"input":["text","image","video"],"output":["text"]},"open_weights":true,"cost":{"input":0.6,"output":1.8},"limit":{"context":64000,"output":16384},"display_name":"GLM 4.5V"},{"id":"glm-4.5-air","name":"GLM-4.5-Air","attachment":false,"reasoning":true,"temperature":true,"tool_call":true,"knowledge":"2025-04","release_date":"2025-07-28","last_updated":"2025-07-28","modalities":{"input":["text"],"output":["text"]},"open_weights":true,"cost":{"input":0.2,"output":1.1,"cache_read":0.03,"cache_write":0},"limit":{"context":131072,"output":98304},"display_name":"GLM-4.5-Air"},{"id":"glm-4.5","name":"GLM-4.5","attachment":false,"reasoning":true,"temperature":true,"tool_call":true,"knowledge":"2025-04","release_date":"2025-07-28","last_updated":"2025-07-28","modalities":{"input":["text"],"output":["text"]},"open_weights":true,"cost":{"input":0.6,"output":2.2,"cache_read":0.11,"cache_write":0},"limit":{"context":131072,"output":98304},"display_name":"GLM-4.5"},{"id":"glm-4.5-flash","name":"GLM-4.5-Flash","attachment":false,"reasoning":true,"temperature":true,"tool_call":true,"knowledge":"2025-04","release_date":"2025-07-28","last_updated":"2025-07-28","modalities":{"input":["text"],"output":["text"]},"open_weights":true,"cost":{"input":0,"output":0,"cache_read":0,"cache_write":0},"limit":{"context":131072,"output":98304},"display_name":"GLM-4.5-Flash"}]},"submodel":{"id":"submodel","api":"https://llm.submodel.ai/v1","name":"submodel","doc":"https://submodel.gitbook.io","display_name":"submodel","models":[{"id":"openai/gpt-oss-120b","name":"GPT OSS 120B","attachment":false,"reasoning":true,"temperature":true,"tool_call":true,"release_date":"2025-08-23","last_updated":"2025-08-23","modalities":{"input":["text"],"output":["text"]},"open_weights":true,"cost":{"input":0.1,"output":0.5},"limit":{"context":131072,"output":32768},"display_name":"GPT OSS 120B"},{"id":"Qwen/Qwen3-235B-A22B-Instruct-2507","name":"Qwen3 235B A22B Instruct 2507","attachment":false,"reasoning":false,"temperature":true,"tool_call":true,"release_date":"2025-08-23","last_updated":"2025-08-23","modalities":{"input":["text"],"output":["text"]},"open_weights":true,"cost":{"input":0.2,"output":0.3},"limit":{"context":262144,"output":131072},"display_name":"Qwen3 235B A22B Instruct 2507"},{"id":"Qwen/Qwen3-Coder-480B-A35B-Instruct-FP8","name":"Qwen3 Coder 480B A35B Instruct","attachment":false,"reasoning":false,"temperature":true,"tool_call":true,"release_date":"2025-08-23","last_updated":"2025-08-23","modalities":{"input":["text"],"output":["text"]},"open_weights":false,"cost":{"input":0.2,"output":0.8},"limit":{"context":262144,"output":262144},"display_name":"Qwen3 Coder 480B A35B Instruct"},{"id":"Qwen/Qwen3-235B-A22B-Thinking-2507","name":"Qwen3 235B A22B Thinking 2507","attachment":false,"reasoning":true,"temperature":true,"tool_call":true,"release_date":"2025-08-23","last_updated":"2025-08-23","modalities":{"input":["text"],"output":["text"]},"open_weights":true,"cost":{"input":0.2,"output":0.6},"limit":{"context":262144,"output":131072},"display_name":"Qwen3 235B A22B Thinking 2507"},{"id":"zai-org/GLM-4.5-FP8","name":"GLM 4.5 FP8","attachment":false,"reasoning":true,"temperature":true,"tool_call":true,"release_date":"2025-07-28","last_updated":"2025-07-28","modalities":{"input":["text"],"output":["text"]},"open_weights":true,"cost":{"input":0.2,"output":0.8},"limit":{"context":131072,"output":131072},"display_name":"GLM 4.5 FP8"},{"id":"zai-org/GLM-4.5-Air","name":"GLM 4.5 Air","attachment":false,"reasoning":false,"temperature":true,"tool_call":true,"release_date":"2025-07-28","last_updated":"2025-07-28","modalities":{"input":["text"],"output":["text"]},"open_weights":true,"cost":{"input":0.1,"output":0.5},"limit":{"context":131072,"output":131072},"display_name":"GLM 4.5 Air"},{"id":"deepseek-ai/DeepSeek-R1-0528","name":"DeepSeek R1 0528","attachment":false,"reasoning":true,"temperature":true,"tool_call":true,"release_date":"2025-08-23","last_updated":"2025-08-23","modalities":{"input":["text"],"output":["text"]},"open_weights":false,"cost":{"input":0.5,"output":2.15},"limit":{"context":75000,"output":163840},"display_name":"DeepSeek R1 0528"},{"id":"deepseek-ai/DeepSeek-V3.1","name":"DeepSeek V3.1","attachment":false,"reasoning":true,"temperature":true,"tool_call":true,"release_date":"2025-08-23","last_updated":"2025-08-23","modalities":{"input":["text"],"output":["text"]},"open_weights":false,"cost":{"input":0.2,"output":0.8},"limit":{"context":75000,"output":163840},"display_name":"DeepSeek V3.1"},{"id":"deepseek-ai/DeepSeek-V3-0324","name":"DeepSeek V3 0324","attachment":false,"reasoning":false,"temperature":true,"tool_call":true,"release_date":"2025-08-23","last_updated":"2025-08-23","modalities":{"input":["text"],"output":["text"]},"open_weights":false,"cost":{"input":0.2,"output":0.8},"limit":{"context":75000,"output":163840},"display_name":"DeepSeek V3 0324"}]},"zai":{"id":"zai","api":"https://api.z.ai/api/paas/v4","name":"Z.AI","doc":"https://docs.z.ai/guides/overview/pricing","display_name":"Z.AI","models":[{"id":"glm-4.5-flash","name":"GLM-4.5-Flash","attachment":false,"reasoning":true,"temperature":true,"tool_call":true,"knowledge":"2025-04","release_date":"2025-07-28","last_updated":"2025-07-28","modalities":{"input":["text"],"output":["text"]},"open_weights":true,"cost":{"input":0,"output":0,"cache_read":0,"cache_write":0},"limit":{"context":131072,"output":98304},"display_name":"GLM-4.5-Flash"},{"id":"glm-4.5","name":"GLM-4.5","attachment":false,"reasoning":true,"temperature":true,"tool_call":true,"knowledge":"2025-04","release_date":"2025-07-28","last_updated":"2025-07-28","modalities":{"input":["text"],"output":["text"]},"open_weights":true,"cost":{"input":0.6,"output":2.2,"cache_read":0.11,"cache_write":0},"limit":{"context":131072,"output":98304},"display_name":"GLM-4.5"},{"id":"glm-4.5-air","name":"GLM-4.5-Air","attachment":false,"reasoning":true,"temperature":true,"tool_call":true,"knowledge":"2025-04","release_date":"2025-07-28","last_updated":"2025-07-28","modalities":{"input":["text"],"output":["text"]},"open_weights":true,"cost":{"input":0.2,"output":1.1,"cache_read":0.03,"cache_write":0},"limit":{"context":131072,"output":98304},"display_name":"GLM-4.5-Air"},{"id":"glm-4.5v","name":"GLM 4.5V","attachment":true,"reasoning":true,"temperature":true,"tool_call":true,"knowledge":"2025-04","release_date":"2025-08-11","last_updated":"2025-08-11","modalities":{"input":["text","image","video"],"output":["text"]},"open_weights":true,"cost":{"input":0.6,"output":1.8},"limit":{"context":64000,"output":16384},"display_name":"GLM 4.5V"},{"id":"glm-4.6","name":"GLM-4.6","attachment":false,"reasoning":true,"temperature":true,"tool_call":true,"knowledge":"2025-04","release_date":"2025-09-30","last_updated":"2025-09-30","modalities":{"input":["text"],"output":["text"]},"open_weights":true,"cost":{"input":0.6,"output":2.2,"cache_read":0.11,"cache_write":0},"limit":{"context":204800,"output":131072},"display_name":"GLM-4.6"}]},"inference":{"id":"inference","api":"https://inference.net/v1","name":"Inference","doc":"https://inference.net/models","display_name":"Inference","models":[{"id":"mistral/mistral-nemo-12b-instruct","name":"Mistral Nemo 12B Instruct","attachment":false,"reasoning":false,"temperature":true,"tool_call":true,"knowledge":"2024-12","release_date":"2025-01-01","last_updated":"2025-01-01","modalities":{"input":["text"],"output":["text"]},"open_weights":true,"cost":{"input":0.038,"output":0.1},"limit":{"context":16000,"output":4096},"display_name":"Mistral Nemo 12B Instruct"},{"id":"google/gemma-3","name":"Google Gemma 3","attachment":true,"reasoning":false,"temperature":true,"tool_call":true,"knowledge":"2024-12","release_date":"2025-01-01","last_updated":"2025-01-01","modalities":{"input":["text","image"],"output":["text"]},"open_weights":true,"cost":{"input":0.15,"output":0.3},"limit":{"context":125000,"output":4096},"display_name":"Google Gemma 3"},{"id":"osmosis/osmosis-structure-0.6b","name":"Osmosis Structure 0.6B","attachment":false,"reasoning":false,"temperature":true,"tool_call":true,"knowledge":"2024-12","release_date":"2025-01-01","last_updated":"2025-01-01","modalities":{"input":["text"],"output":["text"]},"open_weights":true,"cost":{"input":0.1,"output":0.5},"limit":{"context":4000,"output":2048},"display_name":"Osmosis Structure 0.6B"},{"id":"qwen/qwen3-embedding-4b","name":"Qwen 3 Embedding 4B","attachment":false,"reasoning":false,"temperature":false,"tool_call":false,"knowledge":"2024-12","release_date":"2025-01-01","last_updated":"2025-01-01","modalities":{"input":["text"],"output":["text"]},"open_weights":true,"cost":{"input":0.01,"output":0},"limit":{"context":32000,"output":2048},"display_name":"Qwen 3 Embedding 4B"},{"id":"qwen/qwen-2.5-7b-vision-instruct","name":"Qwen 2.5 7B Vision Instruct","attachment":true,"reasoning":false,"temperature":true,"tool_call":true,"knowledge":"2024-12","release_date":"2025-01-01","last_updated":"2025-01-01","modalities":{"input":["text","image"],"output":["text"]},"open_weights":true,"cost":{"input":0.2,"output":0.2},"limit":{"context":125000,"output":4096},"display_name":"Qwen 2.5 7B Vision Instruct"},{"id":"meta/llama-3.2-11b-vision-instruct","name":"Llama 3.2 11B Vision Instruct","attachment":true,"reasoning":false,"temperature":true,"tool_call":true,"knowledge":"2023-12","release_date":"2025-01-01","last_updated":"2025-01-01","modalities":{"input":["text","image"],"output":["text"]},"open_weights":true,"cost":{"input":0.055,"output":0.055},"limit":{"context":16000,"output":4096},"display_name":"Llama 3.2 11B Vision Instruct"},{"id":"meta/llama-3.1-8b-instruct","name":"Llama 3.1 8B Instruct","attachment":false,"reasoning":false,"temperature":true,"tool_call":true,"knowledge":"2023-12","release_date":"2025-01-01","last_updated":"2025-01-01","modalities":{"input":["text"],"output":["text"]},"open_weights":true,"cost":{"input":0.025,"output":0.025},"limit":{"context":16000,"output":4096},"display_name":"Llama 3.1 8B Instruct"},{"id":"meta/llama-3.2-3b-instruct","name":"Llama 3.2 3B Instruct","attachment":false,"reasoning":false,"temperature":true,"tool_call":true,"knowledge":"2023-12","release_date":"2025-01-01","last_updated":"2025-01-01","modalities":{"input":["text"],"output":["text"]},"open_weights":true,"cost":{"input":0.02,"output":0.02},"limit":{"context":16000,"output":4096},"display_name":"Llama 3.2 3B Instruct"},{"id":"meta/llama-3.2-1b-instruct","name":"Llama 3.2 1B Instruct","attachment":false,"reasoning":false,"temperature":true,"tool_call":true,"knowledge":"2023-12","release_date":"2025-01-01","last_updated":"2025-01-01","modalities":{"input":["text"],"output":["text"]},"open_weights":true,"cost":{"input":0.01,"output":0.01},"limit":{"context":16000,"output":4096},"display_name":"Llama 3.2 1B Instruct"}]},"requesty":{"id":"requesty","api":"https://router.requesty.ai/v1","name":"Requesty","doc":"https://requesty.ai/solution/llm-routing/models","display_name":"Requesty","models":[{"id":"google/gemini-2.5-flash","name":"Gemini 2.5 Flash","attachment":true,"reasoning":true,"temperature":true,"tool_call":true,"knowledge":"2025-01","release_date":"2025-06-17","last_updated":"2025-06-17","modalities":{"input":["text","image","audio","video","pdf"],"output":["text"]},"open_weights":false,"cost":{"input":0.3,"output":2.5,"cache_read":0.075,"cache_write":0.55},"limit":{"context":1048576,"output":65536},"display_name":"Gemini 2.5 Flash"},{"id":"google/gemini-2.5-pro","name":"Gemini 2.5 Pro","attachment":true,"reasoning":true,"temperature":true,"tool_call":true,"knowledge":"2025-01","release_date":"2025-06-17","last_updated":"2025-06-17","modalities":{"input":["text","image","audio","video","pdf"],"output":["text"]},"open_weights":false,"cost":{"input":1.25,"output":10,"cache_read":0.31,"cache_write":2.375},"limit":{"context":1048576,"output":65536},"display_name":"Gemini 2.5 Pro"},{"id":"openai/gpt-4.1-mini","name":"GPT-4.1 Mini","attachment":true,"reasoning":false,"temperature":true,"tool_call":true,"knowledge":"2024-04","release_date":"2025-04-14","last_updated":"2025-04-14","modalities":{"input":["text","image"],"output":["text"]},"open_weights":false,"cost":{"input":0.4,"output":1.6,"cache_read":0.1},"limit":{"context":1047576,"output":32768},"display_name":"GPT-4.1 Mini"},{"id":"openai/gpt-5-nano","name":"GPT-5 Nano","attachment":true,"reasoning":true,"temperature":false,"tool_call":true,"knowledge":"2024-05-30","release_date":"2025-08-07","last_updated":"2025-08-07","modalities":{"input":["text"],"output":["text"]},"open_weights":false,"cost":{"input":0.05,"output":0.4,"cache_read":0.01},"limit":{"context":16000,"output":4000},"display_name":"GPT-5 Nano"},{"id":"openai/gpt-4.1","name":"GPT-4.1","attachment":true,"reasoning":false,"temperature":true,"tool_call":true,"knowledge":"2024-04","release_date":"2025-04-14","last_updated":"2025-04-14","modalities":{"input":["text","image"],"output":["text"]},"open_weights":false,"cost":{"input":2,"output":8,"cache_read":0.5},"limit":{"context":1047576,"output":32768},"display_name":"GPT-4.1"},{"id":"openai/o4-mini","name":"o4 Mini","attachment":true,"reasoning":true,"temperature":true,"tool_call":true,"knowledge":"2024-06","release_date":"2025-04-16","last_updated":"2025-04-16","modalities":{"input":["text","image"],"output":["text"]},"open_weights":false,"cost":{"input":1.1,"output":4.4,"cache_read":0.28},"limit":{"context":200000,"output":100000},"display_name":"o4 Mini"},{"id":"openai/gpt-5-mini","name":"GPT-5 Mini","attachment":true,"reasoning":true,"temperature":false,"tool_call":true,"knowledge":"2024-05-30","release_date":"2025-08-07","last_updated":"2025-08-07","modalities":{"input":["text","image"],"output":["text"]},"open_weights":false,"cost":{"input":0.25,"output":2,"cache_read":0.03},"limit":{"context":128000,"output":32000},"display_name":"GPT-5 Mini"},{"id":"openai/gpt-4o-mini","name":"GPT-4o Mini","attachment":true,"reasoning":false,"temperature":true,"tool_call":true,"knowledge":"2024-10","release_date":"2024-07-18","last_updated":"2024-07-18","modalities":{"input":["text","image"],"output":["text"]},"open_weights":false,"cost":{"input":0.15,"output":0.6,"cache_read":0.08},"limit":{"context":128000,"output":16384},"display_name":"GPT-4o Mini"},{"id":"openai/gpt-5","name":"GPT-5","attachment":true,"reasoning":true,"temperature":false,"tool_call":true,"knowledge":"2024-09-30","release_date":"2025-08-07","last_updated":"2025-08-07","modalities":{"input":["text","audio","image","video"],"output":["text","audio","image"]},"open_weights":false,"cost":{"input":1.25,"output":10,"cache_read":0.13},"limit":{"context":400000,"output":128000},"display_name":"GPT-5"},{"id":"anthropic/claude-opus-4","name":"Claude Opus 4","attachment":true,"reasoning":true,"temperature":true,"tool_call":true,"knowledge":"2025-03-31","release_date":"2025-05-22","last_updated":"2025-05-22","modalities":{"input":["text","image"],"output":["text"]},"open_weights":false,"cost":{"input":15,"output":75,"cache_read":1.5,"cache_write":18.75},"limit":{"context":200000,"output":32000},"display_name":"Claude Opus 4"},{"id":"anthropic/claude-3-7-sonnet","name":"Claude Sonnet 3.7","attachment":true,"reasoning":true,"temperature":true,"tool_call":true,"knowledge":"2024-01","release_date":"2025-02-19","last_updated":"2025-02-19","modalities":{"input":["text","image"],"output":["text"]},"open_weights":false,"cost":{"input":3,"output":15,"cache_read":0.3,"cache_write":3.75},"limit":{"context":200000,"output":64000},"display_name":"Claude Sonnet 3.7"},{"id":"anthropic/claude-4-sonnet-20250522","name":"Claude Sonnet 4","attachment":true,"reasoning":true,"temperature":true,"tool_call":true,"knowledge":"2025-03-31","release_date":"2025-05-22","last_updated":"2025-05-22","modalities":{"input":["text","image"],"output":["text"]},"open_weights":false,"cost":{"input":3,"output":15,"cache_read":0.3,"cache_write":3.75},"limit":{"context":200000,"output":64000},"display_name":"Claude Sonnet 4"},{"id":"anthropic/claude-opus-4-1-20250805","name":"Claude Opus 4.1","attachment":true,"reasoning":true,"temperature":true,"tool_call":true,"knowledge":"2025-03-31","release_date":"2025-08-05","last_updated":"2025-08-05","modalities":{"input":["text","image"],"output":["text"]},"open_weights":false,"cost":{"input":15,"output":75,"cache_read":1.5,"cache_write":18.75},"limit":{"context":200000,"output":32000},"display_name":"Claude Opus 4.1"}]},"morph":{"id":"morph","api":"https://api.morphllm.com/v1","name":"Morph","doc":"https://docs.morphllm.com/api-reference/introduction","display_name":"Morph","models":[{"id":"morph-v3-large","name":"Morph v3 Large","attachment":false,"reasoning":false,"temperature":false,"tool_call":false,"release_date":"2024-08-15","last_updated":"2024-08-15","modalities":{"input":["text"],"output":["text"]},"open_weights":false,"cost":{"input":0.9,"output":1.9},"limit":{"context":32000,"output":32000},"display_name":"Morph v3 Large"},{"id":"auto","name":"Auto","attachment":false,"reasoning":false,"temperature":false,"tool_call":false,"release_date":"2024-06-01","last_updated":"2024-06-01","modalities":{"input":["text"],"output":["text"]},"open_weights":false,"cost":{"input":0.85,"output":1.55},"limit":{"context":32000,"output":32000},"display_name":"Auto"},{"id":"morph-v3-fast","name":"Morph v3 Fast","attachment":false,"reasoning":false,"temperature":false,"tool_call":false,"release_date":"2024-08-15","last_updated":"2024-08-15","modalities":{"input":["text"],"output":["text"]},"open_weights":false,"cost":{"input":0.8,"output":1.2},"limit":{"context":16000,"output":16000},"display_name":"Morph v3 Fast"}]},"lmstudio":{"id":"lmstudio","api":"http://127.0.0.1:1234/v1","name":"LMStudio","doc":"https://lmstudio.ai/models","display_name":"LMStudio","models":[{"id":"openai/gpt-oss-20b","name":"GPT OSS 20B","attachment":false,"reasoning":true,"temperature":true,"tool_call":true,"release_date":"2025-08-05","last_updated":"2025-08-05","modalities":{"input":["text"],"output":["text"]},"open_weights":true,"cost":{"input":0,"output":0},"limit":{"context":131072,"output":32768},"display_name":"GPT OSS 20B"},{"id":"qwen/qwen3-30b-a3b-2507","name":"Qwen3 30B A3B 2507","attachment":false,"reasoning":false,"temperature":true,"tool_call":true,"knowledge":"2025-04","release_date":"2025-07-30","last_updated":"2025-07-30","modalities":{"input":["text"],"output":["text"]},"open_weights":true,"cost":{"input":0,"output":0},"limit":{"context":262144,"output":16384},"display_name":"Qwen3 30B A3B 2507"},{"id":"qwen/qwen3-coder-30b","name":"Qwen3 Coder 30B","attachment":false,"reasoning":false,"temperature":true,"tool_call":true,"knowledge":"2025-04","release_date":"2025-07-23","last_updated":"2025-07-23","modalities":{"input":["text"],"output":["text"]},"open_weights":true,"cost":{"input":0,"output":0},"limit":{"context":262144,"output":65536},"display_name":"Qwen3 Coder 30B"}]},"anthropic":{"id":"anthropic","name":"Anthropic","doc":"https://docs.anthropic.com/en/docs/about-claude/models","display_name":"Anthropic","models":[{"id":"claude-3-5-sonnet-20241022","name":"Claude Sonnet 3.5 v2","attachment":true,"reasoning":false,"temperature":true,"tool_call":true,"knowledge":"2024-04-30","release_date":"2024-10-22","last_updated":"2024-10-22","modalities":{"input":["text","image"],"output":["text"]},"open_weights":false,"cost":{"input":3,"output":15,"cache_read":0.3,"cache_write":3.75},"limit":{"context":200000,"output":8192},"display_name":"Claude Sonnet 3.5 v2"},{"id":"claude-3-5-sonnet-20240620","name":"Claude Sonnet 3.5","attachment":true,"reasoning":false,"temperature":true,"tool_call":true,"knowledge":"2024-04-30","release_date":"2024-06-20","last_updated":"2024-06-20","modalities":{"input":["text","image"],"output":["text"]},"open_weights":false,"cost":{"input":3,"output":15,"cache_read":0.3,"cache_write":3.75},"limit":{"context":200000,"output":8192},"display_name":"Claude Sonnet 3.5"},{"id":"claude-3-opus-20240229","name":"Claude Opus 3","attachment":true,"reasoning":false,"temperature":true,"tool_call":true,"knowledge":"2023-08-31","release_date":"2024-02-29","last_updated":"2024-02-29","modalities":{"input":["text","image"],"output":["text"]},"open_weights":false,"cost":{"input":15,"output":75,"cache_read":1.5,"cache_write":18.75},"limit":{"context":200000,"output":4096},"display_name":"Claude Opus 3"},{"id":"claude-sonnet-4-5-20250929","name":"Claude Sonnet 4.5","attachment":true,"reasoning":true,"temperature":true,"tool_call":true,"knowledge":"2025-07-31","release_date":"2025-09-29","last_updated":"2025-09-29","modalities":{"input":["text","image"],"output":["text"]},"open_weights":false,"cost":{"input":3,"output":15,"cache_read":0.3,"cache_write":3.75},"limit":{"context":200000,"output":64000},"display_name":"Claude Sonnet 4.5"},{"id":"claude-sonnet-4-20250514","name":"Claude Sonnet 4","attachment":true,"reasoning":true,"temperature":true,"tool_call":true,"knowledge":"2025-03-31","release_date":"2025-05-22","last_updated":"2025-05-22","modalities":{"input":["text","image"],"output":["text"]},"open_weights":false,"cost":{"input":3,"output":15,"cache_read":0.3,"cache_write":3.75},"limit":{"context":200000,"output":64000},"display_name":"Claude Sonnet 4"},{"id":"claude-opus-4-20250514","name":"Claude Opus 4","attachment":true,"reasoning":true,"temperature":true,"tool_call":true,"knowledge":"2025-03-31","release_date":"2025-05-22","last_updated":"2025-05-22","modalities":{"input":["text","image"],"output":["text"]},"open_weights":false,"cost":{"input":15,"output":75,"cache_read":1.5,"cache_write":18.75},"limit":{"context":200000,"output":32000},"display_name":"Claude Opus 4"},{"id":"claude-3-5-haiku-20241022","name":"Claude Haiku 3.5","attachment":true,"reasoning":false,"temperature":true,"tool_call":true,"knowledge":"2024-07-31","release_date":"2024-10-22","last_updated":"2024-10-22","modalities":{"input":["text","image"],"output":["text"]},"open_weights":false,"cost":{"input":0.8,"output":4,"cache_read":0.08,"cache_write":1},"limit":{"context":200000,"output":8192},"display_name":"Claude Haiku 3.5"},{"id":"claude-3-haiku-20240307","name":"Claude Haiku 3","attachment":true,"reasoning":false,"temperature":true,"tool_call":true,"knowledge":"2023-08-31","release_date":"2024-03-13","last_updated":"2024-03-13","modalities":{"input":["text","image"],"output":["text"]},"open_weights":false,"cost":{"input":0.25,"output":1.25,"cache_read":0.03,"cache_write":0.3},"limit":{"context":200000,"output":4096},"display_name":"Claude Haiku 3"},{"id":"claude-3-7-sonnet-20250219","name":"Claude Sonnet 3.7","attachment":true,"reasoning":true,"temperature":true,"tool_call":true,"knowledge":"2024-10-31","release_date":"2025-02-19","last_updated":"2025-02-19","modalities":{"input":["text","image"],"output":["text"]},"open_weights":false,"cost":{"input":3,"output":15,"cache_read":0.3,"cache_write":3.75},"limit":{"context":200000,"output":64000},"display_name":"Claude Sonnet 3.7"},{"id":"claude-opus-4-1-20250805","name":"Claude Opus 4.1","attachment":true,"reasoning":true,"temperature":true,"tool_call":true,"knowledge":"2025-03-31","release_date":"2025-08-05","last_updated":"2025-08-05","modalities":{"input":["text","image"],"output":["text"]},"open_weights":false,"cost":{"input":15,"output":75,"cache_read":1.5,"cache_write":18.75},"limit":{"context":200000,"output":32000},"display_name":"Claude Opus 4.1"},{"id":"claude-3-sonnet-20240229","name":"Claude Sonnet 3","attachment":true,"reasoning":false,"temperature":true,"tool_call":true,"knowledge":"2023-08-31","release_date":"2024-03-04","last_updated":"2024-03-04","modalities":{"input":["text","image"],"output":["text"]},"open_weights":false,"cost":{"input":3,"output":15,"cache_read":0.3,"cache_write":0.3},"limit":{"context":200000,"output":4096},"display_name":"Claude Sonnet 3"}]},"fireworks-ai":{"id":"fireworks-ai","api":"https://api.fireworks.ai/inference/v1/","name":"Fireworks AI","doc":"https://fireworks.ai/docs/","display_name":"Fireworks AI","models":[{"id":"accounts/fireworks/models/deepseek-r1-0528","name":"Deepseek R1 05/28","attachment":false,"reasoning":true,"temperature":true,"tool_call":true,"knowledge":"2025-05","release_date":"2025-05-28","last_updated":"2025-05-28","modalities":{"input":["text"],"output":["text"]},"open_weights":true,"cost":{"input":3,"output":8},"limit":{"context":160000,"output":16384},"display_name":"Deepseek R1 05/28"},{"id":"accounts/fireworks/models/deepseek-v3p1","name":"DeepSeek V3.1","attachment":false,"reasoning":true,"temperature":true,"tool_call":true,"knowledge":"2025-07","release_date":"2025-08-21","last_updated":"2025-08-21","modalities":{"input":["text"],"output":["text"]},"open_weights":true,"cost":{"input":0.56,"output":1.68},"limit":{"context":163840,"output":163840},"display_name":"DeepSeek V3.1"},{"id":"accounts/fireworks/models/deepseek-v3-0324","name":"Deepseek V3 03-24","attachment":false,"reasoning":false,"temperature":true,"tool_call":true,"knowledge":"2024-10","release_date":"2025-03-24","last_updated":"2025-03-24","modalities":{"input":["text"],"output":["text"]},"open_weights":true,"cost":{"input":0.9,"output":0.9},"limit":{"context":160000,"output":16384},"display_name":"Deepseek V3 03-24"},{"id":"accounts/fireworks/models/kimi-k2-instruct","name":"Kimi K2 Instruct","attachment":false,"reasoning":false,"temperature":true,"tool_call":true,"knowledge":"2024-10","release_date":"2025-07-11","last_updated":"2025-07-11","modalities":{"input":["text"],"output":["text"]},"open_weights":true,"cost":{"input":1,"output":3},"limit":{"context":128000,"output":16384},"display_name":"Kimi K2 Instruct"},{"id":"accounts/fireworks/models/qwen3-235b-a22b","name":"Qwen3 235B-A22B","attachment":false,"reasoning":true,"temperature":true,"tool_call":true,"knowledge":"2025-04","release_date":"2025-04-29","last_updated":"2025-04-29","modalities":{"input":["text"],"output":["text"]},"open_weights":true,"cost":{"input":0.22,"output":0.88},"limit":{"context":128000,"output":16384},"display_name":"Qwen3 235B-A22B"},{"id":"accounts/fireworks/models/gpt-oss-20b","name":"GPT OSS 20B","attachment":false,"reasoning":true,"temperature":true,"tool_call":true,"release_date":"2025-08-05","last_updated":"2025-08-05","modalities":{"input":["text"],"output":["text"]},"open_weights":true,"cost":{"input":0.05,"output":0.2},"limit":{"context":131072,"output":32768},"display_name":"GPT OSS 20B"},{"id":"accounts/fireworks/models/gpt-oss-120b","name":"GPT OSS 120B","attachment":false,"reasoning":true,"temperature":true,"tool_call":true,"release_date":"2025-08-05","last_updated":"2025-08-05","modalities":{"input":["text"],"output":["text"]},"open_weights":true,"cost":{"input":0.15,"output":0.6},"limit":{"context":131072,"output":32768},"display_name":"GPT OSS 120B"},{"id":"accounts/fireworks/models/glm-4p5-air","name":"GLM 4.5 Air","attachment":false,"reasoning":true,"temperature":true,"tool_call":true,"knowledge":"2025-04","release_date":"2025-08-01","last_updated":"2025-08-01","modalities":{"input":["text"],"output":["text"]},"open_weights":true,"cost":{"input":0.22,"output":0.88},"limit":{"context":131072,"output":131072},"display_name":"GLM 4.5 Air"},{"id":"accounts/fireworks/models/qwen3-coder-480b-a35b-instruct","name":"Qwen3 Coder 480B A35B Instruct","attachment":false,"reasoning":false,"temperature":true,"tool_call":true,"release_date":"2025-07-22","last_updated":"2025-07-22","modalities":{"input":["text"],"output":["text"]},"open_weights":true,"cost":{"input":0.45,"output":1.8},"limit":{"context":256000,"output":32768},"display_name":"Qwen3 Coder 480B A35B Instruct"},{"id":"accounts/fireworks/models/glm-4p5","name":"GLM 4.5","attachment":false,"reasoning":true,"temperature":true,"tool_call":true,"knowledge":"2025-04","release_date":"2025-07-29","last_updated":"2025-07-29","modalities":{"input":["text"],"output":["text"]},"open_weights":true,"cost":{"input":0.55,"output":2.19},"limit":{"context":131072,"output":131072},"display_name":"GLM 4.5"}]},"modelscope":{"id":"modelscope","api":"https://api-inference.modelscope.cn/v1","name":"ModelScope","doc":"https://modelscope.cn/docs/model-service/API-Inference/intro","display_name":"ModelScope","models":[{"id":"ZhipuAI/GLM-4.5","name":"GLM-4.5","attachment":false,"reasoning":true,"temperature":true,"tool_call":true,"knowledge":"2025-04","release_date":"2025-07-28","last_updated":"2025-07-28","modalities":{"input":["text"],"output":["text"]},"open_weights":true,"cost":{"input":0,"output":0},"limit":{"context":131072,"output":98304},"display_name":"GLM-4.5"},{"id":"Qwen/Qwen3-30B-A3B-Thinking-2507","name":"Qwen3 30B A3B Thinking 2507","attachment":false,"reasoning":true,"temperature":true,"tool_call":true,"knowledge":"2025-04","release_date":"2025-07-30","last_updated":"2025-07-30","modalities":{"input":["text"],"output":["text"]},"open_weights":true,"cost":{"input":0,"output":0},"limit":{"context":262144,"output":32768},"display_name":"Qwen3 30B A3B Thinking 2507"},{"id":"Qwen/Qwen3-235B-A22B-Instruct-2507","name":"Qwen3 235B A22B Instruct 2507","attachment":false,"reasoning":false,"temperature":true,"tool_call":true,"knowledge":"2025-04","release_date":"2025-04-28","last_updated":"2025-07-21","modalities":{"input":["text"],"output":["text"]},"open_weights":true,"cost":{"input":0,"output":0},"limit":{"context":262144,"output":131072},"display_name":"Qwen3 235B A22B Instruct 2507"},{"id":"Qwen/Qwen3-Coder-30B-A3B-Instruct","name":"Qwen3 Coder 30B A3B Instruct","attachment":false,"reasoning":false,"temperature":true,"tool_call":true,"knowledge":"2025-04","release_date":"2025-07-31","last_updated":"2025-07-31","modalities":{"input":["text"],"output":["text"]},"open_weights":true,"cost":{"input":0,"output":0},"limit":{"context":262144,"output":65536},"display_name":"Qwen3 Coder 30B A3B Instruct"},{"id":"Qwen/Qwen3-Coder-480B-A35B-Instruct","name":"Qwen3-Coder-480B-A35B-Instruct","attachment":false,"reasoning":false,"temperature":true,"tool_call":true,"knowledge":"2025-04","release_date":"2025-07-23","last_updated":"2025-07-23","modalities":{"input":["text"],"output":["text"]},"open_weights":true,"cost":{"input":0,"output":0},"limit":{"context":262144,"output":66536},"display_name":"Qwen3-Coder-480B-A35B-Instruct"},{"id":"Qwen/Qwen3-30B-A3B-Instruct-2507","name":"Qwen3 30B A3B Instruct 2507","attachment":false,"reasoning":false,"temperature":true,"tool_call":true,"knowledge":"2025-04","release_date":"2025-07-30","last_updated":"2025-07-30","modalities":{"input":["text"],"output":["text"]},"open_weights":true,"cost":{"input":0,"output":0},"limit":{"context":262144,"output":16384},"display_name":"Qwen3 30B A3B Instruct 2507"},{"id":"Qwen/Qwen3-235B-A22B-Thinking-2507","name":"Qwen3-235B-A22B-Thinking-2507","attachment":false,"reasoning":true,"temperature":true,"tool_call":true,"knowledge":"2025-04","release_date":"2025-07-25","last_updated":"2025-07-25","modalities":{"input":["text"],"output":["text"]},"open_weights":true,"cost":{"input":0,"output":0},"limit":{"context":262144,"output":131072},"display_name":"Qwen3-235B-A22B-Thinking-2507"}]},"llama":{"id":"llama","api":"https://api.llama.com/compat/v1/","name":"Llama","doc":"https://llama.developer.meta.com/docs/models","display_name":"Llama","models":[{"id":"llama-3.3-8b-instruct","name":"Llama-3.3-8B-Instruct","attachment":true,"reasoning":false,"temperature":true,"tool_call":true,"knowledge":"2023-12","release_date":"2024-12-06","last_updated":"2024-12-06","modalities":{"input":["text"],"output":["text"]},"open_weights":true,"cost":{"input":0,"output":0},"limit":{"context":128000,"output":4096},"display_name":"Llama-3.3-8B-Instruct"},{"id":"llama-4-maverick-17b-128e-instruct-fp8","name":"Llama-4-Maverick-17B-128E-Instruct-FP8","attachment":true,"reasoning":false,"temperature":true,"tool_call":true,"knowledge":"2024-08","release_date":"2025-04-05","last_updated":"2025-04-05","modalities":{"input":["text","image"],"output":["text"]},"open_weights":true,"cost":{"input":0,"output":0},"limit":{"context":128000,"output":4096},"display_name":"Llama-4-Maverick-17B-128E-Instruct-FP8"},{"id":"llama-3.3-70b-instruct","name":"Llama-3.3-70B-Instruct","attachment":true,"reasoning":false,"temperature":true,"tool_call":true,"knowledge":"2023-12","release_date":"2024-12-06","last_updated":"2024-12-06","modalities":{"input":["text"],"output":["text"]},"open_weights":true,"cost":{"input":0,"output":0},"limit":{"context":128000,"output":4096},"display_name":"Llama-3.3-70B-Instruct"},{"id":"llama-4-scout-17b-16e-instruct-fp8","name":"Llama-4-Scout-17B-16E-Instruct-FP8","attachment":true,"reasoning":false,"temperature":true,"tool_call":true,"knowledge":"2024-08","release_date":"2025-04-05","last_updated":"2025-04-05","modalities":{"input":["text","image"],"output":["text"]},"open_weights":true,"cost":{"input":0,"output":0},"limit":{"context":128000,"output":4096},"display_name":"Llama-4-Scout-17B-16E-Instruct-FP8"},{"id":"groq-llama-4-maverick-17b-128e-instruct","name":"Groq-Llama-4-Maverick-17B-128E-Instruct","attachment":true,"reasoning":false,"temperature":true,"tool_call":true,"knowledge":"2025-01","release_date":"2025-04-05","last_updated":"2025-04-05","modalities":{"input":["text"],"output":["text"]},"open_weights":true,"cost":{"input":0,"output":0},"limit":{"context":128000,"output":4096},"display_name":"Groq-Llama-4-Maverick-17B-128E-Instruct"},{"id":"cerebras-llama-4-scout-17b-16e-instruct","name":"Cerebras-Llama-4-Scout-17B-16E-Instruct","attachment":true,"reasoning":false,"temperature":true,"tool_call":true,"knowledge":"2025-01","release_date":"2025-04-05","last_updated":"2025-04-05","modalities":{"input":["text"],"output":["text"]},"open_weights":true,"cost":{"input":0,"output":0},"limit":{"context":128000,"output":4096},"display_name":"Cerebras-Llama-4-Scout-17B-16E-Instruct"},{"id":"cerebras-llama-4-maverick-17b-128e-instruct","name":"Cerebras-Llama-4-Maverick-17B-128E-Instruct","attachment":true,"reasoning":false,"temperature":true,"tool_call":true,"knowledge":"2025-01","release_date":"2025-04-05","last_updated":"2025-04-05","modalities":{"input":["text"],"output":["text"]},"open_weights":true,"cost":{"input":0,"output":0},"limit":{"context":128000,"output":4096},"display_name":"Cerebras-Llama-4-Maverick-17B-128E-Instruct"}]},"amazon-bedrock":{"id":"amazon-bedrock","name":"Amazon Bedrock","doc":"https://docs.aws.amazon.com/bedrock/latest/userguide/models-supported.html","display_name":"Amazon Bedrock","models":[{"id":"cohere.command-r-plus-v1:0","name":"Command R+","attachment":false,"reasoning":false,"temperature":true,"tool_call":true,"knowledge":"2024-04","release_date":"2024-04-04","last_updated":"2024-04-04","modalities":{"input":["text"],"output":["text"]},"open_weights":true,"cost":{"input":3,"output":15},"limit":{"context":128000,"output":4096},"display_name":"Command R+"},{"id":"anthropic.claude-v2","name":"Claude 2","attachment":false,"reasoning":false,"temperature":true,"tool_call":false,"knowledge":"2023-08","release_date":"2023-07-11","last_updated":"2023-07-11","modalities":{"input":["text"],"output":["text"]},"open_weights":false,"cost":{"input":8,"output":24},"limit":{"context":100000,"output":4096},"display_name":"Claude 2"},{"id":"anthropic.claude-3-7-sonnet-20250219-v1:0","name":"Claude Sonnet 3.7","attachment":true,"reasoning":false,"temperature":true,"tool_call":true,"knowledge":"2024-04","release_date":"2025-02-19","last_updated":"2025-02-19","modalities":{"input":["text","image"],"output":["text"]},"open_weights":false,"cost":{"input":3,"output":15,"cache_read":0.3,"cache_write":3.75},"limit":{"context":200000,"output":8192},"display_name":"Claude Sonnet 3.7"},{"id":"anthropic.claude-sonnet-4-20250514-v1:0","name":"Claude Sonnet 4","attachment":true,"reasoning":true,"temperature":true,"tool_call":true,"knowledge":"2024-04","release_date":"2025-05-22","last_updated":"2025-05-22","modalities":{"input":["text","image"],"output":["text"]},"open_weights":false,"cost":{"input":3,"output":15,"cache_read":0.3,"cache_write":3.75},"limit":{"context":200000,"output":64000},"display_name":"Claude Sonnet 4"},{"id":"meta.llama3-2-11b-instruct-v1:0","name":"Llama 3.2 11B Instruct","attachment":true,"reasoning":false,"temperature":true,"tool_call":true,"knowledge":"2023-12","release_date":"2024-09-25","last_updated":"2024-09-25","modalities":{"input":["text","image"],"output":["text"]},"open_weights":true,"cost":{"input":0.16,"output":0.16},"limit":{"context":128000,"output":4096},"display_name":"Llama 3.2 11B Instruct"},{"id":"anthropic.claude-3-haiku-20240307-v1:0","name":"Claude Haiku 3","attachment":true,"reasoning":false,"temperature":true,"tool_call":true,"knowledge":"2024-02","release_date":"2024-03-13","last_updated":"2024-03-13","modalities":{"input":["text","image"],"output":["text"]},"open_weights":false,"cost":{"input":0.25,"output":1.25},"limit":{"context":200000,"output":4096},"display_name":"Claude Haiku 3"},{"id":"meta.llama3-2-90b-instruct-v1:0","name":"Llama 3.2 90B Instruct","attachment":true,"reasoning":false,"temperature":true,"tool_call":true,"knowledge":"2023-12","release_date":"2024-09-25","last_updated":"2024-09-25","modalities":{"input":["text","image"],"output":["text"]},"open_weights":true,"cost":{"input":0.72,"output":0.72},"limit":{"context":128000,"output":4096},"display_name":"Llama 3.2 90B Instruct"},{"id":"meta.llama3-2-1b-instruct-v1:0","name":"Llama 3.2 1B Instruct","attachment":false,"reasoning":false,"temperature":true,"tool_call":true,"knowledge":"2023-12","release_date":"2024-09-25","last_updated":"2024-09-25","modalities":{"input":["text"],"output":["text"]},"open_weights":true,"cost":{"input":0.1,"output":0.1},"limit":{"context":131000,"output":4096},"display_name":"Llama 3.2 1B Instruct"},{"id":"anthropic.claude-v2:1","name":"Claude 2.1","attachment":false,"reasoning":false,"temperature":true,"tool_call":false,"knowledge":"2023-08","release_date":"2023-11-21","last_updated":"2023-11-21","modalities":{"input":["text"],"output":["text"]},"open_weights":false,"cost":{"input":8,"output":24},"limit":{"context":200000,"output":4096},"display_name":"Claude 2.1"},{"id":"cohere.command-light-text-v14","name":"Command Light","attachment":false,"reasoning":false,"temperature":true,"tool_call":false,"knowledge":"2023-08","release_date":"2023-11-01","last_updated":"2023-11-01","modalities":{"input":["text"],"output":["text"]},"open_weights":true,"cost":{"input":0.3,"output":0.6},"limit":{"context":4096,"output":4096},"display_name":"Command Light"},{"id":"ai21.jamba-1-5-large-v1:0","name":"Jamba 1.5 Large","attachment":false,"reasoning":false,"temperature":true,"tool_call":true,"knowledge":"2024-08","release_date":"2024-08-15","last_updated":"2024-08-15","modalities":{"input":["text"],"output":["text"]},"open_weights":true,"cost":{"input":2,"output":8},"limit":{"context":256000,"output":4096},"display_name":"Jamba 1.5 Large"},{"id":"meta.llama3-3-70b-instruct-v1:0","name":"Llama 3.3 70B Instruct","attachment":false,"reasoning":false,"temperature":true,"tool_call":true,"knowledge":"2023-12","release_date":"2024-12-06","last_updated":"2024-12-06","modalities":{"input":["text"],"output":["text"]},"open_weights":true,"cost":{"input":0.72,"output":0.72},"limit":{"context":128000,"output":4096},"display_name":"Llama 3.3 70B Instruct"},{"id":"anthropic.claude-3-opus-20240229-v1:0","name":"Claude Opus 3","attachment":true,"reasoning":false,"temperature":true,"tool_call":true,"knowledge":"2023-08","release_date":"2024-02-29","last_updated":"2024-02-29","modalities":{"input":["text","image"],"output":["text"]},"open_weights":false,"cost":{"input":15,"output":75},"limit":{"context":200000,"output":4096},"display_name":"Claude Opus 3"},{"id":"amazon.nova-pro-v1:0","name":"Nova Pro","attachment":true,"reasoning":false,"temperature":true,"tool_call":true,"knowledge":"2024-10","release_date":"2024-12-03","last_updated":"2024-12-03","modalities":{"input":["text","image","video"],"output":["text"]},"open_weights":false,"cost":{"input":0.8,"output":3.2,"cache_read":0.2},"limit":{"context":300000,"output":8192},"display_name":"Nova Pro"},{"id":"meta.llama3-1-8b-instruct-v1:0","name":"Llama 3.1 8B Instruct","attachment":false,"reasoning":false,"temperature":true,"tool_call":true,"knowledge":"2023-12","release_date":"2024-07-23","last_updated":"2024-07-23","modalities":{"input":["text"],"output":["text"]},"open_weights":true,"cost":{"input":0.22,"output":0.22},"limit":{"context":128000,"output":4096},"display_name":"Llama 3.1 8B Instruct"},{"id":"anthropic.claude-3-5-sonnet-20240620-v1:0","name":"Claude Sonnet 3.5","attachment":true,"reasoning":false,"temperature":true,"tool_call":true,"knowledge":"2024-04","release_date":"2024-06-20","last_updated":"2024-06-20","modalities":{"input":["text","image"],"output":["text"]},"open_weights":false,"cost":{"input":3,"output":15,"cache_read":0.3,"cache_write":3.75},"limit":{"context":200000,"output":8192},"display_name":"Claude Sonnet 3.5"},{"id":"cohere.command-r-v1:0","name":"Command R","attachment":false,"reasoning":false,"temperature":true,"tool_call":true,"knowledge":"2024-04","release_date":"2024-03-11","last_updated":"2024-03-11","modalities":{"input":["text"],"output":["text"]},"open_weights":true,"cost":{"input":0.5,"output":1.5},"limit":{"context":128000,"output":4096},"display_name":"Command R"},{"id":"amazon.nova-micro-v1:0","name":"Nova Micro","attachment":false,"reasoning":false,"temperature":true,"tool_call":true,"knowledge":"2024-10","release_date":"2024-12-03","last_updated":"2024-12-03","modalities":{"input":["text"],"output":["text"]},"open_weights":false,"cost":{"input":0.035,"output":0.14,"cache_read":0.00875},"limit":{"context":128000,"output":8192},"display_name":"Nova Micro"},{"id":"meta.llama3-1-70b-instruct-v1:0","name":"Llama 3.1 70B Instruct","attachment":false,"reasoning":false,"temperature":true,"tool_call":true,"knowledge":"2023-12","release_date":"2024-07-23","last_updated":"2024-07-23","modalities":{"input":["text"],"output":["text"]},"open_weights":true,"cost":{"input":0.72,"output":0.72},"limit":{"context":128000,"output":4096},"display_name":"Llama 3.1 70B Instruct"},{"id":"meta.llama3-70b-instruct-v1:0","name":"Llama 3 70B Instruct","attachment":false,"reasoning":false,"temperature":true,"tool_call":false,"knowledge":"2023-12","release_date":"2024-07-23","last_updated":"2024-07-23","modalities":{"input":["text"],"output":["text"]},"open_weights":true,"cost":{"input":2.65,"output":3.5},"limit":{"context":8192,"output":2048},"display_name":"Llama 3 70B Instruct"},{"id":"deepseek.r1-v1:0","name":"DeepSeek-R1","attachment":false,"reasoning":true,"temperature":true,"tool_call":true,"knowledge":"2024-07","release_date":"2025-01-20","last_updated":"2025-05-29","modalities":{"input":["text"],"output":["text"]},"open_weights":false,"cost":{"input":1.35,"output":5.4},"limit":{"context":128000,"output":32768},"display_name":"DeepSeek-R1"},{"id":"anthropic.claude-3-5-sonnet-20241022-v2:0","name":"Claude Sonnet 3.5 v2","attachment":true,"reasoning":false,"temperature":true,"tool_call":true,"knowledge":"2024-04","release_date":"2024-10-22","last_updated":"2024-10-22","modalities":{"input":["text","image"],"output":["text"]},"open_weights":false,"cost":{"input":3,"output":15,"cache_read":0.3,"cache_write":3.75},"limit":{"context":200000,"output":8192},"display_name":"Claude Sonnet 3.5 v2"},{"id":"cohere.command-text-v14","name":"Command","attachment":false,"reasoning":false,"temperature":true,"tool_call":false,"knowledge":"2023-08","release_date":"2023-11-01","last_updated":"2023-11-01","modalities":{"input":["text"],"output":["text"]},"open_weights":true,"cost":{"input":1.5,"output":2},"limit":{"context":4096,"output":4096},"display_name":"Command"},{"id":"anthropic.claude-opus-4-20250514-v1:0","name":"Claude Opus 4","attachment":true,"reasoning":true,"temperature":true,"tool_call":true,"knowledge":"2024-04","release_date":"2025-05-22","last_updated":"2025-05-22","modalities":{"input":["text","image"],"output":["text"]},"open_weights":false,"cost":{"input":15,"output":75,"cache_read":1.5,"cache_write":18.75},"limit":{"context":200000,"output":32000},"display_name":"Claude Opus 4"},{"id":"anthropic.claude-sonnet-4-5-20250929-v1:0","name":"Claude Sonnet 4.5","attachment":true,"reasoning":true,"temperature":true,"tool_call":true,"knowledge":"2025-07-31","release_date":"2025-09-29","last_updated":"2025-09-29","modalities":{"input":["text","image"],"output":["text"]},"open_weights":false,"cost":{"input":3,"output":15,"cache_read":0.3,"cache_write":3.75},"limit":{"context":200000,"output":64000},"display_name":"Claude Sonnet 4.5"},{"id":"meta.llama3-2-3b-instruct-v1:0","name":"Llama 3.2 3B Instruct","attachment":false,"reasoning":false,"temperature":true,"tool_call":true,"knowledge":"2023-12","release_date":"2024-09-25","last_updated":"2024-09-25","modalities":{"input":["text"],"output":["text"]},"open_weights":true,"cost":{"input":0.15,"output":0.15},"limit":{"context":131000,"output":4096},"display_name":"Llama 3.2 3B Instruct"},{"id":"anthropic.claude-instant-v1","name":"Claude Instant","attachment":false,"reasoning":false,"temperature":true,"tool_call":false,"knowledge":"2023-08","release_date":"2023-03-01","last_updated":"2023-03-01","modalities":{"input":["text"],"output":["text"]},"open_weights":false,"cost":{"input":0.8,"output":2.4},"limit":{"context":100000,"output":4096},"display_name":"Claude Instant"},{"id":"amazon.nova-premier-v1:0","name":"Nova Premier","attachment":true,"reasoning":true,"temperature":true,"tool_call":true,"knowledge":"2024-10","release_date":"2024-12-03","last_updated":"2024-12-03","modalities":{"input":["text","image","video"],"output":["text"]},"open_weights":false,"cost":{"input":2.5,"output":12.5},"limit":{"context":1000000,"output":16384},"display_name":"Nova Premier"},{"id":"anthropic.claude-opus-4-1-20250805-v1:0","name":"Claude Opus 4.1","attachment":true,"reasoning":true,"temperature":true,"tool_call":true,"knowledge":"2025-03-31","release_date":"2025-08-05","last_updated":"2025-08-05","modalities":{"input":["text","image"],"output":["text"]},"open_weights":false,"cost":{"input":15,"output":75,"cache_read":1.5,"cache_write":18.75},"limit":{"context":200000,"output":32000},"display_name":"Claude Opus 4.1"},{"id":"meta.llama4-scout-17b-instruct-v1:0","name":"Llama 4 Scout 17B Instruct","attachment":true,"reasoning":false,"temperature":true,"tool_call":true,"knowledge":"2024-08","release_date":"2025-04-05","last_updated":"2025-04-05","modalities":{"input":["text","image"],"output":["text"]},"open_weights":true,"cost":{"input":0.17,"output":0.66},"limit":{"context":3500000,"output":16384},"display_name":"Llama 4 Scout 17B Instruct"},{"id":"ai21.jamba-1-5-mini-v1:0","name":"Jamba 1.5 Mini","attachment":false,"reasoning":false,"temperature":true,"tool_call":true,"knowledge":"2024-08","release_date":"2024-08-15","last_updated":"2024-08-15","modalities":{"input":["text"],"output":["text"]},"open_weights":true,"cost":{"input":0.2,"output":0.4},"limit":{"context":256000,"output":4096},"display_name":"Jamba 1.5 Mini"},{"id":"meta.llama3-8b-instruct-v1:0","name":"Llama 3 8B Instruct","attachment":false,"reasoning":false,"temperature":true,"tool_call":false,"knowledge":"2023-03","release_date":"2024-07-23","last_updated":"2024-07-23","modalities":{"input":["text"],"output":["text"]},"open_weights":true,"cost":{"input":0.3,"output":0.6},"limit":{"context":8192,"output":2048},"display_name":"Llama 3 8B Instruct"},{"id":"anthropic.claude-3-sonnet-20240229-v1:0","name":"Claude Sonnet 3","attachment":true,"reasoning":false,"temperature":true,"tool_call":true,"knowledge":"2023-08","release_date":"2024-03-04","last_updated":"2024-03-04","modalities":{"input":["text","image"],"output":["text"]},"open_weights":false,"cost":{"input":3,"output":15},"limit":{"context":200000,"output":4096},"display_name":"Claude Sonnet 3"},{"id":"meta.llama4-maverick-17b-instruct-v1:0","name":"Llama 4 Maverick 17B Instruct","attachment":true,"reasoning":false,"temperature":true,"tool_call":true,"knowledge":"2024-08","release_date":"2025-04-05","last_updated":"2025-04-05","modalities":{"input":["text","image"],"output":["text"]},"open_weights":true,"cost":{"input":0.24,"output":0.97},"limit":{"context":1000000,"output":16384},"display_name":"Llama 4 Maverick 17B Instruct"},{"id":"amazon.nova-lite-v1:0","name":"Nova Lite","attachment":true,"reasoning":false,"temperature":true,"tool_call":true,"knowledge":"2024-10","release_date":"2024-12-03","last_updated":"2024-12-03","modalities":{"input":["text","image","video"],"output":["text"]},"open_weights":false,"cost":{"input":0.06,"output":0.24,"cache_read":0.015},"limit":{"context":300000,"output":8192},"display_name":"Nova Lite"},{"id":"anthropic.claude-3-5-haiku-20241022-v1:0","name":"Claude Haiku 3.5","attachment":true,"reasoning":false,"temperature":true,"tool_call":true,"knowledge":"2024-07","release_date":"2024-10-22","last_updated":"2024-10-22","modalities":{"input":["text"],"output":["text"]},"open_weights":false,"cost":{"input":0.8,"output":4,"cache_read":0.08,"cache_write":1},"limit":{"context":200000,"output":8192},"display_name":"Claude Haiku 3.5"}]},"cerebras":{"id":"cerebras","name":"Cerebras","doc":"https://inference-docs.cerebras.ai/models/overview","display_name":"Cerebras","models":[{"id":"qwen-3-235b-a22b-instruct-2507","name":"Qwen 3 235B Instruct","attachment":false,"reasoning":false,"temperature":true,"tool_call":true,"knowledge":"2025-04","release_date":"2025-07-22","last_updated":"2025-07-22","modalities":{"input":["text"],"output":["text"]},"open_weights":true,"cost":{"input":0.6,"output":1.2},"limit":{"context":131000,"output":32000},"display_name":"Qwen 3 235B Instruct"},{"id":"qwen-3-coder-480b","name":"Qwen 3 Coder 480B","attachment":false,"reasoning":false,"temperature":true,"tool_call":true,"knowledge":"2025-04","release_date":"2025-07-23","last_updated":"2025-07-23","modalities":{"input":["text"],"output":["text"]},"open_weights":true,"cost":{"input":2,"output":2},"limit":{"context":131000,"output":32000},"display_name":"Qwen 3 Coder 480B"},{"id":"gpt-oss-120b","name":"GPT OSS 120B","attachment":false,"reasoning":true,"temperature":true,"tool_call":true,"release_date":"2025-08-05","last_updated":"2025-08-05","modalities":{"input":["text"],"output":["text"]},"open_weights":true,"cost":{"input":0.25,"output":0.69},"limit":{"context":131072,"output":32768},"display_name":"GPT OSS 120B"}]},"aihubmix":{"id":"aihubmix","name":"aihubmix","display_name":"aihubmix","updated_at":"2025-10-03T14:35:02.904Z","api":"https://aihubmix.com/call/mdl_info","models":[{"id":"AiHubmix-Phi-4-mini-reasoning","name":"Phi-4-mini-reasoning","display_name":"Phi-4-mini-reasoning","type":"chat","context_length":0,"max_output_tokens":0,"capabilities":{"vision":false,"function_calling":false,"reasoning":true,"tool_calling":false},"reasoning":true,"tool_call":false,"metadata":{"developer":"Microsoft","developerId":3,"providerId":45,"modelRatio":0.06,"cacheRatio":1,"completionRatio":1,"description":"Phi-4-mini-reasoning \n\nPhi-4-mini-reasoning 128K","descriptionEn":"Phi-4-mini-reasoning is a lightweight open model designed for advanced mathematical reasoning and logic-intensive problem-solving. It is particularly well-suited for tasks such as formal proofs, symbolic computation, and solving multi-step word problems. With its efficient architecture, the model balances high-quality reasoning performance with cost-effective deployment, making it ideal for educational applications, embedded tutoring, and lightweight edge or mobile systems.\n\nPhi-4-mini-reasoning supports a 128K token context length, enabling it to process and reason over long mathematical problems and proofs. Built on synthetic and high-quality math datasets, the model leverages advanced fine-tuning techniques such as supervised fine-tuning and preference modeling to enhance reasoning capabilities. Its training incorporates safety and alignment protocols, ensuring robust and reliable performance across supported use cases.","order":49,"flag":1,"features":["thinking"],"typeHints":["t2t"],"source":"public-provider-conf"},"vision":false},{"id":"AiHubmix-Phi-4-reasoning","name":"Phi-4-reasoning","display_name":"Phi-4-reasoning","type":"chat","context_length":0,"max_output_tokens":0,"capabilities":{"vision":false,"function_calling":false,"reasoning":true,"tool_calling":false},"reasoning":true,"tool_call":false,"metadata":{"developer":"Microsoft","developerId":3,"providerId":8,"modelRatio":0.1,"cacheRatio":1,"completionRatio":1,"description":"Phi-4-Reasoning  Phi-4 ","descriptionEn":"Phi-4-Reasoning is a state-of-the-art open-weight reasoning model finetuned from Phi-4 using supervised fine-tuning on a dataset of chain-of-thought traces and reinforcement learning. The supervised fine-tuning dataset includes a blend of synthetic prompts and high-quality filtered data from public domain websites, focused on math, science, and coding skills as well as alignment data for safety and Responsible AI. The goal of this approach was to ensure that small capable models were trained with data focused on high quality and advanced reasoning.","order":50,"flag":1,"features":["thinking"],"typeHints":["t2t"],"source":"public-provider-conf"},"vision":false},{"id":"ByteDance-Seed/Seed-OSS-36B-Instruct","name":"ByteDance-Seed/Seed-OSS-36B-Instruct","display_name":"ByteDance-Seed/Seed-OSS-36B-Instruct","type":"chat","context_length":0,"max_output_tokens":0,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"developer":"Doubao","developerId":4,"providerId":44,"modelRatio":0.1,"cacheRatio":1,"completionRatio":2.67,"description":"Seed-OSS  Seed agent Seed-OSS-36B-Instruct  360 Thinking Budget","descriptionEn":"Seed-OSS is a series of open-source large language models developed by ByteDance's Seed team, designed specifically for powerful long-context processing, reasoning, agents, and general capabilities. Among this series, Seed-OSS-36B-Instruct is an instruction-tuned model with 36 billion parameters that natively supports ultra-long context lengths, enabling it to process massive documents or complex codebases in a single pass. This model is specially optimized for reasoning, code generation, and agent tasks (such as tool usage), while maintaining balanced and excellent general capabilities. A notable feature of this model is the \"Thinking Budget\" functionality, which allows users to flexibly adjust the inference length as needed, thereby effectively improving inference efficiency in practical applications.","order":220,"flag":1,"source":"public-provider-conf"},"vision":false},{"id":"DESCRIBE","name":"describe","display_name":"describe","type":"image-generation","context_length":0,"max_output_tokens":0,"capabilities":{"vision":true,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"modalities":{"input":["text","image"],"output":["text","image"]},"metadata":{"developer":"Ideogram","developerId":21,"providerId":8,"modelRatio":1,"cacheRatio":0,"completionRatio":1,"description":" US $0.01Ideogram AI describe\n\n https://docs.aihubmix.com/cn/api/IdeogramAI","descriptionEn":"This endpoint is used to describe an image.\nSupported image formats include JPEG, PNG, and WebP.\nUS $0.01/ IMG.\nFor usage examples and pricing details, refer to the documentation at https://docs.aihubmix.com/cn/api/IdeogramAI.","order":1,"flag":0,"usage":"","displayInput":"-","displayOutput":"$0.01 / IMG","tags":["best"],"modalities":["text","image"],"typeHints":["t2i"],"source":"public-provider-conf"},"vision":true},{"id":"DeepSeek-R1","name":"DeepSeek-R1","display_name":"DeepSeek-R1","type":"chat","context_length":64000,"max_output_tokens":64000,"capabilities":{"vision":false,"function_calling":false,"reasoning":true,"tool_calling":false},"reasoning":true,"tool_call":false,"modalities":{"input":["text"],"output":["text"]},"metadata":{"developer":"DeepSeek","developerId":7,"providerId":36,"modelRatio":0.273,"cacheRatio":1,"completionRatio":4,"description":"250528 R1 671B 64k","descriptionEn":"DeepSeek-R1 has been automatically upgraded to the latest version 250528;Open-source deployment R1, with a total parameter count of 671B and a maximum input of 64k; currently the most stable, recommended to use this one.","order":820,"flag":2,"features":["thinking"],"tags":["best","economical"],"modalities":["text"],"typeHints":["t2t"],"source":"public-provider-conf"},"vision":false},{"id":"DeepSeek-R1-0528","name":"DeepSeek-R1-0528","display_name":"DeepSeek-R1-0528","type":"chat","context_length":0,"max_output_tokens":0,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"developer":"DeepSeek","developerId":7,"providerId":8,"modelRatio":0.27,"cacheRatio":1,"completionRatio":4,"description":"sophnetDeepSeek R1 0528 \nDeepSeek R1\n\n\nDeepSeek R1 0528DeepSeek R1OpenAI-o3 ","descriptionEn":"The model provider is the Sophnet platform. The DeepSeek R1 0528 model has achieved performance improvements in multiple areas, excelling in programming skills, aesthetic design, and code completion, particularly demonstrating high accuracy and efficiency in handling complex instructions and front-end page generation.\nDeepSeek R1 is the first large-scale language model trained purely through reinforcement learning (without supervised fine-tuning).\nDuring the reinforcement learning process, it naturally developed various powerful reasoning capabilities.\nBy introducing cold-start data before reinforcement learning, it addresses issues such as infinite repetition, poor readability, and language mixing.\nDeepSeek R1 0528, as an upgraded version of DeepSeek R1, has comprehensive capabilities comparable to OpenAI-o3.","order":400,"flag":0,"source":"public-provider-conf"},"vision":false},{"id":"DeepSeek-R1-Distill-Qwen-32B","name":"DeepSeek-R1-Distill-Qwen-32B","display_name":"DeepSeek-R1-Distill-Qwen-32B","type":"chat","context_length":0,"max_output_tokens":0,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"developer":"DeepSeek","developerId":7,"providerId":8,"modelRatio":0.14,"cacheRatio":1,"completionRatio":3,"description":"sophnetDeepseek-R1-Distill-Qwen-32B  Qwen 2.5 32B  DeepSeek R1 \nDeepSeek-R1 \nDeepSeek-R1  OpenAI-o1 \n DeepSeek-R1-ZeroDeepSeek-R1  Llama  Qwen \nDeepSeek-R1-Distill-Qwen-32B  OpenAI-o1-mini\n","descriptionEn":"The model provider is the Sophnet platform. Deepseek-R1-Distill-Qwen-32B is a knowledge-distilled large language model based on Qwen 2.5 32B and trained using outputs from DeepSeek R1.\nDeepSeek-R1 addresses issues such as infinite repetition, poor readability, and language mixing by introducing cold-start data before reinforcement learning.\nDeepSeek-R1s performance in mathematics, programming, and reasoning tasks is comparable to OpenAI-o1.\nTo support the research community, we have open-sourced DeepSeek-R1-Zero, DeepSeek-R1, and six dense models based on Llama and Qwen.\nDeepSeek-R1-Distill-Qwen-32B outperforms OpenAI-o1-mini on multiple benchmark tests, setting new state-of-the-art results for dense models.","order":400,"flag":0,"source":"public-provider-conf"},"vision":false},{"id":"DeepSeek-R1-Distill-Qwen-7B","name":"DeepSeek-R1-Distill-Qwen-7B","display_name":"DeepSeek-R1-Distill-Qwen-7B","type":"chat","context_length":0,"max_output_tokens":0,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"developer":"DeepSeek","developerId":7,"providerId":8,"modelRatio":0.03,"cacheRatio":1,"completionRatio":2,"description":"sophnetDeepSeek-R1-Distill-Qwen-7B  Qwen  7B  70% 40%\nAPI  Qwen-7B  1/4\n\n GSM8K  65%","descriptionEn":"The model provider is the Sophnet platform. DeepSeek-R1-Distill-Qwen-7B is a distilled model based on the Qwen architecture, optimized for high reasoning speed and low cost. It achieves approximately 70% of the performance of the original model at the 7B scale, while reducing response latency by 40%, making it suitable for real-time interactive scenarios.\nThe API call cost is only one-quarter of the original Qwen-7B.\nIt supports streaming output, making it suitable for applications like chatbots.\nIt achieves an accuracy of over 65% on the GSM8K math task.","order":400,"flag":0,"source":"public-provider-conf"},"vision":false},{"id":"DeepSeek-V3","name":"DeepSeek-V3","display_name":"DeepSeek-V3","type":"chat","context_length":0,"max_output_tokens":0,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"modalities":{"input":["text"],"output":["text"]},"metadata":{"developer":"DeepSeek","developerId":7,"providerId":36,"modelRatio":0.136,"cacheRatio":1,"completionRatio":4,"description":" 250324","descriptionEn":"The open-source deployment is currently the most stable, recommended to use this.\nAutomatically upgraded to the latest released version 250324.","order":700,"flag":2,"tags":["best","economical"],"modalities":["text"],"typeHints":["t2t"],"source":"public-provider-conf"},"vision":false},{"id":"DeepSeek-V3-Fast","name":"DeepSeek-V3-Fast","display_name":"DeepSeek-V3-Fast","type":"chat","context_length":0,"max_output_tokens":0,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"developer":"DeepSeek","developerId":7,"providerId":8,"modelRatio":0.28,"cacheRatio":1,"completionRatio":4,"description":"V37310.55/M2.2/MsophnetDeepSeek V3 Fast  DeepSeek V3 0324 TPS\nDeepSeek V3 0324 (MoE)671Btoken37B\n(MLA)DeepSeekMoE\ntoken\n14.8token\nDeepSeek-V3\n2.788M H800 GPU","descriptionEn":"V3 Ultra-Fast Version,The current price is a limited-time 50% discount and will return to the original price on July 31st. The original price is: input: $0.55/M, output: $2.2/M. The model provider is the Sophnet platform. DeepSeek V3 Fast is a high-TPS, ultra-fast version of DeepSeek V3 0324, featuring full-precision (non-quantized) performance, enhanced code and math capabilities, and faster responses!\n\nDeepSeek V3 0324 is a powerful Mixture-of-Experts (MoE) model with a total parameter count of 671B, activating 37B parameters per token.\nIt adopts Multi-Head Latent Attention (MLA) and the DeepSeekMoE architecture to achieve efficient inference and economical training costs.\nIt innovatively implements a load balancing strategy without auxiliary loss and sets multi-token prediction training targets to enhance performance.\nThe model is pre-trained on 14.8 trillion diverse, high-quality tokens and further optimized through supervised fine-tuning and reinforcement learning stages to fully realize its capabilities.\nComprehensive evaluations show that DeepSeek V3 outperforms other open-source models and rivals leading closed-source models in performance.\nThe entire training process only requires 2.788M H800 GPU hours and remains highly stable, with no irrecoverable loss spikes or rollbacks.","order":821,"flag":1,"source":"public-provider-conf"},"vision":false},{"id":"DeepSeek-V3.1","name":"DeepSeek-V3.1","display_name":"DeepSeek-V3.1","type":"chat","context_length":0,"max_output_tokens":0,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"developer":"DeepSeek","developerId":7,"providerId":8,"modelRatio":0.28,"cacheRatio":1,"completionRatio":3,"description":"DeepSeek-V3.1-\nDeepSeek V3.1","descriptionEn":"DeepSeek-V3.1 - Non-Thinking Mode;  \nDeepSeek V3.1 is a text generation model provided by Deep Seek, featuring a hybrid reasoning architecture that effectively integrates thinking and non-thinking modes.","order":972,"flag":1,"source":"public-provider-conf"},"vision":false},{"id":"DeepSeek-V3.1-Fast","name":"DeepSeek-V3.1-Fast","display_name":"DeepSeek-V3.1-Fast","type":"chat","context_length":0,"max_output_tokens":0,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"developer":"DeepSeek","developerId":7,"providerId":8,"modelRatio":0.548,"cacheRatio":1,"completionRatio":3,"description":"sophnetDeepSeek V3.1 Fast  DeepSeek V3.1TPS\n\n","descriptionEn":"The model provider is the Sophon platform. DeepSeek V3.1 Fast is the high-TPS speed version of DeepSeek V3.1.\nHybrid thinking mode: By modifying the chat template, a single model can simultaneously support both thinking and non-thinking modes.\nSmarter tool usage: Through post-training optimization, the models performance in tool utilization and agent tasks has improved significantly.\n","order":862,"flag":1,"source":"public-provider-conf"},"vision":false},{"id":"DeepSeek-V3.1-Think","name":"DeepSeek-V3.1-Think","display_name":"DeepSeek-V3.1-Think","type":"chat","context_length":0,"max_output_tokens":0,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"developer":"DeepSeek","developerId":7,"providerId":15,"modelRatio":0.28,"cacheRatio":1,"completionRatio":3,"description":"DeepSeek-V3.1\nDeepSeek V3.1","descriptionEn":"Thinking mode of DeepSeek-V3.1;  \nDeepSeek V3.1 is a text generation model provided by DeepSeek, featuring a hybrid reasoning architecture that achieves an effective integration of thinking and non-thinking modes.","order":971,"flag":1,"source":"public-provider-conf"},"vision":false},{"id":"DeepSeek-V3.2-Exp","name":"DeepSeek-V3.2-Exp","display_name":"DeepSeek-V3.2-Exp","type":"chat","context_length":0,"max_output_tokens":0,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"developer":"DeepSeek","developerId":7,"providerId":36,"modelRatio":0.14,"cacheRatio":0.1,"completionRatio":1.5,"description":" DeepSeek-V3.2-Exp deepseek-chatExperimentalV3.2-Exp  V3.1-Terminus  DeepSeek Sparse Attention","descriptionEn":"The model DeepSeek-V3.2-Exp is officially named deepseek-chat on the website. It is an experimental version. As an intermediate step towards the next-generation architecture, V3.2-Exp introduces DeepSeek Sparse Attention (a sparse attention mechanism) based on V3.1-Terminus, exploring and validating exploratory optimizations for training and inference efficiency on long texts.","order":973,"flag":1,"source":"public-provider-conf"},"vision":false},{"id":"DeepSeek-V3.2-Exp-Think","name":"DeepSeek-V3.2-Exp-Think","display_name":"DeepSeek-V3.2-Exp-Think","type":"chat","context_length":0,"max_output_tokens":0,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"developer":"DeepSeek","developerId":7,"providerId":36,"modelRatio":0.14,"cacheRatio":0.1,"completionRatio":1.5,"description":"DeepSeek-V3.2-Exp-Think deepseek-reasonerExperimentalV3.2-Exp  V3.1-Terminus  DeepSeek Sparse Attention","descriptionEn":"The model DeepSeek-V3.2-Exp-Think is officially named deepseek-reasoner. It is an experimental version. As an intermediate step towards the next-generation architecture, V3.2-Exp introduces DeepSeek Sparse Attention (a sparse attention mechanism) based on V3.1-Terminus, exploring and validating exploratory optimizations for training and inference efficiency on long texts.","order":973,"flag":1,"source":"public-provider-conf"},"vision":false},{"id":"DeepSeek-v3","name":"DeepSeek-v3","display_name":"DeepSeek-v3","type":"chat","context_length":0,"max_output_tokens":0,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"developer":"DeepSeek","developerId":7,"providerId":8,"modelRatio":0.136,"cacheRatio":1,"completionRatio":4,"order":0,"flag":0,"source":"public-provider-conf"},"vision":false},{"id":"Doubao-1.5-lite-32k","name":"Doubao-1.5-lite-32k","display_name":"Doubao-1.5-lite-32k","type":"chat","context_length":0,"max_output_tokens":0,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"developer":"Doubao","developerId":4,"providerId":47,"modelRatio":0.025,"cacheRatio":1,"completionRatio":2,"description":"Doubao-1.5-lite32k12k tokens","descriptionEn":"Doubao-1.5-lite, a brand-new generation of lightweight model, offers exceptional response speed with both performance and latency reaching world-class levels. It supports a 32k context window and an output length of up to 12k tokens.","order":0,"flag":0,"billingConfig":"{\n  \"model_name\": \"Doubao-1.5-lite-32k\",\n  \"default_tier\": \"tier1\",\n  \"token_based_tier_configs\": {\n    \"tier1\": {\n      \"tier_condition\": {\n        \"min_tokens\": 0,\n        \"max_tokens\": -1\n      },\n      \"model_ratio\": 0.020548,\n      \"prompt_tokens_ratio\": 1.0,\n      \"completion_tokens_ratio\": 2.0,\n      \"cached_tokens_ratio\": 0.2\n    }\n  },\n  \"per_unit_price_config\": {\n    \"cache_storage_price\": 0.002329\n  },\n  \"enabled_billing_items\": [\n    \"prompt_tokens\",\n    \"completion_tokens\",\n    \"cached_tokens\",\n    \"cache_storage_hours\"\n  ]\n}","source":"public-provider-conf"},"vision":false},{"id":"Doubao-1.5-pro-256k","name":"Doubao-1.5-pro-256k","display_name":"Doubao-1.5-pro-256k","type":"chat","context_length":0,"max_output_tokens":0,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"developer":"Doubao","developerId":4,"providerId":47,"modelRatio":0.4,"cacheRatio":1,"completionRatio":1.8,"description":"Doubao-1.5-pro-256kDoubao-1.5-Pro10%256k12k tokens","descriptionEn":"Doubao-1.5-pro-256k, a fully upgraded version based on Doubao-1.5-Pro, delivers an overall performance improvement of 10%. It supports inference with a 256k context window and an output length of up to 12k tokens. With higher performance, larger window size, and exceptional cost-effectiveness, it is suitable for a wider range of application scenarios.","order":0,"flag":0,"billingConfig":"{\n  \"model_name\": \"Doubao-1.5-pro-256k\",\n  \"default_tier\": \"tier1\",\n  \"token_based_tier_configs\": {\n    \"tier1\": {\n      \"tier_condition\": {\n        \"min_tokens\": 0,\n        \"max_tokens\": -1\n      },\n      \"model_ratio\": 0.342466,\n      \"prompt_tokens_ratio\": 1.0,\n      \"completion_tokens_ratio\": 1.8\n    }\n  },\n  \"per_unit_price_config\": {},\n  \"enabled_billing_items\": [\n    \"prompt_tokens\",\n    \"completion_tokens\"\n  ]\n}","source":"public-provider-conf"},"vision":false},{"id":"Doubao-1.5-pro-32k","name":"Doubao-1.5-pro-32k","display_name":"Doubao-1.5-pro-32k","type":"chat","context_length":0,"max_output_tokens":0,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"developer":"Doubao","developerId":4,"providerId":47,"modelRatio":0.067,"cacheRatio":1,"completionRatio":2.5,"description":"Doubao-1.5-pro32k12k tokens","descriptionEn":"Doubao-1.5-pro, a brand-new generation of flagship model, features comprehensive performance upgrades and excels in knowledge, coding, reasoning, and other aspects. It supports a 32k context window and an output length of up to 12k tokens.","order":0,"flag":0,"billingConfig":"{\n  \"model_name\": \"Doubao-1.5-pro-32k\",\n  \"default_tier\": \"tier1\",\n  \"token_based_tier_configs\": {\n    \"tier1\": {\n      \"tier_condition\": {\n        \"min_tokens\": 0,\n        \"max_tokens\": -1\n      },\n      \"model_ratio\": 0.054795,\n      \"prompt_tokens_ratio\": 1.0,\n      \"completion_tokens_ratio\": 2.5,\n      \"cached_tokens_ratio\": 0.2\n    }\n  },\n  \"per_unit_price_config\": {\n    \"cache_storage_price\": 0.002329\n  },\n  \"enabled_billing_items\": [\n    \"prompt_tokens\",\n    \"completion_tokens\",\n    \"cached_tokens\",\n    \"cache_storage_hours\"\n  ]\n}","source":"public-provider-conf"},"vision":false},{"id":"Doubao-1.5-thinking-pro","name":"Doubao-1.5-thinking-pro","display_name":"Doubao-1.5-thinking-pro","type":"chat","context_length":0,"max_output_tokens":0,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"developer":"Doubao","developerId":4,"providerId":47,"modelRatio":0.31,"cacheRatio":1,"completionRatio":4,"description":"Doubao-1.5AIME 2024CodeforcesGPQA128k16k","descriptionEn":"Doubao-1.5 is a brand-new deep thinking model that excels in specialized fields such as mathematics, programming, scientific reasoning, and general tasks like creative writing. It achieves or approaches the top-tier industry level on multiple authoritative benchmarks including AIME 2024, Codeforces, and GPQA. It supports a 128k context window and 16k output.","order":200,"flag":1,"billingConfig":"{\n  \"model_name\": \"Doubao-1.5-thinking-pro\",\n  \"default_tier\": \"tier1\",\n  \"token_based_tier_configs\": {\n    \"tier1\": {\n      \"tier_condition\": {\n        \"min_tokens\": 0,\n        \"max_tokens\": -1\n      },\n      \"model_ratio\": 0.273973,\n      \"prompt_tokens_ratio\": 1.0,\n      \"completion_tokens_ratio\": 4.0\n    }\n  },\n  \"per_unit_price_config\": {},\n  \"enabled_billing_items\": [\n    \"prompt_tokens\",\n    \"completion_tokens\"\n  ]\n}","source":"public-provider-conf"},"vision":false},{"id":"Doubao-1.5-vision-pro-32k","name":"Doubao-1.5-vision-pro-32k","display_name":"Doubao-1.5-vision-pro-32k","type":"chat","context_length":0,"max_output_tokens":0,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"developer":"Doubao","developerId":4,"providerId":47,"modelRatio":0.23,"cacheRatio":1,"completionRatio":3,"description":"Doubao-1.5-vision-pro32k12k tokens","descriptionEn":"Doubao-1.5-vision-pro is a newly upgraded multimodal large model that supports image recognition at any resolution and extreme aspect ratios. It enhances visual reasoning, document recognition, detailed information understanding, and instruction-following capabilities. It supports a 32k context window and an output length of up to 12k tokens.","order":0,"flag":0,"source":"public-provider-conf"},"vision":false},{"id":"Doubao-lite-128k","name":"Doubao-lite-128k","display_name":"Doubao-lite-128k","type":"chat","context_length":0,"max_output_tokens":0,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"developer":"","developerId":4,"providerId":47,"modelRatio":0.07,"cacheRatio":1,"completionRatio":2,"order":0,"flag":0,"billingConfig":"{\n  \"model_name\": \"Doubao-lite-128k\",\n  \"default_tier\": \"tier1\",\n  \"token_based_tier_configs\": {\n    \"tier1\": {\n      \"tier_condition\": {\n        \"min_tokens\": 0,\n        \"max_tokens\": -1\n      },\n      \"model_ratio\": 0.054795,\n      \"prompt_tokens_ratio\": 1.0,\n      \"completion_tokens_ratio\": 1.25\n    }\n  },\n  \"per_unit_price_config\": {},\n  \"enabled_billing_items\": [\n    \"prompt_tokens\",\n    \"completion_tokens\"\n  ]\n}","source":"public-provider-conf"},"vision":false},{"id":"Doubao-lite-32k","name":"Doubao-lite-32k","display_name":"Doubao-lite-32k","type":"chat","context_length":0,"max_output_tokens":0,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"developer":"","developerId":4,"providerId":47,"modelRatio":0.03,"cacheRatio":1,"completionRatio":2,"order":0,"flag":0,"billingConfig":"{\n  \"model_name\": \"Doubao-lite-32k\",\n  \"default_tier\": \"tier1\",\n  \"token_based_tier_configs\": {\n    \"tier1\": {\n      \"tier_condition\": {\n        \"min_tokens\": 0,\n        \"max_tokens\": -1\n      },\n      \"model_ratio\": 0.020548,\n      \"prompt_tokens_ratio\": 1.0,\n      \"completion_tokens_ratio\": 2.0,\n      \"cached_tokens_ratio\": 0.2\n    }\n  },\n  \"per_unit_price_config\": {\n    \"cache_storage_price\": 0.002329\n  },\n  \"enabled_billing_items\": [\n    \"prompt_tokens\",\n    \"completion_tokens\",\n    \"cached_tokens\",\n    \"cache_storage_hours\"\n  ]\n}","source":"public-provider-conf"},"vision":false},{"id":"Doubao-lite-4k","name":"Doubao-lite-4k","display_name":"Doubao-lite-4k","type":"chat","context_length":0,"max_output_tokens":0,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"developer":"","developerId":4,"providerId":47,"modelRatio":0.03,"cacheRatio":1,"completionRatio":2,"order":0,"flag":0,"billingConfig":"{\n  \"model_name\": \"Doubao-lite-4k\",\n  \"default_tier\": \"tier1\",\n  \"token_based_tier_configs\": {\n    \"tier1\": {\n      \"tier_condition\": {\n        \"min_tokens\": 0,\n        \"max_tokens\": -1\n      },\n      \"model_ratio\": 0.020548,\n      \"prompt_tokens_ratio\": 1.0,\n      \"completion_tokens_ratio\": 2.0\n    }\n  },\n  \"per_unit_price_config\": {},\n  \"enabled_billing_items\": [\n    \"prompt_tokens\",\n    \"completion_tokens\"\n  ]\n}","source":"public-provider-conf"},"vision":false},{"id":"Doubao-pro-128k","name":"Doubao-pro-128k","display_name":"Doubao-pro-128k","type":"chat","context_length":0,"max_output_tokens":0,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"developer":"","developerId":4,"providerId":47,"modelRatio":0.4,"cacheRatio":1,"completionRatio":1.8,"order":0,"flag":0,"source":"public-provider-conf"},"vision":false},{"id":"Doubao-pro-256k","name":"Doubao-pro-256k","display_name":"Doubao-pro-256k","type":"chat","context_length":0,"max_output_tokens":0,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"developer":"","developerId":4,"providerId":47,"modelRatio":0.4,"cacheRatio":1,"completionRatio":1.8,"order":0,"flag":0,"billingConfig":"{\n  \"model_name\": \"Doubao-pro-256k\",\n  \"default_tier\": \"tier1\",\n  \"token_based_tier_configs\": {\n    \"tier1\": {\n      \"tier_condition\": {\n        \"min_tokens\": 0,\n        \"max_tokens\": -1\n      },\n      \"model_ratio\": 0.342466,\n      \"prompt_tokens_ratio\": 1.0,\n      \"completion_tokens_ratio\": 1.8\n    }\n  },\n  \"per_unit_price_config\": {},\n  \"enabled_billing_items\": [\n    \"prompt_tokens\",\n    \"completion_tokens\"\n  ]\n}","source":"public-provider-conf"},"vision":false},{"id":"Doubao-pro-32k","name":"Doubao-pro-32k","display_name":"Doubao-pro-32k","type":"chat","context_length":0,"max_output_tokens":0,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"developer":"","developerId":4,"providerId":47,"modelRatio":0.07,"cacheRatio":1,"completionRatio":2.5,"order":0,"flag":0,"billingConfig":"{\n  \"model_name\": \"Doubao-pro-32k\",\n  \"default_tier\": \"tier1\",\n  \"token_based_tier_configs\": {\n    \"tier1\": {\n      \"tier_condition\": {\n        \"min_tokens\": 0,\n        \"max_tokens\": -1\n      },\n      \"model_ratio\": 0.054795,\n      \"prompt_tokens_ratio\": 1.0,\n      \"completion_tokens_ratio\": 2.5,\n      \"cached_tokens_ratio\": 0.2\n    }\n  },\n  \"per_unit_price_config\": {\n    \"cache_storage_price\": 0.002329\n  },\n  \"enabled_billing_items\": [\n    \"prompt_tokens\",\n    \"completion_tokens\",\n    \"cached_tokens\",\n    \"cache_storage_hours\"\n  ]\n}","source":"public-provider-conf"},"vision":false},{"id":"Doubao-pro-4k","name":"Doubao-pro-4k","display_name":"Doubao-pro-4k","type":"chat","context_length":0,"max_output_tokens":0,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"developer":"","developerId":4,"providerId":47,"modelRatio":0.07,"cacheRatio":1,"completionRatio":2.5,"order":0,"flag":0,"source":"public-provider-conf"},"vision":false},{"id":"FLUX-1.1-pro","name":"FLUX-1.1-pro","display_name":"FLUX-1.1-pro","type":"image-generation","context_length":0,"max_output_tokens":0,"capabilities":{"vision":true,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"modalities":{"input":["text","image"],"output":["text","image"]},"metadata":{"developer":"Flux","developerId":27,"providerId":3,"modelRatio":20,"cacheRatio":0,"completionRatio":1,"order":499,"flag":0,"displayInput":"-","displayOutput":" $0.04 / IMG","modalities":["text","image"],"typeHints":["t2i"],"source":"public-provider-conf"},"vision":true},{"id":"FLUX.1-Kontext-pro","name":"FLUX.1-Kontext-pro","display_name":"FLUX.1-Kontext-pro","type":"image-generation","context_length":0,"max_output_tokens":0,"capabilities":{"vision":true,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"modalities":{"input":["text","image"],"output":["text","image"]},"metadata":{"developer":"Flux","developerId":27,"providerId":45,"modelRatio":20,"cacheRatio":1,"completionRatio":1,"description":"Flux.1 Kontext  8 ","descriptionEn":"Generate and edit images through both text and image prompts. Flux.1 Kontext is a multimodal flow matching model that enables both text-to-image generation and in-context image editing. Modify images while maintaining character consistency and performing local edits up to 8x faster than other leading models.","order":500,"flag":1,"displayInput":"-","displayOutput":"$0.04/ IMG","tags":["best"],"modalities":["text","image"],"typeHints":["t2i"],"source":"public-provider-conf"},"vision":true},{"id":"GLM-4.5","name":"GLM-4.5","display_name":"GLM-4.5","type":"chat","context_length":0,"max_output_tokens":0,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"developer":"ChatGLM","developerId":5,"providerId":8,"modelRatio":0.2,"cacheRatio":1,"completionRatio":4,"description":"GLM-4.5","descriptionEn":"GLM-4.5","order":800,"flag":1,"source":"public-provider-conf"},"vision":false},{"id":"GLM-4.5V","name":"GLM-4.5V","display_name":"GLM-4.5V","type":"chat","context_length":0,"max_output_tokens":0,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"developer":"ChatGLM","developerId":5,"providerId":8,"modelRatio":0.14,"cacheRatio":1,"completionRatio":3,"description":"","order":851,"flag":1,"source":"public-provider-conf"},"vision":false},{"id":"GPT-OSS-20B","name":"GPT-OSS-20B","display_name":"GPT-OSS-20B","type":"chat","context_length":0,"max_output_tokens":0,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"developer":"OpenAI","developerId":12,"providerId":8,"modelRatio":0.055,"cacheRatio":1,"completionRatio":5,"order":0,"flag":1,"source":"public-provider-conf"},"vision":false},{"id":"Kimi-K2","name":"Kimi-K2","display_name":"Kimi-K2","type":"chat","context_length":0,"max_output_tokens":0,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"developer":"Moonshot AI","developerId":15,"providerId":8,"modelRatio":0.27,"cacheRatio":1,"completionRatio":4,"description":"sophnetKimi-K2  Agent  MoE  1T 32BAgent K2 \nKimi-K2  128k\n","descriptionEn":"The model provider is the Sophnet platform. Kimi-K2 is a MoE architecture foundational model with extremely powerful coding and agent capabilities, featuring a total of 1 trillion parameters and activating 32 billion parameters. In benchmark performance tests across major categories such as general knowledge reasoning, programming, mathematics, and agents, the K2 model outperforms other mainstream open-source models.\nThe Kimi-K2 model supports a context length of 128k tokens.\nIt does not support visual capabilities.","order":400,"flag":1,"source":"public-provider-conf"},"vision":false},{"id":"Kimi-K2-0905","name":"Kimi-K2-0905","display_name":"Kimi-K2-0905","type":"chat","context_length":0,"max_output_tokens":0,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"developer":"Moonshot AI","developerId":15,"providerId":8,"modelRatio":0.274,"cacheRatio":1,"completionRatio":4,"description":"sophnetKimi-K2-0905  Moonshot AI  (MoE)  1  320  256k  token  128k ","descriptionEn":"The model provider is the Sophnet platform. Kimi-K2-0905 is a large-scale Mixture of Experts (MoE) language model developed by Moonshot AI, with a total of 1 trillion parameters and 32 billion active parameters per forward pass. It supports long-context inference of up to 256k tokens, an expansion from the previous 128k.","order":863,"flag":1,"source":"public-provider-conf"},"vision":false},{"id":"Llama-4-Maverick-17B-128E-Instruct-FP8","name":"Llama-4-Maverick-17B-128E-Instruct-FP8","display_name":"Llama-4-Maverick-17B-128E-Instruct-FP8","type":"chat","context_length":0,"max_output_tokens":0,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"developer":"Llama","developerId":11,"providerId":3,"modelRatio":0.15,"cacheRatio":1,"completionRatio":4,"description":"azure ","descriptionEn":"Azure deployment","order":703,"flag":1,"source":"public-provider-conf"},"vision":false},{"id":"LongCat-Flash-Chat","name":"LongCat-Flash-Chat","display_name":"LongCat-Flash-Chat","type":"chat","context_length":0,"max_output_tokens":0,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"developer":"Meituan","developerId":28,"providerId":8,"modelRatio":0.07,"cacheRatio":1,"completionRatio":5,"description":"LongCat-Flash-ChatMoE560Btoken27BAgent","descriptionEn":"Meituan has officially released and open-sourced LongCat-Flash-Chat, which utilizes an innovative Mixture of Experts (MoE) and \"zero-computation expert\" mechanism to achieve a total of 560B parameters, while only activating around 27B parameters per token as needed. At the same time, end-to-end optimization for agents (including a self-built evaluation set and multi-agent trajectory data) significantly enhances its performance in tool usage and complex task orchestration.","order":700,"flag":1,"source":"public-provider-conf"},"vision":false},{"id":"MiniMax-Text-01","name":"MiniMax-Text-01","display_name":"MiniMax-Text-01","type":"chat","context_length":1000000,"max_output_tokens":1000000,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"modalities":{"input":["text"],"output":["text"]},"metadata":{"developer":"Minimax","developerId":18,"providerId":27,"modelRatio":0.07,"cacheRatio":1,"completionRatio":8,"order":0,"flag":0,"features":["long_context"],"modalities":["text"],"typeHints":["t2t"],"source":"public-provider-conf"},"vision":false},{"id":"MiniMaxAI/MiniMax-M1-80k","name":"MiniMaxAI/MiniMax-M1-80k","display_name":"MiniMaxAI/MiniMax-M1-80k","type":"chat","context_length":0,"max_output_tokens":0,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"developer":"Minimax","developerId":18,"providerId":8,"modelRatio":0.3,"cacheRatio":1,"completionRatio":4,"description":"MiniMax-M1  4560  459  100  Token  10  Token  DeepSeek R1  75%  MoE  CISPO ","descriptionEn":"MiniMax-M1 is an open-source large-scale hybrid attention model with 456B total parameters (45.9B activated per token). It natively supports 1M-token context and reduces FLOPs by 75% versus DeepSeek R1 in 100K-token generation tasks via lightning attention. Built on MoE architecture and optimized by CISPO algorithm, it achieves state-of-the-art performance in long-context reasoning and real-world software engineering scenarios.","order":100,"flag":1,"source":"public-provider-conf"},"vision":false},{"id":"Pro/THUDM/GLM-4.1V-9B-Thinking","name":"Pro/THUDM/GLM-4.1V-9B-Thinking","display_name":"Pro/THUDM/GLM-4.1V-9B-Thinking","type":"chat","context_length":0,"max_output_tokens":0,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"developer":"ChatGLM","developerId":5,"providerId":16,"modelRatio":0.02,"cacheRatio":0,"completionRatio":4,"description":"GLM-4.1V-9B-Thinking  AI  KEG VLM GLM-4-9B-0414 Chain-of-Thought 9B  28  18  72B  Qwen-2.5-VL-72B 4K ","descriptionEn":"GLM-4.1V-9B-Thinking is an open-source Vision Language Model (VLM) jointly released by Zhipu AI and the KEG Laboratory at Tsinghua University, designed specifically for handling complex multimodal cognitive tasks. Based on the GLM-4-9B-0414 foundation model, it significantly enhances cross-modal reasoning ability and stability by introducing the Chain-of-Thought reasoning mechanism and using reinforcement learning strategies. As a lightweight model with 9 billion parameters, it strikes a balance between deployment efficiency and performance. In 28 authoritative benchmark evaluations, it matched or even outperformed the 72-billion-parameter Qwen-2.5-VL-72B model in 18 tasks. The model excels not only in image-text understanding, mathematical and scientific reasoning, and video understanding, but also supports images up to 4K resolution and inputs of arbitrary aspect ratios.","order":34,"flag":1,"source":"public-provider-conf"},"vision":false},{"id":"QwQ-32B","name":"QwQ-32B","display_name":"QwQ-32B","type":"chat","context_length":0,"max_output_tokens":0,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"developer":"Qwen","developerId":13,"providerId":8,"modelRatio":0.14,"cacheRatio":1,"completionRatio":3,"description":"sophnetQwQ \nQwQ \nQwQ-32B  DeepSeek-R1o1-mini\n 128K tokens 128K tokens \n","descriptionEn":"The model provider is the Sophnet platform. QwQ is an inference model from the Qianwen series, featuring outstanding thinking and reasoning capabilities.\nCompared to traditional instruction-finetuned models, QwQ can achieve significantly enhanced performance on downstream tasks, especially on difficult problems.\nQwQ-32B is a medium-sized inference model capable of delivering competitive performance compared to state-of-the-art inference models such as DeepSeek-R1 and o1-mini.\nIt supports long context lengths of up to 128K tokens and can generate text up to 128K tokens.","order":400,"flag":0,"source":"public-provider-conf"},"vision":false},{"id":"Qwen/QVQ-72B-Preview","name":"Qwen/QVQ-72B","display_name":"Qwen/QVQ-72B","type":"chat","context_length":0,"max_output_tokens":0,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"developer":"Qwen","developerId":13,"providerId":44,"modelRatio":0.6,"cacheRatio":1,"completionRatio":1,"order":9,"flag":0,"source":"public-provider-conf"},"vision":false},{"id":"Qwen/QwQ-32B","name":"Qwen/QwQ-32B","display_name":"Qwen/QwQ-32B","type":"chat","context_length":0,"max_output_tokens":0,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"developer":"Qwen","developerId":13,"providerId":17,"modelRatio":0.07,"cacheRatio":1,"completionRatio":4,"description":"","descriptionEn":"Silicon-based flow provision","order":101,"flag":1,"source":"public-provider-conf"},"vision":false},{"id":"Qwen/QwQ-32B-Preview","name":"QwQ-32B-Preview","display_name":"QwQ-32B-Preview","type":"chat","context_length":0,"max_output_tokens":0,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"developer":"Qwen","developerId":13,"providerId":44,"modelRatio":0.08,"cacheRatio":1,"completionRatio":1,"order":8,"flag":0,"source":"public-provider-conf"},"vision":false},{"id":"Qwen/Qwen2-7B-Instruct","name":"Qwen2-7B","display_name":"Qwen2-7B","type":"chat","context_length":0,"max_output_tokens":0,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"developer":"Qwen","developerId":13,"providerId":8,"modelRatio":0.04,"cacheRatio":1,"completionRatio":1,"order":0,"flag":0,"source":"public-provider-conf"},"vision":false},{"id":"Qwen/Qwen2.5-32B-Instruct","name":"Qwen2.5-32B","display_name":"Qwen2.5-32B","type":"chat","context_length":0,"max_output_tokens":0,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"developer":"Qwen","developerId":13,"providerId":8,"modelRatio":0.3,"cacheRatio":1,"completionRatio":1,"order":0,"flag":0,"source":"public-provider-conf"},"vision":false},{"id":"Qwen/Qwen2.5-72B-Instruct","name":"Qwen2.5-72B","display_name":"Qwen2.5-72B","type":"chat","context_length":0,"max_output_tokens":0,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"developer":"Qwen","developerId":13,"providerId":8,"modelRatio":0.4,"cacheRatio":1,"completionRatio":1,"order":0,"flag":0,"source":"public-provider-conf"},"vision":false},{"id":"Qwen/Qwen2.5-72B-Instruct-128K","name":"Qwen2.5-72B","display_name":"Qwen2.5-72B","type":"chat","context_length":0,"max_output_tokens":0,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"developer":"Qwen","developerId":13,"providerId":44,"modelRatio":0.4,"cacheRatio":1,"completionRatio":1,"order":0,"flag":0,"source":"public-provider-conf"},"vision":false},{"id":"Qwen/Qwen2.5-7B-Instruct","name":"Qwen2.5-7B","display_name":"Qwen2.5-7B","type":"chat","context_length":0,"max_output_tokens":0,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"developer":"Qwen","developerId":13,"providerId":8,"modelRatio":0.2,"cacheRatio":1,"completionRatio":1,"order":0,"flag":0,"source":"public-provider-conf"},"vision":false},{"id":"Qwen/Qwen2.5-Coder-32B-Instruct","name":"Qwen2.5-Coder-32B-Instruct","display_name":"Qwen2.5-Coder-32B-Instruct","type":"chat","context_length":0,"max_output_tokens":0,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"developer":"Qwen","developerId":13,"providerId":44,"modelRatio":0.08,"cacheRatio":1,"completionRatio":1,"order":0,"flag":0,"source":"public-provider-conf"},"vision":false},{"id":"Qwen/Qwen2.5-VL-32B-Instruct","name":"Qwen2.5-vl-32b","display_name":"Qwen2.5-vl-32b","type":"chat","context_length":0,"max_output_tokens":0,"capabilities":{"vision":true,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"modalities":{"input":["text","image"],"output":["text","image"]},"metadata":{"developer":"Qwen","developerId":13,"providerId":44,"modelRatio":0.12,"cacheRatio":1,"completionRatio":1,"description":"Qwen2.5-VL-32B-Instruct","descriptionEn":"Qwen2.5-VL-32B-Instruct is an advanced multimodal model from the Tongyi Qianwen team that can recognize objects, analyze text and graphics in images, operate tools, locate objects in images, and generate structured outputs. Through reinforcement learning, it has improved mathematics and problem-solving capabilities, with a more concise and natural response style.","order":100,"flag":1,"tags":["multi_modal"],"modalities":["text","image"],"typeHints":["t2t"],"source":"public-provider-conf"},"vision":true},{"id":"Qwen/Qwen2.5-VL-72B-Instruct","name":"Qwen2.5-VL-72B","display_name":"Qwen2.5-VL-72B","type":"chat","context_length":128000,"max_output_tokens":128000,"capabilities":{"vision":true,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"modalities":{"input":["text","image"],"output":["text","image"]},"metadata":{"developer":"Qwen","developerId":13,"providerId":44,"modelRatio":0.25,"cacheRatio":0,"completionRatio":1,"description":"Qwen2.5-VL  Qwen2.5 ","descriptionEn":"Qwen2.5-VL is a visual language model from the Qwen2.5 series, equipped with strong visual understanding and reasoning capabilities. It can recognize objects, analyze text and charts, understand key events in long videos, and accurately locate targets within images. The model supports structured output, making it suitable for data such as invoices and forms, and performs excellently in multiple benchmark tests.","order":290,"flag":0,"tags":["multi_modal"],"modalities":["text","image"],"typeHints":["t2t"],"source":"public-provider-conf"},"vision":true},{"id":"Qwen/Qwen3-14B","name":"Qwen/Qwen3-14B","display_name":"Qwen/Qwen3-14B","type":"chat","context_length":0,"max_output_tokens":0,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"developer":"Qwen","developerId":13,"providerId":8,"modelRatio":0.25,"cacheRatio":1,"completionRatio":1,"description":"chutes.ai","descriptionEn":"Provided by chutes.ai","order":377,"flag":1,"source":"public-provider-conf"},"vision":false},{"id":"Qwen/Qwen3-235B-A22B","name":"Qwen/Qwen3-235B-A22B","display_name":"Qwen/Qwen3-235B-A22B","type":"chat","context_length":0,"max_output_tokens":0,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"developer":"Qwen","developerId":13,"providerId":8,"modelRatio":0.14,"cacheRatio":0,"completionRatio":4,"description":"chutes.ai","descriptionEn":"Provided by chutes.ai","order":500,"flag":1,"source":"public-provider-conf"},"vision":false},{"id":"Qwen/Qwen3-235B-A22B-Instruct-2507","name":"Qwen/Qwen3-235B-A22B-Instruct-2507","display_name":"Qwen/Qwen3-235B-A22B-Instruct-2507","type":"chat","context_length":0,"max_output_tokens":0,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"developer":"Qwen","developerId":13,"providerId":8,"modelRatio":0.2,"cacheRatio":1,"completionRatio":4,"description":"Qwen3-235B-A22B-Instruct-2507  22  235B  MoE  256K ","descriptionEn":"Qwen3-235B-A22B-Instruct-2507 is a 235B parameter sparse MoE model (with 22B active parameters) that excels at general tasks like reasoning, coding, and multilingual capabilities while supporting a very long 256K context window.","order":600,"flag":1,"source":"public-provider-conf"},"vision":false},{"id":"Qwen/Qwen3-235B-A22B-Thinking-2507","name":"Qwen/Qwen3-235B-A22B-Thinking-2507","display_name":"Qwen/Qwen3-235B-A22B-Thinking-2507","type":"chat","context_length":0,"max_output_tokens":0,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"developer":"Qwen","developerId":13,"providerId":8,"modelRatio":0.14,"cacheRatio":1,"completionRatio":10,"description":"Qwen3-235B-A22B-Thinking-2507  Qwen3  Qwen3-235B-A22B ","descriptionEn":"Qwen3-235B-A22B-Thinking-2507 is the Qwen3's new model with scaling the thinking capability of Qwen3-235B-A22B, improving both the quality and depth of reasoning.","order":400,"flag":0,"source":"public-provider-conf"},"vision":false},{"id":"Qwen/Qwen3-30B-A3B","name":"Qwen/Qwen3-30B-A3B","display_name":"Qwen/Qwen3-30B-A3B","type":"chat","context_length":0,"max_output_tokens":0,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"developer":"Qwen","developerId":13,"providerId":8,"modelRatio":0.5,"cacheRatio":1,"completionRatio":1,"description":"chutes.ai","descriptionEn":"Provided by chutes.ai","order":399,"flag":1,"source":"public-provider-conf"},"vision":false},{"id":"Qwen/Qwen3-32B","name":"Qwen/Qwen3-32B","display_name":"Qwen/Qwen3-32B","type":"chat","context_length":0,"max_output_tokens":0,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"developer":"Qwen","developerId":13,"providerId":8,"modelRatio":0.25,"cacheRatio":1,"completionRatio":1,"description":"chutes.ai","descriptionEn":"Provided by chutes.ai","order":388,"flag":1,"source":"public-provider-conf"},"vision":false},{"id":"Qwen/Qwen3-8B","name":"Qwen/Qwen3-8B","display_name":"Qwen/Qwen3-8B","type":"chat","context_length":0,"max_output_tokens":0,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"developer":"Qwen","developerId":13,"providerId":8,"modelRatio":0.1,"cacheRatio":1,"completionRatio":1,"description":"chutes.ai","descriptionEn":"Provided by chutes.ai","order":375,"flag":1,"source":"public-provider-conf"},"vision":false},{"id":"Qwen/Qwen3-Coder-30B-A3B-Instruct","name":"Qwen/Qwen3-Coder-30B-A3B-Instruct","display_name":"Qwen/Qwen3-Coder-30B-A3B-Instruct","type":"chat","context_length":0,"max_output_tokens":0,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"developer":"Qwen","developerId":13,"providerId":44,"modelRatio":0.05,"cacheRatio":1,"completionRatio":4,"description":"Qwen3-Coder \n\n Agentic Coding () \n\n256K1M Qwen Code  CLINE ","descriptionEn":"Qwen3-Coder is an efficient code model from Alibaba's Qwen team. It's built to be smaller but still powerful.\n\nThe model is very good at complex jobs like agentic coding and browser tasks. It often does better than other open-source models on these.\n\nIt can also read a lot of code at once256K tokens, which can be expanded to 1M. This helps it understand whole code projects. It's designed to work with agent platforms like Qwen Code and CLINE.","order":200,"flag":1,"source":"public-provider-conf"},"vision":false},{"id":"Qwen/Qwen3-Embedding-0.6B","name":"Qwen/Qwen3-Embedding-0.6B","display_name":"Qwen/Qwen3-Embedding-0.6B","type":"embedding","context_length":0,"max_output_tokens":0,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"developer":"Qwen","developerId":13,"providerId":17,"modelRatio":0.0053,"cacheRatio":0,"completionRatio":0,"description":"Qwen3-Embedding-0.6B  Qwen3  6  32K  1024  100  MTEB  64.33 /32-1024","descriptionEn":"Qwen3-Embedding-0.6B is the latest proprietary embedding model in the Qwen3 series, specifically designed for text embedding and ranking. It has 600 million parameters, supports a maximum context length of 32K, and generates embeddings with up to 1024 dimensions. The model boasts excellent multilingual capabilities (supporting over 100 languages), strong long-text understanding and reasoning abilities, and achieved an impressive score of 64.33 on the MTEB leaderboard. It is suitable for tasks such as text/code retrieval, classification, and clustering. The model supports customizable output dimensions (ranging from 32 to 1024) and instruction-awareness, allowing flexible adaptation to different application scenarios, balancing efficiency and effectiveness.","order":60,"flag":1,"typeHints":["embedding"],"source":"public-provider-conf"},"vision":false},{"id":"Qwen2-VL-72B-Instruct","name":"Qwen2-VL-72B-Instruct","display_name":"Qwen2-VL-72B-Instruct","type":"chat","context_length":0,"max_output_tokens":0,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"developer":"Qwen","developerId":13,"providerId":8,"modelRatio":1.09,"cacheRatio":1,"completionRatio":3,"description":"sophnetQwen2-VL-72B-Instruct\nQwen2-VL-72B-InstructQwen2-VL72020\n\n\n20\n\n\n128K\n","descriptionEn":"The model provider is the Sophnet platform. Qwen2-VL-72B-Instruct is the latest iteration in the Qwen2-VL series launched by Alibaba Cloud, representing nearly a year of innovative achievements. This model has 72 billion parameters and can understand images of various resolutions and aspect ratios. Additionally, it supports video understanding of over 20 minutes, enabling high-quality video question answering, dialogue, and content creation, along with complex reasoning and decision-making capabilities.\n\n- State-of-the-art image understanding: capable of processing images of various resolutions and aspect ratios, performing excellently across multiple visual understanding benchmarks.\n- Long video understanding: supports video comprehension exceeding 20 minutes, enabling high-quality video Q&A, dialogues, and content creation.\n- Agent operation capability: equipped with complex reasoning and decision-making abilities, it can integrate with devices such as phones and robots to perform automated operations based on visual environments and textual instructions.\n- Multilingual support: in addition to English and Chinese, it supports understanding text in images in multiple languages, including most European languages, Japanese, Korean, Arabic, Vietnamese, and more.\n- Supports a maximum context length of 128K tokens, offering powerful processing capabilities.","order":400,"flag":0,"source":"public-provider-conf"},"vision":false},{"id":"Qwen2.5-VL-72B-Instruct","name":"Qwen2.5-VL-72B-Instruct","display_name":"Qwen2.5-VL-72B-Instruct","type":"chat","context_length":0,"max_output_tokens":0,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"developer":"Qwen","developerId":13,"providerId":8,"modelRatio":0.31,"cacheRatio":1,"completionRatio":1,"description":"sophnetQwen2.5-VL-72B-InstructQwen1","descriptionEn":"The model provider is the Sophon platform. Qwen2.5-VL-72B-Instruct is the latest vision-language model released by the Qwen team. This model excels not only at recognizing common objects such as flowers, birds, fish, and insects, but also at efficiently analyzing text, charts, icons, graphics, and layouts within images. As a visual agent, it is capable of reasoning and dynamically guiding tool usage, supporting both computer and mobile operations. Moreover, it can understand videos longer than one hour and accurately locate relevant video segments.","order":400,"flag":0,"source":"public-provider-conf"},"vision":false},{"id":"Qwen3-235B-A22B-Instruct-2507","name":"Qwen3-235B-A22B-Instruct-2507","display_name":"Qwen3-235B-A22B-Instruct-2507","type":"chat","context_length":0,"max_output_tokens":0,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"developer":"Qwen","developerId":13,"providerId":8,"modelRatio":0.14,"cacheRatio":1,"completionRatio":4,"description":"Qwen3-235B-A22B-Instruct-2507","descriptionEn":"Qwen3-235B-A22B-Instruct-2507","order":700,"flag":1,"source":"public-provider-conf"},"vision":false},{"id":"Qwen3-235B-A22B-Thinking-2507","name":"Qwen3-235B-A22B-Thinking-2507","display_name":"Qwen3-235B-A22B-Thinking-2507","type":"chat","context_length":0,"max_output_tokens":0,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"developer":"Qwen","developerId":13,"providerId":8,"modelRatio":0.14,"cacheRatio":1,"completionRatio":10,"description":"","order":0,"flag":1,"source":"public-provider-conf"},"vision":false},{"id":"Qwen3-Coder","name":"Qwen3-Coder","display_name":"Qwen3-Coder","type":"chat","context_length":0,"max_output_tokens":0,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"developer":"Qwen","developerId":13,"providerId":8,"modelRatio":0.27,"cacheRatio":1,"completionRatio":4,"description":"sophnetQwen3-Coder-480B-A35B-Instruct  Qwen  (MoE)  4800  350 160  8 \n\nAgentic CodingAgentic Browser-Use Claude Sonnet \n256K  Yarn 1M \nQwen CodeCLINE\n 358 ","descriptionEn":"The model provider is the Sophnet platform. Qwen3-Coder-480B-A35B-Instruct is a mixture-of-experts (MoE) code generation model developed by the Qwen team. This model is optimized for agent coding tasks such as function calls, tool usage, and repository-based long-context reasoning. It contains a total of 48 billion parameters, with 3.5 billion active parameters per forward pass (8 out of 160 experts).\n\nIt achieves results comparable to Claude Sonnet in open models for Agentic Coding, Agentic Browser-Use, and other fundamental coding tasks.\nIt natively supports 256K tokens and can be scaled up to 1 million tokens using Yarn, with optimizations for understanding repository-scale contexts.\nThe model supports most platforms including Qwen Code and CLINE, featuring specially designed function call formats.\nIt also supports 358 programming languages.","order":703,"flag":0,"source":"public-provider-conf"},"vision":false},{"id":"Qwen3-Next-80B-A3B-Instruct","name":"Qwen3-Next-80B-A3B-Instruct","display_name":"Qwen3-Next-80B-A3B-Instruct","type":"chat","context_length":0,"max_output_tokens":0,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"developer":"Qwen","developerId":13,"providerId":8,"modelRatio":0.069,"cacheRatio":1,"completionRatio":4,"description":"sophnetQwen3-Next-80B-A3B-Instruct  Qwen3-Next ","descriptionEn":"The model provider is the Sophnet platform. Qwen3-Next-80B-A3B-Instruct is an instruction-tuned chat model in the Qwen3-Next series, optimized for fast and stable responses without leaving any \"thinking\" traces. It is designed for complex tasks such as reasoning, code generation, knowledge Q&A, and multilingual applications, while maintaining robustness in alignment and formatting.","order":705,"flag":0,"source":"public-provider-conf"},"vision":false},{"id":"Qwen3-Next-80B-A3B-Thinking","name":"Qwen3-Next-80B-A3B-Thinking","display_name":"Qwen3-Next-80B-A3B-Thinking","type":"chat","context_length":0,"max_output_tokens":0,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"developer":"Qwen","developerId":13,"providerId":8,"modelRatio":0.069,"cacheRatio":1,"completionRatio":10,"description":"sophnetQwen3-Next-80B-A3B-Thinking  Qwen3-Next /","descriptionEn":"The model provider is the Sophnet platform. Qwen3-Next-80B-A3B-Thinking is a reasoning-prioritized chat model in the Qwen3-Next series, which by default outputs structured \"thinking\" trajectories. It is specifically designed to solve complex multi-step problems, such as mathematical proofs, code synthesis/debugging, logic, and agent planning, and has achieved excellent results in knowledge, reasoning, coding, alignment, and multilingual evaluations.","order":705,"flag":0,"source":"public-provider-conf"},"vision":false},{"id":"THUDM/GLM-4-32B-0414","name":"THUDM/GLM-4-32B-0414","display_name":"THUDM/GLM-4-32B-0414","type":"chat","context_length":0,"max_output_tokens":0,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"developer":"ChatGLM","developerId":5,"providerId":44,"modelRatio":0.04,"cacheRatio":1,"completionRatio":1,"description":"GLM-4-32B-0414  320  OpenAI  GPT  DeepSeek V3/R1  15T \n\n\n\n Artifact GPT-4o  DeepSeek-V3671B ","descriptionEn":"GLM-4-32B-0414 is a next-generation open-source model with 32 billion parameters, delivering performance comparable to OpenAIs GPT series and DeepSeek V3/R1. It supports smooth local deployment.\n\nThe base model was pre-trained on 15T of high-quality data, including a large amount of reasoning-focused synthetic content, setting the stage for advanced reinforcement learning.\n\nIn the post-training phase, techniques like human preference alignment, rejection sampling, and reinforcement learning were used to improve the models ability to follow instructions, generate code, and handle function callscore skills needed for agent-style tasks.\n\nGLM-4-32B-0414 has shown strong results in engineering code, artifact generation, function calling, search-based QA, and report writingsometimes matching or even surpassing larger models like GPT-4o and DeepSeek-V3 (671B) on specific benchmarks.","order":33,"flag":1,"source":"public-provider-conf"},"vision":false},{"id":"THUDM/GLM-4-9B-0414","name":"THUDM/GLM-4-9B-0414","display_name":"THUDM/GLM-4-9B-0414","type":"chat","context_length":0,"max_output_tokens":0,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"developer":"ChatGLM","developerId":5,"providerId":44,"modelRatio":0.025,"cacheRatio":1,"completionRatio":1,"description":"GLM-4-9B-0414  GLM  90  GLM-4-32B SVG \n\nGLM-4-9B-0414  AI ","descriptionEn":"GLM-4-9B-0414 is a lightweight model in the GLM family, with 9 billion parameters. It inherits the core tech from GLM-4-32B and offers an efficient option for deployment on limited resources.\n\nDespite its smaller size, it performs well in tasks like code generation, web design, SVG graphics creation, and search-based writing. It also supports function calling to interact with external tools, enhancing its versatility.\n\nGLM-4-9B-0414 strikes a solid balance between efficiency and performance, making it a strong choice for low-resource environmentswhile remaining competitive on various benchmarks.","order":30,"flag":1,"source":"public-provider-conf"},"vision":false},{"id":"THUDM/GLM-4.1V-9B-Thinking","name":"THUDM/GLM-4.1V-9B-Thinking","display_name":"THUDM/GLM-4.1V-9B-Thinking","type":"chat","context_length":0,"max_output_tokens":0,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"developer":"ChatGLM","developerId":5,"providerId":16,"modelRatio":0.05,"cacheRatio":0,"completionRatio":1,"description":"GLM-4.1V-9B-Thinking  AI  KEG VLM GLM-4-9B-0414 Chain-of-Thought 9B  28  18  72B  Qwen-2.5-VL-72B 4K ","descriptionEn":"GLM-4.1V-9B-Thinking is an open-source Vision Language Model (VLM) jointly released by Zhipu AI and the KEG Laboratory at Tsinghua University, designed specifically for handling complex multimodal cognitive tasks. Based on the GLM-4-9B-0414 foundation model, it significantly enhances cross-modal reasoning ability and stability by introducing the Chain-of-Thought reasoning mechanism and using reinforcement learning strategies. As a lightweight model with 9 billion parameters, it strikes a balance between deployment efficiency and performance. In 28 authoritative benchmark evaluations, it matched or even outperformed the 72-billion-parameter Qwen-2.5-VL-72B model in 18 tasks. The model excels not only in image-text understanding, mathematical and scientific reasoning, and video understanding, but also supports images up to 4K resolution and inputs of arbitrary aspect ratios.","order":34,"flag":1,"source":"public-provider-conf"},"vision":false},{"id":"THUDM/GLM-Z1-32B-0414","name":"THUDM/GLM-Z1-32B-0414","display_name":"THUDM/GLM-Z1-32B-0414","type":"chat","context_length":0,"max_output_tokens":0,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"developer":"ChatGLM","developerId":5,"providerId":16,"modelRatio":0.04,"cacheRatio":1,"completionRatio":1,"description":"GLM-Z1-32B-0414  AI  GLM-4-32B-0414  32B  DeepSeek-R1671B  AIME 24/25LiveCodeBenchGPQA ","descriptionEn":"GLM-Z1-32B-0414 is a reasoning-focused AI model built on GLM-4-32B-0414. It has been enhanced through cold-start methods and reinforcement learning, with a strong emphasis on math, coding, and logic tasks. Despite having only 32B parameters, it performs comparably to the 671B DeepSeek-R1 on some benchmarks. It excels in complex reasoning tasks, as shown in evaluations like AIME 24/25, LiveCodeBench, and GPQA.","order":35,"flag":1,"source":"public-provider-conf"},"vision":false},{"id":"THUDM/GLM-Z1-9B-0414","name":"THUDM/GLM-Z1-9B-0414","display_name":"THUDM/GLM-Z1-9B-0414","type":"chat","context_length":0,"max_output_tokens":0,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"developer":"ChatGLM","developerId":5,"providerId":44,"modelRatio":0.025,"cacheRatio":1,"completionRatio":1,"description":"GLM-Z1-9B-0414  GLM  90 \n\n","descriptionEn":"GLM-Z1-9B-0414 is a small but powerful model in the GLM series, with only 9 billion parameters. Despite its size, it delivers strong performance in math reasoning and general tasks, ranking among the best in its class of open-source models.\n\nTrained with the same techniques as larger models, it strikes an excellent balance between performance and efficiencymaking it a great option for low-resource or lightweight deployment scenarios.","order":32,"flag":1,"source":"public-provider-conf"},"vision":false},{"id":"UPSCALE","name":"upscale","display_name":"upscale","type":"image-generation","context_length":0,"max_output_tokens":0,"capabilities":{"vision":true,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"modalities":{"input":["text","image"],"output":["text","image"]},"metadata":{"developer":"Ideogram","developerId":21,"providerId":8,"modelRatio":1,"cacheRatio":0,"completionRatio":1,"description":" US $0.06Ideogram AI upscale\n\n https://docs.aihubmix.com/cn/api/IdeogramAI","descriptionEn":"The super-resolution upscale interface of the Ideogram AI drawing model is designed to enlarge low-resolution images into high-resolution ones, redrawing details (with controllable similarity and detail proportions).\nUS $0.06/ IMG.\nFor usage examples and pricing details, refer to the documentation at https://docs.aihubmix.com/cn/api/IdeogramAI.","order":1,"flag":0,"usage":"","displayInput":"-","displayOutput":"$0.06 / IMG","tags":["best"],"modalities":["text","image"],"typeHints":["t2i"],"source":"public-provider-conf"},"vision":true},{"id":"V3","name":"generate","display_name":"generate","type":"image-generation","context_length":0,"max_output_tokens":0,"capabilities":{"vision":true,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"modalities":{"input":["text","image"],"output":["text","image"]},"metadata":{"developer":"Ideogram","developerId":21,"providerId":8,"modelRatio":1,"cacheRatio":0,"completionRatio":1,"description":"Ideogram AI \n   11 /\n   3:12:1 \n  \n  editreplace-background","descriptionEn":"Fast and high-quality  top image quality in just 11 seconds per piece, with almost no extra time for batch generation.\nFlexible ratios  supports ultra-wide and tall formats like 3:1, 2:1, offering diverse perspectives.\nUnique strengths  outstanding design capabilities in the V3 and V2 series, with powerful text rendering (Chinese support coming soon).\nPrecise local editing  fine-tuned mask control for area redrawing (edit) and easy background replacement (replace-background).","order":70,"flag":1,"displayInput":"-","displayOutput":"$ 0.09 / IMG (Quality) ","tags":["best"],"modalities":["text","image"],"typeHints":["t2i"],"source":"public-provider-conf"},"vision":true},{"id":"V_1","name":"generate","display_name":"generate","type":"image-generation","context_length":0,"max_output_tokens":0,"capabilities":{"vision":true,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"modalities":{"input":["text","image"],"output":["text","image"]},"metadata":{"developer":"Ideogram","developerId":21,"providerId":8,"modelRatio":1,"cacheRatio":0,"completionRatio":1,"description":" US $0.06Ideogram AI  /generate /remix\n V_1 \n https://docs.aihubmix.com/cn/api/IdeogramAI","descriptionEn":"The Ideogram AI drawing interface is now live. This model boasts powerful text-to-image capabilities, supporting endpoints are: /generate, /remix.\nThis model is the original V_1 version.\nUS $0.06/ IMG.\nFor usage examples and pricing details, refer to the documentation at https://docs.aihubmix.com/cn/api/IdeogramAI.","order":63,"flag":0,"usage":"","displayInput":"-","displayOutput":"$0.06 / IMG","tags":["best"],"modalities":["text","image"],"typeHints":["t2i"],"source":"public-provider-conf"},"vision":true},{"id":"V_1_TURBO","name":"generate","display_name":"generate","type":"image-generation","context_length":0,"max_output_tokens":0,"capabilities":{"vision":true,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"modalities":{"input":["text","image"],"output":["text","image"]},"metadata":{"developer":"Ideogram","developerId":21,"providerId":8,"modelRatio":1,"cacheRatio":0,"completionRatio":1,"description":" US $0.02Ideogram AI  /generate /remix\n V_1 \n https://docs.aihubmix.com/cn/api/IdeogramAI","descriptionEn":"The Ideogram AI drawing interface is now live. This model boasts powerful text-to-image capabilities, supporting endpoints are: /generate, /remix.\nThis model is the ultra-fast version of the original V_1, offering increased speed at the slight expense of quality.\nUS $0.02/ IMG.\nFor usage examples and pricing details, refer to the documentation at https://docs.aihubmix.com/cn/api/IdeogramAI.","order":62,"flag":0,"usage":"","displayInput":"-","displayOutput":"$0.02 / IMG","tags":["best"],"modalities":["text","image"],"typeHints":["t2i"],"source":"public-provider-conf"},"vision":true},{"id":"V_2","name":"generate","display_name":"generate","type":"image-generation","context_length":0,"max_output_tokens":0,"capabilities":{"vision":true,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"modalities":{"input":["text","image"],"output":["text","image"]},"metadata":{"developer":"Ideogram","developerId":21,"providerId":8,"modelRatio":1,"cacheRatio":0,"completionRatio":1,"description":" US $0.08Ideogram AI  /generate /remix /edit\n  V_2 \n US $0.08\n https://docs.aihubmix.com/cn/api/IdeogramAI","descriptionEn":" The Ideogram AI drawing interface is now live. This model boasts powerful text-to-image capabilities, supporting endpoints are: /generate, /remix, /edit.\nThis model is the stable V_2 version, highly recommended for editing.\nUS $0.08/ 1 IMG.\nFor usage examples and pricing details, refer to the documentation at https://docs.aihubmix.com/cn/api/IdeogramAI.\n","order":69,"flag":2,"usage":"","displayInput":"-","displayOutput":"$0.08 / IMG","tags":["best"],"modalities":["text","image"],"typeHints":["t2i"],"source":"public-provider-conf"},"vision":true},{"id":"V_2A","name":"generate","display_name":"generate","type":"image-generation","context_length":0,"max_output_tokens":0,"capabilities":{"vision":true,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"modalities":{"input":["text","image"],"output":["text","image"]},"metadata":{"developer":"Ideogram","developerId":21,"providerId":8,"modelRatio":1,"cacheRatio":0,"completionRatio":1,"description":" US $0.04Ideogram AI  /generate /remix\n V_2 \n https://docs.aihubmix.com/cn/api/IdeogramAI","descriptionEn":"The Ideogram AI drawing interface is now live. This model boasts powerful text-to-image capabilities, supporting endpoints are: /generate, /remix.\nThis model is the fast version of V_2, faster and cheaper.\nUS $0.04/ IMG.\nFor usage examples and pricing details, refer to the documentation at https://docs.aihubmix.com/cn/api/IdeogramAI.","order":67,"flag":0,"usage":"","displayInput":"-","displayOutput":"$0.04 / IMG","tags":["best"],"modalities":["text","image"],"typeHints":["t2i"],"source":"public-provider-conf"},"vision":true},{"id":"V_2A_TURBO","name":"generate","display_name":"generate","type":"image-generation","context_length":0,"max_output_tokens":0,"capabilities":{"vision":true,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"modalities":{"input":["text","image"],"output":["text","image"]},"metadata":{"developer":"Ideogram","developerId":21,"providerId":8,"modelRatio":1,"cacheRatio":0,"completionRatio":1,"description":" US $0.025Ideogram AI  /generate /remix\n V_2 \n\n https://docs.aihubmix.com/cn/api/IdeogramAI","descriptionEn":"The Ideogram AI drawing interface is now live. This model boasts powerful text-to-image capabilities, supporting endpoints are: /generate, /remix.\nThis model is the ultra-fast version of V_2, delivering the highest speed while slightly reducing quality.\nUS $0.025/ IMG.\nFor usage examples and pricing details, refer to the documentation at https://docs.aihubmix.com/cn/api/IdeogramAI.","order":66,"flag":0,"usage":"","displayInput":"-","displayOutput":"$0.0025 / IMG","tags":["best"],"modalities":["text","image"],"typeHints":["t2i"],"source":"public-provider-conf"},"vision":true},{"id":"V_2_TURBO","name":"generate","display_name":"generate","type":"image-generation","context_length":0,"max_output_tokens":0,"capabilities":{"vision":true,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"modalities":{"input":["text","image"],"output":["text","image"]},"metadata":{"developer":"Ideogram","developerId":21,"providerId":8,"modelRatio":1,"cacheRatio":0,"completionRatio":1,"description":" US $0.05Ideogram AI  /generate /remix /edit\n V_2 \n\n https://docs.aihubmix.com/cn/api/IdeogramAI","descriptionEn":"The Ideogram AI drawing interface is now live. This model boasts powerful text-to-image capabilities, supporting endpoints are: /generate, /remix, /edit.\nThis model is the fast version of V_2, offering increased speed at the slight expense of quality.\nUS $0.05/ IMG.\nFor usage examples and pricing details, refer to the documentation at https://docs.aihubmix.com/cn/api/IdeogramAI.","order":68,"flag":0,"usage":"","displayInput":"-","displayOutput":"$0.05 / IMG","tags":["best"],"modalities":["text","image"],"typeHints":["t2i"],"source":"public-provider-conf"},"vision":true},{"id":"Z/glm-4.5","name":"Z/glm-4.5","display_name":"Z/glm-4.5","type":"chat","context_length":0,"max_output_tokens":0,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"developer":"ChatGLM","developerId":5,"providerId":16,"modelRatio":0.25,"cacheRatio":1,"completionRatio":4,"description":"Z/glm-4.5","descriptionEn":"Z/glm-4.5","order":850,"flag":1,"source":"public-provider-conf"},"vision":false},{"id":"Z/glm-4.5-air","name":"Z/glm-4.5-air","display_name":"Z/glm-4.5-air","type":"chat","context_length":0,"max_output_tokens":0,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"developer":"ChatGLM","developerId":5,"providerId":16,"modelRatio":0.07,"cacheRatio":1,"completionRatio":6,"description":"Z/glm-4.5-air","descriptionEn":"Z/glm-4.5-air","order":849,"flag":1,"source":"public-provider-conf"},"vision":false},{"id":"ahm-Phi-3-5-MoE-instruct","name":"Phi-3-5-MoE-instruct","display_name":"Phi-3-5-MoE-instruct","type":"chat","context_length":0,"max_output_tokens":0,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"developer":"Microsoft","developerId":3,"providerId":45,"modelRatio":0.2,"cacheRatio":1,"completionRatio":4,"description":"Phi-3.5-MoE  Phi-3  128K ","order":0,"flag":0,"source":"public-provider-conf"},"vision":false},{"id":"ahm-Phi-3-5-mini-instruct","name":"Phi-3-5-mini-instruct","display_name":"Phi-3-5-mini-instruct","type":"chat","context_length":0,"max_output_tokens":0,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"developer":"Microsoft","developerId":3,"providerId":45,"modelRatio":0.5,"cacheRatio":1,"completionRatio":3,"description":"Phi-3.5-mini  Phi-3  Phi-3  128K ","descriptionEn":"Phi-3.5-mini is a lightweight, state-of-the-art open model built upon the dataset used for Phi-3which includes synthetic data and carefully curated publicly available websitesfocusing on very high-quality, reasoning-intensive data. This model is part of the Phi-3 model family and supports a context length of 128K tokens.","order":0,"flag":0,"source":"public-provider-conf"},"vision":false},{"id":"ahm-Phi-3-5-vision-instruct","name":"Phi-3-5-vision-instruct","display_name":"Phi-3-5-vision-instruct","type":"chat","context_length":0,"max_output_tokens":0,"capabilities":{"vision":true,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"modalities":{"input":["text","image"],"output":["text","image"]},"metadata":{"developer":"Microsoft","developerId":3,"providerId":45,"modelRatio":0.2,"cacheRatio":1,"completionRatio":4,"order":0,"flag":0,"tags":["multi_modal"],"modalities":["text","image"],"typeHints":["t2t"],"source":"public-provider-conf"},"vision":true},{"id":"ahm-Phi-3-medium-128k","name":"Phi-3-medium-128k","display_name":"Phi-3-medium-128k","type":"chat","context_length":0,"max_output_tokens":0,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"developer":"Microsoft","developerId":3,"providerId":45,"modelRatio":3,"cacheRatio":1,"completionRatio":3,"order":0,"flag":0,"source":"public-provider-conf"},"vision":false},{"id":"ahm-Phi-3-medium-4k","name":"Phi-3-medium-4k","display_name":"Phi-3-medium-4k","type":"chat","context_length":0,"max_output_tokens":0,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"developer":"Microsoft","developerId":3,"providerId":45,"modelRatio":0.5,"cacheRatio":1,"completionRatio":3,"order":0,"flag":0,"source":"public-provider-conf"},"vision":false},{"id":"ahm-Phi-3-small-128k","name":"Phi-3-small-128k","display_name":"Phi-3-small-128k","type":"chat","context_length":0,"max_output_tokens":0,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"developer":"Microsoft","developerId":3,"providerId":45,"modelRatio":0.5,"cacheRatio":1,"completionRatio":3,"order":0,"flag":0,"source":"public-provider-conf"},"vision":false},{"id":"aihub-Phi-4","name":"Phi-4","display_name":"Phi-4","type":"chat","context_length":0,"max_output_tokens":0,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"developer":"Microsoft","developerId":3,"providerId":45,"modelRatio":0.06,"cacheRatio":1,"completionRatio":4,"description":"Phi-4 ","descriptionEn":"Phi-4 is a state-of-the-art open model based on a combination of synthetic datasets, curated public domain website data, and acquired academic books and QA datasets. The approach aims to ensure that small, efficient models are trained using data focused on high quality and advanced reasoning.","order":45,"flag":0,"source":"public-provider-conf"},"vision":false},{"id":"aihub-Phi-4-mini-instruct","name":"Phi-4-mini-instruct","display_name":"Phi-4-mini-instruct","type":"chat","context_length":0,"max_output_tokens":0,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"developer":"Microsoft","developerId":3,"providerId":45,"modelRatio":0.06,"cacheRatio":1,"completionRatio":4,"description":"","descriptionEn":"Microsoft's latest model","order":46,"flag":0,"source":"public-provider-conf"},"vision":false},{"id":"aihub-Phi-4-multimodal-instruct","name":"Phi-4-multimodal-instruct","display_name":"Phi-4-multimodal-instruct","type":"chat","context_length":0,"max_output_tokens":0,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"developer":"Microsoft","developerId":3,"providerId":45,"modelRatio":0.06,"cacheRatio":1,"completionRatio":4,"description":"","descriptionEn":"Microsoft's latest model","order":48,"flag":0,"source":"public-provider-conf"},"vision":false},{"id":"aihubmix-DeepSeek-R1","name":"DeepSeek-R1","display_name":"DeepSeek-R1","type":"chat","context_length":128000,"max_output_tokens":128000,"capabilities":{"vision":false,"function_calling":false,"reasoning":true,"tool_calling":false},"reasoning":true,"tool_call":false,"modalities":{"input":["text"],"output":["text"]},"metadata":{"developer":"DeepSeek","developerId":7,"providerId":36,"modelRatio":0.7,"cacheRatio":1,"completionRatio":4,"description":"Azure  R1 671B 128k Prompt \"\"","descriptionEn":"The fully activated R1 deployed on Azure open source has 671 billion parameters and supports input lengths up to 128k. If the model does not output the reasoning process, you can add a prompt to force it to think first. Suggested prompt: \"Think first, then provide the answer.\"","order":240,"flag":0,"features":["thinking"],"tags":["best"],"modalities":["text"],"typeHints":["t2t"],"source":"public-provider-conf"},"vision":false},{"id":"aihubmix-Llama-3-1-8B-Instruct","name":"Llama-3.1-8B","display_name":"Llama-3.1-8B","type":"chat","context_length":0,"max_output_tokens":0,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"developer":"Meta","developerId":11,"providerId":45,"modelRatio":0.15,"cacheRatio":1,"completionRatio":2,"order":0,"flag":0,"source":"public-provider-conf"},"vision":false},{"id":"aihubmix-Llama-3-3-70B-Instruct","name":"llama-3.3-70b","display_name":"llama-3.3-70b","type":"chat","context_length":0,"max_output_tokens":0,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"developer":"Llama","developerId":11,"providerId":45,"modelRatio":0.4,"cacheRatio":1,"completionRatio":1,"description":"llamaazure","descriptionEn":"The latest llama model is deployed on Microsoft Azure.","order":98,"flag":0,"source":"public-provider-conf"},"vision":false},{"id":"aihubmix-command-r-plus","name":"command-r-plus","display_name":"command-r-plus","type":"chat","context_length":0,"max_output_tokens":0,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"modalities":{"input":["text"],"output":["text"]},"metadata":{"developer":"Cohere","developerId":6,"providerId":45,"modelRatio":1.92,"cacheRatio":1,"completionRatio":5,"order":0,"flag":0,"modalities":["text"],"typeHints":["t2t"],"source":"public-provider-conf"},"vision":false},{"id":"aihubmix-router","name":"aihubmix-router","display_name":"aihubmix-router","type":"chat","context_length":0,"max_output_tokens":0,"capabilities":{"vision":true,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"modalities":{"input":["text","image"],"output":["text","image"]},"metadata":{"developer":"OpenAI","developerId":12,"providerId":1,"modelRatio":0.2,"cacheRatio":0.25,"completionRatio":4,"description":"aihubmix-router GPT-4.160%\n prompt200,00032,768\ngpt-4.1gpt-4.1-minigpt-4.1-nanoo4-mini\naihubmix-router  gpt-4.1-mini \n","descriptionEn":"New model routing capability; request aihubmix-router to automatically route models based on question complexity, so everyone no longer needs to manually switch models; in our tests comparing the use of the model router versus only using GPT-4.1, we observed up to 60% cost savings while maintaining similar accuracy.  \nThe context length of the model router depends on the base model used for each prompt. Input size is 200,000, output size is 32,768.  \nCurrently, there are four routing models: gpt-4.1, gpt-4.1-mini, gpt-4.1-nano, o4-mini.  \nPricing: Due to our current billing structure system, requests through aihubmix-router are billed at the price of gpt-4.1-mini regardless of which final model is used; future billing will be based on the actual model invoked.  \nEveryone is welcome to try it out; the interface will return the name of the actual called model.","order":799,"flag":1,"tags":["best","economical"],"modalities":["text","image"],"typeHints":["t2t"],"source":"public-provider-conf"},"vision":true},{"id":"anthropic-3-5-sonnet-20240620","name":"Claude 3.5 Sonnet","display_name":"Claude 3.5 Sonnet","type":"chat","context_length":200000,"max_output_tokens":200000,"capabilities":{"vision":true,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"modalities":{"input":["text","image"],"output":["text","image"]},"metadata":{"developer":"Anthropic","developerId":2,"providerId":14,"modelRatio":1.65,"cacheRatio":1,"completionRatio":5,"description":"claude","descriptionEn":"Claude model of this site","order":0,"flag":0,"modalities":["text","image"],"typeHints":["t2t"],"source":"public-provider-conf"},"vision":true},{"id":"anthropic-3-5-sonnet-20241022","name":"Claude 3.5 Sonnet","display_name":"Claude 3.5 Sonnet","type":"chat","context_length":200000,"max_output_tokens":200000,"capabilities":{"vision":true,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"modalities":{"input":["text","image"],"output":["text","image"]},"metadata":{"developer":"Anthropic","developerId":2,"providerId":14,"modelRatio":1.65,"cacheRatio":1,"completionRatio":5,"description":"claude","descriptionEn":"Claude model of this site","order":0,"flag":2,"modalities":["text","image"],"typeHints":["t2t"],"source":"public-provider-conf"},"vision":true},{"id":"anthropic-3-7-sonnet-20250219","name":"claude-3-7-sonnet","display_name":"claude-3-7-sonnet","type":"chat","context_length":0,"max_output_tokens":0,"capabilities":{"vision":true,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"modalities":{"input":["text","image"],"output":["text","image"]},"metadata":{"developer":"Anthropic","developerId":2,"providerId":14,"modelRatio":1.65,"cacheRatio":1,"completionRatio":5,"description":"cursor","descriptionEn":"For cursor use only","order":0,"flag":2,"tags":["best","multi_modal","sota"],"modalities":["text","image"],"typeHints":["t2t"],"source":"public-provider-conf"},"vision":true},{"id":"baidu/ERNIE-4.5-300B-A47B","name":"baidu/ERNIE-4.5-300B-A47B","display_name":"baidu/ERNIE-4.5-300B-A47B","type":"chat","context_length":0,"max_output_tokens":0,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"developer":"Baidu","developerId":25,"providerId":44,"modelRatio":0.16,"cacheRatio":0,"completionRatio":4,"description":"ERNIE-4.5-300B-A47B MoE 3000  token  470  ERNIE 4.5  MoE  AI ","descriptionEn":"ERNIE-4.5-300B-A47B is a large language model developed by Baidu based on a Mixture of Experts (MoE) architecture. The model has a total of 300 billion parameters, but only activates 47 billion parameters per token during inference, which balances strong performance with computational efficiency. As one of the core models in the ERNIE 4.5 series, it demonstrates outstanding capabilities in tasks such as text understanding, generation, reasoning, and programming. The model employs an innovative multimodal heterogeneous MoE pretraining approach, leveraging joint training of textual and visual modalities to effectively enhance the models overall abilities, particularly excelling in instruction following and world knowledge memorization. Baidu has open-sourced this model along with other models in the series, aiming to promote the research and application of AI technology.","order":100,"flag":1,"source":"public-provider-conf"},"vision":false},{"id":"bge-large-en","name":"bge-large-en","display_name":"bge-large-en","type":"embedding","context_length":0,"max_output_tokens":0,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"developer":"Baidu","developerId":25,"providerId":15,"modelRatio":0.034,"cacheRatio":1,"completionRatio":1,"description":"bge-large-en ","descriptionEn":"bge-large-en, open-sourced by the Beijing Academy of Artificial Intelligence (BAAI), is currently the most powerful vector representation model for Chinese tasks, with its semantic representation capabilities comprehensively surpassing those of similar open-source models.","order":100,"flag":0,"typeHints":["embedding"],"source":"public-provider-conf"},"vision":false},{"id":"bge-large-zh","name":"bge-large-zh","display_name":"bge-large-zh","type":"embedding","context_length":0,"max_output_tokens":0,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"developer":"Baidu","developerId":25,"providerId":15,"modelRatio":0.034,"cacheRatio":1,"completionRatio":1,"description":"bge-large-zh ","descriptionEn":"bge-large-zh, open-sourced by the Beijing Academy of Artificial Intelligence (BAAI), is currently the most powerful vector representation model for Chinese tasks, with its semantic representation capabilities comprehensively surpassing those of similar open-source models.","order":100,"flag":0,"typeHints":["embedding"],"source":"public-provider-conf"},"vision":false},{"id":"chatgpt-4o-latest","name":"gpt-4o","display_name":"gpt-4o","type":"chat","context_length":0,"max_output_tokens":0,"capabilities":{"vision":true,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"modalities":{"input":["text","image"],"output":["text","image"]},"metadata":{"developer":"OpenAI","developerId":12,"providerId":1,"modelRatio":2.5,"cacheRatio":1,"completionRatio":3,"description":"ChatGPTGPT-4o","descriptionEn":"This model will point to the latest GPT-4o model used by ChatGPT.","order":110,"flag":0,"tags":["multi_modal","bold"],"modalities":["text","image"],"typeHints":["t2t"],"source":"public-provider-conf"},"vision":true},{"id":"chutesai/Llama-4-Maverick-17B-128E-Instruct-FP8","name":"Llama-4-Maverick-17B","display_name":"Llama-4-Maverick-17B","type":"chat","context_length":0,"max_output_tokens":0,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"developer":"Llama","developerId":11,"providerId":8,"modelRatio":0.125,"cacheRatio":0,"completionRatio":1,"description":"chutes.ai \nLlama 4AI\nLlama 4LlamaLlama 4Llama 4 Scout17016Llama 4 Maverick170128","descriptionEn":"chutes.ai\nThe Llama 4 collection of models are natively multimodal AI models that enable text and multimodal experiences. These models leverage a mixture-of-experts architecture to offer industry-leading performance in text and image understanding.\n\nThese Llama 4 models mark the beginning of a new era for the Llama ecosystem. We are launching two efficient models in the Llama 4 series, Llama 4 Scout, a 17 billion parameter model with 16 experts, and Llama 4 Maverick, a 17 billion parameter model with 128 experts.","order":701,"flag":0,"source":"public-provider-conf"},"vision":false},{"id":"chutesai/Llama-4-Scout-17B-16E-Instruct","name":"Llama-4-Scout-17B","display_name":"Llama-4-Scout-17B","type":"chat","context_length":0,"max_output_tokens":0,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"developer":"Llama","developerId":11,"providerId":8,"modelRatio":0.1,"cacheRatio":0,"completionRatio":1,"description":"chutes.ai \nLlama 4AI\nLlama 4LlamaLlama 4Llama 4 Scout17016Llama 4 Maverick170128","descriptionEn":"chutes.ai\nThe Llama 4 collection of models are natively multimodal AI models that enable text and multimodal experiences. These models leverage a mixture-of-experts architecture to offer industry-leading performance in text and image understanding.\nThese Llama 4 models mark the beginning of a new era for the Llama ecosystem. We are launching two efficient models in the Llama 4 series, Llama 4 Scout, a 17 billion parameter model with 16 experts, and Llama 4 Maverick, a 17 billion parameter model with 128 experts.","order":699,"flag":0,"source":"public-provider-conf"},"vision":false},{"id":"chutesai/Mistral-Small-3.1-24B-Instruct-2503","name":"Mistral-Small-3.1-24B","display_name":"Mistral-Small-3.1-24B","type":"chat","context_length":0,"max_output_tokens":0,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"developer":"Mistral","developerId":10,"providerId":8,"modelRatio":0.1,"cacheRatio":1,"completionRatio":4,"description":"Mistralchutes.ai","descriptionEn":"Mistral's latest open-source small model; provided by chutes.ai.","order":101,"flag":0,"source":"public-provider-conf"},"vision":false},{"id":"claude-3-5-haiku-20241022","name":"claude-3-5-haiku","display_name":"claude-3-5-haiku","type":"chat","context_length":0,"max_output_tokens":0,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"developer":"Anthropic","developerId":2,"providerId":14,"modelRatio":0.55,"cacheRatio":1,"completionRatio":5,"description":"Claude 3.5 Haiku ClaudeAiHubMixClaudeAWS ClaudeVertex AI Claude,","descriptionEn":"Claude 3.5 Haiku is the next generation of Claude's fastest model. The AiHubMix model simultaneously and automatically routes through three official channelsClaude, AWS Claude, and Google Vertex AI Claudeto achieve high-concurrency load balancing.","order":98,"flag":0,"source":"public-provider-conf"},"vision":false},{"id":"claude-3-5-haiku-latest","name":"claude-3-5-haiku","display_name":"claude-3-5-haiku","type":"chat","context_length":0,"max_output_tokens":0,"capabilities":{"vision":true,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"modalities":{"input":["text","image"],"output":["text","image"]},"metadata":{"developer":"Anthropic","developerId":2,"providerId":14,"modelRatio":0.55,"cacheRatio":1,"completionRatio":5,"order":0,"flag":0,"tags":["lightning","economical"],"modalities":["text","image"],"typeHints":["t2t"],"source":"public-provider-conf"},"vision":true},{"id":"claude-3-5-sonnet-20240620","name":"Claude 3.5 Sonnet","display_name":"Claude 3.5 Sonnet","type":"chat","context_length":0,"max_output_tokens":0,"capabilities":{"vision":true,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"modalities":{"input":["text","image"],"output":["text","image"]},"metadata":{"developer":"Anthropic","developerId":2,"providerId":14,"modelRatio":1.65,"cacheRatio":1,"completionRatio":5,"order":0,"flag":0,"tags":["multi_modal","best"],"modalities":["text","image"],"typeHints":["t2t"],"source":"public-provider-conf"},"vision":true},{"id":"claude-3-5-sonnet-20241022","name":"Claude 3.5 Sonnet","display_name":"Claude 3.5 Sonnet","type":"chat","context_length":200000,"max_output_tokens":200000,"capabilities":{"vision":true,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"modalities":{"input":["text","image"],"output":["text","image"]},"metadata":{"developer":"Anthropic","developerId":2,"providerId":14,"modelRatio":1.65,"cacheRatio":1,"completionRatio":5,"description":"Claude 3.5 SonnetAiHubMixClaudeAWS ClaudeVertex AI Claude,","descriptionEn":"Claude 3.5 Sonnet is the latest model; this AiHubMix model automatically routes through the three official Claude channelsClaude, AWS Claude, and Google Vertex AI Claudeto achieve high-concurrency load balancing.","order":130,"flag":0,"tags":["multi_modal","best"],"modalities":["text","image"],"typeHints":["t2t"],"source":"public-provider-conf"},"vision":true},{"id":"claude-3-5-sonnet-latest","name":"Claude 3.5 Sonnet","display_name":"Claude 3.5 Sonnet","type":"chat","context_length":200000,"max_output_tokens":200000,"capabilities":{"vision":true,"function_calling":true,"reasoning":false,"tool_calling":true},"reasoning":false,"tool_call":true,"modalities":{"input":["text","image"],"output":["text","image"]},"metadata":{"developer":"Anthropic","developerId":2,"providerId":14,"modelRatio":1.65,"cacheRatio":1,"completionRatio":5,"description":"claude-3-5-sonnet-20241022","descriptionEn":"Automatically points to the latest version; currently pointing to claude-3-5-sonnet-20241022.","order":9,"flag":0,"features":["function_calling","structured_outputs"],"tags":["multi_modal","best","bold"],"modalities":["text","image"],"typeHints":["t2t"],"source":"public-provider-conf"},"vision":true},{"id":"claude-3-5-sonnet@20240620","name":"Claude 3.5 Sonnet","display_name":"Claude 3.5 Sonnet","type":"chat","context_length":0,"max_output_tokens":0,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"developer":"Anthropic","developerId":2,"providerId":42,"modelRatio":1.65,"cacheRatio":1,"completionRatio":5,"description":"Claude","order":0,"flag":0,"source":"public-provider-conf"},"vision":false},{"id":"claude-3-7-sonnet-20250219","name":"Claude 3.7 Sonnet","display_name":"Claude 3.7 Sonnet","type":"chat","context_length":200000,"max_output_tokens":200000,"capabilities":{"vision":true,"function_calling":false,"reasoning":true,"tool_calling":false},"reasoning":true,"tool_call":false,"modalities":{"input":["text","image"],"output":["text","image"]},"metadata":{"developer":"Anthropic","developerId":2,"providerId":14,"modelRatio":1.65,"cacheRatio":1,"completionRatio":5,"description":"claude sdkthinking","descriptionEn":"Support for the thinking parameter through the original Claude SDK.","order":500,"flag":2,"features":["thinking"],"tags":["multi_modal","best","sota","bold"],"modalities":["text","image"],"typeHints":["t2t"],"source":"public-provider-conf"},"vision":true},{"id":"claude-3-haiku-20240307","name":"Claude 3 Haiku","display_name":"Claude 3 Haiku","type":"chat","context_length":0,"max_output_tokens":0,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"developer":"Anthropic","developerId":2,"providerId":14,"modelRatio":0.14,"cacheRatio":1,"completionRatio":5,"order":0,"flag":0,"source":"public-provider-conf"},"vision":false},{"id":"claude-3-opus-20240229","name":"Claude 3 Opus","display_name":"Claude 3 Opus","type":"chat","context_length":0,"max_output_tokens":0,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"developer":"Anthropic","developerId":2,"providerId":14,"modelRatio":8.4,"cacheRatio":1,"completionRatio":5,"description":"claude","descriptionEn":"Claudes previous generation strongest model","order":45,"flag":0,"source":"public-provider-conf"},"vision":false},{"id":"claude-3-sonnet-20240229","name":"Claude 3 Sonnet","display_name":"Claude 3 Sonnet","type":"chat","context_length":200000,"max_output_tokens":200000,"capabilities":{"vision":true,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"modalities":{"input":["text","image"],"output":["text","image"]},"metadata":{"developer":"Anthropic","developerId":2,"providerId":14,"modelRatio":2,"cacheRatio":1,"completionRatio":5,"order":0,"flag":0,"modalities":["text","image"],"typeHints":["t2t"],"source":"public-provider-conf"},"vision":true},{"id":"claude-opus-4-0","name":"claude-opus-4-0","display_name":"claude-opus-4-0","type":"chat","context_length":0,"max_output_tokens":0,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"developer":"Anthropic","developerId":2,"providerId":14,"modelRatio":8.4,"cacheRatio":1,"completionRatio":5,"description":"Alias \nclaude-opus-4-20250514","descriptionEn":"Alias \nclaude-opus-4-20250514","order":1,"flag":0,"source":"public-provider-conf"},"vision":false},{"id":"claude-opus-4-1-20250805","name":"claude-opus-4-1-20250805","display_name":"claude-opus-4-1-20250805","type":"chat","context_length":0,"max_output_tokens":0,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"developer":"Anthropic","developerId":2,"providerId":14,"modelRatio":8.25,"cacheRatio":1,"completionRatio":5,"description":"Opus 4.1  Claude Opus 4  Opus 4 Opus 4.1Opus 4.1  74.5%","descriptionEn":"Opus 4.1 is an upgraded version of Claude Opus 4, with improvements mainly in agent tasks, practical coding, and reasoning. Compared to Opus 4, there is a slight improvement in software engineering accuracy; Opus 4.1 has higher accuracy at 74.5%.","order":954,"flag":1,"source":"public-provider-conf"},"vision":false},{"id":"claude-opus-4-20250514","name":"claude-opus-4-20250514","display_name":"claude-opus-4-20250514","type":"chat","context_length":200000,"max_output_tokens":200000,"capabilities":{"vision":true,"function_calling":true,"reasoning":true,"tool_calling":true},"reasoning":true,"tool_call":true,"modalities":{"input":["text","image"],"output":["text","image"]},"metadata":{"developer":"Anthropic","developerId":2,"providerId":14,"modelRatio":8.4,"cacheRatio":1,"completionRatio":5,"description":"Claude Opus 4  Anthropic  \n\n\t\t SWE-bench  72.5% Terminal-bench  43.2% OpenAI  GPT-4.1  Google  Gemini 2.5 Pro   \n\t\t\n\t\t  \n\t\tOpus 4   \n ","descriptionEn":"Positioning:\nClaude Opus 4 is Anthropic's most powerful model to date, specifically designed for complex, long-running tasks requiring deep reasoning and advanced capabilities.\nKey Features:\nExceptional Coding Skills: Achieves a 72.5% score on SWE-bench and 43.2% on Terminal-bench, surpassing competitors like OpenAI's GPT-4.1 and Google's Gemini 2.5 Pro.\nLong-term Autonomous Operations: Capable of maintaining continuous focus and effectiveness over extended periods, suitable for tasks demanding prolonged reasoning.\nEnhanced Reasoning Capabilities: Incorporates a \"Thought Summarization\" feature, simplifying complex reasoning processes into understandable summaries, improving interpretability.\nAdvanced Safety Measures: Features robust security controls due to its powerful capabilities, aiming to prevent potential misuse.\nIdeal Use Cases:\nBest suited for advanced applications such as scientific research, legal analysis, and large-scale software development.","order":860,"flag":1,"features":["thinking","tools","function_calling","structured_outputs"],"tags":["multi_modal","best","sota"],"modalities":["text","image"],"typeHints":["t2t"],"source":"public-provider-conf"},"vision":true},{"id":"claude-sonnet-4-0","name":"claude-sonnet-4-0","display_name":"claude-sonnet-4-0","type":"chat","context_length":0,"max_output_tokens":0,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"developer":"Anthropic","developerId":2,"providerId":14,"modelRatio":1.65,"cacheRatio":1,"completionRatio":5,"description":"Alias \nclaude-sonnet-4-20250514","descriptionEn":"Alias \nclaude-sonnet-4-20250514","order":1,"flag":0,"source":"public-provider-conf"},"vision":false},{"id":"claude-sonnet-4-20250514","name":"claude-sonnet-4-20250514","display_name":"claude-sonnet-4-20250514","type":"chat","context_length":200000,"max_output_tokens":200000,"capabilities":{"vision":true,"function_calling":true,"reasoning":true,"tool_calling":true},"reasoning":true,"tool_call":true,"modalities":{"input":["text","image"],"output":["text","image"]},"metadata":{"developer":"Anthropic","developerId":2,"providerId":14,"modelRatio":1.65,"cacheRatio":1,"completionRatio":5,"description":"Claude Sonnet 4  Claude Sonnet 3.7  \n\n\t\t SWE-bench  72.7% Terminal-bench  35.5%  \n\t\t\n\t\t  \n\t\tSonnet 4  Anthropic APIAmazon Bedrock  Google Cloud  Vertex AI   \n","descriptionEn":"Positioning:\nClaude Sonnet 4 is an efficient, cost-effective model, an upgraded successor to Claude Sonnet 3.7, optimized for everyday tasks and medium-complexity applications.\nKey Features:\nStrong Coding Performance: Scores 72.7% on SWE-bench and 35.5% on Terminal-bench, demonstrating excellent programming abilities.\nEfficient Reasoning: Balances rapid response times with precise reasoning and adherence to instructions.\nImproved Memory Capabilities: Enhanced ability to store and retrieve critical information effectively when given local file access.\nBroad Accessibility: Available to both free and paid users via Anthropic API, Amazon Bedrock, and Google Cloud's Vertex AI platform.\nIdeal Use Cases:\nIdeal for everyday office tasks, content creation, educational purposes, and mid-complexity programming projects where cost-effectiveness and responsiveness are priorities.","order":855,"flag":1,"billingConfig":"{\n    \"model_name\": \"claude-sonnet-4-20250514\",\n    \"default_tier\": \"tier1\",\n    \"token_based_tier_configs\":\n    {\n        \"tier1\":\n        {\n            \"tier_condition\":\n            {\n                \"min_tokens\": 0,\n                \"max_tokens\": 200000\n            },\n            \"model_ratio\": 1.65,\n            \"prompt_tokens_ratio\": 1.0,\n            \"completion_tokens_ratio\": 5.0,\n            \"cached_tokens_ratio\": 0.1,\n            \"cache_write_5_minutes_tokens_ratio\": 1.25,\n            \"cache_write_1_hour_tokens_ratio\":2\n        },\n        \"tier2\":\n        {\n            \"tier_condition\":\n            {\n                \"min_tokens\": 200001,\n                \"max_tokens\": -1\n            },\n            \"model_ratio\": 2.2,\n            \"prompt_tokens_ratio\": 1.0,\n            \"completion_tokens_ratio\": 3.75,\n            \"cached_tokens_ratio\": 0.1,\n            \"cache_write_5_minutes_tokens_ratio\": 1.25,\n            \"cache_write_1_hour_tokens_ratio\":2\n            \n        }\n    },\n    \"per_unit_price_config\":\n    {\n        \"web_search_price\": 0.01\n    },\n    \"enabled_billing_items\":\n    [\n        \"prompt_tokens\",\n        \"completion_tokens\",\n        \"cached_tokens\",\n        \"web_search_requests\",\n        \"cache_write_5_minutes_tokens\",\n        \"cache_write_1_hour_tokens\"\n    ]\n}","features":["thinking","tools","function_calling","structured_outputs"],"tags":["multi_modal","best","sota","bold"],"modalities":["text","image"],"typeHints":["t2t"],"source":"public-provider-conf"},"vision":true},{"id":"claude-sonnet-4-5-20250929","name":"claude-sonnet-4-5-20250929","display_name":"claude-sonnet-4-5-20250929","type":"chat","context_length":0,"max_output_tokens":0,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"developer":"Anthropic","developerId":2,"providerId":14,"modelRatio":1.65,"cacheRatio":0.1,"completionRatio":5,"description":"Sonnet 4.5 ","descriptionEn":"Sonnet 4.5 is the best model in the world for agents, coding, and computer use. Its also our most accurate and detailed model for long-running tasks, with enhanced domain knowledge in coding, finance, and cybersecurity.","order":1001,"flag":1,"billingConfig":"{\n    \"model_name\": \"claude-sonnet-4-5-20250929\",\n    \"default_tier\": \"tier1\",\n    \"token_based_tier_configs\":\n    {\n        \"tier1\":\n        {\n            \"tier_condition\":\n            {\n                \"min_tokens\": 0,\n                \"max_tokens\": 200000\n            },\n            \"model_ratio\": 1.65,\n            \"prompt_tokens_ratio\": 1.0,\n            \"completion_tokens_ratio\": 5.0,\n            \"cached_tokens_ratio\": 0.1,\n            \"cache_write_5_minutes_tokens_ratio\": 1.25,\n            \"cache_write_1_hour_tokens_ratio\":2\n        },\n        \"tier2\":\n        {\n            \"tier_condition\":\n            {\n                \"min_tokens\": 200001,\n                \"max_tokens\": -1\n            },\n            \"model_ratio\": 2.2,\n            \"prompt_tokens_ratio\": 1.0,\n            \"completion_tokens_ratio\": 3.75,\n            \"cached_tokens_ratio\": 0.1,\n            \"cache_write_5_minutes_tokens_ratio\": 1.25,\n            \"cache_write_1_hour_tokens_ratio\":2\n            \n        }\n    },\n    \"per_unit_price_config\":\n    {\n        \"web_search_price\": 0.01\n    },\n    \"enabled_billing_items\":\n    [\n        \"prompt_tokens\",\n        \"completion_tokens\",\n        \"cached_tokens\",\n        \"web_search_requests\",\n        \"cache_write_5_minutes_tokens\",\n        \"cache_write_1_hour_tokens\"\n    ]\n}","source":"public-provider-conf"},"vision":false},{"id":"codestral-latest","name":"Codestral 25.01","display_name":"Codestral 25.01","type":"chat","context_length":0,"max_output_tokens":0,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"developer":"Mistral","developerId":10,"providerId":28,"modelRatio":0.2,"cacheRatio":1,"completionRatio":3,"description":"Mistral code - Codestral 25.01;https://mistral.ai/news/codestral-2501/","descriptionEn":"Mistral has launched a new code model - Codestral 25.01; https://mistral.ai/news/codestral-2501/","order":100,"flag":0,"source":"public-provider-conf"},"vision":false},{"id":"codex-mini-latest","name":"codex-mini-latest","display_name":"codex-mini-latest","type":"chat","context_length":200000,"max_output_tokens":200000,"capabilities":{"vision":true,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"modalities":{"input":["text","image"],"output":["text","image"]},"metadata":{"developer":"OpenAI","developerId":12,"providerId":1,"modelRatio":0.75,"cacheRatio":0.25,"completionRatio":4,"description":"v1/responses  https://docs.aihubmix.com/cn/api/Responses-API\ncodex-mini-latest  Codex CLI  o4-mini  API  gpt-4.1  75%","descriptionEn":"Only supports v1/responses API calls.https://docs.aihubmix.com/en/api/Responses-API\ncodex-mini-latest is a fine-tuned version of o4-mini specifically for use in Codex CLI. For direct use in the API, we recommend starting with gpt-4.1.","order":600,"flag":1,"tags":["best","economical"],"modalities":["text","image"],"typeHints":["t2t"],"source":"public-provider-conf"},"vision":true},{"id":"cogview-3-plus","name":"cogview-3-plus","display_name":"cogview-3-plus","type":"chat","context_length":0,"max_output_tokens":0,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"developer":" ChatGLM","developerId":5,"providerId":16,"modelRatio":5,"cacheRatio":1,"completionRatio":1,"order":0,"flag":0,"source":"public-provider-conf"},"vision":false},{"id":"command","name":"command","display_name":"command","type":"chat","context_length":0,"max_output_tokens":0,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"modalities":{"input":["text"],"output":["text"]},"metadata":{"developer":"Cohere","developerId":6,"providerId":35,"modelRatio":0.5,"cacheRatio":1,"completionRatio":2,"order":0,"flag":0,"modalities":["text"],"typeHints":["t2t"],"source":"public-provider-conf"},"vision":false},{"id":"command-a-03-2025","name":"Command A","display_name":"Command A","type":"chat","context_length":0,"max_output_tokens":0,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"modalities":{"input":["text"],"output":["text"]},"metadata":{"developer":"Cohere","developerId":6,"providerId":35,"modelRatio":1.25,"cacheRatio":0,"completionRatio":4,"description":"Command A CohereRAGCommand A  256K GPU  Command R+ 08-2024  150%","descriptionEn":"Command A is Cohere most performant model to date, excelling at tool use, agents, retrieval augmented generation (RAG), and multilingual use cases. Command A has a context length of 256K, only requires two GPUs to run, and has 150% higher throughput compared to Command R+ 08-2024.","order":40,"flag":1,"tags":["bold"],"modalities":["text"],"typeHints":["t2t"],"source":"public-provider-conf"},"vision":false},{"id":"command-light","name":"command-light","display_name":"command-light","type":"chat","context_length":0,"max_output_tokens":0,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"developer":"Cohere","developerId":6,"providerId":35,"modelRatio":0.5,"cacheRatio":1,"completionRatio":2,"order":0,"flag":0,"source":"public-provider-conf"},"vision":false},{"id":"command-light-nightly","name":"command-light","display_name":"command-light","type":"chat","context_length":0,"max_output_tokens":0,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"developer":"Cohere","developerId":6,"providerId":35,"modelRatio":0.5,"cacheRatio":1,"completionRatio":2,"order":0,"flag":0,"source":"public-provider-conf"},"vision":false},{"id":"command-nightly","name":"command-nightly","display_name":"command-nightly","type":"chat","context_length":0,"max_output_tokens":0,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"developer":"Cohere","developerId":6,"providerId":35,"modelRatio":0.5,"cacheRatio":1,"completionRatio":2,"order":0,"flag":0,"source":"public-provider-conf"},"vision":false},{"id":"command-r","name":"command-r","display_name":"command-r","type":"chat","context_length":0,"max_output_tokens":0,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"modalities":{"input":["text"],"output":["text"]},"metadata":{"developer":"Cohere","developerId":6,"providerId":35,"modelRatio":0.32,"cacheRatio":1,"completionRatio":3,"order":0,"flag":0,"modalities":["text"],"typeHints":["t2t"],"source":"public-provider-conf"},"vision":false},{"id":"command-r-plus","name":"command-r-plus","display_name":"command-r-plus","type":"chat","context_length":0,"max_output_tokens":0,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"modalities":{"input":["text"],"output":["text"]},"metadata":{"developer":"Cohere","developerId":6,"providerId":35,"modelRatio":1.92,"cacheRatio":1,"completionRatio":5,"order":0,"flag":0,"modalities":["text"],"typeHints":["t2t"],"source":"public-provider-conf"},"vision":false},{"id":"computer-use-preview","name":"computer-use-preview","display_name":"computer-use-preview","type":"chat","context_length":0,"max_output_tokens":0,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"developer":"OpenAI","developerId":12,"providerId":1,"modelRatio":1.5,"cacheRatio":1,"completionRatio":4,"order":1,"flag":1,"source":"public-provider-conf"},"vision":false},{"id":"dall-e-2","name":"dall-e-2","display_name":"dall-e-2","type":"chat","context_length":0,"max_output_tokens":0,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"developer":"OpenAI","developerId":12,"providerId":1,"modelRatio":8,"cacheRatio":1,"completionRatio":1,"order":0,"flag":0,"source":"public-provider-conf"},"vision":false},{"id":"dall-e-3","name":"dall-e-3","display_name":"dall-e-3","type":"image-generation","context_length":0,"max_output_tokens":0,"capabilities":{"vision":true,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"modalities":{"input":["text","image"],"output":["text","image"]},"metadata":{"developer":"OpenAI","developerId":12,"providerId":1,"modelRatio":20,"cacheRatio":1,"completionRatio":1,"order":45,"flag":0,"displayInput":"-","displayOutput":"$ 0.04 / IMG","tags":["best"],"modalities":["text","image"],"typeHints":["t2i"],"source":"public-provider-conf"},"vision":true},{"id":"davinci-002","name":"davinci","display_name":"davinci","type":"chat","context_length":0,"max_output_tokens":0,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"developer":"OpenAI","developerId":12,"providerId":1,"modelRatio":1,"cacheRatio":1,"completionRatio":1,"order":0,"flag":0,"source":"public-provider-conf"},"vision":false},{"id":"deepseek-ai/DeepSeek-Prover-V2-671B","name":"deepseek-ai/DeepSeek-Prover-V2-671B","display_name":"deepseek-ai/DeepSeek-Prover-V2-671B","type":"chat","context_length":0,"max_output_tokens":0,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"developer":"DeepSeek","developerId":7,"providerId":8,"modelRatio":0.05,"cacheRatio":1,"completionRatio":1,"description":"chutes.ai\nDeepSeek Prover V2  6710  DeepSeek-Prover-V1.5  DeepSeek  Hugging Face ","descriptionEn":"Provided by chutes.ai\nDeepSeek Prover V2 is a 671B parameter model, speculated to be geared towards logic and mathematics. Likely an upgrade from DeepSeek-Prover-V1.5 Not much is known about the model yet, as DeepSeek released it on Hugging Face without an announcement or description.","order":500,"flag":0,"source":"public-provider-conf"},"vision":false},{"id":"deepseek-ai/DeepSeek-R1","name":"DeepSeek-R1","display_name":"DeepSeek-R1","type":"chat","context_length":0,"max_output_tokens":0,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"developer":"DeepSeek","developerId":7,"providerId":36,"modelRatio":0.25,"cacheRatio":1,"completionRatio":1,"description":"","descriptionEn":"Deployed from multiple open-source sources","order":100,"flag":0,"source":"public-provider-conf"},"vision":false},{"id":"deepseek-ai/DeepSeek-R1-0528","name":"deepseek-ai/DeepSeek-R1-0528","display_name":"deepseek-ai/DeepSeek-R1-0528","type":"chat","context_length":131072,"max_output_tokens":65536,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":true,"tool_call":false,"metadata":{"developer":"DeepSeek","developerId":7,"providerId":8,"modelRatio":0.3,"cacheRatio":1,"completionRatio":1,"description":"chutes.ai \n R1","descriptionEn":"Provided by chutes.ai\nLatest version R1","order":381,"flag":1,"source":"public-provider-conf"},"vision":false},{"id":"deepseek-ai/DeepSeek-R1-Distill-Qwen-14B","name":"deepseek-ai/DeepSeek-R1-Distill-Qwen-14B","display_name":"deepseek-ai/DeepSeek-R1-Distill-Qwen-14B","type":"chat","context_length":0,"max_output_tokens":0,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"developer":"DeepSeek","developerId":7,"providerId":36,"modelRatio":0.05,"cacheRatio":1,"completionRatio":1,"description":"siliconflow","descriptionEn":"Open source deployment from SiliconFlow, the model itself is obtained through knowledge distillation.","order":0,"flag":0,"source":"public-provider-conf"},"vision":false},{"id":"deepseek-ai/DeepSeek-R1-Distill-Qwen-32B","name":"deepseek-ai/DeepSeek-R1-Distill-Qwen-32B","display_name":"deepseek-ai/DeepSeek-R1-Distill-Qwen-32B","type":"chat","context_length":0,"max_output_tokens":0,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"developer":"DeepSeek","developerId":7,"providerId":36,"modelRatio":0.1,"cacheRatio":1,"completionRatio":1,"description":"siliconflow","descriptionEn":"Open source deployment from SiliconFlow, the model itself is obtained through knowledge distillation.","order":0,"flag":0,"source":"public-provider-conf"},"vision":false},{"id":"deepseek-ai/DeepSeek-R1-Distill-Qwen-7B","name":"deepseek-ai/DeepSeek-R1-Distill-Qwen-7B","display_name":"deepseek-ai/DeepSeek-R1-Distill-Qwen-7B","type":"chat","context_length":0,"max_output_tokens":0,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"developer":"DeepSeek","developerId":7,"providerId":36,"modelRatio":0.005,"cacheRatio":1,"completionRatio":1,"description":"siliconflow","descriptionEn":"Open source deployment from SiliconFlow, the model itself is obtained through knowledge distillation.","order":0,"flag":0,"source":"public-provider-conf"},"vision":false},{"id":"deepseek-ai/DeepSeek-R1-Zero","name":"deepseek-ai/DeepSeek-R1-Zero","display_name":"deepseek-ai/DeepSeek-R1-Zero","type":"chat","context_length":0,"max_output_tokens":0,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"developer":"DeepSeek","developerId":7,"providerId":8,"modelRatio":1.1,"cacheRatio":1,"completionRatio":1,"description":"chutes.aiFP8;zeroR1","descriptionEn":"Openly deployed by chutes.ai; inference with FP8; zero is the initial preliminary version of R1 without optimizations and is not recommended for use unless for research purposes.","order":43,"flag":0,"source":"public-provider-conf"},"vision":false},{"id":"deepseek-ai/DeepSeek-V2.5","name":"DeepSeek-V2.5","display_name":"DeepSeek-V2.5","type":"chat","context_length":0,"max_output_tokens":0,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"developer":"DeepSeek","developerId":7,"providerId":44,"modelRatio":0.08,"cacheRatio":1,"completionRatio":2,"order":0,"flag":0,"source":"public-provider-conf"},"vision":false},{"id":"deepseek-ai/DeepSeek-V3","name":"DeepSeek-V3","display_name":"DeepSeek-V3","type":"chat","context_length":0,"max_output_tokens":0,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"developer":"DeepSeek","developerId":7,"providerId":8,"modelRatio":0.15,"cacheRatio":1,"completionRatio":1,"description":"","descriptionEn":"Sourced from multiple open-source deployment routes; relatively stable provision.","order":13,"flag":0,"source":"public-provider-conf"},"vision":false},{"id":"deepseek-ai/DeepSeek-V3-0324","name":"deepseek-ai/DeepSeek-V3-0324","display_name":"deepseek-ai/DeepSeek-V3-0324","type":"chat","context_length":131072,"max_output_tokens":65536,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"modalities":{"input":["text"],"output":["text"]},"metadata":{"developer":"DeepSeek","developerId":7,"providerId":8,"modelRatio":0.1,"cacheRatio":0,"completionRatio":4,"description":"chutes.ai deepseek  v3-0324\nDeepSeek V3 685  DeepSeek \nDeepSeek V3","descriptionEn":"Provided by chutes.ai;  \nDeepseek latest version v3-0324;  \nDeepSeek V3 is an expert mixture model with 68.5 billion parameters, and it is the latest version in the flagship chat model series of the DeepSeek team. It inherits from the DeepSeek V3 model and performs excellently across various tasks.","order":250,"flag":2,"tags":["best","economical"],"modalities":["text"],"typeHints":["t2t"],"source":"public-provider-conf"},"vision":false},{"id":"deepseek-ai/deepseek-vl2","name":"deepseek-ai/deepseek-vl2","display_name":"deepseek-ai/deepseek-vl2","type":"chat","context_length":0,"max_output_tokens":0,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"developer":"DeepSeek","developerId":7,"providerId":44,"modelRatio":0.08,"cacheRatio":1,"completionRatio":1,"order":0,"flag":0,"source":"public-provider-conf"},"vision":false},{"id":"deepseek-chat","name":"DeepSeek-V3.1","display_name":"DeepSeek-V3.1","type":"chat","context_length":128000,"max_output_tokens":128000,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"developer":"DeepSeek","developerId":7,"providerId":36,"modelRatio":0.28,"cacheRatio":0.125,"completionRatio":3,"description":"DeepSeek-V3.1-Terminus (non-thinking mode)","descriptionEn":"DeepSeek-V3.1-Terminus (non-thinking mode)","order":99,"flag":0,"source":"public-provider-conf"},"vision":false},{"id":"deepseek-r1-250120","name":"deepseek-r1-250120","display_name":"deepseek-r1-250120","type":"chat","context_length":0,"max_output_tokens":0,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"developer":"DeepSeek","developerId":7,"providerId":40,"modelRatio":0.273,"cacheRatio":1,"completionRatio":4,"order":0,"flag":0,"source":"public-provider-conf"},"vision":false},{"id":"deepseek-r1-250528","name":"deepseek-r1-250528","display_name":"deepseek-r1-250528","type":"chat","context_length":0,"max_output_tokens":0,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"developer":"DeepSeek","developerId":7,"providerId":40,"modelRatio":0.273,"cacheRatio":1,"completionRatio":4,"description":"","descriptionEn":"From ByteDance.","order":0,"flag":0,"source":"public-provider-conf"},"vision":false},{"id":"deepseek-r1-distill-llama-70b","name":"deepseek-r1-distill-llama-70b","display_name":"deepseek-r1-distill-llama-70b","type":"chat","context_length":0,"max_output_tokens":0,"capabilities":{"vision":false,"function_calling":false,"reasoning":true,"tool_calling":false},"reasoning":true,"tool_call":false,"modalities":{"input":["text"],"output":["text"]},"metadata":{"developer":"DeepSeek","developerId":7,"providerId":36,"modelRatio":0.4,"cacheRatio":1,"completionRatio":2,"description":"groqDeepSeek-R1-DistillDeepSeek-R1","descriptionEn":"Provided by Groq, the DeepSeek-R1-Distill model is fine-tuned based on an open-source model, using samples generated by DeepSeek-R1. We have made slight modifications to their configurations and tokenizers. Please use our settings to run these models.","order":188,"flag":0,"features":["thinking"],"tags":["lightning"],"modalities":["text"],"typeHints":["t2t"],"source":"public-provider-conf"},"vision":false},{"id":"deepseek-r1-distill-qianfan-llama-8b","name":"deepseek-r1-distill-qianfan-llama-8b","display_name":"deepseek-r1-distill-qianfan-llama-8b","type":"chat","context_length":0,"max_output_tokens":0,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"developer":"DeepSeek","developerId":11,"providerId":24,"modelRatio":0.0685,"cacheRatio":1,"completionRatio":4,"order":0,"flag":0,"source":"public-provider-conf"},"vision":false},{"id":"deepseek-reasoner","name":"DeepSeek-R1","display_name":"DeepSeek-R1","type":"chat","context_length":0,"max_output_tokens":0,"capabilities":{"vision":false,"function_calling":false,"reasoning":true,"tool_calling":false},"reasoning":true,"tool_call":false,"modalities":{"input":["text"],"output":["text"]},"metadata":{"developer":"DeepSeek","developerId":7,"providerId":36,"modelRatio":0.14,"cacheRatio":0.1,"completionRatio":1.5,"description":"DeepSeek-V3.2-Exp-Think","descriptionEn":"DeepSeek-V3.2-Exp-Think","order":248,"flag":0,"features":["thinking"],"modalities":["text"],"typeHints":["t2t"],"source":"public-provider-conf"},"vision":false},{"id":"deepseek-v3-250324","name":"deepseek-v3-250324","display_name":"deepseek-v3-250324","type":"chat","context_length":0,"max_output_tokens":0,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"developer":"DeepSeek","developerId":7,"providerId":40,"modelRatio":0.136,"cacheRatio":1,"completionRatio":4,"order":0,"flag":0,"source":"public-provider-conf"},"vision":false},{"id":"deepseek-v3.1-250821","name":"deepseek-v3.1-250821","display_name":"deepseek-v3.1-250821","type":"chat","context_length":0,"max_output_tokens":0,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"developer":"DeepSeek","developerId":7,"providerId":8,"modelRatio":0.28,"cacheRatio":1,"completionRatio":3,"description":"DeepSeek V3.1\nDeepSeek-V3.1-250821DeepSeek V3.1 ","descriptionEn":"DeepSeek V3.1 is a text generation model provided by DeepSeek, featuring a hybrid inference architecture that effectively integrates thinking and non-thinking modes.  \nDeepSeek-V3.1-250821 is the non-thinking mode of DeepSeek V3.1 and does not support enabling thinking.","order":700,"flag":1,"source":"public-provider-conf"},"vision":false},{"id":"deepseek-v3.1-think-250821","name":"deepseek-v3.1-think-250821","display_name":"deepseek-v3.1-think-250821","type":"chat","context_length":0,"max_output_tokens":0,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"developer":"DeepSeek","developerId":7,"providerId":15,"modelRatio":0.28,"cacheRatio":1,"completionRatio":3,"description":"DeepSeek-V3.1-Think-250821 DeepSeek V3.1 \nDeepSeek V3.1\n","descriptionEn":"DeepSeek-V3.1-Think-250821 is the thinking mode of DeepSeek V3.1.  \nDeepSeek V3.1 is a text generation model provided by DeepSeek, featuring a hybrid reasoning architecture that achieves an effective integration of thinking and non-thinking modes.","order":700,"flag":1,"source":"public-provider-conf"},"vision":false},{"id":"distil-whisper-large-v3-en","name":"whisper-large-v3","display_name":"whisper-large-v3","type":"chat","context_length":0,"max_output_tokens":0,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"modalities":{"input":["audio"],"output":["audio"]},"metadata":{"developer":"OpenAI","developerId":12,"providerId":29,"modelRatio":2.778,"cacheRatio":1,"completionRatio":1,"description":"Groq","order":0,"flag":0,"modalities":["audio"],"typeHints":["stt"],"source":"public-provider-conf"},"vision":false},{"id":"doubao-embedding-large-text-240915","name":"doubao-embedding-large-text-240915","display_name":"doubao-embedding-large-text-240915","type":"embedding","context_length":0,"max_output_tokens":0,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"developer":"Doubao","developerId":4,"providerId":40,"modelRatio":0.05,"cacheRatio":1,"completionRatio":1,"description":"doubao-embedding-large-text-240915\nDoubao Embedding  4K \n","descriptionEn":"doubao-embedding-large-text-240915\nDoubao Embedding is a semantic vectorization model developed by ByteDance, primarily designed for vector search scenarios. It supports both Chinese and English languages and has a maximum context length of approximately 4K tokens.","order":60,"flag":0,"typeHints":["embedding"],"source":"public-provider-conf"},"vision":false},{"id":"doubao-embedding-text-240715","name":"doubao-embedding-text-240715","display_name":"doubao-embedding-text-240715","type":"embedding","context_length":0,"max_output_tokens":0,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"developer":"Doubao","developerId":4,"providerId":40,"modelRatio":0.35,"cacheRatio":1,"completionRatio":1,"description":"doubao-embedding-text-240715\nDoubao Embedding  4K \n","descriptionEn":"doubao-embedding-text-240715\nDoubao Embedding is a semantic vectorization model developed by ByteDance, primarily designed for vector search scenarios. It supports both Chinese and English languages and has a maximum context length of approximately 4K tokens.","order":45,"flag":0,"typeHints":["embedding"],"source":"public-provider-conf"},"vision":false},{"id":"doubao-seed-1-6-250615","name":"doubao-seed-1-6-250615","display_name":"doubao-seed-1-6-250615","type":"chat","context_length":256000,"max_output_tokens":256000,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"developer":"Doubao","developerId":4,"providerId":40,"modelRatio":0.09,"cacheRatio":1,"completionRatio":14,"description":"7  31  00:30 \nDoubao-Seed-1.6auto/thinking/non-thinking non-thinkingDoubao-1.5-pro/250115 256k  16k tokens","descriptionEn":"Doubao-Seed-1.6 is a brand-new multimodal deep thinking model that supports three thinking modes: auto, thinking, and non-thinking. In non-thinking mode, the model's performance is significantly improved compared to Doubao-1.5-pro/250115. It supports a 256k context window and an output length of up to 16k tokens.","order":210,"flag":1,"billingConfig":"{\n  \"model_name\": \"doubao-seed-1-6-250615\",\n  \"default_tier\": \"tier1\",\n  \"token_based_tier_configs\": {\n    \"tier1\": {\n      \"tier_condition\": {\n        \"min_tokens\": 0,\n        \"max_tokens\": 32000\n      },\n      \"model_ratio\": 0.054795,\n      \"prompt_tokens_ratio\": 1.0,\n      \"completion_tokens_ratio\": 10.0,\n      \"cached_tokens_ratio\": 0.2\n    },\n    \"tier2\": {\n      \"tier_condition\": {\n        \"min_tokens\": 32001,\n        \"max_tokens\": 128000\n      },\n      \"model_ratio\": 0.082192,\n      \"prompt_tokens_ratio\": 1.0,\n      \"completion_tokens_ratio\": 13.33,\n      \"cached_tokens_ratio\": 0.133\n    },\n    \"tier3\": {\n      \"tier_condition\": {\n        \"min_tokens\": 128001,\n        \"max_tokens\": 256000\n      },\n      \"model_ratio\": 0.164384,\n      \"prompt_tokens_ratio\": 1.0,\n      \"completion_tokens_ratio\": 10.0,\n      \"cached_tokens_ratio\": 0.067\n    }\n  },\n  \"per_unit_price_config\": {\n    \"cache_storage_price\": 0.002329\n  },\n  \"enabled_billing_items\": [\n    \"prompt_tokens\",\n    \"completion_tokens\",\n    \"cached_tokens\",\n    \"cache_storage_hours\"\n  ]\n}","source":"public-provider-conf"},"vision":false},{"id":"doubao-seed-1-6-flash-250615","name":"doubao-seed-1-6-flash-250615","display_name":"doubao-seed-1-6-flash-250615","type":"chat","context_length":0,"max_output_tokens":0,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"developer":"Doubao","developerId":4,"providerId":40,"modelRatio":0.022,"cacheRatio":1,"completionRatio":10,"description":"Doubao-Seed-1.6-flashTPOT10ms litepro 256k  16k tokens","descriptionEn":"Doubao-Seed-1.6-flash is an extremely fast multimodal deep thinking model, with TPOT requiring only 10ms. It supports both text and visual understanding, with its text comprehension skills surpassing the previous generation lite model and its visual understanding on par with competitor's pro series models. It supports a 256k context window and an output length of up to 16k tokens.","order":210,"flag":1,"billingConfig":"{\n  \"model_name\": \"doubao-seed-1-6-flash-250615\",\n  \"default_tier\": \"tier1\",\n  \"token_based_tier_configs\": {\n    \"tier1\": {\n      \"tier_condition\": {\n        \"min_tokens\": 0,\n        \"max_tokens\": 32000\n      },\n      \"model_ratio\": 0.010274,\n      \"prompt_tokens_ratio\": 1.0,\n      \"completion_tokens_ratio\": 10.0,\n      \"cached_tokens_ratio\": 0.2\n    },\n    \"tier2\": {\n      \"tier_condition\": {\n        \"min_tokens\": 32001,\n        \"max_tokens\": 128000\n      },\n      \"model_ratio\": 0.020548,\n      \"prompt_tokens_ratio\": 1.0,\n      \"completion_tokens_ratio\": 10.0,\n      \"cached_tokens_ratio\": 0.1\n    },\n    \"tier3\": {\n      \"tier_condition\": {\n        \"min_tokens\": 128001,\n        \"max_tokens\": 256000\n      },\n      \"model_ratio\": 0.041096,\n      \"prompt_tokens_ratio\": 1.0,\n      \"completion_tokens_ratio\": 10.0,\n      \"cached_tokens_ratio\": 0.05\n    }\n  },\n  \"per_unit_price_config\": {\n    \"cache_storage_price\": 0.002329\n  },\n  \"enabled_billing_items\": [\n    \"prompt_tokens\",\n    \"completion_tokens\",\n    \"cached_tokens\",\n    \"cache_storage_hours\"\n  ]\n}","source":"public-provider-conf"},"vision":false},{"id":"doubao-seed-1-6-thinking-250615","name":"doubao-seed-1-6-thinking-250615","display_name":"doubao-seed-1-6-thinking-250615","type":"chat","context_length":256000,"max_output_tokens":256000,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"developer":"Doubao","developerId":4,"providerId":40,"modelRatio":0.09,"cacheRatio":1,"completionRatio":14,"description":"Doubao-Seed-1.6-thinking Doubao-1.5-thinking-proCodingMath    256k  16k tokens","descriptionEn":"The Doubao-Seed-1.6-thinking model has significantly enhanced reasoning capabilities. Compared with Doubao-1.5-thinking-pro, it has further improvements in fundamental abilities such as coding, mathematics, and logical reasoning, and now also supports visual understanding. It supports a 256k context window, with output length supporting up to 16k tokens.","order":210,"flag":1,"billingConfig":"{\n  \"model_name\": \"doubao-seed-1-6-thinking-250615\",\n  \"default_tier\": \"tier1\",\n  \"token_based_tier_configs\": {\n    \"tier1\": {\n      \"tier_condition\": {\n        \"min_tokens\": 0,\n        \"max_tokens\": 32000\n      },\n      \"model_ratio\": 0.054795,\n      \"prompt_tokens_ratio\": 1.0,\n      \"completion_tokens_ratio\": 10.0,\n      \"cached_tokens_ratio\": 0.2\n    },\n    \"tier2\": {\n      \"tier_condition\": {\n        \"min_tokens\": 32001,\n        \"max_tokens\": 128000\n      },\n      \"model_ratio\": 0.082192,\n      \"prompt_tokens_ratio\": 1.0,\n      \"completion_tokens_ratio\": 13.33,\n      \"cached_tokens_ratio\": 0.133\n    },\n    \"tier3\": {\n      \"tier_condition\": {\n        \"min_tokens\": 128001,\n        \"max_tokens\": 256000\n      },\n      \"model_ratio\": 0.164384,\n      \"prompt_tokens_ratio\": 1.0,\n      \"completion_tokens_ratio\": 10.0,\n      \"cached_tokens_ratio\": 0.067\n    }\n  },\n  \"per_unit_price_config\": {\n    \"cache_storage_price\": 0.002329\n  },\n  \"enabled_billing_items\": [\n    \"prompt_tokens\",\n    \"completion_tokens\",\n    \"cached_tokens\",\n    \"cache_storage_hours\"\n  ]\n}","source":"public-provider-conf"},"vision":false},{"id":"doubao-seed-1-6-vision-250815","name":"doubao-seed-1-6-vision-250815","display_name":"doubao-seed-1-6-vision-250815","type":"chat","context_length":0,"max_output_tokens":0,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"developer":"Doubao","developerId":4,"providerId":40,"modelRatio":0.054795,"cacheRatio":0.2,"completionRatio":10,"description":"Doubao-Seed-1.6-vision AI  256k  64k tokens","descriptionEn":"Doubao-Seed-1.6-vision is a visual deep-thinking model that demonstrates stronger general multimodal understanding and reasoning capabilities in scenarios such as education, image moderation, inspection and security, and AI search Q&A. It supports a 256K context window and an output length of up to 64K tokens.","order":209,"flag":0,"billingConfig":"{\n  \"model_name\": \"doubao-seed-1-6-vision-250815\",\n  \"default_tier\": \"tier1\",\n  \"token_based_tier_configs\": {\n    \"tier1\": {\n      \"tier_condition\": {\n        \"min_tokens\": 0,\n        \"max_tokens\": 32000\n      },\n      \"model_ratio\": 0.054795,\n      \"prompt_tokens_ratio\": 1.0,\n      \"completion_tokens_ratio\": 10.0,\n      \"cached_tokens_ratio\": 0.2\n    },\n    \"tier2\": {\n      \"tier_condition\": {\n        \"min_tokens\": 32001,\n        \"max_tokens\": 128000\n      },\n      \"model_ratio\": 0.082192,\n      \"prompt_tokens_ratio\": 1.0,\n      \"completion_tokens_ratio\": 13.33,\n      \"cached_tokens_ratio\": 0.133\n    },\n    \"tier3\": {\n      \"tier_condition\": {\n        \"min_tokens\": 128001,\n        \"max_tokens\": 256000\n      },\n      \"model_ratio\": 0.164384,\n      \"prompt_tokens_ratio\": 1.0,\n      \"completion_tokens_ratio\": 10.0,\n      \"cached_tokens_ratio\": 0.067\n    }\n  },\n  \"per_unit_price_config\": {\n    \"cache_storage_price\": 0.002329\n  },\n  \"enabled_billing_items\": [\n    \"prompt_tokens\",\n    \"completion_tokens\",\n    \"cached_tokens\",\n    \"cache_storage_hours\"\n  ]\n}","source":"public-provider-conf"},"vision":false},{"id":"doubao-seedream-4-0-250828","name":"doubao-seedream-4-0-250828","display_name":"doubao-seedream-4-0-250828","type":"image-generation","context_length":0,"max_output_tokens":0,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"developer":"Doubao","developerId":4,"providerId":40,"modelRatio":1,"cacheRatio":0,"completionRatio":0,"description":"\"Seedream 4.0 SOTA\nSeedream 4.0  10  15  4K \"","descriptionEn":"\"Seedream 4.0 is a SOTA-level multimodal image creation model based on leading architecture. It breaks the creative boundaries of traditional text-to-image models by natively supporting text, single image, and multiple image inputs. Users can freely combine text and images to achieve various creative styles within the same model, such as multi-image fusion creation based on subject consistency, image editing, and set image generation, making image creation more flexible and controllable.\nSeedream 4.0 supports composite editing with up to 10 images in a single input. Through deep reasoning of prompt words, it automatically adapts the optimal image aspect ratio and generation quantity, enabling continuous output of up to 15 content-related images at one time. Additionally, the model significantly improves the accuracy and content diversity of Chinese generation, supports 4K ultra-high-definition output, and provides a one-stop solution from generation to editing for professional image creation.\"","order":800,"flag":0,"imagePriceConfig":"{\"generate\":{\"standard\":{\"standard\":0.021}}}","typeHints":["t2i"],"source":"public-provider-conf"},"vision":false},{"id":"embedding-v1","name":"embedding-v1","display_name":"embedding-v1","type":"embedding","context_length":0,"max_output_tokens":0,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"developer":"Baidu","developerId":25,"providerId":15,"modelRatio":0.034,"cacheRatio":1,"completionRatio":1,"description":"Embedding-V1 Embedding-V1Embeddings","descriptionEn":"Embedding-V1 is a text representation model based on Baidu's Wenxin large model technology, capable of converting text into numerical vector forms for applications such as text retrieval, information recommendation, and knowledge mining. Embedding-V1 provides an Embeddings interface that generates corresponding vector representations based on the input content. By calling this interface, you can input text into the model and obtain the corresponding vector representations for subsequent text processing and analysis.","order":600,"flag":0,"typeHints":["embedding"],"source":"public-provider-conf"},"vision":false},{"id":"ernie-4.5-0.3b","name":"ernie-4.5-0.3b","display_name":"ernie-4.5-0.3b","type":"chat","context_length":0,"max_output_tokens":0,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"developer":"Baidu","developerId":25,"providerId":15,"modelRatio":0.0068,"cacheRatio":1,"completionRatio":4,"description":"4.5","descriptionEn":"Wenxin Large Model 4.5 is a next-generation native multimodal foundational large model independently developed by Baidu. It achieves collaborative optimization through joint modeling of multiple modalities, demonstrating excellent multimodal understanding capabilities. The model possesses enhanced language abilities, with comprehensive improvements in understanding, generation, reasoning, and memory. It significantly reduces hallucinations and shows notable advancements in logical reasoning and coding skills.","order":100,"flag":0,"source":"public-provider-conf"},"vision":false},{"id":"ernie-4.5-21b-a3b","name":"ernie-4.5-21b-a3b","display_name":"ernie-4.5-21b-a3b","type":"chat","context_length":0,"max_output_tokens":0,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"developer":"Baidu","developerId":25,"providerId":15,"modelRatio":0.034,"cacheRatio":1,"completionRatio":4,"description":"4.5ERNIE-4.5-21B-A3B  MoE ,  21B 3B","descriptionEn":"Wenxin Large Model 4.5 is a next-generation native multimodal foundational model independently developed by Baidu. It achieves collaborative optimization through joint modeling of multiple modalities, demonstrating excellent multimodal understanding capabilities; it possesses more advanced language abilities, with comprehensive improvements in comprehension, generation, logic, and memory, as well as significant enhancements in hallucination reduction, logical reasoning, and coding capabilities.ERNIE-4.5-21B-A3B is an aligned open-source model with a MoE structure, having a total of 21 billion parameters and 3 billion activated parameters.","order":500,"flag":0,"source":"public-provider-conf"},"vision":false},{"id":"ernie-4.5-21b-a3b-thinking","name":"ernie-4.5-21b-a3b-thinking","display_name":"ernie-4.5-21b-a3b-thinking","type":"chat","context_length":120000,"max_output_tokens":120000,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"developer":"Baidu","developerId":25,"providerId":15,"modelRatio":0.034,"cacheRatio":1,"completionRatio":4,"description":"4.5ERNIE-4.5-21B-A3B-Thinking  MoE ,  21B 3B","descriptionEn":"Wenxin Large Model 4.5 is a next-generation native multimodal foundational model independently developed by Baidu. It achieves collaborative optimization through joint modeling of multiple modalities, demonstrating excellent multimodal understanding capabilities; it possesses more advanced language abilities, with comprehensive improvements in comprehension, generation, logic, and memory, as well as significant enhancements in hallucination reduction, logical reasoning, and coding capabilities.ERNIE-4.5-21B-A3B-Thinking is a text MoE post-training model with a total of 21 billion parameters and 3 billion activated parameters, significantly enhancing inference quality and depth.","order":600,"flag":1,"source":"public-provider-conf"},"vision":false},{"id":"ernie-4.5-turbo-128k-preview","name":"ernie-4.5-turbo-128k-preview","display_name":"ernie-4.5-turbo-128k-preview","type":"chat","context_length":0,"max_output_tokens":0,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"developer":"Baidu","developerId":25,"providerId":15,"modelRatio":0.054,"cacheRatio":1,"completionRatio":4,"description":"4.5 Turbo4.5","descriptionEn":"Wenxin 4.5 Turbo also shows significant enhancements in reducing hallucinations, logical reasoning, and coding capabilities. Compared to Wenxin 4.5, it is faster and more cost-effective.","order":100,"flag":0,"source":"public-provider-conf"},"vision":false},{"id":"ernie-4.5-turbo-latest","name":"ernie-4.5-turbo-latest","display_name":"ernie-4.5-turbo-latest","type":"chat","context_length":128000,"max_output_tokens":128000,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"developer":"Baidu","developerId":25,"providerId":15,"modelRatio":0.055,"cacheRatio":1,"completionRatio":4,"description":"4.5 Turbo4.5","descriptionEn":"Wenxin 4.5 Turbo also has significant improvements in hallucination reduction, logical reasoning, and coding capabilities. Compared to Wenxin 4.5, it is faster and more affordable.","order":600,"flag":0,"source":"public-provider-conf"},"vision":false},{"id":"ernie-4.5-turbo-vl","name":"ernie-4.5-turbo-vl","display_name":"ernie-4.5-turbo-vl","type":"chat","context_length":128000,"max_output_tokens":128000,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"developer":"Baidu","developerId":25,"providerId":15,"modelRatio":0.2,"cacheRatio":1,"completionRatio":3,"description":"32KToken","descriptionEn":"The new version of the Wenxin Yiyan large model significantly improves capabilities in image understanding, creation, translation, and coding. It supports a context length of up to 32K tokens for the first time, with a notable reduction in the latency of the first token.","order":500,"flag":0,"source":"public-provider-conf"},"vision":false},{"id":"ernie-4.5-turbo-vl-32k-preview","name":"ernie-4.5-turbo-vl-32k-preview","display_name":"ernie-4.5-turbo-vl-32k-preview","type":"chat","context_length":0,"max_output_tokens":0,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"developer":"Baidu","developerId":25,"providerId":15,"modelRatio":0.2,"cacheRatio":1,"completionRatio":3,"description":"32KToken","descriptionEn":"The new version of the Wenxin Yiyan large model significantly improves capabilities in image understanding, creation, translation, and coding. It supports a context length of up to 32K tokens for the first time, with a notable reduction in the latency of the first token.","order":100,"flag":0,"source":"public-provider-conf"},"vision":false},{"id":"ernie-4.5-turbo-vl-latest","name":"ernie-4.5-turbo-vl-latest","display_name":"ernie-4.5-turbo-vl-latest","type":"chat","context_length":128000,"max_output_tokens":128000,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"developer":"Baidu","developerId":25,"providerId":15,"modelRatio":0.2,"cacheRatio":1,"completionRatio":3,"description":"32KToken","descriptionEn":"The new version of the Wenxin Yiyan large model significantly improves capabilities in image understanding, creation, translation, and coding. It supports a context length of up to 32K tokens for the first time, with a notable reduction in the latency of the first token.","order":600,"flag":0,"source":"public-provider-conf"},"vision":false},{"id":"ernie-irag-edit","name":"ernie-irag-edit","display_name":"ernie-irag-edit","type":"image-generation","context_length":0,"max_output_tokens":0,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"developer":"Baidu","developerId":25,"providerId":15,"modelRatio":1,"cacheRatio":0,"completionRatio":0,"description":"ERNIE iRAG Editeraserepaintvariation","descriptionEn":"Baidu's self-developed ERNIE iRAG Edit image editing model supports operations based on images such as erase (object removal), repaint (object redrawing), and variation (variant generation).","order":600,"flag":0,"imagePriceConfig":"{\"generate\":{\"standard\":{\"standard\":0.019}}}","typeHints":["t2i"],"source":"public-provider-conf"},"vision":false},{"id":"ernie-x1-turbo-32k-preview","name":"ernie-x1-turbo-32k-preview","display_name":"ernie-x1-turbo-32k-preview","type":"chat","context_length":0,"max_output_tokens":0,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"developer":"Baidu","developerId":25,"providerId":15,"modelRatio":0.068,"cacheRatio":1,"completionRatio":4,"description":"X1X1","descriptionEn":"Wenxin Large Model X1 possesses enhanced abilities in understanding, planning, reflection, and evolution. As a more comprehensive deep-thinking model, Wenxin X1 combines accuracy, creativity, and literary elegance, excelling particularly in Chinese knowledge Q&A, literary creation, document writing, daily conversations, logical reasoning, complex calculations, and tool invocation.","order":100,"flag":0,"source":"public-provider-conf"},"vision":false},{"id":"ernie-x1.1-preview","name":"ernie-x1.1-preview","display_name":"ernie-x1.1-preview","type":"chat","context_length":0,"max_output_tokens":0,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"developer":"Baidu","developerId":25,"providerId":15,"modelRatio":0.068,"cacheRatio":1,"completionRatio":4,"description":"X1.164K tokens","descriptionEn":"The Wenxin large model X1.1 has made significant improvements in question answering, tool invocation, intelligent agents, instruction following, logical reasoning, mathematics, and coding tasks, with notable enhancements in factual accuracy. The context length has been extended to 64K tokens, supporting longer inputs and dialogue history, which improves the coherence of long-chain reasoning while maintaining response speed.","order":101,"flag":1,"source":"public-provider-conf"},"vision":false},{"id":"flux-kontext-max","name":"flux-kontext-max","display_name":"flux-kontext-max","type":"image-generation","context_length":0,"max_output_tokens":0,"capabilities":{"vision":true,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"modalities":{"input":["text","image"],"output":["text","image"]},"metadata":{"developer":"Flux","developerId":27,"providerId":53,"modelRatio":1.1,"cacheRatio":0,"completionRatio":1,"description":"","descriptionEn":"Flux.1 Kontext [max] is a premium text-based image editing model from Black Forest Labs, designed for maximum performance. It excels in advanced prompt adherence, high-quality typography generation, and consistent results, making it ideal for professional workflows requiring precise, context-aware edits and rapid iteration. It supports complex transformations while maintaining character consistency and visual fidelity.  ","order":0,"flag":1,"displayInput":"-","displayOutput":"$0.088 / IMG","modalities":["text","image"],"typeHints":["t2i"],"source":"public-provider-conf"},"vision":true},{"id":"flux-kontext-pro","name":"flux-kontext-pro","display_name":"flux-kontext-pro","type":"image-generation","context_length":0,"max_output_tokens":0,"capabilities":{"vision":true,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"modalities":{"input":["text","image"],"output":["text","image"]},"metadata":{"developer":"Flux","developerId":27,"providerId":53,"modelRatio":1.11,"cacheRatio":0,"completionRatio":1,"description":" AI ","descriptionEn":"A professional-grade AI image editing model by Black Forest Labs, optimized for fast, iterative workflows. It delivers high-quality outputs with excellent prompt following and character preservation, enabling targeted edits like text replacement or style transfer without affecting the rest of the image. Accessible via API, its perfect for efficient, context-aware editing. ","order":0,"flag":1,"displayInput":"-","displayOutput":"$0.044 / IMG","modalities":["text","image"],"typeHints":["t2i"],"source":"public-provider-conf"},"vision":true},{"id":"gemini-1.5-flash","name":"gemini-1.5-flash","display_name":"gemini-1.5-flash","type":"chat","context_length":2000000,"max_output_tokens":2000000,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"modalities":{"input":["text"],"output":["text"]},"metadata":{"developer":"Google","developerId":8,"providerId":24,"modelRatio":0.0375,"cacheRatio":1,"completionRatio":4,"order":0,"flag":0,"billingConfig":"{\n  \"model_name\": \"gemini-1.5-flash\",\n  \"default_tier\": \"tier1\",\n  \"token_based_tier_configs\": {\n    \"tier1\": {\n      \"tier_condition\": {\n        \"min_tokens\": 0,\n        \"max_tokens\": 128000\n      },\n      \"model_ratio\": 0.0375,\n      \"prompt_tokens_ratio\": 1.0,\n      \"completion_tokens_ratio\": 4.0,\n      \"cached_tokens_ratio\": 0.25\n    },\n    \"tier2\": {\n      \"tier_condition\": {\n        \"min_tokens\": 128001,\n        \"max_tokens\": -1\n      },\n      \"model_ratio\": 0.075,\n      \"prompt_tokens_ratio\": 1.0,\n      \"completion_tokens_ratio\": 4.0,\n      \"cached_tokens_ratio\": 0.25\n    }\n  },\n  \"per_unit_price_config\": {\n    \"web_search_price\": 0.035,\n    \"cache_storage_price\": 1.00\n  },\n  \"enabled_billing_items\": [\n    \"prompt_tokens\",\n    \"completion_tokens\",\n    \"cached_tokens\",\n    \"web_search_requests\",\n    \"cache_storage_hours\"\n  ]\n}","features":["long_context"],"tags":["multi_modal","economical","lightning"],"modalities":["text"],"typeHints":["t2t"],"source":"public-provider-conf"},"vision":false},{"id":"gemini-1.5-flash-002","name":"gemini-1.5-flash","display_name":"gemini-1.5-flash","type":"chat","context_length":2000000,"max_output_tokens":2000000,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"modalities":{"input":["text"],"output":["text"]},"metadata":{"developer":"Google","developerId":8,"providerId":24,"modelRatio":0.0375,"cacheRatio":1,"completionRatio":4,"order":0,"flag":0,"billingConfig":"{   \"model_name\": \"gemini-1.5-flash\",   \"default_tier\": \"tier1\",   \"token_based_tier_configs\": {     \"tier1\": {       \"tier_condition\": {         \"min_tokens\": 0,         \"max_tokens\": 128000       },       \"model_ratio\": 0.0375,       \"prompt_tokens_ratio\": 1.0,       \"completion_tokens_ratio\": 4.0,       \"cached_tokens_ratio\": 0.25     },     \"tier2\": {       \"tier_condition\": {         \"min_tokens\": 128001,         \"max_tokens\": -1       },       \"model_ratio\": 0.075,       \"prompt_tokens_ratio\": 1.0,       \"completion_tokens_ratio\": 4.0,       \"cached_tokens_ratio\": 0.25     }   },   \"per_unit_price_config\": {     \"web_search_price\": 0.035,     \"cache_storage_price\": 1.00   },   \"enabled_billing_items\": [     \"prompt_tokens\",     \"completion_tokens\",     \"cached_tokens\",     \"web_search_requests\",     \"cache_storage_hours\"   ] }","features":["long_context"],"tags":["economical","lightning"],"modalities":["text"],"typeHints":["t2t"],"source":"public-provider-conf"},"vision":false},{"id":"gemini-1.5-flash-exp-0827","name":"gemini-1.5-flash","display_name":"gemini-1.5-flash","type":"chat","context_length":0,"max_output_tokens":0,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"developer":"Google","developerId":8,"providerId":24,"modelRatio":0.0375,"cacheRatio":1,"completionRatio":4,"order":0,"flag":0,"source":"public-provider-conf"},"vision":false},{"id":"gemini-1.5-pro","name":"Gemini 1.5 Pro","display_name":"Gemini 1.5 Pro","type":"chat","context_length":2000000,"max_output_tokens":2000000,"capabilities":{"vision":true,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"modalities":{"input":["text","image"],"output":["text","image"]},"metadata":{"developer":"Google","developerId":8,"providerId":24,"modelRatio":0.625,"cacheRatio":1,"completionRatio":4,"order":0,"flag":0,"billingConfig":"{\n  \"model_name\": \"gemini-1.5-pro\",\n  \"default_tier\": \"tier1\",\n  \"token_based_tier_configs\": {\n    \"tier1\": {\n      \"tier_condition\": {\n        \"min_tokens\": 0,\n        \"max_tokens\": 128000\n      },\n      \"model_ratio\": 0.625,\n      \"prompt_tokens_ratio\": 1.0,\n      \"completion_tokens_ratio\": 4.0,\n      \"cached_tokens_ratio\": 0.25\n    },\n    \"tier2\": {\n      \"tier_condition\": {\n        \"min_tokens\": 128001,\n        \"max_tokens\": -1\n      },\n      \"model_ratio\": 1.25,\n      \"prompt_tokens_ratio\": 1.0,\n      \"completion_tokens_ratio\": 4.0,\n      \"cached_tokens_ratio\": 0.25\n    }\n  },\n  \"per_unit_price_config\": {\n    \"web_search_price\": 0.035,\n    \"cache_storage_price\": 4.50\n  },\n  \"enabled_billing_items\": [\n    \"prompt_tokens\",\n    \"completion_tokens\",\n    \"cached_tokens\",\n    \"web_search_requests\",\n    \"cache_storage_hours\"\n  ]\n}","features":["long_context"],"tags":["multi_modal"],"modalities":["text","image"],"typeHints":["t2t"],"source":"public-provider-conf"},"vision":true},{"id":"gemini-1.5-pro-002","name":"Gemini 1.5 Pro","display_name":"Gemini 1.5 Pro","type":"chat","context_length":0,"max_output_tokens":0,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"developer":"Google","developerId":8,"providerId":24,"modelRatio":0.625,"cacheRatio":1,"completionRatio":4,"order":0,"flag":0,"source":"public-provider-conf"},"vision":false},{"id":"gemini-1.5-pro-exp-0801","name":"Gemini 1.5 Pro","display_name":"Gemini 1.5 Pro","type":"chat","context_length":2000000,"max_output_tokens":2000000,"capabilities":{"vision":true,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"modalities":{"input":["text","image","audio","video"],"output":["text","image","audio","video"]},"metadata":{"developer":"Google","developerId":8,"providerId":24,"modelRatio":0.625,"cacheRatio":1,"completionRatio":4,"order":0,"flag":0,"features":["long_context"],"modalities":["text","image","audio","video"],"typeHints":["t2t"],"source":"public-provider-conf"},"vision":true},{"id":"gemini-1.5-pro-exp-0827","name":"Gemini 1.5 Pro","display_name":"Gemini 1.5 Pro","type":"chat","context_length":2000000,"max_output_tokens":2000000,"capabilities":{"vision":true,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"modalities":{"input":["text","image","audio","video"],"output":["text","image","audio","video"]},"metadata":{"developer":"Google","developerId":8,"providerId":24,"modelRatio":0.625,"cacheRatio":1,"completionRatio":4,"order":0,"flag":0,"features":["long_context"],"modalities":["text","image","audio","video"],"typeHints":["t2t"],"source":"public-provider-conf"},"vision":true},{"id":"gemini-2.0-flash","name":"Gemini 2.0 Flash","display_name":"Gemini 2.0 Flash","type":"chat","context_length":1000000,"max_output_tokens":1000000,"capabilities":{"vision":true,"function_calling":true,"reasoning":false,"tool_calling":true},"reasoning":false,"tool_call":true,"modalities":{"input":["text","image","audio","video"],"output":["text","image","audio","video"]},"metadata":{"developer":"Google","developerId":8,"providerId":24,"modelRatio":0.05,"cacheRatio":0.25,"completionRatio":4,"description":"Gemini 2.0 Flash  AI \n","descriptionEn":"Gemini 2.0 Flash is Google's latest lightweight model featuring extremely low hallucination rates while maintaining fast response times, offering developers high-precision and efficient AI solutions particularly suited for applications requiring high factual accuracy.","order":702,"flag":2,"billingConfig":"{\"model_name\": \"gemini-2.0-flash\", \"default_tier\": \"tier1\", \"enabled_billing_items\": [\"prompt_tokens\", \"completion_tokens\", \"cached_tokens\", \"input_audio_tokens\", \"cached_audio_tokens\", \"web_search_requests\", \"image_generation\", \"cache_storage_hours\"], \"per_unit_price_config\": {\"web_search_price\": 0.035, \"cache_storage_price\": 1.0, \"image_generation_price\": 0.039}, \"token_based_tier_configs\": {\"tier1\": {\"model_ratio\": 0.05, \"tier_condition\": {\"max_tokens\": -1, \"min_tokens\": 0}, \"cached_tokens_ratio\": 2.5, \"prompt_tokens_ratio\": 1.0, \"completion_tokens_ratio\": 4.0, \"input_audio_tokens_ratio\": 7.0, \"cached_audio_tokens_ratio\": 1.75}}}","features":["tools","function_calling","structured_outputs","long_context"],"tags":["optimized","lightning","multi_modal","economical"],"modalities":["text","image","audio","video"],"typeHints":["t2t"],"source":"public-provider-conf"},"vision":true},{"id":"gemini-2.0-flash-001","name":"gemini-2.0-flash","display_name":"gemini-2.0-flash","type":"chat","context_length":0,"max_output_tokens":0,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"developer":"Google","developerId":8,"providerId":42,"modelRatio":0.05,"cacheRatio":1,"completionRatio":4,"description":"Google gemini vertex ai","descriptionEn":"Google Gemini's enterprise version VertexAI","order":0,"flag":0,"billingConfig":"{\"model_name\": \"gemini-2.0-flash\", \"default_tier\": \"tier1\", \"enabled_billing_items\": [\"prompt_tokens\", \"completion_tokens\", \"cached_tokens\", \"input_audio_tokens\", \"cached_audio_tokens\", \"web_search_requests\", \"image_generation\", \"cache_storage_hours\"], \"per_unit_price_config\": {\"web_search_price\": 0.035, \"cache_storage_price\": 1.0, \"image_generation_price\": 0.039}, \"token_based_tier_configs\": {\"tier1\": {\"model_ratio\": 0.05, \"tier_condition\": {\"max_tokens\": -1, \"min_tokens\": 0}, \"cached_tokens_ratio\": 2.5, \"prompt_tokens_ratio\": 1.0, \"completion_tokens_ratio\": 4.0, \"input_audio_tokens_ratio\": 7.0, \"cached_audio_tokens_ratio\": 1.75}}}","source":"public-provider-conf"},"vision":false},{"id":"gemini-2.0-flash-exp","name":"Gemini 2.0 Flash","display_name":"Gemini 2.0 Flash","type":"image-generation","context_length":1050000,"max_output_tokens":1050000,"capabilities":{"vision":true,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"modalities":{"input":["text","image","audio","video"],"output":["text","image","audio","video"]},"metadata":{"developer":"Google","developerId":8,"providerId":24,"modelRatio":0.01,"cacheRatio":1,"completionRatio":4,"description":"Gemini 2.0 Flashgemini-2.0-flash-exp-image-generation exp\nhttps://doc.aihubmix.com/api/Gemini%20%E5%9B%BE%E7%89%87%E7%94%9F%E6%88%90%E5%92%8C%E7%BC%96%E8%BE%91\n \"modalities\":[\"text\",\"image\"]\n Base64 \n \"\"\n 1024px\npython  openai sdk  pip install -U openai","descriptionEn":"https://doc.aihubmix.com/en/api/Gemini%20%E5%9B%BE%E7%89%87%E7%94%9F%E6%88%90%E5%92%8C%E7%BC%96%E8%BE%91\nInstructions:\n\nNeed to add parameters to experience new features: \"modalities\":[\"text\",\"image\"]\nImages are passed and output in Base64 encoding\nAs an experimental model, it's recommended to explicitly specify \"output image\", otherwise it might only output text\nDefault height for output images is 1024px\nPython calls require the latest OpenAI SDK, run pip install -U openai first","order":150,"flag":1,"features":["long_context"],"tags":["multi_modal"],"modalities":["text","image","audio","video"],"typeHints":["t2t","t2i"],"source":"public-provider-conf"},"vision":true},{"id":"gemini-2.0-flash-exp-image-generation","name":"gemini-2.0-flash-exp-image-generation","display_name":"gemini-2.0-flash-exp-image-generation","type":"chat","context_length":0,"max_output_tokens":0,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"developer":"Google","developerId":8,"providerId":24,"modelRatio":0.05,"cacheRatio":1,"completionRatio":4,"order":0,"flag":0,"source":"public-provider-conf"},"vision":false},{"id":"gemini-2.0-flash-lite","name":"gemini-2.0-flash-lite","display_name":"gemini-2.0-flash-lite","type":"chat","context_length":1050000,"max_output_tokens":1050000,"capabilities":{"vision":true,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"modalities":{"input":["text","image","audio","video"],"output":["text","image","audio","video"]},"metadata":{"developer":"Google","developerId":8,"providerId":24,"modelRatio":0.038,"cacheRatio":1,"completionRatio":4,"description":"gemini-2.0-flash","descriptionEn":"Gemini-2.0-flash Lightweight Official Version","order":0,"flag":0,"billingConfig":"{\n  \"model_name\": \"gemini-2.0-flash-lite\",\n  \"default_tier\": \"tier1\",\n  \"token_based_tier_configs\": {\n    \"tier1\": {\n      \"tier_condition\": {\n        \"min_tokens\": 0,\n        \"max_tokens\": -1\n      },\n      \"model_ratio\": 0.0375,\n      \"prompt_tokens_ratio\": 1.0,\n      \"completion_tokens_ratio\": 4.0\n    }\n  },\n  \"per_unit_price_config\": {},\n  \"enabled_billing_items\": [\n    \"prompt_tokens\",\n    \"completion_tokens\"\n  ]\n}","features":["long_context"],"tags":["multi_modal","economical","lightning"],"modalities":["text","image","audio","video"],"typeHints":["t2t"],"source":"public-provider-conf"},"vision":true},{"id":"gemini-2.0-flash-lite-001","name":"gemini-2.0-flash-lite","display_name":"gemini-2.0-flash-lite","type":"chat","context_length":0,"max_output_tokens":0,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"developer":"Google","developerId":8,"providerId":42,"modelRatio":0.038,"cacheRatio":1,"completionRatio":4,"description":"Google gemini VertexAI","descriptionEn":"Google Gemini's enterprise version VertexAI","order":0,"flag":0,"billingConfig":"{   \"model_name\": \"gemini-2.0-flash-lite\",   \"default_tier\": \"tier1\",   \"token_based_tier_configs\": {     \"tier1\": {       \"tier_condition\": {         \"min_tokens\": 0,         \"max_tokens\": -1       },       \"model_ratio\": 0.0375,       \"prompt_tokens_ratio\": 1.0,       \"completion_tokens_ratio\": 4.0     }   },   \"per_unit_price_config\": {},   \"enabled_billing_items\": [     \"prompt_tokens\",     \"completion_tokens\"   ] }","source":"public-provider-conf"},"vision":false},{"id":"gemini-2.0-flash-lite-preview-02-05","name":"gemini-2.0-flash-lite","display_name":"gemini-2.0-flash-lite","type":"chat","context_length":0,"max_output_tokens":0,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"developer":"Google","developerId":8,"providerId":24,"modelRatio":0.0375,"cacheRatio":1,"completionRatio":4,"description":"gemini-2.0-flash","descriptionEn":"Gemini 2.0 Flash lightweight version","order":80,"flag":1,"billingConfig":"{   \"model_name\": \"gemini-2.0-flash-lite\",   \"default_tier\": \"tier1\",   \"token_based_tier_configs\": {     \"tier1\": {       \"tier_condition\": {         \"min_tokens\": 0,         \"max_tokens\": -1       },       \"model_ratio\": 0.0375,       \"prompt_tokens_ratio\": 1.0,       \"completion_tokens_ratio\": 4.0     }   },   \"per_unit_price_config\": {},   \"enabled_billing_items\": [     \"prompt_tokens\",     \"completion_tokens\"   ] }","source":"public-provider-conf"},"vision":false},{"id":"gemini-2.0-flash-preview-image-generation","name":"gemini-2.0-flash-preview-image-generation","display_name":"gemini-2.0-flash-preview-image-generation","type":"image-generation","context_length":1050000,"max_output_tokens":1050000,"capabilities":{"vision":true,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"modalities":{"input":["text","image"],"output":["text","image"]},"metadata":{"developer":"Google","developerId":8,"providerId":24,"modelRatio":0.05,"cacheRatio":0,"completionRatio":4,"description":"Gemini 2.0 flash exp  Imagen 3.0 Gemini ","descriptionEn":"Gemini 2.0 Flash EXP is the official preview version of the drawing model. Compared to Imagen 3.0, Geminis image generation is better suited for scenarios that require contextual understanding and reasoning, rather than the pursuit of ultimate artistic performance and visual quality.","order":701,"flag":1,"displayInput":"$ 0.1 / M Tokens","displayOutput":"$ 0.4 / M Tokens","tags":["multi_modal","best"],"modalities":["text","image"],"typeHints":["t2t","t2i"],"source":"public-provider-conf"},"vision":true},{"id":"gemini-2.0-flash-search","name":"Gemini 2.0 Flash","display_name":"Gemini 2.0 Flash","type":"chat","context_length":0,"max_output_tokens":0,"capabilities":{"vision":true,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"modalities":{"input":["text","image","audio","video"],"output":["text","image","audio","video"]},"metadata":{"developer":"Google","developerId":8,"providerId":24,"modelRatio":0.05,"cacheRatio":1,"completionRatio":4,"description":"","descriptionEn":"Integrated with Google's official search and internet connectivity features.","order":300,"flag":0,"billingConfig":"{\"model_name\": \"gemini-2.0-flash\", \"default_tier\": \"tier1\", \"enabled_billing_items\": [\"prompt_tokens\", \"completion_tokens\", \"cached_tokens\", \"input_audio_tokens\", \"cached_audio_tokens\", \"web_search_requests\", \"image_generation\", \"cache_storage_hours\"], \"per_unit_price_config\": {\"web_search_price\": 0.035, \"cache_storage_price\": 1.0, \"image_generation_price\": 0.039}, \"token_based_tier_configs\": {\"tier1\": {\"model_ratio\": 0.05, \"tier_condition\": {\"max_tokens\": -1, \"min_tokens\": 0}, \"cached_tokens_ratio\": 2.5, \"prompt_tokens_ratio\": 1.0, \"completion_tokens_ratio\": 4.0, \"input_audio_tokens_ratio\": 7.0, \"cached_audio_tokens_ratio\": 1.75}}}","features":["web"],"tags":["multi_modal","best","optimized","lightning"],"modalities":["text","image","audio","video"],"typeHints":["t2t","search"],"source":"public-provider-conf"},"vision":true},{"id":"gemini-2.0-flash-thinking-exp","name":"gemini-2.0-flash-thinking-exp","display_name":"gemini-2.0-flash-thinking-exp","type":"chat","context_length":0,"max_output_tokens":0,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"developer":"Google","developerId":8,"providerId":24,"modelRatio":0.038,"cacheRatio":1,"completionRatio":4,"order":1,"flag":1,"source":"public-provider-conf"},"vision":false},{"id":"gemini-2.0-flash-thinking-exp-01-21","name":"Gemini 2.0 Flash Thinking","display_name":"Gemini 2.0 Flash Thinking","type":"chat","context_length":1050000,"max_output_tokens":1050000,"capabilities":{"vision":true,"function_calling":false,"reasoning":true,"tool_calling":false},"reasoning":true,"tool_call":false,"modalities":{"input":["text","image","audio","video"],"output":["text","image","audio","video"]},"metadata":{"developer":"Google","developerId":8,"providerId":24,"modelRatio":0.038,"cacheRatio":1,"completionRatio":4,"description":"Gemini 2.0 Flash Thinking 2.0 Gemini 2.0 Flash ","descriptionEn":"The latest version, Gemini 2.0 Flash Thinking mode, is an experimental model designed to generate the \"thought process\" that the model goes through during its responses. Therefore, Gemini 2.0 Flash Thinking mode has stronger reasoning capabilities in its responses compared to the base Gemini 2.0 Flash model.","order":112,"flag":0,"features":["thinking","long_context"],"tags":["lightning"],"modalities":["text","image","audio","video"],"typeHints":["t2t"],"source":"public-provider-conf"},"vision":true},{"id":"gemini-2.0-flash-thinking-exp-1219","name":"Gemini 2.0 Flash Thinking","display_name":"Gemini 2.0 Flash Thinking","type":"chat","context_length":0,"max_output_tokens":0,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"developer":"Google","developerId":8,"providerId":24,"modelRatio":0.038,"cacheRatio":1,"completionRatio":4,"description":"Gemini2.0Flash Thinking 2.0 Gemini2.0Flash ","descriptionEn":"The Gemini 2.0 Flash Thinking mode is an experimental model designed to generate the \"thinking process\" that the model undergoes during its response. Therefore, the Gemini 2.0 Flash Thinking mode possesses stronger reasoning capabilities in its responses compared to the base Gemini 2.0 Flash model.","order":12,"flag":0,"source":"public-provider-conf"},"vision":false},{"id":"gemini-2.0-pro-exp-02-05","name":"gemini-2.0-pro","display_name":"gemini-2.0-pro","type":"image-generation","context_length":0,"max_output_tokens":0,"capabilities":{"vision":true,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"modalities":{"input":["text","image","audio","video"],"output":["text","image","audio","video"]},"metadata":{"developer":"Google","developerId":8,"providerId":24,"modelRatio":0.625,"cacheRatio":1,"completionRatio":4,"description":"gemini-2.0-pro","descriptionEn":"The latest experimental version of Gemini-2.0-Pro","order":102,"flag":0,"tags":["multi_modal","best"],"modalities":["text","image","audio","video"],"typeHints":["t2t","t2i"],"source":"public-provider-conf"},"vision":true},{"id":"gemini-2.5-flash","name":"gemini-2.5-flash","display_name":"gemini-2.5-flash","type":"chat","context_length":1000000,"max_output_tokens":1000000,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"developer":"Google","developerId":8,"providerId":24,"modelRatio":0.15,"cacheRatio":0.25,"completionRatio":8.33,"description":"gemini-2.5-flash ","descriptionEn":"gemini-2.5-flash official stable version","order":850,"flag":1,"billingConfig":"{\"model_name\": \"gemini-2.5-flash\", \"default_tier\": \"tier1\", \"enabled_billing_items\": [\"prompt_tokens\", \"completion_tokens\", \"cached_tokens\", \"input_audio_tokens\", \"cached_audio_tokens\", \"web_search_requests\", \"cache_storage_hours\"], \"per_unit_price_config\": {\"web_search_price\": 0.035, \"cache_storage_price\": 1.0}, \"token_based_tier_configs\": {\"tier1\": {\"model_ratio\": 0.15, \"tier_condition\": {\"max_tokens\": -1, \"min_tokens\": 0}, \"cached_tokens_ratio\": 0.25, \"prompt_tokens_ratio\": 1.0, \"completion_tokens_ratio\": 8.33, \"input_audio_tokens_ratio\": 3.33, \"cached_audio_tokens_ratio\": 0.83}}}","source":"public-provider-conf"},"vision":false},{"id":"gemini-2.5-flash-image-preview","name":"gemini-2.5-flash-image-preview","display_name":"gemini-2.5-flash-image-preview","type":"image-generation","context_length":32000,"max_output_tokens":32000,"capabilities":{"vision":true,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"modalities":{"input":["image","text"],"output":["image","text"]},"metadata":{"developer":"Google","developerId":8,"providerId":24,"modelRatio":0.15,"cacheRatio":1,"completionRatio":4,"description":"Aihubmix gemini-2.5-flash-image-preview  openai  chat modalities=[\"text\", \"image\"],https://docs.aihubmix.com/cn/api/Multimodal-Interaction-with-Gemini#gemini-2-5-flash-%E5%9B%BE%E5%83%8F%E7%94%9F%E6%88%90","descriptionEn":"Aihubmix supports the gemini-2.5-flash-image-preview model; you can add extra parameters modalities=[\"text\", \"image\"] through the OpenAI-compatible chat interface; https://docs.aihubmix.com/en/api/Gemini-Guides#gemini-2-5-flash%3A-quick-task-support","order":999,"flag":2,"displayInput":"0.1tokens/M","displayOutput":"0.04$/image ;2.49m/tokens","billingConfig":"{     \"model_name\": \"gemini-2.5-flash-image-preview\",     \"default_tier\": \"tier1\",     \"token_based_tier_configs\":     {         \"tier1\":         {             \"tier_condition\":             {                 \"min_tokens\": 0,                 \"max_tokens\": -1             },             \"model_ratio\": 0.15,             \"prompt_tokens_ratio\": 1.0,             \"completion_tokens_ratio\": 8.33,             \"input_image_tokens_ratio\": 1,             \"output_image_tokens_ratio\": 100         }     },     \"per_unit_price_config\":     {},     \"enabled_billing_items\":     [         \"prompt_tokens\",         \"completion_tokens\",         \"input_image_tokens\",         \"output_image_tokens\"     ] } ","modalities":["image","text"],"typeHints":["t2i"],"source":"public-provider-conf"},"vision":true},{"id":"gemini-2.5-flash-lite","name":"gemini-2.5-flash-lite","display_name":"gemini-2.5-flash-lite","type":"chat","context_length":1000000,"max_output_tokens":1000000,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"developer":"Google","developerId":8,"providerId":24,"modelRatio":0.05,"cacheRatio":1,"completionRatio":4,"description":"gemini-2.5-flash-lite ","descriptionEn":"Gemini 2.5 Flash Lite Official Version","order":850,"flag":1,"billingConfig":"{\"model_name\": \"gemini-2.5-flash-lite\", \"default_tier\": \"tier1\", \"enabled_billing_items\": [\"prompt_tokens\", \"completion_tokens\", \"cached_tokens\", \"input_audio_tokens\", \"cached_audio_tokens\", \"web_search_requests\", \"cache_storage_hours\"], \"per_unit_price_config\": {\"web_search_price\": 0.035, \"cache_storage_price\": 1.0}, \"token_based_tier_configs\": {\"tier1\": {\"model_ratio\": 0.05, \"tier_condition\": {\"max_tokens\": -1, \"min_tokens\": 0}, \"cached_tokens_ratio\": 0.25, \"prompt_tokens_ratio\": 1.0, \"completion_tokens_ratio\": 4.0, \"input_audio_tokens_ratio\": 3.0, \"cached_audio_tokens_ratio\": 1.25}}}","source":"public-provider-conf"},"vision":false},{"id":"gemini-2.5-flash-lite-preview-06-17","name":"gemini-2.5-flash-lite-preview-06-17","display_name":"gemini-2.5-flash-lite-preview-06-17","type":"chat","context_length":1000000,"max_output_tokens":1000000,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"developer":"Google","developerId":8,"providerId":24,"modelRatio":0.05,"cacheRatio":1,"completionRatio":4,"description":"gemini-2.5-flash-lite-preview-06-17 ","descriptionEn":"gemini-2.5-flash-lite-preview-06-17 ","order":0,"flag":1,"billingConfig":"{\"model_name\": \"gemini-2.5-flash-lite\", \"default_tier\": \"tier1\", \"enabled_billing_items\": [\"prompt_tokens\", \"completion_tokens\", \"cached_tokens\", \"input_audio_tokens\", \"cached_audio_tokens\", \"web_search_requests\", \"cache_storage_hours\"], \"per_unit_price_config\": {\"web_search_price\": 0.035, \"cache_storage_price\": 1.0}, \"token_based_tier_configs\": {\"tier1\": {\"model_ratio\": 0.05, \"tier_condition\": {\"max_tokens\": -1, \"min_tokens\": 0}, \"cached_tokens_ratio\": 0.25, \"prompt_tokens_ratio\": 1.0, \"completion_tokens_ratio\": 4.0, \"input_audio_tokens_ratio\": 3.0, \"cached_audio_tokens_ratio\": 1.25}}}","source":"public-provider-conf"},"vision":false},{"id":"gemini-2.5-flash-lite-preview-09-2025","name":"gemini-2.5-flash-lite-preview-09-2025","display_name":"gemini-2.5-flash-lite-preview-09-2025","type":"chat","context_length":0,"max_output_tokens":0,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"developer":"Google","developerId":8,"providerId":24,"modelRatio":0.05,"cacheRatio":1,"completionRatio":4,"description":"gemini-2.5-flash-lite-preview-09-2025","descriptionEn":"gemini-2.5-flash-lite-preview-09-2025","order":101,"flag":1,"source":"public-provider-conf"},"vision":false},{"id":"gemini-2.5-flash-nothink","name":"gemini-2.5-flash-nothink","display_name":"gemini-2.5-flash-nothink","type":"chat","context_length":1000000,"max_output_tokens":1000000,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"developer":"Google","developerId":8,"providerId":24,"modelRatio":0.15,"cacheRatio":0.25,"completionRatio":8.33,"description":"gemini-2.5-flashgemini-2.5-flash-nothink openai  gemini sdkgemini  sdk budget=0","descriptionEn":"Gemini-2.5-flash defaults to thinking enabled; to disable thinking, request the name gemini-2.5-flash-nothink, which only supports OpenAI-compatible format calls and does not support Gemini SDK; for the native Gemini SDK, please set the parameter budget=0 directly.","order":849,"flag":1,"billingConfig":"{\"model_name\": \"gemini-2.5-flash\", \"default_tier\": \"tier1\", \"enabled_billing_items\": [\"prompt_tokens\", \"completion_tokens\", \"cached_tokens\", \"input_audio_tokens\", \"cached_audio_tokens\", \"web_search_requests\", \"cache_storage_hours\"], \"per_unit_price_config\": {\"web_search_price\": 0.035, \"cache_storage_price\": 1.0}, \"token_based_tier_configs\": {\"tier1\": {\"model_ratio\": 0.15, \"tier_condition\": {\"max_tokens\": -1, \"min_tokens\": 0}, \"cached_tokens_ratio\": 0.25, \"prompt_tokens_ratio\": 1.0, \"completion_tokens_ratio\": 8.33, \"input_audio_tokens_ratio\": 3.33, \"cached_audio_tokens_ratio\": 0.83}}}","source":"public-provider-conf"},"vision":false},{"id":"gemini-2.5-flash-preview-04-17","name":"gemini-2.5-flash","display_name":"gemini-2.5-flash","type":"chat","context_length":1050000,"max_output_tokens":1050000,"capabilities":{"vision":true,"function_calling":false,"reasoning":true,"tool_calling":false},"reasoning":true,"tool_call":false,"modalities":{"input":["text","image"],"output":["text","image"]},"metadata":{"developer":"Google","developerId":8,"providerId":24,"modelRatio":0.075,"cacheRatio":0.25,"completionRatio":23,"description":" Google  Gemini 2.5 Flash  AI \n\n LMArena  Hard Prompts  2.5 Pro","descriptionEn":"Google's latest release, Gemini 2.5 Flash, is an AI model that combines speed, cost-effectiveness, and controllable reasoning capabilities. It introduces a \"thinking budget\" mechanism, allowing developers to fine-tune the model's reasoning depth based on task complexity, thereby achieving an optimal balance between quality, cost, and response time.","order":766,"flag":1,"billingConfig":"{\"model_name\": \"gemini-2.5-flash\", \"default_tier\": \"tier1\", \"enabled_billing_items\": [\"prompt_tokens\", \"completion_tokens\", \"cached_tokens\", \"input_audio_tokens\", \"cached_audio_tokens\", \"web_search_requests\", \"cache_storage_hours\"], \"per_unit_price_config\": {\"web_search_price\": 0.035, \"cache_storage_price\": 1.0}, \"token_based_tier_configs\": {\"tier1\": {\"model_ratio\": 0.15, \"tier_condition\": {\"max_tokens\": -1, \"min_tokens\": 0}, \"cached_tokens_ratio\": 0.25, \"prompt_tokens_ratio\": 1.0, \"completion_tokens_ratio\": 8.33, \"input_audio_tokens_ratio\": 3.33, \"cached_audio_tokens_ratio\": 0.83}}}","features":["thinking","structured_outputs","long_context"],"tags":["multi_modal","best","optimized"],"modalities":["text","image"],"typeHints":["t2t"],"source":"public-provider-conf"},"vision":true},{"id":"gemini-2.5-flash-preview-05-20","name":"gemini-2.5-flash-preview-05-20","display_name":"gemini-2.5-flash-preview-05-20","type":"chat","context_length":1000000,"max_output_tokens":1000000,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"developer":"Google","developerId":8,"providerId":24,"modelRatio":0.15,"cacheRatio":0.25,"completionRatio":8.33,"description":"gemini-2.5-flash-preview gemini-2.5-flash-preview-05-20 gemini-2.5-flash  6  25 ","descriptionEn":"gemini-2.5-flash-preview ","order":850,"flag":1,"billingConfig":"{\"model_name\": \"gemini-2.5-flash\", \"default_tier\": \"tier1\", \"enabled_billing_items\": [\"prompt_tokens\", \"completion_tokens\", \"cached_tokens\", \"input_audio_tokens\", \"cached_audio_tokens\", \"web_search_requests\", \"cache_storage_hours\"], \"per_unit_price_config\": {\"web_search_price\": 0.035, \"cache_storage_price\": 1.0}, \"token_based_tier_configs\": {\"tier1\": {\"model_ratio\": 0.15, \"tier_condition\": {\"max_tokens\": -1, \"min_tokens\": 0}, \"cached_tokens_ratio\": 0.25, \"prompt_tokens_ratio\": 1.0, \"completion_tokens_ratio\": 8.33, \"input_audio_tokens_ratio\": 3.33, \"cached_audio_tokens_ratio\": 0.83}}}","source":"public-provider-conf"},"vision":false},{"id":"gemini-2.5-flash-preview-09-2025","name":"gemini-2.5-flash-preview-09-2025","display_name":"gemini-2.5-flash-preview-09-2025","type":"chat","context_length":0,"max_output_tokens":0,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"developer":"Google","developerId":8,"providerId":24,"modelRatio":0.15,"cacheRatio":0.25,"completionRatio":8.33,"description":"gemini-2.5-flash-preview-09-2025","descriptionEn":"gemini-2.5-flash-preview-09-2025","order":100,"flag":1,"source":"public-provider-conf"},"vision":false},{"id":"gemini-2.5-flash-search","name":"gemini-2.5-flash-search","display_name":"gemini-2.5-flash-search","type":"chat","context_length":1000000,"max_output_tokens":1000000,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"developer":"Google","developerId":8,"providerId":24,"modelRatio":0.15,"cacheRatio":0.25,"completionRatio":8.33,"description":"gemini-2.5-flash-search openai  gemini sdkgemini  sdk ","descriptionEn":"gemini-2.5-flash-search integrates Google's official search functionality; the search feature will have an additional separate fee log directly incorporated into the scoring, with detailed logs not displayed; this will be fixed and displayed later; only supports OpenAI-compatible formats for invocation, does not support Gemini SDK; for Gemini's native SDK, please set parameters directly using the official search parameters.","order":849,"flag":1,"billingConfig":"{\"model_name\": \"gemini-2.5-flash\", \"default_tier\": \"tier1\", \"enabled_billing_items\": [\"prompt_tokens\", \"completion_tokens\", \"cached_tokens\", \"input_audio_tokens\", \"cached_audio_tokens\", \"web_search_requests\", \"cache_storage_hours\"], \"per_unit_price_config\": {\"web_search_price\": 0.035, \"cache_storage_price\": 1.0}, \"token_based_tier_configs\": {\"tier1\": {\"model_ratio\": 0.15, \"tier_condition\": {\"max_tokens\": -1, \"min_tokens\": 0}, \"cached_tokens_ratio\": 0.25, \"prompt_tokens_ratio\": 1.0, \"completion_tokens_ratio\": 8.33, \"input_audio_tokens_ratio\": 3.33, \"cached_audio_tokens_ratio\": 0.83}}}","features":["web"],"typeHints":["search"],"source":"public-provider-conf"},"vision":false},{"id":"gemini-2.5-pro","name":"gemini-2.5-pro","display_name":"gemini-2.5-pro","type":"chat","context_length":1000000,"max_output_tokens":1000000,"capabilities":{"vision":true,"function_calling":true,"reasoning":true,"tool_calling":true},"reasoning":true,"tool_call":true,"modalities":{"input":["text","image","audio","video"],"output":["text","image","audio","video"]},"metadata":{"developer":"Google","developerId":8,"providerId":24,"modelRatio":0.625,"cacheRatio":0.25,"completionRatio":8,"description":"gemini-2.5-pro ","descriptionEn":"gemini-2.5-pro latest released stable version","order":900,"flag":2,"billingConfig":"{\n  \"model_name\": \"gemini-2.5-pro\",\n  \"default_tier\": \"tier1\",\n  \"token_based_tier_configs\": {\n    \"tier1\": {\n      \"tier_condition\": {\n        \"min_tokens\": 0,\n        \"max_tokens\": 200000\n      },\n      \"model_ratio\": 0.625,\n      \"prompt_tokens_ratio\": 1.0,\n      \"completion_tokens_ratio\": 8.0,\n      \"cached_tokens_ratio\": 0.248\n    },\n    \"tier2\": {\n      \"tier_condition\": {\n        \"min_tokens\": 200001,\n        \"max_tokens\": -1\n      },\n      \"model_ratio\": 1.25,\n      \"prompt_tokens_ratio\": 1.0,\n      \"completion_tokens_ratio\": 6.0,\n      \"cached_tokens_ratio\": 0.25\n    }\n  },\n  \"per_unit_price_config\": {\n    \"web_search_price\": 0.035,\n    \"cache_storage_price\": 4.50\n  },\n  \"enabled_billing_items\": [\n    \"prompt_tokens\",\n    \"completion_tokens\",\n    \"cached_tokens\",\n    \"web_search_requests\",\n    \"cache_storage_hours\"\n  ]\n}","features":["tools","function_calling","structured_outputs","long_context","web","thinking","deepsearch"],"tags":["best"],"modalities":["text","image","audio","video"],"typeHints":["t2t"],"source":"public-provider-conf"},"vision":true},{"id":"gemini-2.5-pro-exp-03-25","name":"gemini-2.5-pro-exp","display_name":"gemini-2.5-pro-exp","type":"chat","context_length":1000000,"max_output_tokens":1000000,"capabilities":{"vision":true,"function_calling":true,"reasoning":false,"tool_calling":true},"reasoning":false,"tool_call":true,"modalities":{"input":["text","image","audio","video"],"output":["text","image","audio","video"]},"metadata":{"developer":"Google","developerId":8,"providerId":24,"modelRatio":0.625,"cacheRatio":1,"completionRatio":4,"description":"\n 100  token \n\n","descriptionEn":"Googles latest experimental model, highly unstable, for experience only.\nIt boasts strong reasoning and coding capabilities, able to \"think\" before responding, enhancing performance and accuracy in complex tasks. It supports multimodal inputs (text, audio, images, video) and a 1 million token context window, suitable for advanced programming, math, and science tasks.\n\nThis means Gemini 2.5 can handle more complex problems in coding, science and math, and support more context-aware agents.","order":0,"flag":1,"billingConfig":"{   \"model_name\": \"gemini-2.5-pro\",   \"default_tier\": \"tier1\",   \"token_based_tier_configs\": {     \"tier1\": {       \"tier_condition\": {         \"min_tokens\": 0,         \"max_tokens\": 200000       },       \"model_ratio\": 0.625,       \"prompt_tokens_ratio\": 1.0,       \"completion_tokens_ratio\": 8.0,       \"cached_tokens_ratio\": 0.248     },     \"tier2\": {       \"tier_condition\": {         \"min_tokens\": 200001,         \"max_tokens\": -1       },       \"model_ratio\": 1.25,       \"prompt_tokens_ratio\": 1.0,       \"completion_tokens_ratio\": 6.0,       \"cached_tokens_ratio\": 0.25     }   },   \"per_unit_price_config\": {     \"web_search_price\": 0.035,     \"cache_storage_price\": 4.50   },   \"enabled_billing_items\": [     \"prompt_tokens\",     \"completion_tokens\",     \"cached_tokens\",     \"web_search_requests\",     \"cache_storage_hours\"   ] }","features":["structured_outputs","tools","long_context"],"tags":["multi_modal"],"modalities":["text","image","audio","video"],"typeHints":["t2t"],"source":"public-provider-conf"},"vision":true},{"id":"gemini-2.5-pro-preview-03-25","name":"gemini 2.5 pro","display_name":"gemini 2.5 pro","type":"chat","context_length":1000000,"max_output_tokens":1000000,"capabilities":{"vision":true,"function_calling":false,"reasoning":true,"tool_calling":false},"reasoning":true,"tool_call":false,"modalities":{"input":["text","image"],"output":["text","image"]},"metadata":{"developer":"Google","developerId":8,"providerId":24,"modelRatio":0.625,"cacheRatio":0.25,"completionRatio":8,"description":"\nGemini 2.5 Pro \ngoogle","descriptionEn":"Supports high concurrency.  \nThe Gemini 2.5 Pro preview version is here, with higher limits for production testing.  \nGoogle's latest and most powerful model;","order":765,"flag":2,"billingConfig":"{   \"model_name\": \"gemini-2.5-pro\",   \"default_tier\": \"tier1\",   \"token_based_tier_configs\": {     \"tier1\": {       \"tier_condition\": {         \"min_tokens\": 0,         \"max_tokens\": 200000       },       \"model_ratio\": 0.625,       \"prompt_tokens_ratio\": 1.0,       \"completion_tokens_ratio\": 8.0,       \"cached_tokens_ratio\": 0.248     },     \"tier2\": {       \"tier_condition\": {         \"min_tokens\": 200001,         \"max_tokens\": -1       },       \"model_ratio\": 1.25,       \"prompt_tokens_ratio\": 1.0,       \"completion_tokens_ratio\": 6.0,       \"cached_tokens_ratio\": 0.25     }   },   \"per_unit_price_config\": {     \"web_search_price\": 0.035,     \"cache_storage_price\": 4.50   },   \"enabled_billing_items\": [     \"prompt_tokens\",     \"completion_tokens\",     \"cached_tokens\",     \"web_search_requests\",     \"cache_storage_hours\"   ] }","features":["thinking"],"tags":["multi_modal"],"modalities":["text","image"],"typeHints":["t2t"],"source":"public-provider-conf"},"vision":true},{"id":"gemini-2.5-pro-preview-03-25-search","name":"gemini-2.5-pro-preview-","display_name":"gemini-2.5-pro-preview-","type":"chat","context_length":1000000,"max_output_tokens":1000000,"capabilities":{"vision":false,"function_calling":true,"reasoning":true,"tool_calling":true},"reasoning":true,"tool_call":true,"metadata":{"developer":"Google","developerId":8,"providerId":24,"modelRatio":0.625,"cacheRatio":1,"completionRatio":8,"description":"gemini-2.5-pro-preview-03-25-search","descriptionEn":"Integrated with Google's official search function.","order":750,"flag":1,"billingConfig":"{   \"model_name\": \"gemini-2.5-pro\",   \"default_tier\": \"tier1\",   \"token_based_tier_configs\": {     \"tier1\": {       \"tier_condition\": {         \"min_tokens\": 0,         \"max_tokens\": 200000       },       \"model_ratio\": 0.625,       \"prompt_tokens_ratio\": 1.0,       \"completion_tokens_ratio\": 8.0,       \"cached_tokens_ratio\": 0.248     },     \"tier2\": {       \"tier_condition\": {         \"min_tokens\": 200001,         \"max_tokens\": -1       },       \"model_ratio\": 1.25,       \"prompt_tokens_ratio\": 1.0,       \"completion_tokens_ratio\": 6.0,       \"cached_tokens_ratio\": 0.25     }   },   \"per_unit_price_config\": {     \"web_search_price\": 0.035,     \"cache_storage_price\": 4.50   },   \"enabled_billing_items\": [     \"prompt_tokens\",     \"completion_tokens\",     \"cached_tokens\",     \"web_search_requests\",     \"cache_storage_hours\"   ] }","features":["thinking","web","tools","function_calling","structured_outputs","long_context"],"typeHints":["t2t","search"],"source":"public-provider-conf"},"vision":false},{"id":"gemini-2.5-pro-preview-05-06","name":"gemini-2.5-pro-preview-05-06","display_name":"gemini-2.5-pro-preview-05-06","type":"chat","context_length":1000000,"max_output_tokens":1000000,"capabilities":{"vision":true,"function_calling":false,"reasoning":true,"tool_calling":false},"reasoning":true,"tool_call":false,"modalities":{"input":["text","image","audio","video"],"output":["text","image","audio","video"]},"metadata":{"developer":"Google","developerId":8,"providerId":24,"modelRatio":0.625,"cacheRatio":0.25,"completionRatio":8,"description":"gemini-2.5-pro ","descriptionEn":"gemini-2.5-pro latest model","order":766,"flag":1,"billingConfig":"{   \"model_name\": \"gemini-2.5-pro\",   \"default_tier\": \"tier1\",   \"token_based_tier_configs\": {     \"tier1\": {       \"tier_condition\": {         \"min_tokens\": 0,         \"max_tokens\": 200000       },       \"model_ratio\": 0.625,       \"prompt_tokens_ratio\": 1.0,       \"completion_tokens_ratio\": 8.0,       \"cached_tokens_ratio\": 0.248     },     \"tier2\": {       \"tier_condition\": {         \"min_tokens\": 200001,         \"max_tokens\": -1       },       \"model_ratio\": 1.25,       \"prompt_tokens_ratio\": 1.0,       \"completion_tokens_ratio\": 6.0,       \"cached_tokens_ratio\": 0.25     }   },   \"per_unit_price_config\": {     \"web_search_price\": 0.035,     \"cache_storage_price\": 4.50   },   \"enabled_billing_items\": [     \"prompt_tokens\",     \"completion_tokens\",     \"cached_tokens\",     \"web_search_requests\",     \"cache_storage_hours\"   ] }","features":["thinking","long_context"],"tags":["multi_modal","best","sota"],"modalities":["text","image","audio","video"],"typeHints":["t2t"],"source":"public-provider-conf"},"vision":true},{"id":"gemini-2.5-pro-preview-05-06-search","name":"gemini-2.5-pro-preview-05-06-search","display_name":"gemini-2.5-pro-preview-05-06-search","type":"chat","context_length":1000000,"max_output_tokens":1000000,"capabilities":{"vision":true,"function_calling":false,"reasoning":true,"tool_calling":false},"reasoning":true,"tool_call":false,"modalities":{"input":["text","image","audio","video"],"output":["text","image","audio","video"]},"metadata":{"developer":"Google","developerId":8,"providerId":24,"modelRatio":0.625,"cacheRatio":1,"completionRatio":8,"description":"gemini-2.5-pro-preview-05-06-search","descriptionEn":"Integrated with Google's official search function.","order":755,"flag":1,"billingConfig":"{   \"model_name\": \"gemini-2.5-pro\",   \"default_tier\": \"tier1\",   \"token_based_tier_configs\": {     \"tier1\": {       \"tier_condition\": {         \"min_tokens\": 0,         \"max_tokens\": 200000       },       \"model_ratio\": 0.625,       \"prompt_tokens_ratio\": 1.0,       \"completion_tokens_ratio\": 8.0,       \"cached_tokens_ratio\": 0.248     },     \"tier2\": {       \"tier_condition\": {         \"min_tokens\": 200001,         \"max_tokens\": -1       },       \"model_ratio\": 1.25,       \"prompt_tokens_ratio\": 1.0,       \"completion_tokens_ratio\": 6.0,       \"cached_tokens_ratio\": 0.25     }   },   \"per_unit_price_config\": {     \"web_search_price\": 0.035,     \"cache_storage_price\": 4.50   },   \"enabled_billing_items\": [     \"prompt_tokens\",     \"completion_tokens\",     \"cached_tokens\",     \"web_search_requests\",     \"cache_storage_hours\"   ] }","features":["thinking","web"],"modalities":["text","image","audio","video"],"typeHints":["t2t","search"],"source":"public-provider-conf"},"vision":true},{"id":"gemini-2.5-pro-preview-06-05","name":"gemini-2.5-pro-preview-06-05","display_name":"gemini-2.5-pro-preview-06-05","type":"chat","context_length":1000000,"max_output_tokens":1000000,"capabilities":{"vision":true,"function_calling":true,"reasoning":true,"tool_calling":true},"reasoning":true,"tool_call":true,"modalities":{"input":["text","image","audio","video"],"output":["text","image","audio","video"]},"metadata":{"developer":"Google","developerId":8,"providerId":24,"modelRatio":0.625,"cacheRatio":0.25,"completionRatio":8,"description":"Gemini 2.5 Pro Preview (06-05)  Google  100  token  200  WebDevArena  LMArena  Web ","descriptionEn":"Googles latest multimodal flagship model, combining exceptional coding and reasoning capabilities. Its massive 1 million token context window (soon to expand to 2 million) places it at the top of the WebDevArena and LMArena leaderboards. It is particularly well-suited for developing aesthetically pleasing and highly functional interactive web applications, code transformation, and complex workflows. The newly introduced \"reasoning budget\" feature cleverly balances cost and performance, while optimized tool calls and response styles further enhance development efficiency, making it the ideal choice for rapid prototyping and advanced coding.","order":300,"flag":1,"billingConfig":"{   \"model_name\": \"gemini-2.5-pro\",   \"default_tier\": \"tier1\",   \"token_based_tier_configs\": {     \"tier1\": {       \"tier_condition\": {         \"min_tokens\": 0,         \"max_tokens\": 200000       },       \"model_ratio\": 0.625,       \"prompt_tokens_ratio\": 1.0,       \"completion_tokens_ratio\": 8.0,       \"cached_tokens_ratio\": 0.248     },     \"tier2\": {       \"tier_condition\": {         \"min_tokens\": 200001,         \"max_tokens\": -1       },       \"model_ratio\": 1.25,       \"prompt_tokens_ratio\": 1.0,       \"completion_tokens_ratio\": 6.0,       \"cached_tokens_ratio\": 0.25     }   },   \"per_unit_price_config\": {     \"web_search_price\": 0.035,     \"cache_storage_price\": 4.50   },   \"enabled_billing_items\": [     \"prompt_tokens\",     \"completion_tokens\",     \"cached_tokens\",     \"web_search_requests\",     \"cache_storage_hours\"   ] }","features":["thinking","tools","function_calling","structured_outputs","long_context"],"tags":["multi_modal","best"],"modalities":["text","image","audio","video"],"typeHints":["t2t"],"source":"public-provider-conf"},"vision":true},{"id":"gemini-2.5-pro-preview-06-05-search","name":"gemini-2.5-pro-preview-06-05-search","display_name":"gemini-2.5-pro-preview-06-05-search","type":"chat","context_length":1000000,"max_output_tokens":1000000,"capabilities":{"vision":true,"function_calling":true,"reasoning":true,"tool_calling":true},"reasoning":true,"tool_call":true,"modalities":{"input":["text","image","audio","video"],"output":["text","image","audio","video"]},"metadata":{"developer":"Google","developerId":8,"providerId":24,"modelRatio":0.625,"cacheRatio":0.25,"completionRatio":8,"description":"gemini-2.5-pro-preview-06-05-search openai gemini  sdk  search ","descriptionEn":"Integrated with Google's official search function.","order":700,"flag":1,"billingConfig":"{   \"model_name\": \"gemini-2.5-pro\",   \"default_tier\": \"tier1\",   \"token_based_tier_configs\": {     \"tier1\": {       \"tier_condition\": {         \"min_tokens\": 0,         \"max_tokens\": 200000       },       \"model_ratio\": 0.625,       \"prompt_tokens_ratio\": 1.0,       \"completion_tokens_ratio\": 8.0,       \"cached_tokens_ratio\": 0.248     },     \"tier2\": {       \"tier_condition\": {         \"min_tokens\": 200001,         \"max_tokens\": -1       },       \"model_ratio\": 1.25,       \"prompt_tokens_ratio\": 1.0,       \"completion_tokens_ratio\": 6.0,       \"cached_tokens_ratio\": 0.25     }   },   \"per_unit_price_config\": {     \"web_search_price\": 0.035,     \"cache_storage_price\": 4.50   },   \"enabled_billing_items\": [     \"prompt_tokens\",     \"completion_tokens\",     \"cached_tokens\",     \"web_search_requests\",     \"cache_storage_hours\"   ] }","features":["thinking","web","tools","function_calling","structured_outputs","long_context"],"tags":["multi_modal"],"modalities":["text","image","audio","video"],"typeHints":["t2t","search"],"source":"public-provider-conf"},"vision":true},{"id":"gemini-2.5-pro-search","name":"gemini-2.5-pro-search","display_name":"gemini-2.5-pro-search","type":"chat","context_length":1000000,"max_output_tokens":1000000,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"developer":"Google","developerId":8,"providerId":24,"modelRatio":0.625,"cacheRatio":0.25,"completionRatio":8,"description":"gemini-2.5-pro-search openai  gemini sdkgemini  sdk ","descriptionEn":"gemini-2.5-pro-search integrates Google's official search functionality; the search feature will have an additional separate fee log directly incorporated into the scoring, with detailed logs not displayed; this will be fixed and displayed later; only supports OpenAI-compatible formats for invocation, does not support Gemini SDK; for Gemini's native SDK, please set parameters directly using the official search parameters.","order":899,"flag":1,"billingConfig":"{   \"model_name\": \"gemini-2.5-pro-search\",   \"default_tier\": \"tier1\",   \"token_based_tier_configs\": {     \"tier1\": {       \"tier_condition\": {         \"min_tokens\": 0,         \"max_tokens\": 200000       },       \"model_ratio\": 0.625,       \"prompt_tokens_ratio\": 1.0,       \"completion_tokens_ratio\": 8.0,       \"cached_tokens_ratio\": 0.248     },     \"tier2\": {       \"tier_condition\": {         \"min_tokens\": 200001,         \"max_tokens\": -1       },       \"model_ratio\": 1.25,       \"prompt_tokens_ratio\": 1.0,       \"completion_tokens_ratio\": 6.0,       \"cached_tokens_ratio\": 0.25     }   },   \"per_unit_price_config\": {     \"web_search_price\": 0.035,     \"cache_storage_price\": 4.50   },   \"enabled_billing_items\": [     \"prompt_tokens\",     \"completion_tokens\",     \"cached_tokens\",     \"web_search_requests\",     \"cache_storage_hours\"   ] }","features":["web"],"typeHints":["search"],"source":"public-provider-conf"},"vision":false},{"id":"gemini-embedding-001","name":"gemini-embedding-001","display_name":"gemini-embedding-001","type":"embedding","context_length":0,"max_output_tokens":0,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"developer":"Google","developerId":8,"providerId":24,"modelRatio":0.075,"cacheRatio":1,"completionRatio":1,"description":"","descriptionEn":"Latest version","order":400,"flag":1,"typeHints":["embedding"],"source":"public-provider-conf"},"vision":false},{"id":"gemini-embedding-exp-03-07","name":"gemini-embedding-exp-03-07","display_name":"gemini-embedding-exp-03-07","type":"embedding","context_length":0,"max_output_tokens":0,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"modalities":{"input":["text"],"output":["text"]},"metadata":{"developer":"Google","developerId":8,"providerId":24,"modelRatio":0.01,"cacheRatio":1,"completionRatio":1,"order":0,"flag":0,"modalities":["text"],"typeHints":["embedding"],"source":"public-provider-conf"},"vision":false},{"id":"gemini-exp-1114","name":"Gemini 2","display_name":"Gemini 2","type":"chat","context_length":0,"max_output_tokens":0,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"developer":"Google","developerId":8,"providerId":24,"modelRatio":0.625,"cacheRatio":1,"completionRatio":4,"order":0,"flag":0,"source":"public-provider-conf"},"vision":false},{"id":"gemini-exp-1121","name":"Gemini 2","display_name":"Gemini 2","type":"chat","context_length":0,"max_output_tokens":0,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"developer":"Google","developerId":8,"providerId":24,"modelRatio":0.625,"cacheRatio":1,"completionRatio":4,"order":0,"flag":0,"source":"public-provider-conf"},"vision":false},{"id":"gemini-exp-1206","name":"Gemini 2","display_name":"Gemini 2","type":"chat","context_length":0,"max_output_tokens":0,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"developer":"Google","developerId":8,"providerId":24,"modelRatio":0.625,"cacheRatio":1,"completionRatio":4,"description":"","descriptionEn":"Google's latest experimental model, currently Google's most powerful model.","order":99,"flag":0,"source":"public-provider-conf"},"vision":false},{"id":"gemini-flash-latest","name":"gemini-flash-latest","display_name":"gemini-flash-latest","type":"chat","context_length":0,"max_output_tokens":0,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"developer":"Google","developerId":8,"providerId":24,"modelRatio":0.15,"cacheRatio":0.25,"completionRatio":8.33,"description":"gemini-2.5-flash-preview-09-2025\n Gemini 2.5 Flash  \n 2.5 Flash \n\n SWE-Bench Verified  5%48.9%  54%  \n","descriptionEn":"Pointing to the latest version gemini-2.5-flash-preview-09-2025\nThis latest 2.5 Flash model comes with improvements in two key areas we heard consistent feedback on:\n\nBetter agentic tool use: We've improved how the model uses tools, leading to better performance in more complex, agentic and multi-step applications. This model shows noticeable improvements on key agentic benchmarks, including a 5% gain on SWE-Bench Verified, compared to our last release (48.9%  54%).\nMore efficient: With thinking on, the model is now significantly more cost-efficientachieving higher quality outputs while using fewer tokens, reducing latency and cost (see charts above).","order":974,"flag":1,"source":"public-provider-conf"},"vision":false},{"id":"gemini-flash-lite-latest","name":"gemini-flash-lite-latest","display_name":"gemini-flash-lite-latest","type":"chat","context_length":0,"max_output_tokens":0,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"developer":"Google","developerId":8,"providerId":24,"modelRatio":0.05,"cacheRatio":1,"completionRatio":4,"description":"gemini-2.5-flash-lite-preview-09-2025","descriptionEn":"Pointing to the latest versiongemini-2.5-flash-lite-preview-09-2025","order":973,"flag":1,"source":"public-provider-conf"},"vision":false},{"id":"gemma-3-12b-it","name":"gemma-3-12b-it","display_name":"gemma-3-12b-it","type":"chat","context_length":0,"max_output_tokens":0,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"developer":"Google","developerId":8,"providerId":24,"modelRatio":0.1,"cacheRatio":0,"completionRatio":1,"description":"Gemma 3 Gemma 3  128K  140 Gemma 3  AI ","descriptionEn":"Gemma 3 models are multimodal, handling text and image input and generating text output, with open weights for both pre-trained variants and instruction-tuned variants. Gemma 3 has a large, 128K context window, multilingual support in over 140 languages, and is available in more sizes than previous versions. Gemma 3 models are well-suited for a variety of text generation and image understanding tasks, including question answering, summarization, and reasoning. Their relatively small size makes it possible to deploy them in environments with limited resources such as laptops, desktops or your own cloud infrastructure, democratizing access to state of the art AI models and helping foster innovation for everyone.","order":200,"flag":1,"source":"public-provider-conf"},"vision":false},{"id":"gemma-3-1b-it","name":"gemma-3-1b-it","display_name":"gemma-3-1b-it","type":"chat","context_length":0,"max_output_tokens":0,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"developer":"Google","developerId":8,"providerId":24,"modelRatio":0.1,"cacheRatio":0,"completionRatio":1,"description":"Gemma 3 Gemma 3  128K  140 Gemma 3  AI ","descriptionEn":"Gemma 3 models are multimodal, handling text and image input and generating text output, with open weights for both pre-trained variants and instruction-tuned variants. Gemma 3 has a large, 128K context window, multilingual support in over 140 languages, and is available in more sizes than previous versions. Gemma 3 models are well-suited for a variety of text generation and image understanding tasks, including question answering, summarization, and reasoning. Their relatively small size makes it possible to deploy them in environments with limited resources such as laptops, desktops or your own cloud infrastructure, democratizing access to state of the art AI models and helping foster innovation for everyone.","order":200,"flag":1,"source":"public-provider-conf"},"vision":false},{"id":"gemma-3-27b-it","name":"gemma-3-27b-it","display_name":"gemma-3-27b-it","type":"chat","context_length":0,"max_output_tokens":0,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"developer":"Google","developerId":8,"providerId":24,"modelRatio":0.1,"cacheRatio":0,"completionRatio":1,"description":"Gemma 3 Gemma 3  128K  140 Gemma 3  AI ","descriptionEn":"Gemma 3 models are multimodal, handling text and image input and generating text output, with open weights for both pre-trained variants and instruction-tuned variants. Gemma 3 has a large, 128K context window, multilingual support in over 140 languages, and is available in more sizes than previous versions. Gemma 3 models are well-suited for a variety of text generation and image understanding tasks, including question answering, summarization, and reasoning. Their relatively small size makes it possible to deploy them in environments with limited resources such as laptops, desktops or your own cloud infrastructure, democratizing access to state of the art AI models and helping foster innovation for everyone.","order":200,"flag":1,"source":"public-provider-conf"},"vision":false},{"id":"gemma-3-4b-it","name":"gemma-3-4b-it","display_name":"gemma-3-4b-it","type":"chat","context_length":0,"max_output_tokens":0,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"developer":"Google","developerId":8,"providerId":24,"modelRatio":0.1,"cacheRatio":0,"completionRatio":1,"description":"Gemma 3 Gemma 3  128K  140 Gemma 3  AI ","descriptionEn":"Gemma 3 models are multimodal, handling text and image input and generating text output, with open weights for both pre-trained variants and instruction-tuned variants. Gemma 3 has a large, 128K context window, multilingual support in over 140 languages, and is available in more sizes than previous versions. Gemma 3 models are well-suited for a variety of text generation and image understanding tasks, including question answering, summarization, and reasoning. Their relatively small size makes it possible to deploy them in environments with limited resources such as laptops, desktops or your own cloud infrastructure, democratizing access to state of the art AI models and helping foster innovation for everyone.","order":200,"flag":1,"source":"public-provider-conf"},"vision":false},{"id":"gemma-3n-e4b-it","name":"gemma-3n-e4b-it","display_name":"gemma-3n-e4b-it","type":"chat","context_length":0,"max_output_tokens":0,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"developer":"Google","developerId":8,"providerId":24,"modelRatio":0.1,"cacheRatio":0,"completionRatio":1,"description":"Gemma 3n  AI  (PLE)  MatFormer ","descriptionEn":"Gemma 3n is a generative AI model optimized for use in everyday devices, such as phones, laptops, and tablets. This model includes innovations in parameter-efficient processing, including Per-Layer Embedding (PLE) parameter caching and a MatFormer model architecture that provides the flexibility to reduce compute and memory requirements. These models feature audio input handling, as well as text and visual data.","order":200,"flag":1,"source":"public-provider-conf"},"vision":false},{"id":"gemma2-9b-it","name":"gemma2-9b","display_name":"gemma2-9b","type":"chat","context_length":0,"max_output_tokens":0,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"developer":"Google","developerId":8,"providerId":29,"modelRatio":0.2,"cacheRatio":1,"completionRatio":1,"order":0,"flag":0,"source":"public-provider-conf"},"vision":false},{"id":"glm-3-turbo","name":"glm-3-turbo","display_name":"glm-3-turbo","type":"chat","context_length":0,"max_output_tokens":0,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"developer":" ChatGLM","developerId":5,"providerId":16,"modelRatio":0.355,"cacheRatio":1,"completionRatio":1,"order":0,"flag":0,"source":"public-provider-conf"},"vision":false},{"id":"glm-4","name":"glm-4","display_name":"glm-4","type":"chat","context_length":0,"max_output_tokens":0,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"developer":" ChatGLM","developerId":5,"providerId":16,"modelRatio":7.1,"cacheRatio":1,"completionRatio":1,"order":0,"flag":0,"source":"public-provider-conf"},"vision":false},{"id":"glm-4-flash","name":"glm-4-flash","display_name":"glm-4-flash","type":"chat","context_length":0,"max_output_tokens":0,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"developer":" ChatGLM","developerId":5,"providerId":16,"modelRatio":0.05,"cacheRatio":1,"completionRatio":1,"order":0,"flag":0,"source":"public-provider-conf"},"vision":false},{"id":"glm-4-plus","name":"glm-4-plus","display_name":"glm-4-plus","type":"chat","context_length":0,"max_output_tokens":0,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"developer":" ChatGLM","developerId":5,"providerId":16,"modelRatio":4,"cacheRatio":1,"completionRatio":1,"order":0,"flag":0,"source":"public-provider-conf"},"vision":false},{"id":"glm-4.5","name":"glm-4.5","display_name":"glm-4.5","type":"chat","context_length":0,"max_output_tokens":0,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"developer":"ChatGLM","developerId":5,"providerId":16,"modelRatio":0.25,"cacheRatio":1,"completionRatio":4,"order":10,"flag":1,"source":"public-provider-conf"},"vision":false},{"id":"glm-4.5-air","name":"glm-4.5-air","display_name":"glm-4.5-air","type":"chat","context_length":0,"max_output_tokens":0,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"developer":"ChatGLM","developerId":5,"providerId":16,"modelRatio":0.07,"cacheRatio":1,"completionRatio":6,"order":10,"flag":1,"source":"public-provider-conf"},"vision":false},{"id":"glm-4.5-airx","name":"glm-4.5-airx","display_name":"glm-4.5-airx","type":"chat","context_length":0,"max_output_tokens":0,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"developer":"ChatGLM","developerId":5,"providerId":8,"modelRatio":0.55,"cacheRatio":0.2,"completionRatio":4.1,"description":"GLM-4.5-AirX  GLM-4.5-Air ","descriptionEn":"GLM-4.5-AirX is the high-speed version of GLM-4.5-Air, with faster response times, specifically designed for large-scale high-speed demands.","order":0,"flag":1,"source":"public-provider-conf"},"vision":false},{"id":"glm-4.5-flash","name":"glm-4.5-flash","display_name":"glm-4.5-flash","type":"chat","context_length":0,"max_output_tokens":0,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"developer":"ChatGLM","developerId":5,"providerId":8,"modelRatio":0.01,"cacheRatio":1,"completionRatio":1,"order":1,"flag":1,"tags":["multi_modal","best","optimized","economical","lightning","bold","sota","discount","free"],"source":"public-provider-conf"},"vision":false},{"id":"glm-4.5-x","name":"glm-4.5-x","display_name":"glm-4.5-x","type":"chat","context_length":0,"max_output_tokens":0,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"developer":"ChatGLM","developerId":5,"providerId":8,"modelRatio":1.1,"cacheRatio":0.2,"completionRatio":4.05,"description":"GLM-4.5-X  GLM-4.5  100 tokens/","descriptionEn":"GLM-4.5-X is the high-speed version of GLM-4.5, offering powerful performance with a generation speed of up to 100 tokens per second.","order":500,"flag":1,"source":"public-provider-conf"},"vision":false},{"id":"glm-4.5v","name":"glm-4.5v","display_name":"glm-4.5v","type":"chat","context_length":0,"max_output_tokens":0,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"developer":"ChatGLM","developerId":5,"providerId":16,"modelRatio":0.3,"cacheRatio":1,"completionRatio":3,"description":"\nGLM-4.5V  SOTA GUI ","descriptionEn":"GLM-4.5V is Zhipu's most powerful visual reasoning model, the state-of-the-art open-source model of its kind globally, covering core tasks such as image, video, document understanding, and GUI.","order":850,"flag":0,"source":"public-provider-conf"},"vision":false},{"id":"glm-4.6","name":"glm-4.6","display_name":"glm-4.6","type":"chat","context_length":0,"max_output_tokens":0,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"developer":"ChatGLM","developerId":5,"providerId":16,"modelRatio":0.3,"cacheRatio":0.1833,"completionRatio":3.666666,"description":"GLM-4.6  355B 32BGLM-4.6  GLM-4.5 \nGLM-4.6Claude Sonnet 4Coding\n128K200K\n\n\n\n","descriptionEn":"GLM-4.6 is Zhipus latest flagship model, with a total of 355 billion parameters and 32 billion activation parameters. In every core capability, GLM-4.6 surpasses GLM-4.5, as detailed below:\n\nAdvanced coding ability: On public benchmarks and real-world programming tasks, GLM-4.6s coding performance matches Claude Sonnet 4, making it the best-known coding model in China.\nContext length: The context window has been extended from 128K to 200K tokens, accommodating longer code and agent tasks.\nReasoning ability: Reasoning performance has been improved, with support for tool calls during inference.\nSearch ability: Enhanced performance in tool invocation and search agents, delivering better results within agent frameworks.\nWriting ability: Better alignment with human preferences in writing style, readability, and role-play scenarios.\nMultilingual translation: Further improved handling of cross-language tasks.","order":1000,"flag":1,"source":"public-provider-conf"},"vision":false},{"id":"glm-zero-preview","name":"glm-zero-preview","display_name":"glm-zero-preview","type":"chat","context_length":0,"max_output_tokens":0,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"developer":"ChatGLM","developerId":5,"providerId":16,"modelRatio":1,"cacheRatio":1,"completionRatio":1,"description":"o1","descriptionEn":"Simply put, it is the intelligent enhanced version of O1.","order":20,"flag":0,"source":"public-provider-conf"},"vision":false},{"id":"gme-qwen2-vl-2b-instruct","name":"gme-qwen2-vl-2b-instruct","display_name":"gme-qwen2-vl-2b-instruct","type":"embedding","context_length":0,"max_output_tokens":0,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"developer":"Qwen","developerId":13,"providerId":15,"modelRatio":0.069,"cacheRatio":1,"completionRatio":1,"description":"GME-Qwen2VLEmbeddingQwen2-VL  (MLLMs)\nGME-","descriptionEn":"The GME-Qwen2VL series is a unified multimodal Embedding model trained based on the Qwen2-VL multimodal large language model (MLLMs). The GME model supports three types of inputs: text, images, and image-text pairs. All these input types can generate universal vector representations and exhibit excellent retrieval performance.","order":600,"flag":0,"typeHints":["embedding"],"source":"public-provider-conf"},"vision":false},{"id":"google/gemma-2-27b-it","name":"gemma-2-27b-it","display_name":"gemma-2-27b-it","type":"chat","context_length":0,"max_output_tokens":0,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"developer":"Google","developerId":8,"providerId":24,"modelRatio":0.4,"cacheRatio":1,"completionRatio":1,"order":0,"flag":0,"source":"public-provider-conf"},"vision":false},{"id":"google/gemma-3-27b-it","name":"gemma-3-27b","display_name":"gemma-3-27b","type":"chat","context_length":0,"max_output_tokens":0,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"developer":"Google","developerId":8,"providerId":8,"modelRatio":0.1,"cacheRatio":0,"completionRatio":1,"description":"GemmaGeminiGemma 3Gemma 3128K140Gemma 3AI","descriptionEn":"Gemma is a family of lightweight, state-of-the-art open models from Google, built from the same research and technology used to create the Gemini models. Gemma 3 models are multimodal, handling text and image input and generating text output, with open weights for both pre-trained variants and instruction-tuned variants. Gemma 3 has a large, 128K context window, multilingual support in over 140 languages, and is available in more sizes than previous versions. Gemma 3 models are well-suited for a variety of text generation and image understanding tasks, including question answering, summarization, and reasoning. Their relatively small size makes it possible to deploy them in environments with limited resources such as laptops, desktops or your own cloud infrastructure, democratizing access to state of the art AI models and helping foster innovation for everyone. This model is ready for commercial use.","order":60,"flag":0,"source":"public-provider-conf"},"vision":false},{"id":"gpt-3.5-turbo","name":"gpt-3.5-turbo","display_name":"gpt-3.5-turbo","type":"chat","context_length":0,"max_output_tokens":0,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"developer":"OpenAI","developerId":12,"providerId":1,"modelRatio":0.25,"cacheRatio":1,"completionRatio":3,"order":0,"flag":0,"source":"public-provider-conf"},"vision":false},{"id":"gpt-3.5-turbo-0125","name":"gpt-3.5-turbo","display_name":"gpt-3.5-turbo","type":"chat","context_length":0,"max_output_tokens":0,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"developer":"OpenAI","developerId":12,"providerId":1,"modelRatio":0.25,"cacheRatio":1,"completionRatio":3,"order":0,"flag":0,"source":"public-provider-conf"},"vision":false},{"id":"gpt-3.5-turbo-1106","name":"gpt-3.5-turbo","display_name":"gpt-3.5-turbo","type":"chat","context_length":0,"max_output_tokens":0,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"developer":"OpenAI","developerId":12,"providerId":1,"modelRatio":0.5,"cacheRatio":1,"completionRatio":2,"order":0,"flag":0,"source":"public-provider-conf"},"vision":false},{"id":"gpt-3.5-turbo-16k","name":"gpt-3.5-turbo","display_name":"gpt-3.5-turbo","type":"chat","context_length":0,"max_output_tokens":0,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"developer":"OpenAI","developerId":12,"providerId":1,"modelRatio":1.5,"cacheRatio":1,"completionRatio":1.333333333,"order":0,"flag":0,"source":"public-provider-conf"},"vision":false},{"id":"gpt-3.5-turbo-instruct","name":"gpt-3.5-turbo-instruct","display_name":"gpt-3.5-turbo-instruct","type":"chat","context_length":0,"max_output_tokens":0,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"developer":"OpenAI","developerId":12,"providerId":1,"modelRatio":0.75,"cacheRatio":1,"completionRatio":1.333333333,"order":0,"flag":0,"source":"public-provider-conf"},"vision":false},{"id":"gpt-4","name":"gpt-4","display_name":"gpt-4","type":"chat","context_length":0,"max_output_tokens":0,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"developer":"OpenAI","developerId":12,"providerId":1,"modelRatio":15,"cacheRatio":1,"completionRatio":2,"order":0,"flag":0,"source":"public-provider-conf"},"vision":false},{"id":"gpt-4-0125-preview","name":"gpt-4","display_name":"gpt-4","type":"chat","context_length":0,"max_output_tokens":0,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"developer":"OpenAI","developerId":12,"providerId":1,"modelRatio":5,"cacheRatio":1,"completionRatio":3,"order":0,"flag":0,"source":"public-provider-conf"},"vision":false},{"id":"gpt-4-0613","name":"gpt-4","display_name":"gpt-4","type":"chat","context_length":0,"max_output_tokens":0,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"developer":"OpenAI","developerId":12,"providerId":1,"modelRatio":15,"cacheRatio":1,"completionRatio":2,"order":0,"flag":0,"source":"public-provider-conf"},"vision":false},{"id":"gpt-4-1106-preview","name":"gpt-4","display_name":"gpt-4","type":"chat","context_length":0,"max_output_tokens":0,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"developer":"OpenAI","developerId":12,"providerId":1,"modelRatio":5,"cacheRatio":1,"completionRatio":3,"order":0,"flag":0,"source":"public-provider-conf"},"vision":false},{"id":"gpt-4-32k","name":"gpt-4-32k","display_name":"gpt-4-32k","type":"chat","context_length":0,"max_output_tokens":0,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"developer":"OpenAI","developerId":12,"providerId":1,"modelRatio":30,"cacheRatio":1,"completionRatio":2,"description":"gpt-4openai32kazure openai","descriptionEn":"The smartest version of GPT-4; OpenAI no longer offers it officially. All the 32k versions on this site are provided by Microsoft, deployed on Azure OpenAI by the official Microsoft service.","order":10,"flag":0,"source":"public-provider-conf"},"vision":false},{"id":"gpt-4-turbo","name":"gpt-4-turbo","display_name":"gpt-4-turbo","type":"chat","context_length":0,"max_output_tokens":0,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"developer":"OpenAI","developerId":12,"providerId":1,"modelRatio":5,"cacheRatio":1,"completionRatio":3,"order":0,"flag":0,"source":"public-provider-conf"},"vision":false},{"id":"gpt-4-turbo-2024-04-09","name":"gpt-4-turbo","display_name":"gpt-4-turbo","type":"chat","context_length":0,"max_output_tokens":0,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"developer":"OpenAI","developerId":12,"providerId":1,"modelRatio":5,"cacheRatio":1,"completionRatio":3,"order":0,"flag":0,"source":"public-provider-conf"},"vision":false},{"id":"gpt-4-turbo-preview","name":"gpt-4-turbo","display_name":"gpt-4-turbo","type":"chat","context_length":0,"max_output_tokens":0,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"developer":"OpenAI","developerId":12,"providerId":1,"modelRatio":5,"cacheRatio":1,"completionRatio":3,"order":0,"flag":0,"source":"public-provider-conf"},"vision":false},{"id":"gpt-4.1","name":"gpt-4.1","display_name":"gpt-4.1","type":"chat","context_length":1050000,"max_output_tokens":1050000,"capabilities":{"vision":true,"function_calling":true,"reasoning":false,"tool_calling":true},"reasoning":false,"tool_call":true,"modalities":{"input":["text","image"],"output":["text","image"]},"metadata":{"developer":"OpenAI","developerId":12,"providerId":1,"modelRatio":1,"cacheRatio":0.25,"completionRatio":4,"description":" token SWE-bench 54.6%Scale AI 38.3% GPT-4o 26% 75%\n\n","descriptionEn":"The latest flagship multimodal model supports million-token context, with encoding capability (SWE-bench 54.6%) and instruction-following (Scale AI 38.3%) performance significantly surpassing GPT-4o, while reducing costs by 26%, making it suitable for complex tasks. Its automatic caching mechanism offers a 75% cost reduction on cache hits.","order":800,"flag":2,"billingConfig":"{\"model_name\": \"gpt-4.1\", \"default_tier\": \"tier1\", \"enabled_billing_items\": [\"prompt_tokens\", \"completion_tokens\", \"cached_tokens\", \"image_generation\", \"web_search_requests\"], \"per_unit_price_config\": {\"web_search_price\": 0.025}, \"token_based_tier_configs\": {\"tier1\": {\"model_ratio\": 1.0, \"tier_condition\": {\"max_tokens\": -1, \"min_tokens\": 0}, \"cached_tokens_ratio\": 0.25, \"prompt_tokens_ratio\": 1.0, \"completion_tokens_ratio\": 4.0}}}","features":["tools","function_calling","structured_outputs","long_context"],"tags":["best"],"modalities":["text","image"],"typeHints":["t2t"],"source":"public-provider-conf"},"vision":true},{"id":"gpt-4.1-mini","name":"gpt-4.1-mini","display_name":"gpt-4.1-mini","type":"chat","context_length":1050000,"max_output_tokens":1050000,"capabilities":{"vision":true,"function_calling":true,"reasoning":false,"tool_calling":true},"reasoning":false,"tool_call":true,"modalities":{"input":["text","image"],"output":["text","image"]},"metadata":{"developer":"OpenAI","developerId":12,"providerId":1,"modelRatio":0.2,"cacheRatio":0.25,"completionRatio":4,"description":" token  83%   75%","descriptionEn":"Lightweight, high-performance model with million-token context and near-flagship-level encoding and image understanding capabilities, while reducing costs by 83%. It is suitable for rapid development and small to medium-sized applications. The automatic caching mechanism provides a 75% cost reduction on cache hits.","order":799,"flag":1,"billingConfig":"{\"model_name\": \"gpt-4.1-mini\", \"default_tier\": \"tier1\", \"enabled_billing_items\": [\"prompt_tokens\", \"completion_tokens\", \"cached_tokens\", \"image_generation\", \"web_search_requests\"], \"per_unit_price_config\": {\"web_search_price\": 0.025}, \"token_based_tier_configs\": {\"tier1\": {\"model_ratio\": 0.2, \"tier_condition\": {\"max_tokens\": -1, \"min_tokens\": 0}, \"cached_tokens_ratio\": 0.25, \"prompt_tokens_ratio\": 1.0, \"completion_tokens_ratio\": 4.0}}}","features":["tools","structured_outputs","function_calling","long_context"],"tags":["economical","lightning"],"modalities":["text","image"],"typeHints":["t2t"],"source":"public-provider-conf"},"vision":true},{"id":"gpt-4.1-nano","name":"gpt-4.1-nano","display_name":"gpt-4.1-nano","type":"chat","context_length":1050000,"max_output_tokens":1050000,"capabilities":{"vision":true,"function_calling":true,"reasoning":false,"tool_calling":true},"reasoning":false,"tool_call":true,"modalities":{"input":["text","image"],"output":["text","image"]},"metadata":{"developer":"OpenAI","developerId":12,"providerId":1,"modelRatio":0.05,"cacheRatio":0.25,"completionRatio":4,"description":" token  0.1 / token 75%","descriptionEn":"Ultra-lightweight model with million-token context, optimized for speed and low latency, costing only $0.10 per million input tokens. It is suitable for edge computing and real-time interaction. The automatic caching mechanism offers a 75% cost reduction on cache hits.","order":798,"flag":1,"billingConfig":"{\"model_name\": \"gpt-4.1-nano\", \"default_tier\": \"tier1\", \"enabled_billing_items\": [\"prompt_tokens\", \"completion_tokens\", \"cached_tokens\", \"image_generation\", \"web_search_requests\"], \"per_unit_price_config\": {\"web_search_price\": 0.01}, \"token_based_tier_configs\": {\"tier1\": {\"model_ratio\": 0.05, \"tier_condition\": {\"max_tokens\": -1, \"min_tokens\": 0}, \"cached_tokens_ratio\": 0.25, \"prompt_tokens_ratio\": 1.0, \"completion_tokens_ratio\": 4.0}}}","features":["tools","function_calling","structured_outputs","long_context"],"tags":["lightning"],"modalities":["text","image"],"typeHints":["t2t"],"source":"public-provider-conf"},"vision":true},{"id":"gpt-4o","name":"gpt-4o","display_name":"gpt-4o","type":"chat","context_length":128000,"max_output_tokens":128000,"capabilities":{"vision":true,"function_calling":true,"reasoning":false,"tool_calling":true},"reasoning":false,"tool_call":true,"modalities":{"input":["text","image"],"output":["text","image"]},"metadata":{"developer":"OpenAI","developerId":12,"providerId":1,"modelRatio":1.25,"cacheRatio":0.5,"completionRatio":4,"description":"openaigpt-4o-2024-08-06","descriptionEn":"The stable multimodal model from OpenAI, with the official designated version being gpt-4o-2024-08-06; our site supports the official automatic caching, and charges for hits on some parts will be automatically halved.","order":111,"flag":0,"billingConfig":"{\"model_name\": \"gpt-4o\", \"default_tier\": \"tier1\", \"enabled_billing_items\": [\"prompt_tokens\", \"completion_tokens\", \"cached_tokens\", \"image_generation\", \"web_search_requests\"], \"per_unit_price_config\": {\"web_search_price\": 0.025}, \"token_based_tier_configs\": {\"tier1\": {\"model_ratio\": 1.25, \"tier_condition\": {\"max_tokens\": -1, \"min_tokens\": 0}, \"cached_tokens_ratio\": 0.5, \"prompt_tokens_ratio\": 1.0, \"completion_tokens_ratio\": 4.0}}}","features":["tools","function_calling","structured_outputs"],"tags":["multi_modal","best"],"modalities":["text","image"],"typeHints":["t2t"],"source":"public-provider-conf"},"vision":true},{"id":"gpt-4o-2024-05-13","name":"gpt-4o","display_name":"gpt-4o","type":"chat","context_length":0,"max_output_tokens":0,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"developer":"OpenAI","developerId":12,"providerId":1,"modelRatio":2.5,"cacheRatio":1,"completionRatio":3,"order":0,"flag":0,"billingConfig":"{\"model_name\": \"gpt-4o-2024-05-13\", \"default_tier\": \"tier1\", \"enabled_billing_items\": [\"prompt_tokens\", \"completion_tokens\", \"cached_tokens\", \"image_generation\", \"web_search_requests\"], \"per_unit_price_config\": {\"web_search_price\": 0.025}, \"token_based_tier_configs\": {\"tier1\": {\"model_ratio\": 2.5, \"tier_condition\": {\"max_tokens\": -1, \"min_tokens\": 0}, \"cached_tokens_ratio\": 1.0, \"prompt_tokens_ratio\": 1.0, \"completion_tokens_ratio\": 3.0}}}","source":"public-provider-conf"},"vision":false},{"id":"gpt-4o-2024-08-06","name":"gpt-4o","display_name":"gpt-4o","type":"chat","context_length":0,"max_output_tokens":0,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"developer":"OpenAI","developerId":12,"providerId":1,"modelRatio":1.25,"cacheRatio":0.5,"completionRatio":4,"description":"","descriptionEn":"Supports caching, with automatic halving of charges upon a cache hit.","order":56,"flag":0,"source":"public-provider-conf"},"vision":false},{"id":"gpt-4o-2024-11-20","name":"gpt-4o","display_name":"gpt-4o","type":"chat","context_length":128000,"max_output_tokens":128000,"capabilities":{"vision":true,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"modalities":{"input":["text","image"],"output":["text","image"]},"metadata":{"developer":"OpenAI","developerId":12,"providerId":1,"modelRatio":1.25,"cacheRatio":0.5,"completionRatio":4,"description":"gpt-4o4o","descriptionEn":"The latest version of the GPT-4o model; it is recommended to use this version, as it is currently smarter than the regular 4o.","order":112,"flag":0,"tags":["multi_modal","best","bold"],"modalities":["text","image"],"typeHints":["t2t"],"source":"public-provider-conf"},"vision":true},{"id":"gpt-4o-audio-preview","name":"gpt-4o-audio-preview","display_name":"gpt-4o-audio-preview","type":"audio","context_length":0,"max_output_tokens":0,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"modalities":{"input":["text","audio"],"output":["text","audio"]},"metadata":{"developer":"OpenAI","developerId":12,"providerId":1,"modelRatio":1.25,"cacheRatio":1,"completionRatio":4,"description":"openaiopenai","descriptionEn":"OpenAI voice input and output model, with prices consistent with the official ones. For now, only the text portion prices are displayed; voice prices can be found on the official OpenAI website. Backend billing is the same as the official.","order":101,"flag":0,"displayInput":"$ 40 /M","displayOutput":"$ 80 /M","tags":["multi_modal","bold"],"modalities":["text","audio"],"typeHints":["t2t","tts"],"source":"public-provider-conf"},"vision":false},{"id":"gpt-4o-audio-preview-2024-10-01","name":"gpt-4o-audio-preview","display_name":"gpt-4o-audio-preview","type":"chat","context_length":0,"max_output_tokens":0,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"developer":"OpenAI","developerId":12,"providerId":1,"modelRatio":2,"cacheRatio":1,"completionRatio":2,"order":0,"flag":0,"source":"public-provider-conf"},"vision":false},{"id":"gpt-4o-image","name":"gpt-4o-image","display_name":"gpt-4o-image","type":"image-generation","context_length":0,"max_output_tokens":0,"capabilities":{"vision":true,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"modalities":{"input":["text","image"],"output":["text","image"]},"metadata":{"developer":"OpenAI","developerId":12,"providerId":1,"modelRatio":1.5,"cacheRatio":0,"completionRatio":1,"description":"GPT 4o Web 0.0050.04","descriptionEn":"First Taste of GPT-4o's Image Generation API: Perfectly mirrors the web version's raw image creation capabilities, supporting both text-to-image and image+text-to-image generation. Each creation costs as little as $0.005.","order":199,"flag":1,"displayInput":"-","displayOutput":"$0.005 / IMG","tags":["best","sota"],"modalities":["text","image"],"typeHints":["t2i"],"source":"public-provider-conf"},"vision":true},{"id":"gpt-4o-image-vip","name":"gpt-4o-image-vip","display_name":"gpt-4o-image-vip","type":"image-generation","context_length":0,"max_output_tokens":0,"capabilities":{"vision":true,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"modalities":{"input":["text","image"],"output":["text","image"]},"metadata":{"developer":"OpenAI","developerId":12,"providerId":1,"modelRatio":3.5,"cacheRatio":0,"completionRatio":1,"description":"GPT 4o Web 0.0090.06\n","descriptionEn":"First Taste of GPT-4o's Image Generation API: Perfectly mirrors the web version's raw image creation capabilities, supporting both text-to-image and image+text-to-image generation. Each creation costs as little as $0.009.","order":200,"flag":1,"displayInput":"-","displayOutput":"$0.009 / IMG","modalities":["text","image"],"typeHints":["t2i"],"source":"public-provider-conf"},"vision":true},{"id":"gpt-4o-mini","name":"gpt-4o-mini","display_name":"gpt-4o-mini","type":"chat","context_length":128000,"max_output_tokens":128000,"capabilities":{"vision":true,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"modalities":{"input":["text","image"],"output":["text","image"]},"metadata":{"developer":"OpenAI","developerId":12,"providerId":1,"modelRatio":0.075,"cacheRatio":0.5,"completionRatio":4,"description":"gpt-4o","descriptionEn":"The lightweight version of GPT-4o, which is affordable and fast, suitable for handling simple tasks; our site supports the official automatic caching for this model, and charges for cache hits will be automatically halved.","order":108,"flag":0,"billingConfig":"{\"model_name\": \"gpt-4o-mini\", \"default_tier\": \"tier1\", \"enabled_billing_items\": [\"prompt_tokens\", \"completion_tokens\", \"cached_tokens\", \"image_generation\", \"web_search_requests\"], \"per_unit_price_config\": {\"web_search_price\": 0.025}, \"token_based_tier_configs\": {\"tier1\": {\"model_ratio\": 0.075, \"tier_condition\": {\"max_tokens\": -1, \"min_tokens\": 0}, \"cached_tokens_ratio\": 0.5, \"prompt_tokens_ratio\": 1.0, \"completion_tokens_ratio\": 4.0}}}","tags":["multi_modal","best","economical","lightning"],"modalities":["text","image"],"typeHints":["t2t"],"source":"public-provider-conf"},"vision":true},{"id":"gpt-4o-mini-2024-07-18","name":"gpt-4o-mini","display_name":"gpt-4o-mini","type":"chat","context_length":0,"max_output_tokens":0,"capabilities":{"vision":true,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"modalities":{"input":["text","image"],"output":["text","image"]},"metadata":{"developer":"OpenAI","developerId":12,"providerId":1,"modelRatio":0.075,"cacheRatio":0.5,"completionRatio":4,"order":0,"flag":0,"tags":["multi_modal","economical","lightning"],"modalities":["text","image"],"typeHints":["t2t"],"source":"public-provider-conf"},"vision":true},{"id":"gpt-4o-mini-audio-preview","name":"gpt-4o-mini-audio-preview","display_name":"gpt-4o-mini-audio-preview","type":"audio","context_length":0,"max_output_tokens":0,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"modalities":{"input":["audio"],"output":["audio"]},"metadata":{"developer":"OpenAI","developerId":12,"providerId":1,"modelRatio":0.075,"cacheRatio":1,"completionRatio":4,"description":"openaiopenai","order":100,"flag":0,"modalities":["audio"],"typeHints":["tts"],"source":"public-provider-conf"},"vision":false},{"id":"gpt-4o-mini-search-preview","name":"gpt-4o-mini-search-preview","display_name":"gpt-4o-mini-search-preview","type":"chat","context_length":128000,"max_output_tokens":128000,"capabilities":{"vision":true,"function_calling":true,"reasoning":false,"tool_calling":true},"reasoning":false,"tool_call":true,"modalities":{"input":["text","image"],"output":["text","image"]},"metadata":{"developer":"OpenAI","developerId":12,"providerId":1,"modelRatio":0.075,"cacheRatio":0.5,"completionRatio":4,"description":" API ChatGPT \n\n web_search_preview  gpt-4o  gpt-4o-mini API\n\n\n\ngpt-4o-search-preview  \ngpt-4o-mini-search-preview  \n\n  \n```javascript\nimport OpenAI from \"openai\";  \nconst client = new OpenAI();  \n\nconst completion = await client.chat.completions.create({  \n    model: \"gpt-4o-search-preview\",  \n    web_search_options: {},  \n    messages: [{  \n        \"role\": \"user\",  \n        \"content\": \"\"  \n    }],  \n});  \n\nconsole.log(completion.choices[0].message.content); \n```\n\n   \n API \n\nmessage.content    \nannotations  URL    \n\n URL url_citation ","descriptionEn":"Using the Chat Completions API, you can directly access the fine-tuned models and tool used by Search in ChatGPT.\n\nWhen using Chat Completions, the model always retrieves information from the web before responding to your query. To use web_search_preview as a tool that models like gpt-4o and gpt-4o-mini invoke only when necessary, switch to using the Responses API.\n\nCurrently, you need to use one of these models to use web search in Chat Completions:\n\ngpt-4o-search-preview\ngpt-4o-mini-search-preview\nWeb search parameter example\nimport OpenAI from \"openai\";\nconst client = new OpenAI();\n\nconst completion = await client.chat.completions.create({\n    model: \"gpt-4o-search-preview\",\n    web_search_options: {},\n    messages: [{\n        \"role\": \"user\",\n        \"content\": \"What was a positive news story from today?\"\n    }],\n});\n\nconsole.log(completion.choices[0].message.content);\nOutput and citations\nThe API response item in the choices array will include:\n\nmessage.content with the text result from the model, inclusive of any inline citations\nannotations with a list of cited URLs\nBy default, the model's response will include inline citations for URLs found in the web search results. In addition to this, the url_citation annotation object will contain the URL and title of the cited source, as well as the start and end index characters in the model's response where those sources were used.","order":549,"flag":1,"features":["web","function_calling","structured_outputs"],"tags":["multi_modal","best"],"modalities":["text","image"],"typeHints":["t2t","search"],"source":"public-provider-conf"},"vision":true},{"id":"gpt-4o-mini-tts","name":"gpt-4o-mini-tts","display_name":"gpt-4o-mini-tts","type":"audio","context_length":0,"max_output_tokens":0,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"modalities":{"input":["audio"],"output":["audio"]},"metadata":{"developer":"OpenAI","developerId":12,"providerId":1,"modelRatio":7.5,"cacheRatio":1,"completionRatio":1,"description":"OpenAI  TTS tts-1/v1/audio/speech aihubmix ","descriptionEn":"OpenAIs latest TTS model, gpt-4o-mini-tts, uses the same API endpoint (/v1/audio/speech) as tts-1. However, OpenAI introduced a new pricing method without providing billing details via API, causing discrepancies between official pricing and aihubmixs chargessome requests may cost more, others less. Avoid using this model if precise billing accuracy is essential.","order":160,"flag":1,"displayInput":"$ 15 / M Tokens","displayOutput":"-","tags":["bold","lightning"],"modalities":["audio"],"typeHints":["tts"],"source":"public-provider-conf"},"vision":false},{"id":"gpt-4o-search-preview","name":"gpt-4o-search-preview","display_name":"gpt-4o-search-preview","type":"chat","context_length":128000,"max_output_tokens":128000,"capabilities":{"vision":true,"function_calling":true,"reasoning":false,"tool_calling":true},"reasoning":false,"tool_call":true,"modalities":{"input":["text","image"],"output":["text","image"]},"metadata":{"developer":"OpenAI","developerId":12,"providerId":1,"modelRatio":1.25,"cacheRatio":0.5,"completionRatio":4,"description":" API ChatGPT \n\n web_search_preview  gpt-4o  gpt-4o-mini API\n\n\n\ngpt-4o-search-preview  \ngpt-4o-mini-search-preview  \n\n  \n```javascript\nimport OpenAI from \"openai\";  \nconst client = new OpenAI();  \n\nconst completion = await client.chat.completions.create({  \n    model: \"gpt-4o-search-preview\",  \n    web_search_options: {},  \n    messages: [{  \n        \"role\": \"user\",  \n        \"content\": \"\"  \n    }],  \n});  \n\nconsole.log(completion.choices[0].message.content); \n```\n\n   \n API \n\nmessage.content    \nannotations  URL    \n\n URL url_citation ","descriptionEn":"Using the Chat Completions API, you can directly access the fine-tuned models and tool used by Search in ChatGPT.\n\nWhen using Chat Completions, the model always retrieves information from the web before responding to your query. To use web_search_preview as a tool that models like gpt-4o and gpt-4o-mini invoke only when necessary, switch to using the Responses API.\n\nCurrently, you need to use one of these models to use web search in Chat Completions:\n\ngpt-4o-search-preview\ngpt-4o-mini-search-preview\nWeb search parameter example\nimport OpenAI from \"openai\";\nconst client = new OpenAI();\n\nconst completion = await client.chat.completions.create({\n    model: \"gpt-4o-search-preview\",\n    web_search_options: {},\n    messages: [{\n        \"role\": \"user\",\n        \"content\": \"What was a positive news story from today?\"\n    }],\n});\n\nconsole.log(completion.choices[0].message.content);\nOutput and citations\nThe API response item in the choices array will include:\n\nmessage.content with the text result from the model, inclusive of any inline citations\nannotations with a list of cited URLs\nBy default, the model's response will include inline citations for URLs found in the web search results. In addition to this, the url_citation annotation object will contain the URL and title of the cited source, as well as the start and end index characters in the model's response where those sources were used.","order":550,"flag":1,"features":["web","function_calling","structured_outputs"],"tags":["multi_modal","best"],"modalities":["text","image"],"typeHints":["t2t","search"],"source":"public-provider-conf"},"vision":true},{"id":"gpt-5","name":"gpt-5","display_name":"gpt-5","type":"chat","context_length":0,"max_output_tokens":0,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"developer":"OpenAI","developerId":12,"providerId":1,"modelRatio":0.625,"cacheRatio":0.1,"completionRatio":8,"description":"GPT-5 OpenAI ","descriptionEn":"GPT-5 is OpenAI flagship model for coding, reasoning, and agentic tasks across domains.","order":971,"flag":1,"billingConfig":"{\"model_name\": \"gpt-5\", \"default_tier\": \"tier1\", \"enabled_billing_items\": [\"prompt_tokens\", \"completion_tokens\", \"cached_tokens\", \"image_generation\", \"web_search_requests\"], \"per_unit_price_config\": {\"web_search_price\": 0.01}, \"token_based_tier_configs\": {\"tier1\": {\"model_ratio\": 0.625, \"tier_condition\": {\"max_tokens\": -1, \"min_tokens\": 0}, \"cached_tokens_ratio\": 0.1, \"prompt_tokens_ratio\": 1.0, \"completion_tokens_ratio\": 8.0}}}","source":"public-provider-conf"},"vision":false},{"id":"gpt-5-chat-latest","name":"gpt-5-chat-latest","display_name":"gpt-5-chat-latest","type":"chat","context_length":0,"max_output_tokens":0,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"developer":"OpenAI","developerId":12,"providerId":1,"modelRatio":0.625,"cacheRatio":0.1,"completionRatio":8,"description":"GPT-5-chat ChatGPT  GPT-5 GPT-5 ","descriptionEn":"GPT-5 Chat points to the GPT-5 snapshot currently used in ChatGPT. GPT-5 is our next-generation, high-intelligence flagship model. It accepts both text and image inputs, and produces text outputs.","order":968,"flag":1,"source":"public-provider-conf"},"vision":false},{"id":"gpt-5-codex","name":"gpt-5-codex","display_name":"gpt-5-codex","type":"chat","context_length":0,"max_output_tokens":0,"capabilities":{"vision":false,"function_calling":false,"reasoning":true,"tool_calling":false},"reasoning":true,"tool_call":false,"metadata":{"developer":"OpenAI","developerId":12,"providerId":1,"modelRatio":0.625,"cacheRatio":0.1,"completionRatio":8,"description":"GPT-5-Codex  GPT-5  Codex  Responses API https://docs.aihubmix.com/cn/api/Responses-API","descriptionEn":"GPT-5-Codex is a version of GPT-5 optimized for agentic coding tasks in Codex or similar environments. It's available in the Responses API only and the underlying model snapshot will be regularly updated. If you want to learn more abouthttps://docs.aihubmix.com/en/api/Responses-API","order":973,"flag":1,"features":["thinking"],"source":"public-provider-conf"},"vision":false},{"id":"gpt-5-mini","name":"gpt-5-mini","display_name":"gpt-5-mini","type":"chat","context_length":0,"max_output_tokens":0,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"developer":"OpenAI","developerId":12,"providerId":1,"modelRatio":0.125,"cacheRatio":0.1,"completionRatio":8,"description":"GPT-5 mini  GPT-5 ","descriptionEn":"GPT-5 mini is a faster, more cost-efficient version of GPT-5. It's great for well-defined tasks and precise prompts. ","order":970,"flag":1,"billingConfig":"{\"model_name\": \"gpt-5-mini\", \"default_tier\": \"tier1\", \"enabled_billing_items\": [\"prompt_tokens\", \"completion_tokens\", \"cached_tokens\", \"image_generation\", \"web_search_requests\"], \"per_unit_price_config\": {\"web_search_price\": 0.01}, \"token_based_tier_configs\": {\"tier1\": {\"model_ratio\": 0.125, \"tier_condition\": {\"max_tokens\": -1, \"min_tokens\": 0}, \"cached_tokens_ratio\": 0.1, \"prompt_tokens_ratio\": 1.0, \"completion_tokens_ratio\": 8.0}}}","source":"public-provider-conf"},"vision":false},{"id":"gpt-5-nano","name":"gpt-5-nano","display_name":"gpt-5-nano","type":"chat","context_length":0,"max_output_tokens":0,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"developer":"OpenAI","developerId":12,"providerId":1,"modelRatio":0.025,"cacheRatio":0.1,"completionRatio":8,"description":"GPT-5 NanoGPT-5","descriptionEn":"GPT-5 Nano is our fastest, cheapest version of GPT-5. It's great for summarization and classification tasks.","order":969,"flag":1,"billingConfig":"{\"model_name\": \"gpt-5-nano\", \"default_tier\": \"tier1\", \"enabled_billing_items\": [\"prompt_tokens\", \"completion_tokens\", \"cached_tokens\", \"image_generation\", \"web_search_requests\"], \"per_unit_price_config\": {\"web_search_price\": 0.01}, \"token_based_tier_configs\": {\"tier1\": {\"model_ratio\": 0.025, \"tier_condition\": {\"max_tokens\": -1, \"min_tokens\": 0}, \"cached_tokens_ratio\": 0.1, \"prompt_tokens_ratio\": 1.0, \"completion_tokens_ratio\": 8.0}}}","source":"public-provider-conf"},"vision":false},{"id":"gpt-image-1","name":"gpt-image-1","display_name":"gpt-image-1","type":"image-generation","context_length":0,"max_output_tokens":0,"capabilities":{"vision":true,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"modalities":{"input":["text","image"],"output":["text","image"]},"metadata":{"developer":"OpenAI","developerId":12,"providerId":1,"modelRatio":2.5,"cacheRatio":1,"completionRatio":8,"description":"OpenAI  gpt-image-1generateedit\n pip install -U openai  openai \n\n","descriptionEn":"Azure OpenAIs gpt-image-1 image generation API offers both text-to-image generation and image-to-image editing with text guidance capabilities.\nBefore using this API, please ensure you have the latest OpenAI package installed by running pip install -U openai.","order":812,"flag":2,"displayInput":" $ 5 /M (text)","displayOutput":" $ 0.6 / IMG (high quality) ","tags":["sota"],"modalities":["text","image"],"typeHints":["t2i"],"source":"public-provider-conf"},"vision":true},{"id":"gpt-oss-120b","name":"gpt-oss-120b","display_name":"gpt-oss-120b","type":"chat","context_length":0,"max_output_tokens":0,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"developer":"OpenAI","developerId":12,"providerId":8,"modelRatio":0.09,"cacheRatio":1,"completionRatio":5,"description":"azure gpt-oss-120b\n","descriptionEn":"The model gpt-oss-120b provided by Azure deployment.","order":400,"flag":1,"source":"public-provider-conf"},"vision":false},{"id":"grok-3","name":"grok-3","display_name":"grok-3","type":"chat","context_length":0,"max_output_tokens":0,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"developer":"Grok","developerId":9,"providerId":46,"modelRatio":1.5,"cacheRatio":1,"completionRatio":5,"description":"grok","descriptionEn":"Grok's latest model","order":46,"flag":1,"source":"public-provider-conf"},"vision":false},{"id":"grok-3-mini","name":"grok-3-mini","display_name":"grok-3-mini","type":"chat","context_length":0,"max_output_tokens":0,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"developer":"Grok","developerId":9,"providerId":46,"modelRatio":0.15,"cacheRatio":0,"completionRatio":1.67,"order":43,"flag":0,"source":"public-provider-conf"},"vision":false},{"id":"grok-4","name":"grok-4","display_name":"grok-4","type":"chat","context_length":0,"max_output_tokens":0,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"developer":"Grok","developerId":9,"providerId":46,"modelRatio":1.65,"cacheRatio":0.25,"completionRatio":5,"description":"Grok\ngrok-4-0709 10% ","descriptionEn":"Grok, their latest and greatest flagship model, offers unparalleled performance in natural language, math, and reasoning  the perfect jack of all trades.\nThe current pointing model version is grok-4-0709.","order":800,"flag":1,"source":"public-provider-conf"},"vision":false},{"id":"grok-4-fast-non-reasoning","name":"grok-4-fast-non-reasoning","display_name":"grok-4-fast-non-reasoning","type":"chat","context_length":0,"max_output_tokens":0,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"developer":"Grok","developerId":9,"providerId":29,"modelRatio":0.1,"cacheRatio":0.25,"completionRatio":2.5,"description":"Grok-4-fast  xAI token200tokenWebXGrok 440%token98%","descriptionEn":"Grok-4-fast is a cost-effective inference model developed by xAI that delivers cutting-edge performance with excellent token efficiency. The model features a 2 million token context window, advanced Web and X search capabilities, and a unified architecture supporting both \"inference\" and \"non-inference\" modes. Compared to Grok 4, it reduces thinking tokens by an average of 40% and lowers the price by 98% while achieving the same performance.","order":800,"flag":1,"source":"public-provider-conf"},"vision":false},{"id":"grok-4-fast-reasoning","name":"grok-4-fast-reasoning","display_name":"grok-4-fast-reasoning","type":"chat","context_length":0,"max_output_tokens":0,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"developer":"Grok","developerId":9,"providerId":29,"modelRatio":0.1,"cacheRatio":0.25,"completionRatio":2.5,"description":"Grok-4-fast  xAI token200tokenWebXGrok 440%token98%","descriptionEn":"Grok-4-fast is a cost-effective inference model developed by xAI that delivers cutting-edge performance with excellent token efficiency. The model features a 2 million token context window, advanced Web and X search capabilities, and a unified architecture supporting both \"inference\" and \"non-inference\" modes. Compared to Grok 4, it reduces thinking tokens by an average of 40% and lowers the price by 98% while achieving the same performance.","order":800,"flag":1,"source":"public-provider-conf"},"vision":false},{"id":"grok-code-fast-1","name":"grok-code-fast-1","display_name":"grok-code-fast-1","type":"chat","context_length":0,"max_output_tokens":0,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"developer":"Grok","developerId":9,"providerId":8,"modelRatio":0.1,"cacheRatio":0.1,"completionRatio":7.5,"description":" grok-code-fast-1","descriptionEn":"We're thrilled to introduce grok-code-fast-1, a speedy and economical reasoning model that excels at agentic coding.","order":850,"flag":1,"source":"public-provider-conf"},"vision":false},{"id":"gte-rerank-v2","name":"gte-rerank-v2","display_name":"gte-rerank-v2","type":"chat","context_length":0,"max_output_tokens":0,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"developer":"Qwen","developerId":13,"providerId":17,"modelRatio":0.055,"cacheRatio":1,"completionRatio":1,"description":"gte-rerank-v2RAG(Query)(documents)","descriptionEn":"gte-rerank-v2 is a multilingual unified text ranking model developed by Tongyi Laboratory, serving multiple mainstream global languages and providing high-level text ranking services. It is commonly used in scenarios such as semantic retrieval and RAG, enabling simple and effective improvement of text search results. Given a query and a series of candidate documents, the model ranks the candidate texts from highest to lowest based on their semantic relevance to the query.","order":600,"flag":0,"source":"public-provider-conf"},"vision":false},{"id":"imagen-3.0-generate-002","name":"imagen-3.0-generate-002","display_name":"imagen-3.0-generate-002","type":"image-generation","context_length":0,"max_output_tokens":0,"capabilities":{"vision":true,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"modalities":{"input":["text","image"],"output":["text","image"]},"metadata":{"developer":"Google","developerId":8,"providerId":24,"modelRatio":1,"cacheRatio":0,"completionRatio":1,"description":"Google Imagen 3.0 ","descriptionEn":"Imagen 3.0 is Google's latest text-to-image generation model, capable of creating high-quality images from natural language prompts. Compared to its predecessors, Imagen 3.0 offers significant improvements in detail, lighting, and reduced visual artifacts. It supports rendering in various artistic styles, from photorealism to impressionism, as well as abstract and anime styles.","order":701,"flag":1,"displayInput":"-","displayOutput":"$0.03 / IMG","tags":["multi_modal"],"modalities":["text","image"],"typeHints":["t2i"],"source":"public-provider-conf"},"vision":true},{"id":"imagen-4.0-fast-generate-001","name":"imagen-4.0-fast-generate-001","display_name":"imagen-4.0-fast-generate-001","type":"image-generation","context_length":0,"max_output_tokens":0,"capabilities":{"vision":true,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"modalities":{"input":["text","image"],"output":["text","image"]},"metadata":{"developer":"Google","developerId":8,"providerId":42,"modelRatio":1,"cacheRatio":1,"completionRatio":1,"description":"Imagen-4.0 ","order":815,"flag":1,"displayOutput":"$0.02 / IMG","imagePriceConfig":"{\"generate\":{\"standard\":{\"standard\":0.02}}} ","modalities":["text","image"],"typeHints":["t2i"],"source":"public-provider-conf"},"vision":true},{"id":"imagen-4.0-generate-001","name":"imagen-4.0-generate-001","display_name":"imagen-4.0-generate-001","type":"image-generation","context_length":0,"max_output_tokens":0,"capabilities":{"vision":true,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"modalities":{"input":["text","image"],"output":["text","image"]},"metadata":{"developer":"Google","developerId":8,"providerId":42,"modelRatio":1,"cacheRatio":1,"completionRatio":1,"order":815,"flag":1,"displayOutput":"$0.04 / IMG","imagePriceConfig":"{\"generate\":{\"standard\":{\"standard\":0.04}}}","modalities":["text","image"],"typeHints":["t2i"],"source":"public-provider-conf"},"vision":true},{"id":"imagen-4.0-generate-preview-05-20","name":"imagen-4.0-generate-preview-05-20","display_name":"imagen-4.0-generate-preview-05-20","type":"image-generation","context_length":0,"max_output_tokens":0,"capabilities":{"vision":true,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"modalities":{"input":["text","image"],"output":["text","image"]},"metadata":{"developer":"Google","developerId":8,"providerId":24,"modelRatio":1,"cacheRatio":0,"completionRatio":1,"description":"","descriptionEn":"Google's latest raw image model","order":0,"flag":1,"displayInput":"-","displayOutput":"$0.04 / IMG","tags":["multi_modal"],"modalities":["text","image"],"typeHints":["t2i"],"source":"public-provider-conf"},"vision":true},{"id":"imagen-4.0-generate-preview-06-06","name":"imagen-4.0-generate-preview-06-06","display_name":"imagen-4.0-generate-preview-06-06","type":"image-generation","context_length":0,"max_output_tokens":0,"capabilities":{"vision":true,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"modalities":{"input":["text","image"],"output":["text","image"]},"metadata":{"developer":"Google","developerId":8,"providerId":42,"modelRatio":1,"cacheRatio":0,"completionRatio":1,"description":"Imagen-4.0 ","order":815,"flag":1,"displayInput":"-","displayOutput":"$0.04 / IMG","modalities":["text","image"],"typeHints":["t2i"],"source":"public-provider-conf"},"vision":true},{"id":"imagen-4.0-ultra-generate-001","name":"imagen-4.0-ultra-generate-001","display_name":"imagen-4.0-ultra-generate-001","type":"image-generation","context_length":0,"max_output_tokens":0,"capabilities":{"vision":true,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"modalities":{"input":["text","image"],"output":["text","image"]},"metadata":{"developer":"Google","developerId":8,"providerId":42,"modelRatio":1,"cacheRatio":1,"completionRatio":1,"description":"Imagen-4.0 ","order":815,"flag":1,"displayOutput":"$0.06 / IMG","imagePriceConfig":"{\"generate\":{\"standard\":{\"standard\":0.06}}}","modalities":["text","image"],"typeHints":["t2i"],"source":"public-provider-conf"},"vision":true},{"id":"imagen-4.0-ultra-generate-exp-05-20","name":"imagen-4.0-ultra-generate-exp-05-20","display_name":"imagen-4.0-ultra-generate-exp-05-20","type":"image-generation","context_length":0,"max_output_tokens":0,"capabilities":{"vision":true,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"modalities":{"input":["text","image"],"output":["text","image"]},"metadata":{"developer":"Google","developerId":8,"providerId":24,"modelRatio":1,"cacheRatio":0,"completionRatio":1,"description":"imagen 4.0  imagen-4.0-generate-preview-05-20","descriptionEn":"Image 4.0 Beta version, for testing purposes only. For production environment, it is recommended to use imagen-4.0-generate-preview-05-20.","order":700,"flag":1,"displayInput":"-","displayOutput":"$0.06 / IMG","tags":["multi_modal"],"modalities":["text","image"],"typeHints":["t2i"],"source":"public-provider-conf"},"vision":true},{"id":"imagen-4.0-ultra-generate-preview-06-06","name":"imagen-4.0-ultra-generate-preview-06-06","display_name":"imagen-4.0-ultra-generate-preview-06-06","type":"image-generation","context_length":0,"max_output_tokens":0,"capabilities":{"vision":true,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"modalities":{"input":["text","image"],"output":["text","image"]},"metadata":{"developer":"Google","developerId":8,"providerId":42,"modelRatio":1,"cacheRatio":0,"completionRatio":1,"description":"Imagen-4.0 Ultra ","order":814,"flag":1,"displayInput":"-","displayOutput":"$0.06 / IMG","modalities":["text","image"],"typeHints":["t2i"],"source":"public-provider-conf"},"vision":true},{"id":"inclusionAI/Ling-flash-2.0","name":"inclusionAI/Ling-flash-2.0","display_name":"inclusionAI/Ling-flash-2.0","type":"chat","context_length":0,"max_output_tokens":0,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"developer":"Qwen","developerId":13,"providerId":8,"modelRatio":0.068,"cacheRatio":1,"completionRatio":4,"description":"Ling-flash-2.0  inclusionAI 10006.14.8 Ling 2.0 MoE400 MoE ","descriptionEn":"Ling-flash-2.0 is a language model from inclusionAI with a total of 100 billion parameters, of which 6.1 billion are activated per token (4.8 billion non-embedding). As part of the Ling 2.0 architecture series, it is designed as a lightweight yet powerful Mixture-of-Experts (MoE) model. It aims to deliver performance comparable to or even exceeding that of 40B-level dense models and other larger MoE models, but with a significantly smaller active parameter count. The model represents a strategy focused on achieving high performance and efficiency through extreme architectural design and training methods.","order":600,"flag":0,"source":"public-provider-conf"},"vision":false},{"id":"inclusionAI/Ling-mini-2.0","name":"inclusionAI/Ling-mini-2.0","display_name":"inclusionAI/Ling-mini-2.0","type":"chat","context_length":0,"max_output_tokens":0,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"developer":"Qwen","developerId":13,"providerId":8,"modelRatio":0.034,"cacheRatio":1,"completionRatio":4,"description":"Ling-mini-2.0  MoE   16B  token  1.4Bnon-embedding 789M MoE  1.4BLing-mini-2.0  10B  dense LLM  MoE ","descriptionEn":"Ling-mini-2.0 is a small-sized, high-performance large language model based on the MoE architecture. It has a total of 16 billion parameters, but only activates 1.4 billion parameters per token (non-embedding 789 million), achieving extremely high generation speed. Thanks to the efficient MoE design and large-scale high-quality training data, despite activating only 1.4 billion parameters, Ling-mini-2.0 still demonstrates top-tier performance on downstream tasks comparable to dense LLMs under 10 billion parameters and even larger-scale MoE models.","order":600,"flag":0,"source":"public-provider-conf"},"vision":false},{"id":"irag-1.0","name":"irag-1.0","display_name":"irag-1.0","type":"image-generation","context_length":0,"max_output_tokens":0,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"developer":"Baidu","developerId":25,"providerId":15,"modelRatio":1,"cacheRatio":0,"completionRatio":0,"description":"ERNIE iRAGERNIE image based RAGAIERNIE iRAG","descriptionEn":"Baidu's self-developed ERNIE iRAG (ERNIE image-based RAG), a retrieval-augmented text-to-image technology, combines Baidu Search's hundreds of millions of image resources with powerful foundational model capabilities to generate various ultra-realistic images. The overall effect far surpasses native text-to-image systems, eliminating the typical AI feel while maintaining low costs. ERNIE iRAG features no hallucinations, ultra-realism, and instant usability.","order":600,"flag":0,"imagePriceConfig":"{\"generate\":{\"standard\":{\"standard\":0.019}}}","typeHints":["t2i"],"source":"public-provider-conf"},"vision":false},{"id":"jina-colbert-v2","name":"jina-colbert-v2","display_name":"jina-colbert-v2","type":"embedding","context_length":8000,"max_output_tokens":8000,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"modalities":{"input":["text"],"output":["text"]},"metadata":{"developer":"Jina AI","developerId":22,"providerId":50,"modelRatio":0.025,"cacheRatio":1,"completionRatio":1,"description":" ColBERT 560M ","descriptionEn":"Multi-language ColBERT embeddings model, 560M parameters, used for embedding and reranking.","order":555,"flag":1,"modalities":["text"],"typeHints":["embedding","reranking"],"source":"public-provider-conf"},"vision":false},{"id":"jina-deepsearch-v1","name":"jina-deepsearch-v1","display_name":"jina-deepsearch-v1","type":"chat","context_length":1000000,"max_output_tokens":1000000,"capabilities":{"vision":true,"function_calling":false,"reasoning":true,"tool_calling":false},"reasoning":true,"tool_call":false,"modalities":{"input":["text","image"],"output":["text","image"]},"metadata":{"developer":"Jina AI","developerId":22,"providerId":50,"modelRatio":0.025,"cacheRatio":1,"completionRatio":1,"description":"DeepSearch DeepSearch  OpenAI  Chat API  1 M Tokens\n (stream) ","descriptionEn":"DeepSearch combines search, reading, and reasoning capabilities to pursue the best possible answer. It's fully compatible with OpenAI's Chat API formatjust replace api.openai.com with aihubmix.com to get started.  \nThe stream will return the thinking process.","order":600,"flag":1,"features":["thinking","web","deepsearch"],"tags":["best"],"modalities":["text","image"],"typeHints":["t2t","search"],"source":"public-provider-conf"},"vision":true},{"id":"jina-embeddings-v2-base-code","name":"jina-embeddings-v2-base-code","display_name":"jina-embeddings-v2-base-code","type":"embedding","context_length":8000,"max_output_tokens":8000,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"modalities":{"input":["text"],"output":["text"]},"metadata":{"developer":"Jina AI","developerId":22,"providerId":50,"modelRatio":0.025,"cacheRatio":1,"completionRatio":1,"description":"768 137M ","descriptionEn":"Model optimized for code and document search, 768-dimensional, 137M parameters.","order":0,"flag":0,"modalities":["text"],"typeHints":["embedding"],"source":"public-provider-conf"},"vision":false},{"id":"jina-embeddings-v3","name":"jina-embeddings-v3","display_name":"jina-embeddings-v3","type":"embedding","context_length":8000,"max_output_tokens":8000,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"modalities":{"input":["text"],"output":["text"]},"metadata":{"developer":"Jina AI","developerId":22,"providerId":50,"modelRatio":0.025,"cacheRatio":0,"completionRatio":1,"description":"1024 570M ","descriptionEn":"Text Embeddings Model, multilingual, 1024-dimensional, 570M parameters.","order":545,"flag":1,"tags":["best"],"modalities":["text"],"typeHints":["embedding"],"source":"public-provider-conf"},"vision":false},{"id":"jina-embeddings-v4","name":"jina-embeddings-v4","display_name":"jina-embeddings-v4","type":"embedding","context_length":0,"max_output_tokens":0,"capabilities":{"vision":true,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"modalities":{"input":["text","image"],"output":["text","image"]},"metadata":{"developer":"Jina AI","developerId":22,"providerId":50,"modelRatio":0.025,"cacheRatio":1,"completionRatio":1,"description":"38  (embedding model) (embedding) ","descriptionEn":"A general-purpose vector model with 3.8 billion parameters, used for multimodal and multilingual retrieval, supporting both unidirectional and multi-vector embedding outputs.","order":600,"flag":1,"tags":["multi_modal","best"],"modalities":["text","image"],"typeHints":["embedding"],"source":"public-provider-conf"},"vision":true},{"id":"jina-reranker-m0","name":"jina-reranker-m0","display_name":"jina-reranker-m0","type":"chat","context_length":10000,"max_output_tokens":10000,"capabilities":{"vision":true,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"modalities":{"input":["text","image"],"output":["text","image"]},"metadata":{"developer":"Jina AI","developerId":22,"providerId":50,"modelRatio":0.025,"cacheRatio":1,"completionRatio":1,"description":"10K Tokens 2.4B ","descriptionEn":"Multimodal multilingual document reranker, 10K context, 2.4B parameters, for visual document sorting.","order":558,"flag":1,"tags":["multi_modal","best"],"modalities":["text","image"],"typeHints":["reranking"],"source":"public-provider-conf"},"vision":true},{"id":"kimi-k2-0711-preview","name":"kimi-k2-0711-preview","display_name":"kimi-k2-0711-preview","type":"chat","context_length":0,"max_output_tokens":0,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"developer":"Moonshot AI","developerId":15,"providerId":25,"modelRatio":0.31,"cacheRatio":0,"completionRatio":4,"description":"kimi-k2  Agent  MoE  1T 32BAgent K2 ","descriptionEn":"kimi-k2 is a MoE architecture foundation model with powerful coding and Agent capabilities, having a total of 1 trillion parameters and 32 billion active parameters. In benchmark performance tests across major categories such as general knowledge reasoning, programming, mathematics, and Agent tasks, the K2 model outperforms other mainstream open-source models.","order":800,"flag":0,"source":"public-provider-conf"},"vision":false},{"id":"kimi-k2-0905-preview","name":"kimi-k2-0905-preview","display_name":"kimi-k2-0905-preview","type":"chat","context_length":0,"max_output_tokens":0,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"developer":"Moonshot AI","developerId":15,"providerId":25,"modelRatio":0.274,"cacheRatio":0.25,"completionRatio":4,"description":"kimi-k2  Agent  MoE  1T 32BAgent K2 \nkimi-k2-0905-preview  256k Agentic Coding ","descriptionEn":"kimi-k2 is a MoE architecture base model with exceptionally strong coding and agent capabilities, containing a total of 1 trillion parameters and 32 billion activated parameters. In benchmark performance tests across key categories such as general knowledge reasoning, programming, mathematics, and agents, the K2 model outperforms other mainstream open-source models.\nThe kimi-k2-0905-preview model features a context length of 256k and offers enhanced agentic coding abilities, improved aesthetics and practicality of front-end code, as well as better context understanding capabilities.","order":800,"flag":0,"source":"public-provider-conf"},"vision":false},{"id":"kimi-k2-turbo-preview","name":"kimi-k2-turbo-preview","display_name":"kimi-k2-turbo-preview","type":"chat","context_length":0,"max_output_tokens":0,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"developer":"Moonshot AI","developerId":15,"providerId":25,"modelRatio":0.6,"cacheRatio":0.25,"completionRatio":4,"description":"kimi-k2-turbo-preview  kimi-k2  kimi-k2  10 Tokens  40 Tokens\n","descriptionEn":"The kimi-k2-turbo-preview model is a high-speed version of kimi-k2, with the same model parameters as kimi-k2, but the output speed has been increased from 10 tokens per second to 40 tokens per second.","order":800,"flag":1,"source":"public-provider-conf"},"vision":false},{"id":"kimi-latest","name":"kimi-latest","display_name":"kimi-latest","type":"chat","context_length":0,"max_output_tokens":0,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"developer":"Moonshot AI","developerId":15,"providerId":25,"modelRatio":2,"cacheRatio":1,"completionRatio":1,"description":"8k,32k,128k332k","descriptionEn":"The official billing is tiered based on input lengths of 8k, 32k, and 128k. This site does not support that billing structure and uses the middle 32k tier as the standard for charging. If you are price-sensitive, please avoid using it.","order":199,"flag":1,"source":"public-provider-conf"},"vision":false},{"id":"kimi-thinking-preview","name":"kimi-thinking-preview","display_name":"kimi-thinking-preview","type":"chat","context_length":0,"max_output_tokens":0,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"developer":"Moonshot AI","developerId":15,"providerId":25,"modelRatio":15,"cacheRatio":1,"completionRatio":1,"description":"kimi","descriptionEn":"The latest kimi model.","order":60,"flag":1,"source":"public-provider-conf"},"vision":false},{"id":"learnlm-1.5-pro-experimental","name":"Gemini 1.5 Pro","display_name":"Gemini 1.5 Pro","type":"chat","context_length":0,"max_output_tokens":0,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"developer":"Google","developerId":8,"providerId":24,"modelRatio":0.625,"cacheRatio":1,"completionRatio":4,"order":0,"flag":0,"source":"public-provider-conf"},"vision":false},{"id":"llama-3.1-8b-instant","name":"llama-3.1-8b","display_name":"llama-3.1-8b","type":"chat","context_length":0,"max_output_tokens":0,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"developer":"Llama","developerId":11,"providerId":29,"modelRatio":0.15,"cacheRatio":1,"completionRatio":2,"order":0,"flag":0,"source":"public-provider-conf"},"vision":false},{"id":"llama-3.3-70b","name":"llama-3.3-70b","display_name":"llama-3.3-70b","type":"chat","context_length":0,"max_output_tokens":0,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"developer":"Llama","developerId":11,"providerId":8,"modelRatio":0.3,"cacheRatio":1,"completionRatio":1,"description":"cerebras","descriptionEn":"cerebras","order":50,"flag":0,"source":"public-provider-conf"},"vision":false},{"id":"llama-3.3-70b-versatile","name":"llama-3.3-70b","display_name":"llama-3.3-70b","type":"chat","context_length":0,"max_output_tokens":0,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"developer":"Meta","developerId":11,"providerId":29,"modelRatio":0.3,"cacheRatio":1,"completionRatio":1,"order":0,"flag":0,"source":"public-provider-conf"},"vision":false},{"id":"llama-4-maverick-17b-128e-instruct","name":"llama-4-maverick-17b-128e-instruct","display_name":"llama-4-maverick-17b-128e-instruct","type":"chat","context_length":0,"max_output_tokens":0,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"developer":"Llama","developerId":11,"providerId":8,"modelRatio":0.1,"cacheRatio":1,"completionRatio":1,"description":"cerebras","descriptionEn":"cerebras","order":1,"flag":0,"source":"public-provider-conf"},"vision":false},{"id":"llama-4-scout-17b-16e-instruct","name":"llama-4-scout-17b-16e-instruct","display_name":"llama-4-scout-17b-16e-instruct","type":"chat","context_length":0,"max_output_tokens":0,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"developer":"Llama","developerId":11,"providerId":8,"modelRatio":0.1,"cacheRatio":1,"completionRatio":1,"description":"cerebras","descriptionEn":"cerebras","order":1,"flag":1,"source":"public-provider-conf"},"vision":false},{"id":"llama3-70b-8192","name":"llama3-70b","display_name":"llama3-70b","type":"chat","context_length":0,"max_output_tokens":0,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"developer":"Meta","developerId":11,"providerId":29,"modelRatio":0.35,"cacheRatio":1,"completionRatio":1.338983051,"order":0,"flag":0,"source":"public-provider-conf"},"vision":false},{"id":"llama3-8b-8192","name":"llama3-8b","display_name":"llama3-8b","type":"chat","context_length":0,"max_output_tokens":0,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"developer":"Meta","developerId":11,"providerId":29,"modelRatio":0.03,"cacheRatio":1,"completionRatio":2,"order":0,"flag":0,"source":"public-provider-conf"},"vision":false},{"id":"llama3.1-8b","name":"llama3.1-8b","display_name":"llama3.1-8b","type":"chat","context_length":0,"max_output_tokens":0,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"developer":"Llama","developerId":11,"providerId":8,"modelRatio":0.15,"cacheRatio":1,"completionRatio":2,"description":"cerebras","descriptionEn":"cerebras","order":1,"flag":0,"source":"public-provider-conf"},"vision":false},{"id":"meta-llama-3-70b","name":"meta-llama-3-70b","display_name":"meta-llama-3-70b","type":"chat","context_length":0,"max_output_tokens":0,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"developer":"Meta","developerId":11,"providerId":24,"modelRatio":2.3975,"cacheRatio":1,"completionRatio":1,"order":0,"flag":0,"source":"public-provider-conf"},"vision":false},{"id":"meta-llama-3-8b","name":"meta-llama-3-8b","display_name":"meta-llama-3-8b","type":"chat","context_length":0,"max_output_tokens":0,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"developer":"Meta","developerId":11,"providerId":24,"modelRatio":0.274,"cacheRatio":1,"completionRatio":1,"order":0,"flag":0,"source":"public-provider-conf"},"vision":false},{"id":"meta-llama/llama-4-scout-17b-16e-instruct","name":"llama-4-scout","display_name":"llama-4-scout","type":"chat","context_length":0,"max_output_tokens":0,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"developer":"Llama","developerId":11,"providerId":29,"modelRatio":0.1,"cacheRatio":1,"completionRatio":1,"description":"groq","descriptionEn":"groq","order":54,"flag":0,"source":"public-provider-conf"},"vision":false},{"id":"moonshot-v1-128k","name":"moonshot-v1-128k","display_name":"moonshot-v1-128k","type":"chat","context_length":0,"max_output_tokens":0,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"developer":"Moonshot AI","developerId":15,"providerId":25,"modelRatio":5,"cacheRatio":1,"completionRatio":1,"order":0,"flag":0,"source":"public-provider-conf"},"vision":false},{"id":"moonshot-v1-128k-vision-preview","name":"moonshot-v1-128k-vision-preview","display_name":"moonshot-v1-128k-vision-preview","type":"chat","context_length":0,"max_output_tokens":0,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"developer":"Moonshot AI","developerId":15,"providerId":25,"modelRatio":5,"cacheRatio":1,"completionRatio":1,"order":0,"flag":0,"source":"public-provider-conf"},"vision":false},{"id":"moonshot-v1-32k","name":"moonshot-v1-32k","display_name":"moonshot-v1-32k","type":"chat","context_length":0,"max_output_tokens":0,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"developer":"Moonshot AI","developerId":15,"providerId":25,"modelRatio":2,"cacheRatio":1,"completionRatio":1,"order":0,"flag":0,"source":"public-provider-conf"},"vision":false},{"id":"moonshot-v1-32k-vision-preview","name":"moonshot-v1-32k-vision-preview","display_name":"moonshot-v1-32k-vision-preview","type":"chat","context_length":0,"max_output_tokens":0,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"developer":"Moonshot AI","developerId":15,"providerId":25,"modelRatio":2,"cacheRatio":1,"completionRatio":1,"order":0,"flag":0,"source":"public-provider-conf"},"vision":false},{"id":"moonshot-v1-8k","name":"moonshot-v1-8k","display_name":"moonshot-v1-8k","type":"chat","context_length":0,"max_output_tokens":0,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"developer":"Moonshot AI","developerId":15,"providerId":25,"modelRatio":1,"cacheRatio":1,"completionRatio":1,"order":0,"flag":0,"source":"public-provider-conf"},"vision":false},{"id":"moonshot-v1-8k-vision-preview","name":"moonshot-v1-8k-vision-preview","display_name":"moonshot-v1-8k-vision-preview","type":"chat","context_length":0,"max_output_tokens":0,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"developer":"Moonshot AI","developerId":15,"providerId":25,"modelRatio":1,"cacheRatio":1,"completionRatio":1,"order":0,"flag":0,"source":"public-provider-conf"},"vision":false},{"id":"moonshotai/Kimi-Dev-72B","name":"moonshotai/Kimi-Dev-72B","display_name":"moonshotai/Kimi-Dev-72B","type":"chat","context_length":0,"max_output_tokens":0,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"developer":"Moonshot AI","developerId":15,"providerId":44,"modelRatio":0.16,"cacheRatio":0,"completionRatio":4,"description":"Kimi-Dev-72B  SWE-bench Verified  60.4%  Docker ","descriptionEn":"Kimi-Dev-72B is a new generation open-source programming large model that achieved a leading performance of 60.4% on SWE-bench Verified. Through large-scale reinforcement learning optimization, it can automatically fix code in real Docker environments, receiving rewards only when passing the complete test suite, thereby ensuring the correctness and robustness of solutions and aligning more closely with real software development standards.","order":100,"flag":1,"source":"public-provider-conf"},"vision":false},{"id":"moonshotai/Moonlight-16B-A3B-Instruct","name":"Moonlight-16B-A3B","display_name":"Moonlight-16B-A3B","type":"chat","context_length":0,"max_output_tokens":0,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"developer":"Moonshot AI","developerId":15,"providerId":8,"modelRatio":0.1,"cacheRatio":0,"completionRatio":1,"description":"chutes.ai","descriptionEn":"Provided by chutes.ai.","order":100,"flag":1,"source":"public-provider-conf"},"vision":false},{"id":"moonshotai/kimi-k2-instruct","name":"moonshotai/kimi-k2-instruct","display_name":"moonshotai/kimi-k2-instruct","type":"chat","context_length":0,"max_output_tokens":0,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"developer":"Moonshot AI","developerId":15,"providerId":8,"modelRatio":0.31,"cacheRatio":1,"completionRatio":4,"description":"Kimi K2  Moonshot AI MoE 1  320 ","descriptionEn":"Kimi K2 is Moonshot AI's state-of-the-art Mixture-of-Experts (MoE) language model with 1 trillion total parameters and 32 billion activated parameters. Designed for agentic intelligence, it excels at tool use, coding, and autonomous problem-solving across diverse domains.","order":845,"flag":0,"source":"public-provider-conf"},"vision":false},{"id":"nvidia/Llama-3_1-Nemotron-Ultra-253B-v1","name":"nvidia/Llama-3_1-Nemotron-Ultra-253B-v1","display_name":"nvidia/Llama-3_1-Nemotron-Ultra-253B-v1","type":"chat","context_length":0,"max_output_tokens":0,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"developer":"Nvidia","developerId":17,"providerId":8,"modelRatio":0.25,"cacheRatio":0,"completionRatio":1,"description":"Llama-3.1-Nemotron-Ultra-253B  2530  8xH100 ","descriptionEn":"Llama-3.1-Nemotron-Ultra-253B is a 253 billion parameter reasoning-focused language model optimized for efficiency that excels at math, coding, and general instruction-following tasks while running on a single 8xH100 node.","order":12,"flag":1,"source":"public-provider-conf"},"vision":false},{"id":"nvidia/llama-3.1-nemotron-70b-instruct","name":"llama-3.1-nemotron-70b","display_name":"llama-3.1-nemotron-70b","type":"chat","context_length":0,"max_output_tokens":0,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"developer":"Nvidia","developerId":17,"providerId":8,"modelRatio":0.3,"cacheRatio":1,"completionRatio":1,"order":0,"flag":0,"source":"public-provider-conf"},"vision":false},{"id":"o1","name":"o1","display_name":"o1","type":"chat","context_length":200,"max_output_tokens":200,"capabilities":{"vision":false,"function_calling":false,"reasoning":true,"tool_calling":false},"reasoning":true,"tool_call":false,"modalities":{"input":["text"],"output":["text"]},"metadata":{"developer":"OpenAI","developerId":12,"providerId":1,"modelRatio":7.5,"cacheRatio":0.5,"completionRatio":4,"description":"openaio","descriptionEn":"OpenAI's most powerful O-series model supports official cache hits that halve the input cost.","order":410,"flag":2,"billingConfig":"{\"model_name\": \"o1\", \"default_tier\": \"tier1\", \"enabled_billing_items\": [\"prompt_tokens\", \"completion_tokens\", \"cached_tokens\", \"image_generation\", \"web_search_requests\"], \"per_unit_price_config\": {\"web_search_price\": 0.01}, \"token_based_tier_configs\": {\"tier1\": {\"model_ratio\": 7.5, \"tier_condition\": {\"max_tokens\": -1, \"min_tokens\": 0}, \"cached_tokens_ratio\": 0.5, \"prompt_tokens_ratio\": 1.0, \"completion_tokens_ratio\": 4.0}}}","features":["thinking"],"tags":["multi_modal","best","bold"],"modalities":["text"],"typeHints":["t2t"],"source":"public-provider-conf"},"vision":false},{"id":"o1-2024-12-17","name":"o1","display_name":"o1","type":"chat","context_length":0,"max_output_tokens":0,"capabilities":{"vision":true,"function_calling":false,"reasoning":true,"tool_calling":false},"reasoning":true,"tool_call":false,"modalities":{"input":["text","image"],"output":["text","image"]},"metadata":{"developer":"OpenAI","developerId":12,"providerId":1,"modelRatio":7.5,"cacheRatio":0.5,"completionRatio":4,"order":1,"flag":0,"features":["thinking"],"tags":["best"],"modalities":["text","image"],"typeHints":["t2t"],"source":"public-provider-conf"},"vision":true},{"id":"o1-mini","name":"o1-mini","display_name":"o1-mini","type":"chat","context_length":0,"max_output_tokens":0,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"developer":"OpenAI","developerId":12,"providerId":1,"modelRatio":1.5,"cacheRatio":0.5,"completionRatio":4,"description":"o1-mini  80% o1-preview AiHubMixopenaiazure openai","descriptionEn":"o1-mini is faster and 80% cheaper, and is competitive with o1-preview on coding tasks. AiHubMix uses both OpenAI and Microsoft Azure OpenAI channels simultaneously.","order":113,"flag":0,"billingConfig":"{\"model_name\": \"o1-mini\", \"default_tier\": \"tier1\", \"enabled_billing_items\": [\"prompt_tokens\", \"completion_tokens\", \"cached_tokens\", \"image_generation\", \"web_search_requests\"], \"per_unit_price_config\": {\"web_search_price\": 0.01}, \"token_based_tier_configs\": {\"tier1\": {\"model_ratio\": 0.55, \"tier_condition\": {\"max_tokens\": -1, \"min_tokens\": 0}, \"cached_tokens_ratio\": 0.5, \"prompt_tokens_ratio\": 1.0, \"completion_tokens_ratio\": 4.0}}}","source":"public-provider-conf"},"vision":false},{"id":"o1-mini-2024-09-12","name":"o1-mini","display_name":"o1-mini","type":"chat","context_length":0,"max_output_tokens":0,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"developer":"OpenAI","developerId":12,"providerId":1,"modelRatio":1.5,"cacheRatio":0.5,"completionRatio":4,"order":0,"flag":0,"source":"public-provider-conf"},"vision":false},{"id":"o1-preview","name":"o1-preview","display_name":"o1-preview","type":"chat","context_length":0,"max_output_tokens":0,"capabilities":{"vision":true,"function_calling":false,"reasoning":true,"tool_calling":false},"reasoning":true,"tool_call":false,"modalities":{"input":["text","image"],"output":["text","image"]},"metadata":{"developer":"OpenAI","developerId":12,"providerId":1,"modelRatio":7.5,"cacheRatio":0.5,"completionRatio":4,"description":"OpenAIAiHubMixopenaiazure openai","descriptionEn":"The latest and most powerful inference model from OpenAI; AiHubMix uses both OpenAI and Microsoft Azure OpenAI channels simultaneously to achieve high-concurrency load balancing.","order":114,"flag":0,"features":["thinking"],"modalities":["text","image"],"typeHints":["t2t"],"source":"public-provider-conf"},"vision":true},{"id":"o1-preview-2024-09-12","name":"o1-preview","display_name":"o1-preview","type":"chat","context_length":0,"max_output_tokens":0,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"developer":"OpenAI","developerId":12,"providerId":1,"modelRatio":7.5,"cacheRatio":0.5,"completionRatio":4,"order":10,"flag":0,"source":"public-provider-conf"},"vision":false},{"id":"o1-pro","name":"o1-pro","display_name":"o1-pro","type":"chat","context_length":200000,"max_output_tokens":200000,"capabilities":{"vision":false,"function_calling":false,"reasoning":true,"tool_calling":false},"reasoning":true,"tool_call":false,"modalities":{"input":["text"],"output":["text"]},"metadata":{"developer":"OpenAI","developerId":12,"providerId":1,"modelRatio":85,"cacheRatio":1,"completionRatio":4,"description":"\n v1/responses https://docs.aihubmix.com/cn/api/Responses-API\no1 o1-pro ","descriptionEn":"The o1 series of models are trained with reinforcement learning to think before they answer and perform complex reasoning. The o1-pro model uses more compute to think harder and provide consistently better answers.","order":350,"flag":0,"billingConfig":"{\"model_name\": \"o1-pro\", \"default_tier\": \"tier1\", \"enabled_billing_items\": [\"prompt_tokens\", \"completion_tokens\", \"cached_tokens\", \"image_generation\", \"web_search_requests\"], \"per_unit_price_config\": {\"web_search_price\": 0.01}, \"token_based_tier_configs\": {\"tier1\": {\"model_ratio\": 75, \"tier_condition\": {\"max_tokens\": -1, \"min_tokens\": 0}, \"cached_tokens_ratio\": 1.0, \"prompt_tokens_ratio\": 1.0, \"completion_tokens_ratio\": 4.0}}}","features":["thinking"],"tags":["best","sota"],"modalities":["text"],"typeHints":["t2t"],"source":"public-provider-conf"},"vision":false},{"id":"o3","name":"o3","display_name":"o3","type":"chat","context_length":200000,"max_output_tokens":200000,"capabilities":{"vision":true,"function_calling":true,"reasoning":true,"tool_calling":true},"reasoning":true,"tool_call":true,"modalities":{"input":["text","image"],"output":["text","image"]},"metadata":{"developer":"OpenAI","developerId":12,"providerId":1,"modelRatio":1,"cacheRatio":0.25,"completionRatio":4,"description":" o3  OpenAI  75%","descriptionEn":"OpenAI o3 is a powerful model across multiple domains, setting a new standard for coding, math, science, and visual reasoning tasks.","order":901,"flag":1,"billingConfig":"{\"model_name\": \"o3\", \"default_tier\": \"tier1\", \"enabled_billing_items\": [\"prompt_tokens\", \"completion_tokens\", \"cached_tokens\", \"image_generation\", \"web_search_requests\"], \"per_unit_price_config\": {\"web_search_price\": 0.01}, \"token_based_tier_configs\": {\"tier1\": {\"model_ratio\": 1.0, \"tier_condition\": {\"max_tokens\": -1, \"min_tokens\": 0}, \"cached_tokens_ratio\": 0.25, \"prompt_tokens_ratio\": 1.0, \"completion_tokens_ratio\": 4.0}}}","features":["thinking","tools","function_calling","structured_outputs"],"tags":["multi_modal","best","sota","bold"],"modalities":["text","image"],"typeHints":["t2t"],"source":"public-provider-conf"},"vision":true},{"id":"o3-mini","name":"o3-mini","display_name":"o3-mini","type":"chat","context_length":200000,"max_output_tokens":200000,"capabilities":{"vision":true,"function_calling":false,"reasoning":true,"tool_calling":false},"reasoning":true,"tool_call":false,"modalities":{"input":["text","image"],"output":["text","image"]},"metadata":{"developer":"OpenAI","developerId":12,"providerId":1,"modelRatio":0.55,"cacheRatio":0.5,"completionRatio":4,"description":"openai  STEAM \n","descriptionEn":"OpenAI's latest fast inference model excels at STEAM tasks and offers exceptional cost-effectiveness. Official support for cache hits reduces input prices by half.","order":455,"flag":0,"billingConfig":"{\"model_name\": \"o3-mini\", \"default_tier\": \"tier1\", \"enabled_billing_items\": [\"prompt_tokens\", \"completion_tokens\", \"cached_tokens\", \"image_generation\", \"web_search_requests\"], \"per_unit_price_config\": {\"web_search_price\": 0.01}, \"token_based_tier_configs\": {\"tier1\": {\"model_ratio\": 0.55, \"tier_condition\": {\"max_tokens\": -1, \"min_tokens\": 0}, \"cached_tokens_ratio\": 0.5, \"prompt_tokens_ratio\": 1.0, \"completion_tokens_ratio\": 4.0}}}","features":["thinking"],"tags":["multi_modal","best","optimized","economical","lightning"],"modalities":["text","image"],"typeHints":["t2t"],"source":"public-provider-conf"},"vision":true},{"id":"o3-pro","name":"o3-pro","display_name":"o3-pro","type":"chat","context_length":0,"max_output_tokens":0,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"developer":"OpenAI","developerId":12,"providerId":1,"modelRatio":10,"cacheRatio":1,"completionRatio":4,"description":"o3-pro\nResponses API \n v1/responses https://docs.aihubmix.com/cn/api/Responses-API","descriptionEn":"o3-pro\nThis model only supports Requests API interface requests.The model's thinking time is relatively long, so the response will be slow.","order":900,"flag":1,"billingConfig":"{\"model_name\": \"o3-pro\", \"default_tier\": \"tier1\", \"enabled_billing_items\": [\"prompt_tokens\", \"completion_tokens\", \"cached_tokens\", \"image_generation\", \"web_search_requests\"], \"per_unit_price_config\": {\"web_search_price\": 0.01}, \"token_based_tier_configs\": {\"tier1\": {\"model_ratio\": 10.0, \"tier_condition\": {\"max_tokens\": -1, \"min_tokens\": 0}, \"cached_tokens_ratio\": 1.0, \"prompt_tokens_ratio\": 1.0, \"completion_tokens_ratio\": 4.0}}}","tags":["multi_modal"],"source":"public-provider-conf"},"vision":false},{"id":"o4-mini","name":"o4-mini","display_name":"o4-mini","type":"chat","context_length":0,"max_output_tokens":0,"capabilities":{"vision":true,"function_calling":false,"reasoning":true,"tool_calling":false},"reasoning":true,"tool_call":false,"modalities":{"input":["text","image"],"output":["text","image"]},"metadata":{"developer":"OpenAI","developerId":12,"providerId":1,"modelRatio":0.55,"cacheRatio":0.25,"completionRatio":4,"description":"o4-mini  o3  75%","descriptionEn":"o4-mini is a remarkably smart model for its speed and cost-efficiency. This allows it to support significantly higher usage limits than o3, making it a strong high-volume, high-throughput option for everyone with questions that benefit from reasoning.","order":808,"flag":1,"billingConfig":"{\"model_name\": \"o4-mini\", \"default_tier\": \"tier1\", \"enabled_billing_items\": [\"prompt_tokens\", \"completion_tokens\", \"cached_tokens\", \"image_generation\", \"web_search_requests\"], \"per_unit_price_config\": {\"web_search_price\": 0.01}, \"token_based_tier_configs\": {\"tier1\": {\"model_ratio\": 0.55, \"tier_condition\": {\"max_tokens\": -1, \"min_tokens\": 0}, \"cached_tokens_ratio\": 0.25, \"prompt_tokens_ratio\": 1.0, \"completion_tokens_ratio\": 4.0}}}","features":["thinking"],"tags":["best","optimized","economical","lightning","multi_modal"],"modalities":["text","image"],"typeHints":["t2t"],"source":"public-provider-conf"},"vision":true},{"id":"omni-moderation-latest","name":"omni-moderation","display_name":"omni-moderation","type":"chat","context_length":0,"max_output_tokens":0,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"developer":"OpenAI","developerId":12,"providerId":1,"modelRatio":0.1,"cacheRatio":1,"completionRatio":1,"order":0,"flag":0,"source":"public-provider-conf"},"vision":false},{"id":"openai/gpt-oss-120b","name":"openai/gpt-oss-120b","display_name":"openai/gpt-oss-120b","type":"chat","context_length":0,"max_output_tokens":0,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"developer":"OpenAI","developerId":12,"providerId":29,"modelRatio":0.09,"cacheRatio":1,"completionRatio":5,"description":"GPT-OSS 120B  OpenAI MoE 200  128 ","descriptionEn":"GPT-OSS 120B is OpenAI's flagship open source model, built on a Mixture-of-Experts (MoE) architecture with 20 billion parameters and 128 experts.","order":946,"flag":1,"source":"public-provider-conf"},"vision":false},{"id":"openai/gpt-oss-20b","name":"openai/gpt-oss-20b","display_name":"openai/gpt-oss-20b","type":"chat","context_length":0,"max_output_tokens":0,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"developer":"OpenAI","developerId":12,"providerId":29,"modelRatio":0.055,"cacheRatio":1,"completionRatio":5,"description":"GPT-OSS 20B  OpenAI MoE 200  32 ","descriptionEn":"GPT-OSS 20B is OpenAI's flagship open source model, built on a Mixture-of-Experts (MoE) architecture with 20 billion parameters and 32 experts.","order":945,"flag":1,"source":"public-provider-conf"},"vision":false},{"id":"qianfan-chinese-llama-2-13b","name":"qianfan-chinese-llama-2-13b","display_name":"qianfan-chinese-llama-2-13b","type":"chat","context_length":0,"max_output_tokens":0,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"developer":"Baidu","developerId":11,"providerId":24,"modelRatio":0.411,"cacheRatio":1,"completionRatio":1,"order":0,"flag":0,"source":"public-provider-conf"},"vision":false},{"id":"qianfan-llama-vl-8b","name":"qianfan-llama-vl-8b","display_name":"qianfan-llama-vl-8b","type":"chat","context_length":0,"max_output_tokens":0,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"developer":"Baidu","developerId":11,"providerId":24,"modelRatio":0.137,"cacheRatio":1,"completionRatio":2.5,"order":0,"flag":0,"source":"public-provider-conf"},"vision":false},{"id":"qianfan-qi-vl","name":"qianfan-qi-vl","display_name":"qianfan-qi-vl","type":"chat","context_length":0,"max_output_tokens":0,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"developer":"Baidu","developerId":25,"providerId":15,"modelRatio":0.1,"cacheRatio":1,"completionRatio":3,"description":"Qianfan-QI-VL-(Quality Inspection Large Vision Language Model,Qianfan-QI-VL)AIGC","descriptionEn":"The Qianfan-QI-VL model is a proprietary image quality inspection and visual understanding large model (Quality Inspection Large Vision Language Model, Qianfan-QI-VL) developed by Baidu Clouds Qianfan platform. It is designed for quality inspection of product images uploaded in e-commerce scenarios, with detection capabilities including AIGC human defect detection, mosaic recognition, watermark recognition, and trademark detection.","order":100,"flag":0,"source":"public-provider-conf"},"vision":false},{"id":"qwen-3-235b-a22b-instruct-2507","name":"qwen-3-235b-a22b-instruct-2507","display_name":"qwen-3-235b-a22b-instruct-2507","type":"chat","context_length":0,"max_output_tokens":0,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"developer":"Qwen","developerId":13,"providerId":8,"modelRatio":0.14,"cacheRatio":1,"completionRatio":5,"description":"cerebras","descriptionEn":"cerebras","order":20,"flag":1,"source":"public-provider-conf"},"vision":false},{"id":"qwen-3-235b-a22b-thinking-2507","name":"qwen-3-235b-a22b-thinking-2507","display_name":"qwen-3-235b-a22b-thinking-2507","type":"chat","context_length":0,"max_output_tokens":0,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"developer":"Qwen","developerId":13,"providerId":8,"modelRatio":0.14,"cacheRatio":1,"completionRatio":10,"description":"cerebras","descriptionEn":"cerebras","order":400,"flag":1,"source":"public-provider-conf"},"vision":false},{"id":"qwen-3-32b","name":"qwen-3-32b","display_name":"qwen-3-32b","type":"chat","context_length":0,"max_output_tokens":0,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"developer":"Qwen","developerId":13,"providerId":8,"modelRatio":0.2,"cacheRatio":1,"completionRatio":4,"description":"cerebras","descriptionEn":"cerebras","order":40,"flag":0,"source":"public-provider-conf"},"vision":false},{"id":"qwen-3-coder-480b","name":"qwen-3-coder-480b","display_name":"qwen-3-coder-480b","type":"chat","context_length":0,"max_output_tokens":0,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"developer":"Qwen","developerId":13,"providerId":8,"modelRatio":0.7,"cacheRatio":1,"completionRatio":4,"description":"cerebras","descriptionEn":"cerebras","order":400,"flag":1,"source":"public-provider-conf"},"vision":false},{"id":"qwen-flash","name":"qwen-flash","display_name":"qwen-flash","type":"chat","context_length":0,"max_output_tokens":0,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"developer":"Qwen","developerId":13,"providerId":17,"modelRatio":0.01,"cacheRatio":1,"completionRatio":10,"description":"","descriptionEn":"The model adopts tiered pricing.","order":0,"flag":0,"billingConfig":"{\"model_name\": \"qwen-flash\", \"default_tier\": \"tier1\", \"enabled_billing_items\": [\"prompt_tokens\", \"completion_tokens\", \"cached_tokens\"], \"token_based_tier_configs\": {\"tier1\": {\"model_ratio\": 0.010273, \"tier_condition\": {\"max_tokens\": 128000, \"min_tokens\": 0}, \"prompt_tokens_ratio\": 1.0, \"completion_tokens_ratio\": 10.0}, \"tier2\": {\"model_ratio\": 0.041096, \"tier_condition\": {\"max_tokens\": 256000, \"min_tokens\": 128001}, \"prompt_tokens_ratio\": 1.0, \"completion_tokens_ratio\": 10.0}, \"tier3\": {\"model_ratio\": 0.082191, \"tier_condition\": {\"max_tokens\": 1000000, \"min_tokens\": 256001}, \"prompt_tokens_ratio\": 1.0, \"completion_tokens_ratio\": 10.0}}}","source":"public-provider-conf"},"vision":false},{"id":"qwen-flash-2025-07-28","name":"qwen-flash-2025-07-28","display_name":"qwen-flash-2025-07-28","type":"chat","context_length":0,"max_output_tokens":0,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"developer":"Qwen","developerId":13,"providerId":17,"modelRatio":0.01,"cacheRatio":1,"completionRatio":10,"description":"","descriptionEn":"The model adopts tiered pricing.","order":0,"flag":0,"billingConfig":"{\"model_name\": \"qwen-flash-2025-07-28\", \"default_tier\": \"tier1\", \"enabled_billing_items\": [\"prompt_tokens\", \"completion_tokens\", \"cached_tokens\"], \"token_based_tier_configs\": {\"tier1\": {\"model_ratio\": 0.010273, \"tier_condition\": {\"max_tokens\": 128000, \"min_tokens\": 0}, \"prompt_tokens_ratio\": 1.0, \"completion_tokens_ratio\": 10.0}, \"tier2\": {\"model_ratio\": 0.041095, \"tier_condition\": {\"max_tokens\": 256000, \"min_tokens\": 128001}, \"prompt_tokens_ratio\": 1.0, \"completion_tokens_ratio\": 10.0}, \"tier3\": {\"model_ratio\": 0.082191, \"tier_condition\": {\"max_tokens\": 1000000, \"min_tokens\": 256001}, \"prompt_tokens_ratio\": 1.0, \"completion_tokens_ratio\": 10.0}}}","source":"public-provider-conf"},"vision":false},{"id":"qwen-image","name":"qwen-image","display_name":"qwen-image","type":"image-generation","context_length":0,"max_output_tokens":0,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"developer":"Qwen","developerId":13,"providerId":15,"modelRatio":1,"cacheRatio":0,"completionRatio":0,"description":"Qwen-Image Qwen ","descriptionEn":"Qwen-Image is a foundational image generation model in the Qwen series, achieving significant progress in complex text rendering and precise image editing. Experiments show that the model has strong general capabilities in image generation and editing, especially excelling in Chinese text rendering.","order":600,"flag":0,"imagePriceConfig":"{\"generate\":{\"standard\":{\"standard\":0.034}}}","typeHints":["t2i"],"source":"public-provider-conf"},"vision":false},{"id":"qwen-image-edit","name":"qwen-image-edit","display_name":"qwen-image-edit","type":"image-generation","context_length":0,"max_output_tokens":0,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"developer":"Qwen","developerId":13,"providerId":15,"modelRatio":1,"cacheRatio":0,"completionRatio":0,"description":"Qwen-Image-Edit  Qwen-Image Qwen-Image-Edit  20B Qwen-Image  Qwen-Image Qwen-Image-Edit  Qwen2.5-VL VAE ","descriptionEn":"Qwen-Image-Edit is the image editing version of Qwen-Image. Based on the 20B Qwen-Image model, Qwen-Image-Edit successfully extends Qwen-Image's unique text rendering capabilities to image editing tasks, achieving precise text editing. Additionally, Qwen-Image-Edit can input the same image into Qwen2.5-VL (for visual semantic control) and the VAE encoder (for visual appearance control), enabling both semantic and appearance editing functionalities.","order":799,"flag":0,"imagePriceConfig":"{\"generate\":{\"standard\":{\"standard\":0.041}}}","typeHints":["t2i"],"source":"public-provider-conf"},"vision":false},{"id":"qwen-long","name":"qwen-long","display_name":"qwen-long","type":"chat","context_length":0,"max_output_tokens":0,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"developer":"Qwen","developerId":13,"providerId":17,"modelRatio":0.05,"cacheRatio":1,"completionRatio":4,"order":0,"flag":0,"source":"public-provider-conf"},"vision":false},{"id":"qwen-max","name":"qwen-max","display_name":"qwen-max","type":"chat","context_length":0,"max_output_tokens":0,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"developer":"Qwen","developerId":13,"providerId":17,"modelRatio":0.19,"cacheRatio":1,"completionRatio":4,"order":0,"flag":0,"source":"public-provider-conf"},"vision":false},{"id":"qwen-max-0125","name":"Qwen2.5-Max","display_name":"Qwen2.5-Max","type":"chat","context_length":0,"max_output_tokens":0,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"developer":"Qwen","developerId":13,"providerId":17,"modelRatio":0.19,"cacheRatio":1,"completionRatio":4,"description":"Qwen2.5-Max","descriptionEn":"Qwen 2.5-Max latest model","order":98,"flag":1,"source":"public-provider-conf"},"vision":false},{"id":"qwen-max-longcontext","name":"qwen-max-longcontext","display_name":"qwen-max-longcontext","type":"chat","context_length":0,"max_output_tokens":0,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"developer":"Qwen","developerId":13,"providerId":17,"modelRatio":3.5,"cacheRatio":1,"completionRatio":3,"order":0,"flag":0,"source":"public-provider-conf"},"vision":false},{"id":"qwen-plus","name":"qwen-plus","display_name":"qwen-plus","type":"chat","context_length":0,"max_output_tokens":0,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"developer":"Qwen","developerId":13,"providerId":17,"modelRatio":0.35,"cacheRatio":1,"completionRatio":3,"order":0,"flag":0,"source":"public-provider-conf"},"vision":false},{"id":"qwen-plus-2025-04-28","name":"qwen-plus-2025-04-28","display_name":"qwen-plus-2025-04-28","type":"chat","context_length":0,"max_output_tokens":0,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"developer":"Qwen","developerId":13,"providerId":17,"modelRatio":0.065,"cacheRatio":0,"completionRatio":20,"description":"Qwen3PlusQwQQwen2.5-PlusSOTA2025428","descriptionEn":"The Qwen3 series Plus model effectively integrates thinking and non-thinking modes, allowing for mode switching during conversations. Its reasoning abilities significantly surpass those of QwQ, and its general capabilities are markedly superior to Qwen2.5-Plus, reaching state-of-the-art (SOTA) levels among models of the same scale. This version is a snapshot model as of April 28, 2025.","order":39,"flag":1,"typeHints":["t2t"],"source":"public-provider-conf"},"vision":false},{"id":"qwen-plus-2025-07-28","name":"qwen-plus-2025-07-28","display_name":"qwen-plus-2025-07-28","type":"chat","context_length":0,"max_output_tokens":0,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"developer":"Qwen","developerId":13,"providerId":17,"modelRatio":0.055,"cacheRatio":1,"completionRatio":2.5,"description":"-Max-Turbo","descriptionEn":"The Tongyi Qianwen series balanced capability model has inference performance and speed between Tongyi Qianwen-Max and Tongyi Qianwen-Turbo, making it suitable for moderately complex tasks. This model adopts tiered pricing.","order":50,"flag":0,"billingConfig":"{\"model_name\": \"qwen-plus-2025-07-28\", \"default_tier\": \"tier1\", \"enabled_billing_items\": [\"prompt_tokens\", \"completion_tokens\", \"cached_tokens\"], \"token_based_tier_configs\": {\"tier1\": {\"model_ratio\": 0.054794, \"tier_condition\": {\"max_tokens\": 128000, \"min_tokens\": 0}, \"prompt_tokens_ratio\": 1.0, \"completion_tokens_ratio\": 2.5}, \"tier2\": {\"model_ratio\": 0.164383, \"tier_condition\": {\"max_tokens\": 256000, \"min_tokens\": 128001}, \"prompt_tokens_ratio\": 1.0, \"completion_tokens_ratio\": 8.333333}, \"tier3\": {\"model_ratio\": 0.328767, \"tier_condition\": {\"max_tokens\": 1000000, \"min_tokens\": 256001}, \"prompt_tokens_ratio\": 1.0, \"completion_tokens_ratio\": 10.0}}}","source":"public-provider-conf"},"vision":false},{"id":"qwen-plus-latest","name":"qwen-plus-latest","display_name":"qwen-plus-latest","type":"chat","context_length":0,"max_output_tokens":0,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"developer":"Qwen","developerId":13,"providerId":17,"modelRatio":0.055,"cacheRatio":1,"completionRatio":2.5,"description":"-Max-Turboqwen-plus-2025-07-28","descriptionEn":"The Qwen series models with balanced capabilities have inference performance and speed between Qwen-Max and Qwen-Turbo, making them suitable for moderately complex tasks. This model is a dynamically updated version, and updates will not be announced in advance. The current version is qwen-plus-2025-04-28.The model adopts tiered pricing.","order":50,"flag":1,"billingConfig":"{\"model_name\": \"qwen-plus-latest\", \"default_tier\": \"tier1\", \"enabled_billing_items\": [\"prompt_tokens\", \"completion_tokens\", \"cached_tokens\"], \"token_based_tier_configs\": {\"tier1\": {\"model_ratio\": 0.054794, \"tier_condition\": {\"max_tokens\": 128000, \"min_tokens\": 0}, \"prompt_tokens_ratio\": 1.0, \"completion_tokens_ratio\": 2.5}, \"tier2\": {\"model_ratio\": 0.164383, \"tier_condition\": {\"max_tokens\": 256000, \"min_tokens\": 128001}, \"prompt_tokens_ratio\": 1.0, \"completion_tokens_ratio\": 8.333333}, \"tier3\": {\"model_ratio\": 0.328767, \"tier_condition\": {\"max_tokens\": 1000000, \"min_tokens\": 256001}, \"prompt_tokens_ratio\": 1.0, \"completion_tokens_ratio\": 10.0}}}","typeHints":["t2t"],"source":"public-provider-conf"},"vision":false},{"id":"qwen-qwq-32b","name":"qwen-qwq-32b","display_name":"qwen-qwq-32b","type":"chat","context_length":0,"max_output_tokens":0,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"developer":"Qwen","developerId":13,"providerId":17,"modelRatio":0.2,"cacheRatio":1,"completionRatio":2,"order":99,"flag":0,"source":"public-provider-conf"},"vision":false},{"id":"qwen-turbo","name":"qwen-turbo","display_name":"qwen-turbo","type":"chat","context_length":1000000,"max_output_tokens":1000000,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"modalities":{"input":["text"],"output":["text"]},"metadata":{"developer":"Qwen","developerId":13,"providerId":17,"modelRatio":0.18,"cacheRatio":1,"completionRatio":3,"order":0,"flag":0,"features":["long_context"],"modalities":["text"],"typeHints":["t2t"],"source":"public-provider-conf"},"vision":false},{"id":"qwen-turbo-2024-11-01","name":"Qwen2.5-Turbo","display_name":"Qwen2.5-Turbo","type":"chat","context_length":1000000,"max_output_tokens":1000000,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"modalities":{"input":["text"],"output":["text"]},"metadata":{"developer":"Qwen","developerId":13,"providerId":17,"modelRatio":0.18,"cacheRatio":1,"completionRatio":3,"order":0,"flag":0,"features":["long_context"],"modalities":["text"],"typeHints":["t2t"],"source":"public-provider-conf"},"vision":false},{"id":"qwen-turbo-2025-04-28","name":"qwen-turbo-2025-04-28","display_name":"qwen-turbo-2025-04-28","type":"chat","context_length":0,"max_output_tokens":0,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"developer":"Qwen","developerId":13,"providerId":17,"modelRatio":0.023,"cacheRatio":0,"completionRatio":20,"description":"Qwen3TurboQwQ-32BQwen2.5-TurboSOTA2025428","descriptionEn":"The Qwen3 series Turbo model effectively integrates thinking and non-thinking modes, allowing seamless switching between modes during conversations. With a smaller parameter size, its reasoning ability rivals that of QwQ-32B, and its general capabilities significantly surpass those of Qwen2.5-Turbo, reaching state-of-the-art (SOTA) levels among models of the same scale. This version is a snapshot model as of April 28, 2025.","order":40,"flag":1,"typeHints":["t2t"],"source":"public-provider-conf"},"vision":false},{"id":"qwen-turbo-latest","name":"qwen-turbo-latest","display_name":"qwen-turbo-latest","type":"chat","context_length":0,"max_output_tokens":0,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"developer":"Qwen","developerId":13,"providerId":17,"modelRatio":0.023,"cacheRatio":0,"completionRatio":20,"description":"qwen-turbo-2025-04-28","descriptionEn":"The Qwen series model with the fastest speed and lowest cost, suitable for simple tasks. This model is a dynamically updated version, and updates will not be announced in advance. The model's overall Chinese and English abilities have been significantly improved, human preference alignment has been greatly enhanced, inference capability and complex instruction understanding have been substantially strengthened, performance on difficult tasks is better, and mathematics and coding skills have been significantly improved. The current version is qwen-turbo-2025-04-28.","order":49,"flag":1,"typeHints":["t2t"],"source":"public-provider-conf"},"vision":false},{"id":"qwen2.5-14b-instruct","name":"qwen2.5-14b","display_name":"qwen2.5-14b","type":"chat","context_length":0,"max_output_tokens":0,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"developer":"Qwen","developerId":13,"providerId":17,"modelRatio":0.2,"cacheRatio":1,"completionRatio":3,"order":0,"flag":0,"source":"public-provider-conf"},"vision":false},{"id":"qwen2.5-32b-instruct","name":"qwen2.5-32b","display_name":"qwen2.5-32b","type":"chat","context_length":0,"max_output_tokens":0,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"developer":"Qwen","developerId":13,"providerId":17,"modelRatio":0.3,"cacheRatio":1,"completionRatio":2,"order":0,"flag":0,"source":"public-provider-conf"},"vision":false},{"id":"qwen2.5-3b-instruct","name":"qwen2.5-3b","display_name":"qwen2.5-3b","type":"chat","context_length":0,"max_output_tokens":0,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"developer":"Qwen","developerId":13,"providerId":17,"modelRatio":0.2,"cacheRatio":1,"completionRatio":2,"order":0,"flag":0,"source":"public-provider-conf"},"vision":false},{"id":"qwen2.5-72b-instruct","name":"qwen2.5-72b","display_name":"qwen2.5-72b","type":"chat","context_length":0,"max_output_tokens":0,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"developer":"Qwen","developerId":13,"providerId":17,"modelRatio":0.4,"cacheRatio":1,"completionRatio":3,"order":0,"flag":0,"source":"public-provider-conf"},"vision":false},{"id":"qwen2.5-7b-instruct","name":"qwen2.5-7b","display_name":"qwen2.5-7b","type":"chat","context_length":0,"max_output_tokens":0,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"developer":"Qwen","developerId":13,"providerId":17,"modelRatio":0.2,"cacheRatio":1,"completionRatio":2,"order":0,"flag":0,"source":"public-provider-conf"},"vision":false},{"id":"qwen2.5-coder-1.5b-instruct","name":"qwen2.5-coder-1.5b","display_name":"qwen2.5-coder-1.5b","type":"chat","context_length":0,"max_output_tokens":0,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"developer":"Qwen","developerId":13,"providerId":17,"modelRatio":0.1,"cacheRatio":1,"completionRatio":2,"order":0,"flag":0,"source":"public-provider-conf"},"vision":false},{"id":"qwen2.5-coder-7b-instruct","name":"qwen2.5-coder-7b","display_name":"qwen2.5-coder-7b","type":"chat","context_length":0,"max_output_tokens":0,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"developer":"Qwen","developerId":13,"providerId":17,"modelRatio":0.1,"cacheRatio":1,"completionRatio":2,"order":0,"flag":0,"source":"public-provider-conf"},"vision":false},{"id":"qwen2.5-math-72b-instruct","name":"qwen2.5-math-72b","display_name":"qwen2.5-math-72b","type":"chat","context_length":0,"max_output_tokens":0,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"developer":"Qwen","developerId":13,"providerId":17,"modelRatio":0.4,"cacheRatio":1,"completionRatio":3,"order":0,"flag":0,"source":"public-provider-conf"},"vision":false},{"id":"qwen2.5-math-7b-instruct","name":"qwen2.5-math-7b","display_name":"qwen2.5-math-7b","type":"chat","context_length":0,"max_output_tokens":0,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"developer":"Qwen","developerId":13,"providerId":17,"modelRatio":0.1,"cacheRatio":1,"completionRatio":2,"order":0,"flag":0,"source":"public-provider-conf"},"vision":false},{"id":"qwen2.5-vl-72b-instruct","name":"qwen2.5-vl-72b","display_name":"qwen2.5-vl-72b","type":"chat","context_length":0,"max_output_tokens":0,"capabilities":{"vision":true,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"modalities":{"input":["text","image"],"output":["text","image"]},"metadata":{"developer":"Qwen","developerId":13,"providerId":17,"modelRatio":1.2,"cacheRatio":1,"completionRatio":3,"description":" ChatGPT 4o","descriptionEn":"Strong capability in Chinese domain recognition, comparable to ChatGPT-4.0.","order":100,"flag":1,"tags":["multi_modal"],"modalities":["text","image"],"typeHints":["t2t"],"source":"public-provider-conf"},"vision":true},{"id":"qwen3-0.6b","name":"qwen3-0.6b","display_name":"qwen3-0.6b","type":"chat","context_length":0,"max_output_tokens":0,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"developer":"Qwen","developerId":13,"providerId":17,"modelRatio":0.023,"cacheRatio":0,"completionRatio":10,"description":"Qwen2.5","descriptionEn":"Effectively integrates thinking and non-thinking modes, allowing mode switching during conversations. Its general capabilities significantly surpass those of the Qwen2.5 small-scale series.","order":41,"flag":1,"typeHints":["t2t"],"source":"public-provider-conf"},"vision":false},{"id":"qwen3-1.7b","name":"qwen3-1.7b","display_name":"qwen3-1.7b","type":"chat","context_length":0,"max_output_tokens":0,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"developer":"Qwen","developerId":13,"providerId":17,"modelRatio":0.023,"cacheRatio":0,"completionRatio":10,"description":"Qwen2.5","descriptionEn":"Effectively integrates thinking and non-thinking modes, allowing mode switching during conversations. Its general capabilities significantly surpass those of the Qwen2.5 small-scale series, with greatly enhanced human preference alignment. There are notable improvements in creative writing, role-playing, multi-turn dialogue, and instruction following, resulting in a significantly better expected user experience.","order":42,"flag":1,"typeHints":["t2t"],"source":"public-provider-conf"},"vision":false},{"id":"qwen3-14b","name":"qwen3-14b","display_name":"qwen3-14b","type":"chat","context_length":0,"max_output_tokens":0,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"developer":"Qwen","developerId":13,"providerId":17,"modelRatio":0.08,"cacheRatio":0,"completionRatio":10,"description":"SOTAQwen2.5-14B","descriptionEn":"Achieves effective integration of thinking and non-thinking modes, enabling mode switching during conversations. Its reasoning ability reaches state-of-the-art (SOTA) levels among models of the same scale, and its general capability significantly surpasses Qwen2.5-14B.","order":45,"flag":1,"typeHints":["t2t"],"source":"public-provider-conf"},"vision":false},{"id":"qwen3-235b-a22b","name":"qwen3-235b-a22b","display_name":"qwen3-235b-a22b","type":"chat","context_length":0,"max_output_tokens":0,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"developer":"Qwen","developerId":13,"providerId":17,"modelRatio":0.16,"cacheRatio":0,"completionRatio":10,"description":"QwQQwen2.5-72B-InstructSOTA","descriptionEn":"Achieves effective integration of thinking and non-thinking modes, allowing mode switching during conversations. Its reasoning ability significantly surpasses QwQ, and its general capability notably exceeds Qwen2.5-72B-Instruct, reaching SOTA (state-of-the-art) levels among industry models of the same scale.","order":48,"flag":1,"typeHints":["t2t"],"source":"public-provider-conf"},"vision":false},{"id":"qwen3-235b-a22b-instruct-2507","name":"qwen3-235b-a22b-instruct-2507","display_name":"qwen3-235b-a22b-instruct-2507","type":"chat","context_length":0,"max_output_tokens":0,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"developer":"Qwen","developerId":13,"providerId":17,"modelRatio":0.14,"cacheRatio":1,"completionRatio":4,"order":200,"flag":0,"source":"public-provider-conf"},"vision":false},{"id":"qwen3-235b-a22b-thinking-2507","name":"qwen3-235b-a22b-thinking-2507","display_name":"qwen3-235b-a22b-thinking-2507","type":"chat","context_length":0,"max_output_tokens":0,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"developer":"Qwen","developerId":13,"providerId":17,"modelRatio":0.14,"cacheRatio":1,"completionRatio":10,"description":"Qwen33-235B-A22B","descriptionEn":"The open-source thinking model based on Qwen3 has significantly improved in logical ability, general capability, knowledge enhancement, and creative ability compared to the previous version (Tongyi Qianwen 3-235B-A22B). It is suitable for high-difficulty and strong reasoning scenarios.","order":704,"flag":0,"source":"public-provider-conf"},"vision":false},{"id":"qwen3-30b-a3b","name":"qwen3-30b-a3b","display_name":"qwen3-30b-a3b","type":"chat","context_length":0,"max_output_tokens":0,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"developer":"Qwen","developerId":13,"providerId":17,"modelRatio":0.06,"cacheRatio":0,"completionRatio":10,"description":"QwQ-32BQwen2.5-14BSOTA","descriptionEn":"Achieves effective integration of thinking and non-thinking modes, allowing mode switching during conversations. Its reasoning ability matches that of QwQ-32B with a smaller parameter size, and its general capability significantly surpasses Qwen2.5-14B, reaching state-of-the-art (SOTA) levels among industry models of the same scale.","order":47,"flag":1,"typeHints":["t2t"],"source":"public-provider-conf"},"vision":false},{"id":"qwen3-30b-a3b-instruct-2507","name":"qwen3-30b-a3b-instruct-2507","display_name":"qwen3-30b-a3b-instruct-2507","type":"chat","context_length":0,"max_output_tokens":0,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"developer":"Qwen","developerId":13,"providerId":17,"modelRatio":0.06,"cacheRatio":1,"completionRatio":4,"description":"\n  \n  \n256K","descriptionEn":"Significantly improved performance on reasoning tasks, including logical reasoning, mathematics, science, coding, and academic benchmarks that typically require human expertise.\nMarkedly better general capabilities, such as instruction following, tool usage, text generation, and alignment with human preferences.\nEnhanced 256K long-context understanding capabilities.","order":402,"flag":1,"source":"public-provider-conf"},"vision":false},{"id":"qwen3-30b-a3b-thinking-2507","name":"qwen3-30b-a3b-thinking-2507","display_name":"qwen3-30b-a3b-thinking-2507","type":"chat","context_length":0,"max_output_tokens":0,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"developer":"Qwen","developerId":13,"providerId":17,"modelRatio":0.06,"cacheRatio":1,"completionRatio":10,"description":"  \n  \n256K","descriptionEn":"Significantly improved performance on reasoning tasks, including logical reasoning, mathematics, science, coding, and academic benchmarks that typically require human expertise.\nMarkedly better general capabilities, such as instruction following, tool usage, text generation, and alignment with human preferences.\nEnhanced 256K long-context understanding capabilities.","order":401,"flag":1,"source":"public-provider-conf"},"vision":false},{"id":"qwen3-32b","name":"qwen3-32b","display_name":"qwen3-32b","type":"chat","context_length":0,"max_output_tokens":0,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"developer":"Qwen","developerId":13,"providerId":17,"modelRatio":0.16,"cacheRatio":0,"completionRatio":10,"description":"QwQQwen2.5-32B-InstructSOTA","descriptionEn":"Achieves effective integration of thinking and non-thinking modes, allowing mode switching during conversations. Its reasoning ability significantly surpasses QwQ, and its general capability significantly exceeds Qwen2.5-32B-Instruct, reaching state-of-the-art (SOTA) levels among industry models of the same scale.","order":46,"flag":1,"typeHints":["t2t"],"source":"public-provider-conf"},"vision":false},{"id":"qwen3-4b","name":"qwen3-4b","display_name":"qwen3-4b","type":"chat","context_length":0,"max_output_tokens":0,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"developer":"Qwen","developerId":13,"providerId":17,"modelRatio":0.023,"cacheRatio":0,"completionRatio":10,"description":"SOTA","descriptionEn":"Achieves effective integration of thinking and non-thinking modes, allowing mode switching during conversations. Its reasoning ability reaches state-of-the-art (SOTA) levels among models of the same scale, with significantly enhanced human preference alignment. There are notable improvements in creative writing, role-playing, multi-turn dialogue, and instruction following, resulting in a noticeably better user experience.","order":43,"flag":1,"typeHints":["t2t"],"source":"public-provider-conf"},"vision":false},{"id":"qwen3-8b","name":"qwen3-8b","display_name":"qwen3-8b","type":"chat","context_length":0,"max_output_tokens":0,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"developer":"Qwen","developerId":13,"providerId":17,"modelRatio":0.04,"cacheRatio":0,"completionRatio":10,"description":"SOTAQwen2.5-7B","descriptionEn":"Achieves effective integration of thinking and non-thinking modes, enabling mode switching during conversations. Its reasoning ability reaches state-of-the-art (SOTA) levels among models of the same scale, and its general capability significantly surpasses Qwen2.5-7B.","order":44,"flag":1,"typeHints":["t2t"],"source":"public-provider-conf"},"vision":false},{"id":"qwen3-coder-30b-a3b-instruct","name":"qwen3-coder-30b-a3b-instruct","display_name":"qwen3-coder-30b-a3b-instruct","type":"chat","context_length":0,"max_output_tokens":0,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"developer":"Qwen","developerId":13,"providerId":17,"modelRatio":0.1,"cacheRatio":1,"completionRatio":4,"description":"Qwen3Coding Agent SOTA\n","descriptionEn":"The code generation model based on Qwen3 has powerful Coding Agent capabilities, achieving state-of-the-art performance compared to open-source models.The model adopts tiered pricing.","order":702,"flag":0,"billingConfig":"{\"model_name\": \"qwen3-coder-30b-a3b-instruct\", \"default_tier\": \"tier1\", \"enabled_billing_items\": [\"prompt_tokens\", \"completion_tokens\", \"cached_tokens\"], \"token_based_tier_configs\": {\"tier1\": {\"model_ratio\": 0.102739, \"tier_condition\": {\"max_tokens\": 32000, \"min_tokens\": 0}, \"prompt_tokens_ratio\": 1.0, \"completion_tokens_ratio\": 4.0}, \"tier2\": {\"model_ratio\": 0.154109, \"tier_condition\": {\"max_tokens\": 128000, \"min_tokens\": 32001}, \"prompt_tokens_ratio\": 1.0, \"completion_tokens_ratio\": 4.0}, \"tier3\": {\"model_ratio\": 0.513698, \"tier_condition\": {\"max_tokens\": 200000, \"min_tokens\": 128001}, \"prompt_tokens_ratio\": 1.0, \"completion_tokens_ratio\": 5.0}}}","source":"public-provider-conf"},"vision":false},{"id":"qwen3-coder-480b-a35b-instruct","name":"qwen3-coder-480b-a35b-instruct","display_name":"qwen3-coder-480b-a35b-instruct","type":"chat","context_length":0,"max_output_tokens":0,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"developer":"Qwen","developerId":13,"providerId":17,"modelRatio":0.41,"cacheRatio":1,"completionRatio":4,"description":"Qwen3Coding Agent SOTA\n","descriptionEn":"The code generation model based on Qwen3 has powerful Coding Agent capabilities, achieving state-of-the-art performance compared to open-source models.The model adopts tiered pricing.","order":702,"flag":1,"billingConfig":"{\"model_name\": \"qwen3-coder-480b-a35b-instruct\", \"default_tier\": \"tier1\", \"enabled_billing_items\": [\"prompt_tokens\", \"completion_tokens\", \"cached_tokens\"], \"token_based_tier_configs\": {\"tier1\": {\"model_ratio\": 0.410958, \"tier_condition\": {\"max_tokens\": 32000, \"min_tokens\": 0}, \"prompt_tokens_ratio\": 1.0, \"completion_tokens_ratio\": 4.0}, \"tier2\": {\"model_ratio\": 0.616438, \"tier_condition\": {\"max_tokens\": 128000, \"min_tokens\": 32001}, \"prompt_tokens_ratio\": 1.0, \"completion_tokens_ratio\": 4.0}, \"tier3\": {\"model_ratio\": 1.027397, \"tier_condition\": {\"max_tokens\": 200000, \"min_tokens\": 128001}, \"prompt_tokens_ratio\": 1.0, \"completion_tokens_ratio\": 4.0}}}","source":"public-provider-conf"},"vision":false},{"id":"qwen3-coder-flash","name":"qwen3-coder-flash","display_name":"qwen3-coder-flash","type":"chat","context_length":0,"max_output_tokens":0,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"developer":"Qwen","developerId":13,"providerId":17,"modelRatio":0.068,"cacheRatio":1,"completionRatio":4,"order":0,"flag":1,"billingConfig":"{\"model_name\": \"qwen3-coder-flash\", \"default_tier\": \"tier1\", \"enabled_billing_items\": [\"prompt_tokens\", \"completion_tokens\", \"cached_tokens\"], \"token_based_tier_configs\": {\"tier1\": {\"model_ratio\": 0.068493, \"tier_condition\": {\"max_tokens\": 32000, \"min_tokens\": 0}, \"prompt_tokens_ratio\": 1.0, \"completion_tokens_ratio\": 4.0}, \"tier2\": {\"model_ratio\": 0.102739, \"tier_condition\": {\"max_tokens\": 128000, \"min_tokens\": 32001}, \"prompt_tokens_ratio\": 1.0, \"completion_tokens_ratio\": 4.0}, \"tier3\": {\"model_ratio\": 0.171232, \"tier_condition\": {\"max_tokens\": 256000, \"min_tokens\": 128001}, \"prompt_tokens_ratio\": 1.0, \"completion_tokens_ratio\": 4.0}, \"tier4\": {\"model_ratio\": 0.342465, \"tier_condition\": {\"max_tokens\": 1000000, \"min_tokens\": 256001}, \"prompt_tokens_ratio\": 1.0, \"completion_tokens_ratio\": 5.0}}}","source":"public-provider-conf"},"vision":false},{"id":"qwen3-coder-flash-2025-07-28","name":"qwen3-coder-flash-2025-07-28","display_name":"qwen3-coder-flash-2025-07-28","type":"chat","context_length":0,"max_output_tokens":0,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"developer":"Qwen","developerId":13,"providerId":17,"modelRatio":0.068,"cacheRatio":1,"completionRatio":4,"order":0,"flag":0,"billingConfig":"{\"model_name\": \"qwen3-coder-flash-2025-07-28\", \"default_tier\": \"tier1\", \"enabled_billing_items\": [\"prompt_tokens\", \"completion_tokens\", \"cached_tokens\"], \"token_based_tier_configs\": {\"tier1\": {\"model_ratio\": 0.068493, \"tier_condition\": {\"max_tokens\": 32000, \"min_tokens\": 0}, \"prompt_tokens_ratio\": 1.0, \"completion_tokens_ratio\": 4.0}, \"tier2\": {\"model_ratio\": 0.102739, \"tier_condition\": {\"max_tokens\": 128000, \"min_tokens\": 32001}, \"prompt_tokens_ratio\": 1.0, \"completion_tokens_ratio\": 4.0}, \"tier3\": {\"model_ratio\": 0.171232, \"tier_condition\": {\"max_tokens\": 256000, \"min_tokens\": 128001}, \"prompt_tokens_ratio\": 1.0, \"completion_tokens_ratio\": 4.0}, \"tier4\": {\"model_ratio\": 0.342465, \"tier_condition\": {\"max_tokens\": 1000000, \"min_tokens\": 256001}, \"prompt_tokens_ratio\": 1.0, \"completion_tokens_ratio\": 5.0}}}","source":"public-provider-conf"},"vision":false},{"id":"qwen3-coder-plus","name":"qwen3-coder-plus","display_name":"qwen3-coder-plus","type":"chat","context_length":0,"max_output_tokens":0,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"developer":"Qwen","developerId":13,"providerId":17,"modelRatio":0.27,"cacheRatio":0.2,"completionRatio":4,"description":"Qwen3Coding Agent","descriptionEn":"The code generation model based on Qwen3 has powerful Coding Agent capabilities, excels in tool invocation and environment interaction, and can achieve autonomous programming with outstanding coding abilities while also possessing general capabilities.The model adopts tiered pricing.","order":700,"flag":0,"billingConfig":"{\"model_name\": \"qwen3-coder-plus\", \"default_tier\": \"tier1\", \"enabled_billing_items\": [\"prompt_tokens\", \"completion_tokens\", \"cached_tokens\"], \"token_based_tier_configs\": {\"tier1\": {\"model_ratio\": 0.273972, \"tier_condition\": {\"max_tokens\": 32000, \"min_tokens\": 0}, \"prompt_tokens_ratio\": 1.0, \"completion_tokens_ratio\": 4.0}, \"tier2\": {\"model_ratio\": 0.410958, \"tier_condition\": {\"max_tokens\": 128000, \"min_tokens\": 32001}, \"prompt_tokens_ratio\": 1.0, \"completion_tokens_ratio\": 4.0}, \"tier3\": {\"model_ratio\": 0.684931, \"tier_condition\": {\"max_tokens\": 256000, \"min_tokens\": 128001}, \"prompt_tokens_ratio\": 1.0, \"completion_tokens_ratio\": 4.0}, \"tier4\": {\"model_ratio\": 1.369863, \"tier_condition\": {\"max_tokens\": 1000000, \"min_tokens\": 256001}, \"prompt_tokens_ratio\": 1.0, \"completion_tokens_ratio\": 10.0}}}","source":"public-provider-conf"},"vision":false},{"id":"qwen3-coder-plus-2025-07-22","name":"qwen3-coder-plus-2025-07-22","display_name":"qwen3-coder-plus-2025-07-22","type":"chat","context_length":0,"max_output_tokens":0,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"developer":"Qwen","developerId":13,"providerId":17,"modelRatio":0.27,"cacheRatio":1,"completionRatio":4,"description":"Qwen3Coding Agent","descriptionEn":"The code generation model based on Qwen3 has powerful Coding Agent capabilities, excels in tool invocation and environment interaction, and can achieve autonomous programming with outstanding coding abilities while also possessing general capabilities.The model adopts tiered pricing.","order":700,"flag":1,"billingConfig":"{\"model_name\": \"qwen3-coder-plus-2025-07-22\", \"default_tier\": \"tier1\", \"enabled_billing_items\": [\"prompt_tokens\", \"completion_tokens\", \"cached_tokens\"], \"token_based_tier_configs\": {\"tier1\": {\"model_ratio\": 0.273972, \"tier_condition\": {\"max_tokens\": 32000, \"min_tokens\": 0}, \"prompt_tokens_ratio\": 1.0, \"completion_tokens_ratio\": 4.0}, \"tier2\": {\"model_ratio\": 0.410958, \"tier_condition\": {\"max_tokens\": 128000, \"min_tokens\": 32001}, \"prompt_tokens_ratio\": 1.0, \"completion_tokens_ratio\": 4.0}, \"tier3\": {\"model_ratio\": 0.684931, \"tier_condition\": {\"max_tokens\": 256000, \"min_tokens\": 128001}, \"prompt_tokens_ratio\": 1.0, \"completion_tokens_ratio\": 4.0}, \"tier4\": {\"model_ratio\": 1.369863, \"tier_condition\": {\"max_tokens\": 1000000, \"min_tokens\": 256001}, \"prompt_tokens_ratio\": 1.0, \"completion_tokens_ratio\": 10.0}}}","source":"public-provider-conf"},"vision":false},{"id":"qwen3-embedding-0.6b","name":"qwen3-embedding-0.6b","display_name":"qwen3-embedding-0.6b","type":"embedding","context_length":0,"max_output_tokens":0,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"developer":"Qwen","developerId":13,"providerId":15,"modelRatio":0.034,"cacheRatio":1,"completionRatio":1,"description":"Qwen3 Embedding  Qwen  Qwen3 0.6B4B  8BQwen3 Embedding ","descriptionEn":"The Qwen3 Embedding model series is the latest proprietary model family from Qwen, specifically designed for text embedding and ranking tasks. Based on the dense base models of the Qwen3 series, it offers comprehensive text embedding and reranking models in various sizes (0.6B, 4B, and 8B). This series inherits the excellent multilingual capabilities, long-text understanding, and reasoning skills of its base models. The Qwen3 Embedding series demonstrates significant advancements in various text embedding and ranking tasks, including text retrieval, code retrieval, text classification, text clustering, and bilingual text mining.","order":600,"flag":0,"typeHints":["embedding"],"source":"public-provider-conf"},"vision":false},{"id":"qwen3-embedding-4b","name":"qwen3-embedding-4b","display_name":"qwen3-embedding-4b","type":"embedding","context_length":0,"max_output_tokens":0,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"developer":"Qwen","developerId":13,"providerId":15,"modelRatio":0.034,"cacheRatio":1,"completionRatio":1,"description":"Qwen3 Embedding  Qwen  Qwen3 0.6B4B  8BQwen3 Embedding \n","descriptionEn":"The Qwen3 Embedding model series is the latest proprietary model family from Qwen, specifically designed for text embedding and ranking tasks. Based on the dense base models of the Qwen3 series, it offers comprehensive text embedding and reranking models in various sizes (0.6B, 4B, and 8B). This series inherits the excellent multilingual capabilities, long-text understanding, and reasoning skills of its base models. The Qwen3 Embedding series demonstrates significant advancements in various text embedding and ranking tasks, including text retrieval, code retrieval, text classification, text clustering, and bilingual text mining.","order":600,"flag":0,"typeHints":["embedding"],"source":"public-provider-conf"},"vision":false},{"id":"qwen3-embedding-8b","name":"qwen3-embedding-8b","display_name":"qwen3-embedding-8b","type":"embedding","context_length":0,"max_output_tokens":0,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"developer":"Qwen","developerId":13,"providerId":15,"modelRatio":0.034,"cacheRatio":1,"completionRatio":1,"description":"Qwen3 Embedding  Qwen  Qwen3 0.6B4B  8BQwen3 Embedding \n","descriptionEn":"The Qwen3 Embedding model series is the latest proprietary model family from Qwen, specifically designed for text embedding and ranking tasks. Based on the dense base models of the Qwen3 series, it offers comprehensive text embedding and reranking models in various sizes (0.6B, 4B, and 8B). This series inherits the excellent multilingual capabilities, long-text understanding, and reasoning skills of its base models. The Qwen3 Embedding series demonstrates significant advancements in various text embedding and ranking tasks, including text retrieval, code retrieval, text classification, text clustering, and bilingual text mining.","order":600,"flag":0,"typeHints":["embedding"],"source":"public-provider-conf"},"vision":false},{"id":"qwen3-max","name":"qwen3-max","display_name":"qwen3-max","type":"chat","context_length":0,"max_output_tokens":0,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"developer":"Qwen","developerId":13,"providerId":17,"modelRatio":0.411,"cacheRatio":0.2,"completionRatio":4,"description":"3MaxpreviewSOTA","descriptionEn":"The Tongyi Qianwen 3 series Max model has undergone special upgrades in intelligent agent programming and tool invocation compared to the preview version. The officially released model this time reaches SOTA level in the field and is adapted to more complex intelligent agent scenarios.","order":800,"flag":1,"billingConfig":"{\n  \"model_name\": \"qwen3-max\",\n  \"default_tier\": \"tier1\",\n  \"token_based_tier_configs\": {\n    \"tier1\": {\n      \"tier_condition\": {\n        \"min_tokens\": 0,\n        \"max_tokens\": 32000\n      },\n      \"model_ratio\": 0.410958,\n      \"prompt_tokens_ratio\": 1.0,\n      \"completion_tokens_ratio\": 4.0,\n      \"cached_tokens_ratio\": 0.2\n    },\n    \"tier2\": {\n      \"tier_condition\": {\n        \"min_tokens\": 32001,\n        \"max_tokens\": 128000\n      },\n      \"model_ratio\": 0.684931,\n      \"prompt_tokens_ratio\": 1.0,\n      \"completion_tokens_ratio\": 4.0,\n      \"cached_tokens_ratio\": 0.2\n    },\n    \"tier3\": {\n      \"tier_condition\": {\n        \"min_tokens\": 128001,\n        \"max_tokens\": 256000\n      },\n      \"model_ratio\": 1.027397,\n      \"prompt_tokens_ratio\": 1.0,\n      \"completion_tokens_ratio\": 4.0,\n      \"cached_tokens_ratio\": 0.2\n    }\n  },\n  \"enabled_billing_items\": [\n    \"prompt_tokens\",\n    \"completion_tokens\",\n    \"cached_tokens\"\n  ]\n}","source":"public-provider-conf"},"vision":false},{"id":"qwen3-max-preview","name":"qwen3-max-preview","display_name":"qwen3-max-preview","type":"chat","context_length":0,"max_output_tokens":0,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"developer":"Qwen","developerId":13,"providerId":17,"modelRatio":0.411,"cacheRatio":1,"completionRatio":4,"description":"qwen3-max-previewQwen3 MaxPreviewQwen 2.5","descriptionEn":"The latest qwen3-max-preview model is the preview version of the Qwen3 series Max model. Compared to the Qwen 2.5 series, it features significant improvements in overall general capabilities, including enhanced bilingual (Chinese and English) text comprehension, complex instruction following, subjective open-task performance, multilingual abilities, and tool usage. Additionally, the model exhibits reduced knowledge hallucination.","order":705,"flag":1,"billingConfig":"{\n  \"model_name\": \"qwen3-max-preview\",\n  \"default_tier\": \"tier1\",\n  \"token_based_tier_configs\": {\n    \"tier1\": {\n      \"tier_condition\": {\n        \"min_tokens\": 0,\n        \"max_tokens\": 32000\n      },\n      \"model_ratio\": 0.410959,\n      \"prompt_tokens_ratio\": 1.0,\n      \"completion_tokens_ratio\": 4.0\n    },\n    \"tier2\": {\n      \"tier_condition\": {\n        \"min_tokens\": 32001,\n        \"max_tokens\": 128000\n      },\n      \"model_ratio\": 0.684932,\n      \"prompt_tokens_ratio\": 1.0,\n      \"completion_tokens_ratio\": 4.0\n    },\n    \"tier3\": {\n      \"tier_condition\": {\n        \"min_tokens\": 128001,\n        \"max_tokens\": 2520000\n      },\n      \"model_ratio\": 1.027397,\n      \"prompt_tokens_ratio\": 1.0,\n      \"completion_tokens_ratio\": 4.0\n    }\n  },\n  \"enabled_billing_items\": [\n    \"prompt_tokens\",\n    \"completion_tokens\",\n    \"cached_tokens\"\n  ]\n}","source":"public-provider-conf"},"vision":false},{"id":"qwen3-vl-235b-a22b-instruct","name":"qwen3-vl-235b-a22b-instruct","display_name":"qwen3-vl-235b-a22b-instruct","type":"chat","context_length":0,"max_output_tokens":0,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"developer":"Qwen","developerId":13,"providerId":17,"modelRatio":0.137,"cacheRatio":1,"completionRatio":4,"description":"Qwen3SOTA","descriptionEn":"The Qwen3 series open-source models include hybrid models, thinking models, and non-thinking models, with both reasoning capabilities and general abilities reaching industry SOTA levels at the same scale.","order":800,"flag":1,"source":"public-provider-conf"},"vision":false},{"id":"qwen3-vl-235b-a22b-thinking","name":"qwen3-vl-235b-a22b-thinking","display_name":"qwen3-vl-235b-a22b-thinking","type":"chat","context_length":0,"max_output_tokens":0,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"developer":"Qwen","developerId":13,"providerId":17,"modelRatio":0.137,"cacheRatio":1,"completionRatio":10,"description":"Qwen3SOTA","descriptionEn":"The Qwen3 series open-source models include hybrid models, thinking models, and non-thinking models, with both reasoning capabilities and general abilities reaching industry SOTA levels at the same scale.","order":800,"flag":1,"source":"public-provider-conf"},"vision":false},{"id":"qwen3-vl-plus","name":"qwen3-vl-plus","display_name":"qwen3-vl-plus","type":"chat","context_length":0,"max_output_tokens":0,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"developer":"Qwen","developerId":13,"providerId":17,"modelRatio":0.0685,"cacheRatio":0.2,"completionRatio":10,"description":"Qwen3OS Worldcoding","descriptionEn":"The Qwen3 series visual understanding model achieves an effective fusion of thinking and non-thinking modes. Its visual agent capabilities reach world-class levels on public test sets such as OS World. This version features comprehensive upgrades in visual coding, spatial perception, and multimodal reasoning; visual perception and recognition abilities are greatly enhanced, supporting ultra-long video understanding.","order":800,"flag":1,"billingConfig":"{\n  \"model_name\": \"qwen3-vl-plus\",\n  \"default_tier\": \"tier1\",\n  \"token_based_tier_configs\": {\n    \"tier1\": {\n      \"tier_condition\": {\n        \"min_tokens\": 0,\n        \"max_tokens\": 32000\n      },\n      \"model_ratio\": 0.068493,\n      \"prompt_tokens_ratio\": 1.0,\n      \"completion_tokens_ratio\": 10.0,\n      \"cached_tokens_ratio\": 0.2\n    },\n    \"tier2\": {\n      \"tier_condition\": {\n        \"min_tokens\": 32001,\n        \"max_tokens\": 128000\n      },\n      \"model_ratio\": 0.102739,\n      \"prompt_tokens_ratio\": 1.0,\n      \"completion_tokens_ratio\": 10.0,\n      \"cached_tokens_ratio\": 0.2\n    },\n    \"tier3\": {\n      \"tier_condition\": {\n        \"min_tokens\": 128001,\n        \"max_tokens\": 256000\n      },\n      \"model_ratio\": 0.205479,\n      \"prompt_tokens_ratio\": 1.0,\n      \"completion_tokens_ratio\": 10.0,\n      \"cached_tokens_ratio\": 0.2\n    }\n  },\n  \"enabled_billing_items\": [\n    \"prompt_tokens\",\n    \"completion_tokens\",\n    \"cached_tokens\"\n  ]\n}","source":"public-provider-conf"},"vision":false},{"id":"sora-2","name":"sora-2","display_name":"sora-2","type":"chat","context_length":0,"max_output_tokens":0,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"developer":"OpenAI","developerId":12,"providerId":1,"modelRatio":10,"cacheRatio":1,"completionRatio":1,"description":" OpenAI sora-2 api api chat ","descriptionEn":"This model is an unofficial reverse-engineered API of the OpenAI web version sora-2. The official API has not been formally released to the public and is for entertainment purposes only; charges apply per request regardless of success or failure; please do not use if you mind this; it can be used via the chat interface.","order":900,"flag":1,"source":"public-provider-conf"},"vision":false},{"id":"step-2-16k","name":"step-2","display_name":"step-2","type":"chat","context_length":0,"max_output_tokens":0,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"developer":"","developerId":16,"providerId":8,"modelRatio":1,"cacheRatio":1,"completionRatio":1,"order":0,"flag":0,"source":"public-provider-conf"},"vision":false},{"id":"stepfun-ai/step3","name":"stepfun-ai/step3","display_name":"stepfun-ai/step3","type":"chat","context_length":0,"max_output_tokens":0,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"developer":"StepFun","developerId":16,"providerId":8,"modelRatio":0.55,"cacheRatio":1,"completionRatio":2.5,"description":"Step3  StepFun  321B 38B  MoE MFAFFN AFDStep3  20T  token  4T  token Step3 ","descriptionEn":"Step3 is a multimodal reasoning model released by StepFun. It uses a MixtureofExperts (MoE) architecture with 321billion total parameters and 38billion activation parameters. The model follows an endtoend design that reduces decoding cost while delivering toptier performance on visionlanguage reasoning tasks. Thanks to the combined use of MultiHead Factorized Attention (MFA) and AttentionFFN Decoupling (AFD), Step3 remains highly efficient on both flagship and lowend accelerators. During pretraining, it processed over 20trillion text tokens and 4trillion imagetext mixed tokens, covering more than ten languages. On benchmarks for mathematics, code, and multimodal tasks, Step3 consistently outperforms other opensource models.","order":50,"flag":1,"source":"public-provider-conf"},"vision":false},{"id":"tao-8k","name":"tao-8k","display_name":"tao-8k","type":"embedding","context_length":0,"max_output_tokens":0,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"developer":"Baidu","developerId":25,"providerId":15,"modelRatio":0.034,"cacheRatio":1,"completionRatio":1,"description":"tao-8kHuggingfaceamu8kC-MTEBembeddings","order":600,"flag":0,"typeHints":["embedding"],"source":"public-provider-conf"},"vision":false},{"id":"tencent/Hunyuan-A13B-Instruct","name":"tencent/Hunyuan-A13B-Instruct","display_name":"tencent/Hunyuan-A13B-Instruct","type":"chat","context_length":0,"max_output_tokens":0,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"developer":"Hunyuan","developerId":24,"providerId":8,"modelRatio":0.07,"cacheRatio":1,"completionRatio":4,"description":"Hunyuan-A13B-Instruct 800  130 / BFCL-v3  -Bench Agent  GQA ","descriptionEn":"Hunyuan-A13B-Instruct has 8 billion parameters and can match larger models by activating only 1.3 billion parameters, supporting \"fast thinking/slow thinking\" hybrid inference. It offers stable long text understanding. Verified by BFCL-v3 and -Bench, its Agent capabilities are leading in the field. Combined with GQA and multiple quantization formats, it enables efficient inference.","order":100,"flag":1,"source":"public-provider-conf"},"vision":false},{"id":"tencent/Hunyuan-MT-7B","name":"tencent/Hunyuan-MT-7B","display_name":"tencent/Hunyuan-MT-7B","type":"chat","context_length":0,"max_output_tokens":0,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"developer":"Hunyuan","developerId":24,"providerId":23,"modelRatio":0.1,"cacheRatio":1,"completionRatio":1,"description":"Hunyuan-MT-7B  70  33  5  WMT25 Hunyuan-MT-7B  31  30 ","descriptionEn":"Hunyuan-MT-7B is a lightweight translation model with 7 billion parameters, designed to translate source text into target languages. The model supports translation among 33 languages as well as 5 Chinese minority languages. In the WMT25 International Machine Translation Competition, Hunyuan-MT-7B achieved first place in 30 out of 31 language categories it participated in, demonstrating its exceptional translation capabilities. For translation scenarios, Tencent Hunyuan proposed a complete training paradigm from pre-training to supervised fine-tuning, followed by translation reinforcement and ensemble reinforcement, enabling it to achieve industry-leading performance among models of similar scale. The model is computationally efficient, easy to deploy, and suitable for various application scenarios.","order":90,"flag":0,"source":"public-provider-conf"},"vision":false},{"id":"text-ada-001","name":"text-ada-001","display_name":"text-ada-001","type":"chat","context_length":0,"max_output_tokens":0,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"developer":"OpenAI","developerId":12,"providerId":1,"modelRatio":0.2,"cacheRatio":1,"completionRatio":1,"order":0,"flag":0,"source":"public-provider-conf"},"vision":false},{"id":"text-babbage-001","name":"text-babbage-001","display_name":"text-babbage-001","type":"chat","context_length":0,"max_output_tokens":0,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"developer":"OpenAI","developerId":12,"providerId":1,"modelRatio":0.25,"cacheRatio":1,"completionRatio":1,"order":0,"flag":0,"source":"public-provider-conf"},"vision":false},{"id":"text-davinci-002","name":"text-davinci","display_name":"text-davinci","type":"chat","context_length":0,"max_output_tokens":0,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"developer":"OpenAI","developerId":12,"providerId":1,"modelRatio":10,"cacheRatio":1,"completionRatio":1,"order":0,"flag":0,"source":"public-provider-conf"},"vision":false},{"id":"text-davinci-003","name":"text-davinci","display_name":"text-davinci","type":"chat","context_length":0,"max_output_tokens":0,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"developer":"OpenAI","developerId":12,"providerId":1,"modelRatio":10,"cacheRatio":1,"completionRatio":1,"order":0,"flag":0,"source":"public-provider-conf"},"vision":false},{"id":"text-davinci-edit-001","name":"text-davinci-edit-001","display_name":"text-davinci-edit-001","type":"chat","context_length":0,"max_output_tokens":0,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"developer":"OpenAI","developerId":12,"providerId":1,"modelRatio":10,"cacheRatio":1,"completionRatio":1,"order":0,"flag":0,"source":"public-provider-conf"},"vision":false},{"id":"text-embedding-004","name":"text-embedding-004","display_name":"text-embedding-004","type":"chat","context_length":0,"max_output_tokens":0,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"developer":"Google","developerId":8,"providerId":24,"modelRatio":0.01,"cacheRatio":1,"completionRatio":1,"order":34,"flag":1,"source":"public-provider-conf"},"vision":false},{"id":"text-embedding-3-large","name":"text-embedding-3-large","display_name":"text-embedding-3-large","type":"embedding","context_length":0,"max_output_tokens":0,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"modalities":{"input":["text"],"output":["text"]},"metadata":{"developer":"OpenAI","developerId":12,"providerId":1,"modelRatio":0.065,"cacheRatio":1,"completionRatio":1,"order":0,"flag":0,"modalities":["text"],"typeHints":["embedding"],"source":"public-provider-conf"},"vision":false},{"id":"text-embedding-3-small","name":"text-embedding-3-small","display_name":"text-embedding-3-small","type":"embedding","context_length":0,"max_output_tokens":0,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"modalities":{"input":["text"],"output":["text"]},"metadata":{"developer":"OpenAI","developerId":12,"providerId":1,"modelRatio":0.01,"cacheRatio":1,"completionRatio":1,"order":0,"flag":0,"modalities":["text"],"typeHints":["embedding"],"source":"public-provider-conf"},"vision":false},{"id":"text-embedding-ada-002","name":"text-embedding-ada-002","display_name":"text-embedding-ada-002","type":"embedding","context_length":0,"max_output_tokens":0,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"modalities":{"input":["text"],"output":["text"]},"metadata":{"developer":"OpenAI","developerId":12,"providerId":1,"modelRatio":0.05,"cacheRatio":1,"completionRatio":1,"order":0,"flag":0,"modalities":["text"],"typeHints":["embedding"],"source":"public-provider-conf"},"vision":false},{"id":"text-embedding-v4","name":"text-embedding-v4","display_name":"text-embedding-v4","type":"embedding","context_length":0,"max_output_tokens":0,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"developer":"Qwen","developerId":13,"providerId":17,"modelRatio":0.04,"cacheRatio":1,"completionRatio":1,"description":"Qwen3V3MTEBCode15%~40%64~2048","descriptionEn":"This is the Tongyi Laboratory's multilingual unified text vector model trained based on Qwen3, which significantly improves performance in text retrieval, clustering, and classification compared to version V3; it achieves a 15% to 40% improvement on evaluation tasks such as MTEB multilingual, Chinese-English, and code retrieval; supports user-defined vector dimensions ranging from 64 to 2048.","order":50,"flag":1,"typeHints":["embedding"],"source":"public-provider-conf"},"vision":false},{"id":"text-moderation-stable","name":"text-moderation","display_name":"text-moderation","type":"chat","context_length":0,"max_output_tokens":0,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"developer":"OpenAI","developerId":12,"providerId":1,"modelRatio":0.1,"cacheRatio":1,"completionRatio":1,"order":0,"flag":0,"source":"public-provider-conf"},"vision":false},{"id":"tngtech/DeepSeek-R1T-Chimera","name":"tngtech/DeepSeek-R1T-Chimera","display_name":"tngtech/DeepSeek-R1T-Chimera","type":"chat","context_length":0,"max_output_tokens":0,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"developer":"DeepSeek","developerId":7,"providerId":8,"modelRatio":0.01,"cacheRatio":1,"completionRatio":1,"description":"chutes.ai\nDeepSeek-R1T-Chimera  DeepSeek-R1  DeepSeek-V30324 MoE Transformer  MIT ","descriptionEn":"Provided by chutes.ai\nDeepSeek-R1T-Chimera merges DeepSeek-R1s reasoning strengths with DeepSeek-V3 (0324)s token-efficiency improvements into a MoE Transformer optimized for general text generation. It integrates pretrained weights from both models and is released under the MIT license for research and commercial use.\n","order":150,"flag":0,"source":"public-provider-conf"},"vision":false},{"id":"tts-1","name":"tts-1","display_name":"tts-1","type":"audio","context_length":0,"max_output_tokens":0,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"modalities":{"input":["audio"],"output":["audio"]},"metadata":{"developer":"OpenAI","developerId":12,"providerId":1,"modelRatio":7.5,"cacheRatio":1,"completionRatio":1,"order":0,"flag":0,"modalities":["audio"],"typeHints":["tts"],"source":"public-provider-conf"},"vision":false},{"id":"tts-1-hd","name":"tts-1-hd","display_name":"tts-1-hd","type":"audio","context_length":0,"max_output_tokens":0,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"modalities":{"input":["audio"],"output":["audio"]},"metadata":{"developer":"OpenAI","developerId":12,"providerId":1,"modelRatio":15,"cacheRatio":1,"completionRatio":1,"order":0,"flag":0,"modalities":["audio"],"typeHints":["tts"],"source":"public-provider-conf"},"vision":false},{"id":"unsloth/gemma-3-12b-it","name":"gemma-3-12b","display_name":"gemma-3-12b","type":"chat","context_length":0,"max_output_tokens":0,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"developer":"Google","developerId":8,"providerId":8,"modelRatio":0.1,"cacheRatio":0,"completionRatio":4,"description":"chutes.ai","descriptionEn":"Provided by chutes.ai.","order":99,"flag":0,"source":"public-provider-conf"},"vision":false},{"id":"unsloth/gemma-3-27b-it","name":"gemma-3-27b","display_name":"gemma-3-27b","type":"chat","context_length":0,"max_output_tokens":0,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"developer":"Google","developerId":8,"providerId":8,"modelRatio":0.11,"cacheRatio":0,"completionRatio":1,"description":"chutes.ai","descriptionEn":"Google's latest open-source model; provided by chutes.ai","order":100,"flag":1,"source":"public-provider-conf"},"vision":false},{"id":"veo-2.0-generate-001","name":"veo-2.0-generate-001","display_name":"veo-2.0-generate-001","type":"chat","context_length":0,"max_output_tokens":0,"capabilities":{"vision":true,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"modalities":{"input":["video"],"output":["video"]},"metadata":{"developer":"Google","developerId":8,"providerId":24,"modelRatio":1,"cacheRatio":0,"completionRatio":1,"description":"Veo 2.0 Veo 2.0 720p 8 ","descriptionEn":"Veo 2.0 is an advanced video generation model capable of producing high-quality videos based on text or image prompts. It excels in understanding real-world physics and human motion, resulting in fluid character movements and lifelike scenes. Veo 2.0 supports various visual styles and camera control options, including lens types, angles, and motion effects. Users can generate 8-second video clips at 720p resolution.","order":820,"flag":1,"displayInput":"-","displayOutput":"$ 0.35 / S","imagePriceConfig":"{\"generate\":{\"standard\":{\"standard\":0.35}}}","tags":["multi_modal"],"modalities":["video"],"typeHints":["t2v"],"source":"public-provider-conf"},"vision":true},{"id":"veo-3","name":"veo3","display_name":"veo3","type":"chat","context_length":0,"max_output_tokens":0,"capabilities":{"vision":true,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"modalities":{"input":["text","image","audio","video"],"output":["text","image","audio","video"]},"metadata":{"developer":"Google","developerId":8,"providerId":1,"modelRatio":1,"cacheRatio":0,"completionRatio":1,"description":"veo3 OpenAI chat  $0.41","descriptionEn":"veo3 reverse access with a total cost of just $0.41 per video generation., OpenAI chat port compatible format.","order":0,"flag":1,"displayInput":"-","displayOutput":"$ 0.41 / Request","tags":["multi_modal"],"modalities":["text","image","audio","video"],"typeHints":["t2v"],"source":"public-provider-conf"},"vision":true},{"id":"veo-3.0-generate-preview","name":"veo-3.0-generate-preview","display_name":"veo-3.0-generate-preview","type":"chat","context_length":0,"max_output_tokens":0,"capabilities":{"vision":true,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"modalities":{"input":["text","image","video"],"output":["text","image","video"]},"metadata":{"developer":"Google","developerId":8,"providerId":24,"modelRatio":1,"cacheRatio":0,"completionRatio":1,"description":" Veo 3.0 AI  10% \n","descriptionEn":" Veo 3.0 Generate Preview is an advanced AI video generation model that supports text-to-video creation with synchronized audio, featuring excellent physical simulation and lip-sync capabilities. Users can generate vivid video clips from short story prompts.  Limited-Time Deal: Save 10% Now.","order":800,"flag":1,"displayInput":"-","displayOutput":"$0.75 / S","imagePriceConfig":"{\"generate\":{\"standard\":{\"standard\":0.75}}}","tags":["multi_modal"],"modalities":["text","image","video"],"typeHints":["t2v"],"source":"public-provider-conf"},"vision":true},{"id":"whisper-1","name":"whisper-1","display_name":"whisper-1","type":"chat","context_length":0,"max_output_tokens":0,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"developer":"OpenAI","developerId":12,"providerId":1,"modelRatio":50,"cacheRatio":1,"completionRatio":1,"description":"","descriptionEn":"Ignore the displayed price on the page; the actual charge for this model request is consistent with the official, so you can use it with confidence.","order":0,"flag":0,"displayInput":"-","displayOutput":"Transcription: $ 0.006 /Minutes","typeHints":["stt"],"source":"public-provider-conf"},"vision":false},{"id":"whisper-large-v3","name":"whisper-large","display_name":"whisper-large","type":"chat","context_length":0,"max_output_tokens":0,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"developer":"OpenAI","developerId":12,"providerId":29,"modelRatio":15.417,"cacheRatio":1,"completionRatio":1,"order":0,"flag":0,"typeHints":["stt"],"source":"public-provider-conf"},"vision":false},{"id":"yi-large","name":"yi-large","display_name":"yi-large","type":"chat","context_length":0,"max_output_tokens":0,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"developer":"","developerId":14,"providerId":31,"modelRatio":1.5,"cacheRatio":1,"completionRatio":1,"order":0,"flag":0,"source":"public-provider-conf"},"vision":false},{"id":"yi-large-rag","name":"yi-large-rag","display_name":"yi-large-rag","type":"chat","context_length":0,"max_output_tokens":0,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"developer":"","developerId":14,"providerId":31,"modelRatio":2,"cacheRatio":1,"completionRatio":1,"order":0,"flag":0,"source":"public-provider-conf"},"vision":false},{"id":"yi-large-turbo","name":"yi-large-turbo","display_name":"yi-large-turbo","type":"chat","context_length":0,"max_output_tokens":0,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"developer":"","developerId":14,"providerId":31,"modelRatio":0.9,"cacheRatio":1,"completionRatio":1,"order":0,"flag":0,"source":"public-provider-conf"},"vision":false},{"id":"yi-lightning","name":"yi-lightning","display_name":"yi-lightning","type":"chat","context_length":0,"max_output_tokens":0,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"developer":"","developerId":14,"providerId":31,"modelRatio":0.1,"cacheRatio":1,"completionRatio":1,"order":0,"flag":0,"source":"public-provider-conf"},"vision":false},{"id":"yi-medium","name":"yi-medium","display_name":"yi-medium","type":"chat","context_length":0,"max_output_tokens":0,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"developer":"","developerId":14,"providerId":31,"modelRatio":0.2,"cacheRatio":1,"completionRatio":1,"order":0,"flag":0,"source":"public-provider-conf"},"vision":false},{"id":"yi-vl-plus","name":"yi-vl-plus","display_name":"yi-vl-plus","type":"chat","context_length":0,"max_output_tokens":0,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"developer":"","developerId":14,"providerId":8,"modelRatio":0.000426,"cacheRatio":1,"completionRatio":1,"order":0,"flag":0,"source":"public-provider-conf"},"vision":false},{"id":"zai-org/GLM-4.5","name":"zai-org/GLM-4.5","display_name":"zai-org/GLM-4.5","type":"chat","context_length":0,"max_output_tokens":0,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"developer":"ChatGLM","developerId":5,"providerId":44,"modelRatio":0.25,"cacheRatio":1,"completionRatio":4,"description":"zai-org/GLM-4.5","descriptionEn":"zai-org/GLM-4.5","order":800,"flag":1,"source":"public-provider-conf"},"vision":false},{"id":"zai-org/GLM-4.5-Air","name":"zai-org/GLM-4.5-Air","display_name":"zai-org/GLM-4.5-Air","type":"chat","context_length":0,"max_output_tokens":0,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"developer":"ChatGLM","developerId":5,"providerId":44,"modelRatio":0.07,"cacheRatio":1,"completionRatio":6,"description":"zai-org/GLM-4.5-Air\n","descriptionEn":"zai-org/GLM-4.5-Air\nsiliconflow","order":799,"flag":1,"source":"public-provider-conf"},"vision":false}],"metadata":{"upstream":"aihubmix-api","fetchedAt":"2025-10-03T14:35:02.898Z","modelCount":444,"source":"public-provider-conf"}},"doubao":{"id":"doubao","name":"Doubao","display_name":"Doubao","metadata":{"source":"public-provider-conf-template"},"models":[{"id":"deepseek-v3-1-250821","name":"DeepSeek V3.1","display_name":"DeepSeek V3.1","type":"chat","context_length":128000,"max_output_tokens":32000,"capabilities":{"vision":false,"function_calling":true,"reasoning":false},"metadata":{"source":"public-provider-conf-template"}},{"id":"deepseek-r1-250120","name":"DeepSeek R1","display_name":"DeepSeek R1","type":"chat","context_length":64000,"max_output_tokens":4096,"capabilities":{"vision":false,"function_calling":false,"reasoning":true},"metadata":{"source":"public-provider-conf-template"}},{"id":"deepseek-r1-distill-qwen-32b-250120","name":"DeepSeek R1 Distill Qwen 32B","display_name":"DeepSeek R1 Distill Qwen 32B","type":"chat","context_length":32000,"max_output_tokens":4096,"capabilities":{"vision":false,"function_calling":false,"reasoning":true},"metadata":{"source":"public-provider-conf-template"}},{"id":"deepseek-r1-distill-qwen-7b-250120","name":"DeepSeek R1 Distill Qwen 7B","display_name":"DeepSeek R1 Distill Qwen 7B","type":"chat","context_length":32000,"max_output_tokens":4096,"capabilities":{"vision":false,"function_calling":false,"reasoning":true},"metadata":{"source":"public-provider-conf-template"}},{"id":"deepseek-v3-250324","name":"DeepSeek V3","display_name":"DeepSeek V3","type":"chat","context_length":64000,"max_output_tokens":4096,"capabilities":{"vision":false,"function_calling":true,"reasoning":false},"metadata":{"source":"public-provider-conf-template"}},{"id":"doubao-seed-1-6-vision-250815","name":"Doubao Seed 1.6 Vision","display_name":"Doubao Seed 1.6 Vision","type":"chat","context_length":256000,"max_output_tokens":32000,"capabilities":{"vision":true,"function_calling":true,"reasoning":true},"metadata":{"source":"public-provider-conf-template"}},{"id":"doubao-seed-1-6-250615","name":"Doubao Seed 1.6","display_name":"Doubao Seed 1.6","type":"chat","context_length":256000,"max_output_tokens":32000,"capabilities":{"vision":true,"function_calling":true,"reasoning":true},"metadata":{"source":"public-provider-conf-template"}},{"id":"doubao-seed-1-6-flash-250715","name":"Doubao Seed 1.6 Flash","display_name":"Doubao Seed 1.6 Flash","type":"chat","context_length":256000,"max_output_tokens":32000,"capabilities":{"vision":true,"function_calling":true,"reasoning":true},"metadata":{"source":"public-provider-conf-template"}},{"id":"doubao-seed-1-6-flash-250615","name":"Doubao Seed 1.6 Flash (250615)","display_name":"Doubao Seed 1.6 Flash (250615)","type":"chat","context_length":256000,"max_output_tokens":32000,"capabilities":{"vision":true,"function_calling":true,"reasoning":true},"metadata":{"source":"public-provider-conf-template"}},{"id":"doubao-seed-1-6-thinking-250715","name":"Doubao Seed 1.6 Thinking","display_name":"Doubao Seed 1.6 Thinking","type":"chat","context_length":256000,"max_output_tokens":32000,"capabilities":{"vision":true,"function_calling":true,"reasoning":true},"metadata":{"source":"public-provider-conf-template"}},{"id":"doubao-seed-1-6-thinking-250615","name":"Doubao Seed 1.6 Thinking (250615)","display_name":"Doubao Seed 1.6 Thinking (250615)","type":"chat","context_length":256000,"max_output_tokens":32000,"capabilities":{"vision":true,"function_calling":true,"reasoning":true},"metadata":{"source":"public-provider-conf-template"}}]},"ollama":{"id":"ollama","name":"Ollama","display_name":"Ollama","metadata":{"source":"public-provider-conf-template"},"models":[{"id":"gpt-oss:20b","name":"GPT-OSS 20B","display_name":"GPT-OSS 20B","type":"chat","context_length":128000,"max_output_tokens":16000,"capabilities":{"vision":false,"function_calling":true,"reasoning":true},"metadata":{"source":"public-provider-conf-template"}},{"id":"gpt-oss:120b","name":"GPT-OSS 120B","display_name":"GPT-OSS 120B","type":"chat","context_length":128000,"max_output_tokens":32000,"capabilities":{"vision":false,"function_calling":true,"reasoning":true},"metadata":{"source":"public-provider-conf-template"}},{"id":"deepseek-r1:1.5b","name":"DeepSeek R1 1.5B","display_name":"DeepSeek R1 1.5B","type":"chat","context_length":65536,"max_output_tokens":32768,"capabilities":{"vision":false,"function_calling":false,"reasoning":true},"metadata":{"source":"public-provider-conf-template"}},{"id":"deepseek-r1:7b","name":"DeepSeek R1 7B","display_name":"DeepSeek R1 7B","type":"chat","context_length":65536,"max_output_tokens":32768,"capabilities":{"vision":false,"function_calling":false,"reasoning":true},"metadata":{"source":"public-provider-conf-template"}},{"id":"deepseek-r1:8b","name":"DeepSeek R1 8B","display_name":"DeepSeek R1 8B","type":"chat","context_length":65536,"max_output_tokens":32768,"capabilities":{"vision":false,"function_calling":false,"reasoning":true},"metadata":{"source":"public-provider-conf-template"}},{"id":"deepseek-r1:14b","name":"DeepSeek R1 14B","display_name":"DeepSeek R1 14B","type":"chat","context_length":65536,"max_output_tokens":32768,"capabilities":{"vision":false,"function_calling":false,"reasoning":true},"metadata":{"source":"public-provider-conf-template"}},{"id":"deepseek-r1:32b","name":"DeepSeek R1 32B","display_name":"DeepSeek R1 32B","type":"chat","context_length":65536,"max_output_tokens":32768,"capabilities":{"vision":false,"function_calling":false,"reasoning":true},"metadata":{"source":"public-provider-conf-template"}},{"id":"deepseek-r1:70b","name":"DeepSeek R1 70B","display_name":"DeepSeek R1 70B","type":"chat","context_length":131072,"max_output_tokens":32768,"capabilities":{"vision":false,"function_calling":false,"reasoning":true},"metadata":{"source":"public-provider-conf-template"}},{"id":"deepseek-r1:671b","name":"DeepSeek R1 671B","display_name":"DeepSeek R1 671B","type":"chat","context_length":131072,"max_output_tokens":65536,"capabilities":{"vision":false,"function_calling":false,"reasoning":true},"metadata":{"source":"public-provider-conf-template"}},{"id":"deepseek-v3:671b","name":"DeepSeek V3 671B","display_name":"DeepSeek V3 671B","type":"chat","context_length":131072,"max_output_tokens":32768,"capabilities":{"vision":false,"function_calling":true,"reasoning":false},"metadata":{"source":"public-provider-conf-template"}},{"id":"deepseek-v2.5:236b","name":"DeepSeek V2.5 236B","display_name":"DeepSeek V2.5 236B","type":"chat","context_length":131072,"max_output_tokens":32768,"capabilities":{"vision":false,"function_calling":true,"reasoning":false},"metadata":{"source":"public-provider-conf-template"}},{"id":"gemma3:1b","name":"Gemma3 1B","display_name":"Gemma3 1B","type":"chat","context_length":32768,"max_output_tokens":8192,"capabilities":{"vision":false,"function_calling":true,"reasoning":false},"metadata":{"source":"public-provider-conf-template"}},{"id":"gemma3:4b","name":"Gemma3 4B","display_name":"Gemma3 4B","type":"chat","context_length":32768,"max_output_tokens":8192,"capabilities":{"vision":false,"function_calling":true,"reasoning":false},"metadata":{"source":"public-provider-conf-template"}},{"id":"gemma3:12b","name":"Gemma3 12B","display_name":"Gemma3 12B","type":"chat","context_length":65536,"max_output_tokens":16384,"capabilities":{"vision":false,"function_calling":true,"reasoning":false},"metadata":{"source":"public-provider-conf-template"}},{"id":"gemma3:27b","name":"Gemma3 27B","display_name":"Gemma3 27B","type":"chat","context_length":65536,"max_output_tokens":16384,"capabilities":{"vision":false,"function_calling":true,"reasoning":false},"metadata":{"source":"public-provider-conf-template"}}]},"ppinfra":{"id":"ppinfra","models":[{"id":"deepseek/deepseek-r1-0528","context_length":128000,"max_output_tokens":16000,"name":"deepseek/deepseek-r1-0528","display_name":"deepseek/deepseek-r1-0528"},{"id":"deepseek/deepseek-v3-0324","context_length":128000,"max_output_tokens":16000,"name":"deepseek/deepseek-v3-0324","display_name":"deepseek/deepseek-v3-0324"},{"id":"deepseek/deepseek-prover-v2-671b","reasoning":true,"capabilities":{"reasoning":true},"name":"deepseek/deepseek-prover-v2-671b","display_name":"deepseek/deepseek-prover-v2-671b"},{"id":"meta-llama/llama-3.3-70b-instruct","type":"chat","context_length":131072,"max_output_tokens":8000,"capabilities":{"vision":false,"function_calling":false,"reasoning":true},"name":"meta-llama/llama-3.3-70b-instruct","display_name":"meta-llama/llama-3.3-70b-instruct"}],"name":"ppinfra","display_name":"ppinfra"},"siliconflow":{"id":"siliconflow","name":"SiliconFlow","display_name":"SiliconFlow","metadata":{"source":"public-provider-conf-template"},"models":[{"id":"deepseek-r1:32b","name":"DeepSeek R1 32B","display_name":"DeepSeek R1 32B","type":"chat","context_length":65536,"max_output_tokens":32768,"capabilities":{"vision":false,"function_calling":false,"reasoning":true},"metadata":{"source":"public-provider-conf-template"}},{"id":"deepseek-v2.5:236b","name":"DeepSeek V2.5 236B","display_name":"DeepSeek V2.5 236B","type":"chat","context_length":131072,"max_output_tokens":32768,"capabilities":{"vision":false,"function_calling":true,"reasoning":false},"metadata":{"source":"public-provider-conf-template"}},{"id":"deepseek-r1:7b","name":"DeepSeek R1 7B","display_name":"DeepSeek R1 7B","type":"chat","context_length":65536,"max_output_tokens":32768,"capabilities":{"vision":false,"function_calling":false,"reasoning":true},"metadata":{"source":"public-provider-conf-template"}},{"id":"gpt-oss:120b","name":"GPT-OSS 120B","display_name":"GPT-OSS 120B","type":"chat","context_length":128000,"max_output_tokens":32000,"capabilities":{"vision":false,"function_calling":true,"reasoning":true},"metadata":{"source":"public-provider-conf-template"}},{"id":"gemma3:1b","name":"Gemma3 1B","display_name":"Gemma3 1B","type":"chat","context_length":32768,"max_output_tokens":8192,"capabilities":{"vision":false,"function_calling":true,"reasoning":false},"metadata":{"source":"public-provider-conf-template"}},{"id":"deepseek-r1:70b","name":"DeepSeek R1 70B","display_name":"DeepSeek R1 70B","type":"chat","context_length":131072,"max_output_tokens":32768,"capabilities":{"vision":false,"function_calling":false,"reasoning":true},"metadata":{"source":"public-provider-conf-template"}},{"id":"deepseek-r1:14b","name":"DeepSeek R1 14B","display_name":"DeepSeek R1 14B","type":"chat","context_length":65536,"max_output_tokens":32768,"capabilities":{"vision":false,"function_calling":false,"reasoning":true},"metadata":{"source":"public-provider-conf-template"}},{"id":"gemma3:27b","name":"Gemma3 27B","display_name":"Gemma3 27B","type":"chat","context_length":65536,"max_output_tokens":16384,"capabilities":{"vision":false,"function_calling":true,"reasoning":false},"metadata":{"source":"public-provider-conf-template"}},{"id":"gemma3:12b","name":"Gemma3 12B","display_name":"Gemma3 12B","type":"chat","context_length":65536,"max_output_tokens":16384,"capabilities":{"vision":false,"function_calling":true,"reasoning":false},"metadata":{"source":"public-provider-conf-template"}},{"id":"gpt-oss:20b","name":"GPT-OSS 20B","display_name":"GPT-OSS 20B","type":"chat","context_length":128000,"max_output_tokens":16000,"capabilities":{"vision":false,"function_calling":true,"reasoning":true},"metadata":{"source":"public-provider-conf-template"}},{"id":"deepseek-r1:671b","name":"DeepSeek R1 671B","display_name":"DeepSeek R1 671B","type":"chat","context_length":131072,"max_output_tokens":65536,"capabilities":{"vision":false,"function_calling":false,"reasoning":true},"metadata":{"source":"public-provider-conf-template"}},{"id":"gemma3:4b","name":"Gemma3 4B","display_name":"Gemma3 4B","type":"chat","context_length":32768,"max_output_tokens":8192,"capabilities":{"vision":false,"function_calling":true,"reasoning":false},"metadata":{"source":"public-provider-conf-template"}},{"id":"deepseek-r1:8b","name":"DeepSeek R1 8B","display_name":"DeepSeek R1 8B","type":"chat","context_length":65536,"max_output_tokens":32768,"capabilities":{"vision":false,"function_calling":false,"reasoning":true},"metadata":{"source":"public-provider-conf-template"}},{"id":"deepseek-r1:1.5b","name":"DeepSeek R1 1.5B","display_name":"DeepSeek R1 1.5B","type":"chat","context_length":65536,"max_output_tokens":32768,"capabilities":{"vision":false,"function_calling":false,"reasoning":true},"metadata":{"source":"public-provider-conf-template"}},{"id":"deepseek-v3:671b","name":"DeepSeek V3 671B","display_name":"DeepSeek V3 671B","type":"chat","context_length":131072,"max_output_tokens":32768,"capabilities":{"vision":false,"function_calling":true,"reasoning":false},"metadata":{"source":"public-provider-conf-template"}}]},"tokenflux":{"id":"tokenflux","name":"Tokenflux","display_name":"Tokenflux","updated_at":"2025-10-03T14:35:07.383Z","models":[{"id":"agentica-org/deepcoder-14b-preview","name":"Agentica: Deepcoder 14B Preview","display_name":"Agentica: Deepcoder 14B Preview","type":"chat","context_length":4096,"max_output_tokens":4096,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"source":"public-provider-conf"},"vision":false},{"id":"ai21/jamba-large-1.7","name":"AI21: Jamba Large 1.7","display_name":"AI21: Jamba Large 1.7","type":"chat","context_length":4096,"max_output_tokens":4096,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"source":"public-provider-conf"},"vision":false},{"id":"ai21/jamba-mini-1.7","name":"AI21: Jamba Mini 1.7","display_name":"AI21: Jamba Mini 1.7","type":"chat","context_length":4096,"max_output_tokens":4096,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"source":"public-provider-conf"},"vision":false},{"id":"aion-labs/aion-1.0","name":"AionLabs: Aion-1.0","display_name":"AionLabs: Aion-1.0","type":"chat","context_length":4096,"max_output_tokens":4096,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"source":"public-provider-conf"},"vision":false},{"id":"aion-labs/aion-1.0-mini","name":"AionLabs: Aion-1.0-Mini","display_name":"AionLabs: Aion-1.0-Mini","type":"chat","context_length":4096,"max_output_tokens":4096,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"source":"public-provider-conf"},"vision":false},{"id":"aion-labs/aion-rp-llama-3.1-8b","name":"AionLabs: Aion-RP 1.0 (8B)","display_name":"AionLabs: Aion-RP 1.0 (8B)","type":"chat","context_length":4096,"max_output_tokens":4096,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"source":"public-provider-conf"},"vision":false},{"id":"alfredpros/codellama-7b-instruct-solidity","name":"AlfredPros: CodeLLaMa 7B Instruct Solidity","display_name":"AlfredPros: CodeLLaMa 7B Instruct Solidity","type":"completion","context_length":4096,"max_output_tokens":4096,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"source":"public-provider-conf"},"vision":false},{"id":"allenai/molmo-7b-d","name":"AllenAI: Molmo 7B D","display_name":"AllenAI: Molmo 7B D","type":"chat","context_length":4096,"max_output_tokens":4096,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"source":"public-provider-conf"},"vision":false},{"id":"allenai/olmo-2-0325-32b-instruct","name":"AllenAI: Olmo 2 32B Instruct","display_name":"AllenAI: Olmo 2 32B Instruct","type":"completion","context_length":4096,"max_output_tokens":4096,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"source":"public-provider-conf"},"vision":false},{"id":"amazon/nova-lite-v1","name":"Amazon: Nova Lite 1.0","display_name":"Amazon: Nova Lite 1.0","type":"chat","context_length":4096,"max_output_tokens":4096,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"source":"public-provider-conf"},"vision":false},{"id":"amazon/nova-micro-v1","name":"Amazon: Nova Micro 1.0","display_name":"Amazon: Nova Micro 1.0","type":"chat","context_length":4096,"max_output_tokens":4096,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"source":"public-provider-conf"},"vision":false},{"id":"amazon/nova-pro-v1","name":"Amazon: Nova Pro 1.0","display_name":"Amazon: Nova Pro 1.0","type":"chat","context_length":4096,"max_output_tokens":4096,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"source":"public-provider-conf"},"vision":false},{"id":"anthropic/claude-3-haiku","name":"Anthropic: Claude 3 Haiku","display_name":"Anthropic: Claude 3 Haiku","type":"chat","context_length":4096,"max_output_tokens":4096,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"source":"public-provider-conf"},"vision":false},{"id":"anthropic/claude-3-opus","name":"Anthropic: Claude 3 Opus","display_name":"Anthropic: Claude 3 Opus","type":"chat","context_length":4096,"max_output_tokens":4096,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"source":"public-provider-conf"},"vision":false},{"id":"anthropic/claude-3.5-haiku","name":"Anthropic: Claude 3.5 Haiku","display_name":"Anthropic: Claude 3.5 Haiku","type":"chat","context_length":4096,"max_output_tokens":4096,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"source":"public-provider-conf"},"vision":false},{"id":"anthropic/claude-3.5-haiku-20241022","name":"Anthropic: Claude 3.5 Haiku (2024-10-22)","display_name":"Anthropic: Claude 3.5 Haiku (2024-10-22)","type":"chat","context_length":4096,"max_output_tokens":4096,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"source":"public-provider-conf"},"vision":false},{"id":"anthropic/claude-3.5-sonnet","name":"Anthropic: Claude 3.5 Sonnet","display_name":"Anthropic: Claude 3.5 Sonnet","type":"chat","context_length":4096,"max_output_tokens":4096,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"source":"public-provider-conf"},"vision":false},{"id":"anthropic/claude-3.5-sonnet-20240620","name":"Anthropic: Claude 3.5 Sonnet (2024-06-20)","display_name":"Anthropic: Claude 3.5 Sonnet (2024-06-20)","type":"chat","context_length":4096,"max_output_tokens":4096,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"source":"public-provider-conf"},"vision":false},{"id":"anthropic/claude-3.7-sonnet","name":"Anthropic: Claude 3.7 Sonnet","display_name":"Anthropic: Claude 3.7 Sonnet","type":"chat","context_length":4096,"max_output_tokens":4096,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"source":"public-provider-conf"},"vision":false},{"id":"anthropic/claude-3.7-sonnet:thinking","name":"Anthropic: Claude 3.7 Sonnet (thinking)","display_name":"Anthropic: Claude 3.7 Sonnet (thinking)","type":"chat","context_length":4096,"max_output_tokens":4096,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"source":"public-provider-conf"},"vision":false},{"id":"anthropic/claude-opus-4","name":"Anthropic: Claude Opus 4","display_name":"Anthropic: Claude Opus 4","type":"chat","context_length":4096,"max_output_tokens":4096,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"source":"public-provider-conf"},"vision":false},{"id":"anthropic/claude-opus-4.1","name":"Anthropic: Claude Opus 4.1","display_name":"Anthropic: Claude Opus 4.1","type":"chat","context_length":4096,"max_output_tokens":4096,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"source":"public-provider-conf"},"vision":false},{"id":"anthropic/claude-sonnet-4","name":"Anthropic: Claude Sonnet 4","display_name":"Anthropic: Claude Sonnet 4","type":"chat","context_length":4096,"max_output_tokens":4096,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"source":"public-provider-conf"},"vision":false},{"id":"arcee-ai/afm-4.5b","name":"Arcee AI: AFM 4.5B","display_name":"Arcee AI: AFM 4.5B","type":"chat","context_length":4096,"max_output_tokens":4096,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"source":"public-provider-conf"},"vision":false},{"id":"arcee-ai/coder-large","name":"Arcee AI: Coder Large","display_name":"Arcee AI: Coder Large","type":"chat","context_length":4096,"max_output_tokens":4096,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"source":"public-provider-conf"},"vision":false},{"id":"arcee-ai/maestro-reasoning","name":"Arcee AI: Maestro Reasoning","display_name":"Arcee AI: Maestro Reasoning","type":"chat","context_length":4096,"max_output_tokens":4096,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"source":"public-provider-conf"},"vision":false},{"id":"arcee-ai/spotlight","name":"Arcee AI: Spotlight","display_name":"Arcee AI: Spotlight","type":"chat","context_length":4096,"max_output_tokens":4096,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"source":"public-provider-conf"},"vision":false},{"id":"arcee-ai/virtuoso-large","name":"Arcee AI: Virtuoso Large","display_name":"Arcee AI: Virtuoso Large","type":"chat","context_length":4096,"max_output_tokens":4096,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"source":"public-provider-conf"},"vision":false},{"id":"arliai/qwq-32b-arliai-rpr-v1","name":"ArliAI: QwQ 32B RpR v1","display_name":"ArliAI: QwQ 32B RpR v1","type":"chat","context_length":4096,"max_output_tokens":4096,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"source":"public-provider-conf"},"vision":false},{"id":"openrouter/auto","name":"Auto Router","display_name":"Auto Router","type":"chat","context_length":4096,"max_output_tokens":4096,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"source":"public-provider-conf"},"vision":false},{"id":"baidu/ernie-4.5-21b-a3b","name":"Baidu: ERNIE 4.5 21B A3B","display_name":"Baidu: ERNIE 4.5 21B A3B","type":"chat","context_length":4096,"max_output_tokens":4096,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"source":"public-provider-conf"},"vision":false},{"id":"baidu/ernie-4.5-300b-a47b","name":"Baidu: ERNIE 4.5 300B A47B","display_name":"Baidu: ERNIE 4.5 300B A47B","type":"chat","context_length":4096,"max_output_tokens":4096,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"source":"public-provider-conf"},"vision":false},{"id":"baidu/ernie-4.5-vl-28b-a3b","name":"Baidu: ERNIE 4.5 VL 28B A3B","display_name":"Baidu: ERNIE 4.5 VL 28B A3B","type":"chat","context_length":4096,"max_output_tokens":4096,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"source":"public-provider-conf"},"vision":false},{"id":"baidu/ernie-4.5-vl-424b-a47b","name":"Baidu: ERNIE 4.5 VL 424B A47B","display_name":"Baidu: ERNIE 4.5 VL 424B A47B","type":"chat","context_length":4096,"max_output_tokens":4096,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"source":"public-provider-conf"},"vision":false},{"id":"bytedance/doubao-embedding-text-240715","name":"ByteDance: Doubao Embedding","display_name":"ByteDance: Doubao Embedding","type":"embedding","context_length":4096,"max_output_tokens":4096,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"source":"public-provider-conf"},"vision":false},{"id":"bytedance/doubao-embedding-large-text-240915","name":"ByteDance: Doubao Embedding Large Text (240915)","display_name":"ByteDance: Doubao Embedding Large Text (240915)","type":"embedding","context_length":4096,"max_output_tokens":4096,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"source":"public-provider-conf"},"vision":false},{"id":"bytedance/doubao-embedding-vision-241215","name":"ByteDance: Doubao Embedding Vision","display_name":"ByteDance: Doubao Embedding Vision","type":"embedding","context_length":4096,"max_output_tokens":4096,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"source":"public-provider-conf"},"vision":false},{"id":"bytedance/doubao-embedding-vision-250328","name":"ByteDance: Doubao Embedding Vision","display_name":"ByteDance: Doubao Embedding Vision","type":"embedding","context_length":4096,"max_output_tokens":4096,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"source":"public-provider-conf"},"vision":false},{"id":"bytedance/doubao-seed-1.6","name":"ByteDance: Doubao Seed 1.6","display_name":"ByteDance: Doubao Seed 1.6","type":"chat","context_length":4096,"max_output_tokens":4096,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"source":"public-provider-conf"},"vision":false},{"id":"bytedance/doubao-seed-1.6-flash","name":"ByteDance: Doubao Seed 1.6 Flash","display_name":"ByteDance: Doubao Seed 1.6 Flash","type":"chat","context_length":4096,"max_output_tokens":4096,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"source":"public-provider-conf"},"vision":false},{"id":"bytedance/doubao-seed-1.6-thinking","name":"ByteDance: Doubao Seed 1.6 Thinking","display_name":"ByteDance: Doubao Seed 1.6 Thinking","type":"chat","context_length":4096,"max_output_tokens":4096,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"source":"public-provider-conf"},"vision":false},{"id":"bytedance/seed-oss-36b-instruct","name":"ByteDance: Seed OSS 36B Instruct","display_name":"ByteDance: Seed OSS 36B Instruct","type":"completion","context_length":4096,"max_output_tokens":4096,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"source":"public-provider-conf"},"vision":false},{"id":"bytedance/ui-tars-1.5-7b","name":"ByteDance: UI-TARS 7B","display_name":"ByteDance: UI-TARS 7B","type":"chat","context_length":4096,"max_output_tokens":4096,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"source":"public-provider-conf"},"vision":false},{"id":"deepcogito/cogito-v2-preview-llama-109b-moe","name":"Cogito V2 Preview Llama 109B","display_name":"Cogito V2 Preview Llama 109B","type":"chat","context_length":4096,"max_output_tokens":4096,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"source":"public-provider-conf"},"vision":false},{"id":"cohere/command-a","name":"Cohere: Command A","display_name":"Cohere: Command A","type":"chat","context_length":4096,"max_output_tokens":4096,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"source":"public-provider-conf"},"vision":false},{"id":"cohere/command-r-08-2024","name":"Cohere: Command R (08-2024)","display_name":"Cohere: Command R (08-2024)","type":"chat","context_length":4096,"max_output_tokens":4096,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"source":"public-provider-conf"},"vision":false},{"id":"cohere/command-r-plus-08-2024","name":"Cohere: Command R+ (08-2024)","display_name":"Cohere: Command R+ (08-2024)","type":"chat","context_length":4096,"max_output_tokens":4096,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"source":"public-provider-conf"},"vision":false},{"id":"cohere/command-r7b-12-2024","name":"Cohere: Command R7B (12-2024)","display_name":"Cohere: Command R7B (12-2024)","type":"chat","context_length":4096,"max_output_tokens":4096,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"source":"public-provider-conf"},"vision":false},{"id":"deepcogito/cogito-v2-preview-deepseek-671b","name":"Deep Cogito: Cogito V2 Preview Deepseek 671B","display_name":"Deep Cogito: Cogito V2 Preview Deepseek 671B","type":"chat","context_length":4096,"max_output_tokens":4096,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"source":"public-provider-conf"},"vision":false},{"id":"deepseek/deepseek-prover-v2","name":"DeepSeek: DeepSeek Prover V2","display_name":"DeepSeek: DeepSeek Prover V2","type":"chat","context_length":4096,"max_output_tokens":4096,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"source":"public-provider-conf"},"vision":false},{"id":"deepseek/deepseek-r1-0528-qwen3-8b","name":"DeepSeek: Deepseek R1 0528 Qwen3 8B","display_name":"DeepSeek: Deepseek R1 0528 Qwen3 8B","type":"chat","context_length":4096,"max_output_tokens":4096,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"source":"public-provider-conf"},"vision":false},{"id":"deepseek/deepseek-chat","name":"DeepSeek: DeepSeek V3","display_name":"DeepSeek: DeepSeek V3","type":"chat","context_length":4096,"max_output_tokens":4096,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"source":"public-provider-conf"},"vision":false},{"id":"deepseek/deepseek-chat-v3-0324","name":"DeepSeek: DeepSeek V3 0324","display_name":"DeepSeek: DeepSeek V3 0324","type":"chat","context_length":4096,"max_output_tokens":4096,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"source":"public-provider-conf"},"vision":false},{"id":"deepseek/deepseek-chat-v3.1","name":"DeepSeek: DeepSeek V3.1","display_name":"DeepSeek: DeepSeek V3.1","type":"chat","context_length":4096,"max_output_tokens":4096,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"source":"public-provider-conf"},"vision":false},{"id":"deepseek/deepseek-v3.1-base","name":"DeepSeek: DeepSeek V3.1 Base","display_name":"DeepSeek: DeepSeek V3.1 Base","type":"chat","context_length":4096,"max_output_tokens":4096,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"source":"public-provider-conf"},"vision":false},{"id":"deepseek/deepseek-v3.1-terminus","name":"DeepSeek: DeepSeek V3.1 Terminus","display_name":"DeepSeek: DeepSeek V3.1 Terminus","type":"chat","context_length":4096,"max_output_tokens":4096,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"source":"public-provider-conf"},"vision":false},{"id":"deepseek/deepseek-r1","name":"DeepSeek: R1","display_name":"DeepSeek: R1","type":"chat","context_length":4096,"max_output_tokens":4096,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"source":"public-provider-conf"},"vision":false},{"id":"deepseek/deepseek-r1-0528","name":"DeepSeek: R1 0528","display_name":"DeepSeek: R1 0528","type":"chat","context_length":4096,"max_output_tokens":4096,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"source":"public-provider-conf"},"vision":false},{"id":"deepseek/deepseek-r1-distill-llama-70b","name":"DeepSeek: R1 Distill Llama 70B","display_name":"DeepSeek: R1 Distill Llama 70B","type":"chat","context_length":4096,"max_output_tokens":4096,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"source":"public-provider-conf"},"vision":false},{"id":"deepseek/deepseek-r1-distill-llama-8b","name":"DeepSeek: R1 Distill Llama 8B","display_name":"DeepSeek: R1 Distill Llama 8B","type":"chat","context_length":4096,"max_output_tokens":4096,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"source":"public-provider-conf"},"vision":false},{"id":"deepseek/deepseek-r1-distill-qwen-14b","name":"DeepSeek: R1 Distill Qwen 14B","display_name":"DeepSeek: R1 Distill Qwen 14B","type":"chat","context_length":4096,"max_output_tokens":4096,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"source":"public-provider-conf"},"vision":false},{"id":"deepseek/deepseek-r1-distill-qwen-32b","name":"DeepSeek: R1 Distill Qwen 32B","display_name":"DeepSeek: R1 Distill Qwen 32B","type":"chat","context_length":4096,"max_output_tokens":4096,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"source":"public-provider-conf"},"vision":false},{"id":"cognitivecomputations/dolphin3.0-mistral-24b","name":"Dolphin3.0 Mistral 24B","display_name":"Dolphin3.0 Mistral 24B","type":"chat","context_length":4096,"max_output_tokens":4096,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"source":"public-provider-conf"},"vision":false},{"id":"cognitivecomputations/dolphin3.0-r1-mistral-24b","name":"Dolphin3.0 R1 Mistral 24B","display_name":"Dolphin3.0 R1 Mistral 24B","type":"chat","context_length":4096,"max_output_tokens":4096,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"source":"public-provider-conf"},"vision":false},{"id":"eleutherai/llemma_7b","name":"EleutherAI: Llemma 7b","display_name":"EleutherAI: Llemma 7b","type":"chat","context_length":4096,"max_output_tokens":4096,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"source":"public-provider-conf"},"vision":false},{"id":"google/gemini-2.5-flash-image-preview","name":"Gemini 2.5 Flash Image (Nano Banana)","display_name":"Gemini 2.5 Flash Image (Nano Banana)","type":"chat","context_length":4096,"max_output_tokens":4096,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"source":"public-provider-conf"},"vision":false},{"id":"alpindale/goliath-120b","name":"Goliath 120B","display_name":"Goliath 120B","type":"chat","context_length":4096,"max_output_tokens":4096,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"source":"public-provider-conf"},"vision":false},{"id":"google/gemini-flash-1.5-8b","name":"Google: Gemini 1.5 Flash 8B","display_name":"Google: Gemini 1.5 Flash 8B","type":"chat","context_length":4096,"max_output_tokens":4096,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"source":"public-provider-conf"},"vision":false},{"id":"google/gemini-2.0-flash-001","name":"Google: Gemini 2.0 Flash","display_name":"Google: Gemini 2.0 Flash","type":"chat","context_length":4096,"max_output_tokens":4096,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"source":"public-provider-conf"},"vision":false},{"id":"google/gemini-2.0-flash-lite-001","name":"Google: Gemini 2.0 Flash Lite","display_name":"Google: Gemini 2.0 Flash Lite","type":"chat","context_length":4096,"max_output_tokens":4096,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"source":"public-provider-conf"},"vision":false},{"id":"google/gemini-2.5-flash","name":"Google: Gemini 2.5 Flash","display_name":"Google: Gemini 2.5 Flash","type":"chat","context_length":4096,"max_output_tokens":4096,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"source":"public-provider-conf"},"vision":false},{"id":"google/gemini-2.5-flash-lite","name":"Google: Gemini 2.5 Flash Lite","display_name":"Google: Gemini 2.5 Flash Lite","type":"chat","context_length":4096,"max_output_tokens":4096,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"source":"public-provider-conf"},"vision":false},{"id":"google/gemini-2.5-flash-lite-preview-06-17","name":"Google: Gemini 2.5 Flash Lite Preview 06-17","display_name":"Google: Gemini 2.5 Flash Lite Preview 06-17","type":"chat","context_length":4096,"max_output_tokens":4096,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"source":"public-provider-conf"},"vision":false},{"id":"google/gemini-2.5-flash-lite-preview-09-2025","name":"Google: Gemini 2.5 Flash Lite Preview 09-2025","display_name":"Google: Gemini 2.5 Flash Lite Preview 09-2025","type":"chat","context_length":4096,"max_output_tokens":4096,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"source":"public-provider-conf"},"vision":false},{"id":"google/gemini-2.5-flash-preview-09-2025","name":"Google: Gemini 2.5 Flash Preview 09-2025","display_name":"Google: Gemini 2.5 Flash Preview 09-2025","type":"chat","context_length":4096,"max_output_tokens":4096,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"source":"public-provider-conf"},"vision":false},{"id":"google/gemini-2.5-pro","name":"Google: Gemini 2.5 Pro","display_name":"Google: Gemini 2.5 Pro","type":"chat","context_length":4096,"max_output_tokens":4096,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"source":"public-provider-conf"},"vision":false},{"id":"google/gemini-2.5-pro-preview-05-06","name":"Google: Gemini 2.5 Pro Preview 05-06","display_name":"Google: Gemini 2.5 Pro Preview 05-06","type":"chat","context_length":4096,"max_output_tokens":4096,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"source":"public-provider-conf"},"vision":false},{"id":"google/gemini-2.5-pro-preview","name":"Google: Gemini 2.5 Pro Preview 06-05","display_name":"Google: Gemini 2.5 Pro Preview 06-05","type":"chat","context_length":4096,"max_output_tokens":4096,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"source":"public-provider-conf"},"vision":false},{"id":"google/gemma-2-27b-it","name":"Google: Gemma 2 27B","display_name":"Google: Gemma 2 27B","type":"chat","context_length":4096,"max_output_tokens":4096,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"source":"public-provider-conf"},"vision":false},{"id":"google/gemma-2-9b-it","name":"Google: Gemma 2 9B","display_name":"Google: Gemma 2 9B","type":"chat","context_length":4096,"max_output_tokens":4096,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"source":"public-provider-conf"},"vision":false},{"id":"google/gemma-3-12b-it","name":"Google: Gemma 3 12B","display_name":"Google: Gemma 3 12B","type":"chat","context_length":4096,"max_output_tokens":4096,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"source":"public-provider-conf"},"vision":false},{"id":"google/gemma-3-27b-it","name":"Google: Gemma 3 27B","display_name":"Google: Gemma 3 27B","type":"chat","context_length":4096,"max_output_tokens":4096,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"source":"public-provider-conf"},"vision":false},{"id":"google/gemma-3-4b-it","name":"Google: Gemma 3 4B","display_name":"Google: Gemma 3 4B","type":"chat","context_length":4096,"max_output_tokens":4096,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"source":"public-provider-conf"},"vision":false},{"id":"google/gemma-3n-e4b-it","name":"Google: Gemma 3n 4B","display_name":"Google: Gemma 3n 4B","type":"chat","context_length":4096,"max_output_tokens":4096,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"source":"public-provider-conf"},"vision":false},{"id":"inception/mercury","name":"Inception: Mercury","display_name":"Inception: Mercury","type":"chat","context_length":4096,"max_output_tokens":4096,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"source":"public-provider-conf"},"vision":false},{"id":"inception/mercury-coder","name":"Inception: Mercury Coder","display_name":"Inception: Mercury Coder","type":"chat","context_length":4096,"max_output_tokens":4096,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"source":"public-provider-conf"},"vision":false},{"id":"inflection/inflection-3-pi","name":"Inflection: Inflection 3 Pi","display_name":"Inflection: Inflection 3 Pi","type":"chat","context_length":4096,"max_output_tokens":4096,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"source":"public-provider-conf"},"vision":false},{"id":"inflection/inflection-3-productivity","name":"Inflection: Inflection 3 Productivity","display_name":"Inflection: Inflection 3 Productivity","type":"chat","context_length":4096,"max_output_tokens":4096,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"source":"public-provider-conf"},"vision":false},{"id":"liquid/lfm-3b","name":"Liquid: LFM 3B","display_name":"Liquid: LFM 3B","type":"chat","context_length":4096,"max_output_tokens":4096,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"source":"public-provider-conf"},"vision":false},{"id":"liquid/lfm-7b","name":"Liquid: LFM 7B","display_name":"Liquid: LFM 7B","type":"chat","context_length":4096,"max_output_tokens":4096,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"source":"public-provider-conf"},"vision":false},{"id":"meta-llama/llama-guard-3-8b","name":"Llama Guard 3 8B","display_name":"Llama Guard 3 8B","type":"chat","context_length":4096,"max_output_tokens":4096,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"source":"public-provider-conf"},"vision":false},{"id":"anthracite-org/magnum-v2-72b","name":"Magnum v2 72B","display_name":"Magnum v2 72B","type":"chat","context_length":4096,"max_output_tokens":4096,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"source":"public-provider-conf"},"vision":false},{"id":"anthracite-org/magnum-v4-72b","name":"Magnum v4 72B","display_name":"Magnum v4 72B","type":"chat","context_length":4096,"max_output_tokens":4096,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"source":"public-provider-conf"},"vision":false},{"id":"mancer/weaver","name":"Mancer: Weaver (alpha)","display_name":"Mancer: Weaver (alpha)","type":"chat","context_length":4096,"max_output_tokens":4096,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"source":"public-provider-conf"},"vision":false},{"id":"meituan/longcat-flash-chat","name":"Meituan: LongCat Flash Chat","display_name":"Meituan: LongCat Flash Chat","type":"chat","context_length":4096,"max_output_tokens":4096,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"source":"public-provider-conf"},"vision":false},{"id":"meta-llama/llama-3-70b-instruct","name":"Meta: Llama 3 70B Instruct","display_name":"Meta: Llama 3 70B Instruct","type":"completion","context_length":4096,"max_output_tokens":4096,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"source":"public-provider-conf"},"vision":false},{"id":"meta-llama/llama-3-8b-instruct","name":"Meta: Llama 3 8B Instruct","display_name":"Meta: Llama 3 8B Instruct","type":"completion","context_length":4096,"max_output_tokens":4096,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"source":"public-provider-conf"},"vision":false},{"id":"meta-llama/llama-3.1-405b","name":"Meta: Llama 3.1 405B (base)","display_name":"Meta: Llama 3.1 405B (base)","type":"chat","context_length":4096,"max_output_tokens":4096,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"source":"public-provider-conf"},"vision":false},{"id":"meta-llama/llama-3.1-405b-instruct","name":"Meta: Llama 3.1 405B Instruct","display_name":"Meta: Llama 3.1 405B Instruct","type":"completion","context_length":4096,"max_output_tokens":4096,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"source":"public-provider-conf"},"vision":false},{"id":"meta-llama/llama-3.1-70b-instruct","name":"Meta: Llama 3.1 70B Instruct","display_name":"Meta: Llama 3.1 70B Instruct","type":"completion","context_length":4096,"max_output_tokens":4096,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"source":"public-provider-conf"},"vision":false},{"id":"meta-llama/llama-3.1-8b-instruct","name":"Meta: Llama 3.1 8B Instruct","display_name":"Meta: Llama 3.1 8B Instruct","type":"completion","context_length":4096,"max_output_tokens":4096,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"source":"public-provider-conf"},"vision":false},{"id":"meta-llama/llama-3.2-11b-vision-instruct","name":"Meta: Llama 3.2 11B Vision Instruct","display_name":"Meta: Llama 3.2 11B Vision Instruct","type":"completion","context_length":4096,"max_output_tokens":4096,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"source":"public-provider-conf"},"vision":false},{"id":"meta-llama/llama-3.2-1b-instruct","name":"Meta: Llama 3.2 1B Instruct","display_name":"Meta: Llama 3.2 1B Instruct","type":"completion","context_length":4096,"max_output_tokens":4096,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"source":"public-provider-conf"},"vision":false},{"id":"meta-llama/llama-3.2-3b-instruct","name":"Meta: Llama 3.2 3B Instruct","display_name":"Meta: Llama 3.2 3B Instruct","type":"completion","context_length":4096,"max_output_tokens":4096,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"source":"public-provider-conf"},"vision":false},{"id":"meta-llama/llama-3.2-90b-vision-instruct","name":"Meta: Llama 3.2 90B Vision Instruct","display_name":"Meta: Llama 3.2 90B Vision Instruct","type":"completion","context_length":4096,"max_output_tokens":4096,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"source":"public-provider-conf"},"vision":false},{"id":"meta-llama/llama-3.3-70b-instruct","name":"Meta: Llama 3.3 70B Instruct","display_name":"Meta: Llama 3.3 70B Instruct","type":"completion","context_length":4096,"max_output_tokens":4096,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"source":"public-provider-conf"},"vision":false},{"id":"meta-llama/llama-4-maverick","name":"Meta: Llama 4 Maverick","display_name":"Meta: Llama 4 Maverick","type":"chat","context_length":4096,"max_output_tokens":4096,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"source":"public-provider-conf"},"vision":false},{"id":"meta-llama/llama-4-scout","name":"Meta: Llama 4 Scout","display_name":"Meta: Llama 4 Scout","type":"chat","context_length":4096,"max_output_tokens":4096,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"source":"public-provider-conf"},"vision":false},{"id":"meta-llama/llama-guard-4-12b","name":"Meta: Llama Guard 4 12B","display_name":"Meta: Llama Guard 4 12B","type":"chat","context_length":4096,"max_output_tokens":4096,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"source":"public-provider-conf"},"vision":false},{"id":"meta-llama/llama-guard-2-8b","name":"Meta: LlamaGuard 2 8B","display_name":"Meta: LlamaGuard 2 8B","type":"chat","context_length":4096,"max_output_tokens":4096,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"source":"public-provider-conf"},"vision":false},{"id":"microsoft/mai-ds-r1","name":"Microsoft: MAI DS R1","display_name":"Microsoft: MAI DS R1","type":"chat","context_length":4096,"max_output_tokens":4096,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"source":"public-provider-conf"},"vision":false},{"id":"microsoft/phi-4","name":"Microsoft: Phi 4","display_name":"Microsoft: Phi 4","type":"chat","context_length":4096,"max_output_tokens":4096,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"source":"public-provider-conf"},"vision":false},{"id":"microsoft/phi-4-multimodal-instruct","name":"Microsoft: Phi 4 Multimodal Instruct","display_name":"Microsoft: Phi 4 Multimodal Instruct","type":"completion","context_length":4096,"max_output_tokens":4096,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"source":"public-provider-conf"},"vision":false},{"id":"microsoft/phi-4-reasoning-plus","name":"Microsoft: Phi 4 Reasoning Plus","display_name":"Microsoft: Phi 4 Reasoning Plus","type":"chat","context_length":4096,"max_output_tokens":4096,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"source":"public-provider-conf"},"vision":false},{"id":"microsoft/phi-3-medium-128k-instruct","name":"Microsoft: Phi-3 Medium 128K Instruct","display_name":"Microsoft: Phi-3 Medium 128K Instruct","type":"completion","context_length":4096,"max_output_tokens":4096,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"source":"public-provider-conf"},"vision":false},{"id":"microsoft/phi-3-mini-128k-instruct","name":"Microsoft: Phi-3 Mini 128K Instruct","display_name":"Microsoft: Phi-3 Mini 128K Instruct","type":"completion","context_length":4096,"max_output_tokens":4096,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"source":"public-provider-conf"},"vision":false},{"id":"microsoft/phi-3.5-mini-128k-instruct","name":"Microsoft: Phi-3.5 Mini 128K Instruct","display_name":"Microsoft: Phi-3.5 Mini 128K Instruct","type":"completion","context_length":4096,"max_output_tokens":4096,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"source":"public-provider-conf"},"vision":false},{"id":"minimax/minimax-m1","name":"MiniMax: MiniMax M1","display_name":"MiniMax: MiniMax M1","type":"chat","context_length":4096,"max_output_tokens":4096,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"source":"public-provider-conf"},"vision":false},{"id":"minimax/minimax-01","name":"MiniMax: MiniMax-01","display_name":"MiniMax: MiniMax-01","type":"chat","context_length":4096,"max_output_tokens":4096,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"source":"public-provider-conf"},"vision":false},{"id":"mistralai/mistral-large","name":"Mistral Large","display_name":"Mistral Large","type":"chat","context_length":4096,"max_output_tokens":4096,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"source":"public-provider-conf"},"vision":false},{"id":"mistralai/mistral-large-2407","name":"Mistral Large 2407","display_name":"Mistral Large 2407","type":"chat","context_length":4096,"max_output_tokens":4096,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"source":"public-provider-conf"},"vision":false},{"id":"mistralai/mistral-large-2411","name":"Mistral Large 2411","display_name":"Mistral Large 2411","type":"chat","context_length":4096,"max_output_tokens":4096,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"source":"public-provider-conf"},"vision":false},{"id":"mistralai/mistral-small","name":"Mistral Small","display_name":"Mistral Small","type":"chat","context_length":4096,"max_output_tokens":4096,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"source":"public-provider-conf"},"vision":false},{"id":"mistralai/mistral-tiny","name":"Mistral Tiny","display_name":"Mistral Tiny","type":"chat","context_length":4096,"max_output_tokens":4096,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"source":"public-provider-conf"},"vision":false},{"id":"mistralai/codestral-2501","name":"Mistral: Codestral 2501","display_name":"Mistral: Codestral 2501","type":"chat","context_length":4096,"max_output_tokens":4096,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"source":"public-provider-conf"},"vision":false},{"id":"mistralai/codestral-2508","name":"Mistral: Codestral 2508","display_name":"Mistral: Codestral 2508","type":"chat","context_length":4096,"max_output_tokens":4096,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"source":"public-provider-conf"},"vision":false},{"id":"mistralai/devstral-medium","name":"Mistral: Devstral Medium","display_name":"Mistral: Devstral Medium","type":"chat","context_length":4096,"max_output_tokens":4096,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"source":"public-provider-conf"},"vision":false},{"id":"mistralai/devstral-small","name":"Mistral: Devstral Small 1.1","display_name":"Mistral: Devstral Small 1.1","type":"chat","context_length":4096,"max_output_tokens":4096,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"source":"public-provider-conf"},"vision":false},{"id":"mistralai/devstral-small-2505","name":"Mistral: Devstral Small 2505","display_name":"Mistral: Devstral Small 2505","type":"chat","context_length":4096,"max_output_tokens":4096,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"source":"public-provider-conf"},"vision":false},{"id":"mistralai/magistral-medium-2506","name":"Mistral: Magistral Medium 2506","display_name":"Mistral: Magistral Medium 2506","type":"chat","context_length":4096,"max_output_tokens":4096,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"source":"public-provider-conf"},"vision":false},{"id":"mistralai/magistral-medium-2506:thinking","name":"Mistral: Magistral Medium 2506 (thinking)","display_name":"Mistral: Magistral Medium 2506 (thinking)","type":"chat","context_length":4096,"max_output_tokens":4096,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"source":"public-provider-conf"},"vision":false},{"id":"mistralai/magistral-small-2506","name":"Mistral: Magistral Small 2506","display_name":"Mistral: Magistral Small 2506","type":"chat","context_length":4096,"max_output_tokens":4096,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"source":"public-provider-conf"},"vision":false},{"id":"mistralai/ministral-3b","name":"Mistral: Ministral 3B","display_name":"Mistral: Ministral 3B","type":"chat","context_length":4096,"max_output_tokens":4096,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"source":"public-provider-conf"},"vision":false},{"id":"mistralai/ministral-8b","name":"Mistral: Ministral 8B","display_name":"Mistral: Ministral 8B","type":"chat","context_length":4096,"max_output_tokens":4096,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"source":"public-provider-conf"},"vision":false},{"id":"mistralai/mistral-7b-instruct","name":"Mistral: Mistral 7B Instruct","display_name":"Mistral: Mistral 7B Instruct","type":"completion","context_length":4096,"max_output_tokens":4096,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"source":"public-provider-conf"},"vision":false},{"id":"mistralai/mistral-7b-instruct-v0.1","name":"Mistral: Mistral 7B Instruct v0.1","display_name":"Mistral: Mistral 7B Instruct v0.1","type":"completion","context_length":4096,"max_output_tokens":4096,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"source":"public-provider-conf"},"vision":false},{"id":"mistralai/mistral-7b-instruct-v0.3","name":"Mistral: Mistral 7B Instruct v0.3","display_name":"Mistral: Mistral 7B Instruct v0.3","type":"completion","context_length":4096,"max_output_tokens":4096,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"source":"public-provider-conf"},"vision":false},{"id":"mistralai/mistral-medium-3","name":"Mistral: Mistral Medium 3","display_name":"Mistral: Mistral Medium 3","type":"chat","context_length":4096,"max_output_tokens":4096,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"source":"public-provider-conf"},"vision":false},{"id":"mistralai/mistral-medium-3.1","name":"Mistral: Mistral Medium 3.1","display_name":"Mistral: Mistral Medium 3.1","type":"chat","context_length":4096,"max_output_tokens":4096,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"source":"public-provider-conf"},"vision":false},{"id":"mistralai/mistral-nemo","name":"Mistral: Mistral Nemo","display_name":"Mistral: Mistral Nemo","type":"chat","context_length":4096,"max_output_tokens":4096,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"source":"public-provider-conf"},"vision":false},{"id":"mistralai/mistral-small-24b-instruct-2501","name":"Mistral: Mistral Small 3","display_name":"Mistral: Mistral Small 3","type":"completion","context_length":4096,"max_output_tokens":4096,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"source":"public-provider-conf"},"vision":false},{"id":"mistralai/mistral-small-3.1-24b-instruct","name":"Mistral: Mistral Small 3.1 24B","display_name":"Mistral: Mistral Small 3.1 24B","type":"completion","context_length":4096,"max_output_tokens":4096,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"source":"public-provider-conf"},"vision":false},{"id":"mistralai/mistral-small-3.2-24b-instruct","name":"Mistral: Mistral Small 3.2 24B","display_name":"Mistral: Mistral Small 3.2 24B","type":"completion","context_length":4096,"max_output_tokens":4096,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"source":"public-provider-conf"},"vision":false},{"id":"mistralai/mixtral-8x22b-instruct","name":"Mistral: Mixtral 8x22B Instruct","display_name":"Mistral: Mixtral 8x22B Instruct","type":"completion","context_length":4096,"max_output_tokens":4096,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"source":"public-provider-conf"},"vision":false},{"id":"mistralai/mixtral-8x7b-instruct","name":"Mistral: Mixtral 8x7B Instruct","display_name":"Mistral: Mixtral 8x7B Instruct","type":"completion","context_length":4096,"max_output_tokens":4096,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"source":"public-provider-conf"},"vision":false},{"id":"mistralai/pixtral-12b","name":"Mistral: Pixtral 12B","display_name":"Mistral: Pixtral 12B","type":"chat","context_length":4096,"max_output_tokens":4096,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"source":"public-provider-conf"},"vision":false},{"id":"mistralai/pixtral-large-2411","name":"Mistral: Pixtral Large 2411","display_name":"Mistral: Pixtral Large 2411","type":"chat","context_length":4096,"max_output_tokens":4096,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"source":"public-provider-conf"},"vision":false},{"id":"mistralai/mistral-saba","name":"Mistral: Saba","display_name":"Mistral: Saba","type":"chat","context_length":4096,"max_output_tokens":4096,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"source":"public-provider-conf"},"vision":false},{"id":"moonshotai/kimi-dev-72b","name":"MoonshotAI: Kimi Dev 72B","display_name":"MoonshotAI: Kimi Dev 72B","type":"chat","context_length":4096,"max_output_tokens":4096,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"source":"public-provider-conf"},"vision":false},{"id":"moonshotai/kimi-k2","name":"MoonshotAI: Kimi K2 0711","display_name":"MoonshotAI: Kimi K2 0711","type":"chat","context_length":4096,"max_output_tokens":4096,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"source":"public-provider-conf"},"vision":false},{"id":"moonshotai/kimi-k2-0905","name":"MoonshotAI: Kimi K2 0905","display_name":"MoonshotAI: Kimi K2 0905","type":"chat","context_length":4096,"max_output_tokens":4096,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"source":"public-provider-conf"},"vision":false},{"id":"moonshotai/kimi-vl-a3b-thinking","name":"MoonshotAI: Kimi VL A3B Thinking","display_name":"MoonshotAI: Kimi VL A3B Thinking","type":"chat","context_length":4096,"max_output_tokens":4096,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"source":"public-provider-conf"},"vision":false},{"id":"morph/morph-v3-fast","name":"Morph: Morph V3 Fast","display_name":"Morph: Morph V3 Fast","type":"chat","context_length":4096,"max_output_tokens":4096,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"source":"public-provider-conf"},"vision":false},{"id":"morph/morph-v3-large","name":"Morph: Morph V3 Large","display_name":"Morph: Morph V3 Large","type":"chat","context_length":4096,"max_output_tokens":4096,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"source":"public-provider-conf"},"vision":false},{"id":"gryphe/mythomax-l2-13b","name":"MythoMax 13B","display_name":"MythoMax 13B","type":"chat","context_length":4096,"max_output_tokens":4096,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"source":"public-provider-conf"},"vision":false},{"id":"neversleep/llama-3-lumimaid-70b","name":"NeverSleep: Llama 3 Lumimaid 70B","display_name":"NeverSleep: Llama 3 Lumimaid 70B","type":"chat","context_length":4096,"max_output_tokens":4096,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"source":"public-provider-conf"},"vision":false},{"id":"neversleep/llama-3.1-lumimaid-8b","name":"NeverSleep: Lumimaid v0.2 8B","display_name":"NeverSleep: Lumimaid v0.2 8B","type":"chat","context_length":4096,"max_output_tokens":4096,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"source":"public-provider-conf"},"vision":false},{"id":"neversleep/noromaid-20b","name":"Noromaid 20B","display_name":"Noromaid 20B","type":"chat","context_length":4096,"max_output_tokens":4096,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"source":"public-provider-conf"},"vision":false},{"id":"nousresearch/deephermes-3-llama-3-8b-preview","name":"Nous: DeepHermes 3 Llama 3 8B Preview","display_name":"Nous: DeepHermes 3 Llama 3 8B Preview","type":"chat","context_length":4096,"max_output_tokens":4096,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"source":"public-provider-conf"},"vision":false},{"id":"nousresearch/deephermes-3-mistral-24b-preview","name":"Nous: DeepHermes 3 Mistral 24B Preview","display_name":"Nous: DeepHermes 3 Mistral 24B Preview","type":"chat","context_length":4096,"max_output_tokens":4096,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"source":"public-provider-conf"},"vision":false},{"id":"nousresearch/hermes-3-llama-3.1-405b","name":"Nous: Hermes 3 405B Instruct","display_name":"Nous: Hermes 3 405B Instruct","type":"chat","context_length":4096,"max_output_tokens":4096,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"source":"public-provider-conf"},"vision":false},{"id":"nousresearch/hermes-3-llama-3.1-70b","name":"Nous: Hermes 3 70B Instruct","display_name":"Nous: Hermes 3 70B Instruct","type":"chat","context_length":4096,"max_output_tokens":4096,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"source":"public-provider-conf"},"vision":false},{"id":"nousresearch/hermes-4-405b","name":"Nous: Hermes 4 405B","display_name":"Nous: Hermes 4 405B","type":"chat","context_length":4096,"max_output_tokens":4096,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"source":"public-provider-conf"},"vision":false},{"id":"nousresearch/hermes-4-70b","name":"Nous: Hermes 4 70B","display_name":"Nous: Hermes 4 70B","type":"chat","context_length":4096,"max_output_tokens":4096,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"source":"public-provider-conf"},"vision":false},{"id":"nousresearch/hermes-2-pro-llama-3-8b","name":"NousResearch: Hermes 2 Pro - Llama-3 8B","display_name":"NousResearch: Hermes 2 Pro - Llama-3 8B","type":"chat","context_length":4096,"max_output_tokens":4096,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"source":"public-provider-conf"},"vision":false},{"id":"nvidia/llama-3.1-nemotron-70b-instruct","name":"NVIDIA: Llama 3.1 Nemotron 70B Instruct","display_name":"NVIDIA: Llama 3.1 Nemotron 70B Instruct","type":"completion","context_length":4096,"max_output_tokens":4096,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"source":"public-provider-conf"},"vision":false},{"id":"nvidia/llama-3.1-nemotron-ultra-253b-v1","name":"NVIDIA: Llama 3.1 Nemotron Ultra 253B v1","display_name":"NVIDIA: Llama 3.1 Nemotron Ultra 253B v1","type":"chat","context_length":4096,"max_output_tokens":4096,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"source":"public-provider-conf"},"vision":false},{"id":"nvidia/nemotron-nano-9b-v2","name":"NVIDIA: Nemotron Nano 9B V2","display_name":"NVIDIA: Nemotron Nano 9B V2","type":"chat","context_length":4096,"max_output_tokens":4096,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"source":"public-provider-conf"},"vision":false},{"id":"openai/chatgpt-4o-latest","name":"OpenAI: ChatGPT-4o","display_name":"OpenAI: ChatGPT-4o","type":"chat","context_length":4096,"max_output_tokens":4096,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"source":"public-provider-conf"},"vision":false},{"id":"openai/codex-mini","name":"OpenAI: Codex Mini","display_name":"OpenAI: Codex Mini","type":"chat","context_length":4096,"max_output_tokens":4096,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"source":"public-provider-conf"},"vision":false},{"id":"openai/gpt-3.5-turbo","name":"OpenAI: GPT-3.5 Turbo","display_name":"OpenAI: GPT-3.5 Turbo","type":"chat","context_length":4096,"max_output_tokens":4096,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"source":"public-provider-conf"},"vision":false},{"id":"openai/gpt-3.5-turbo-0613","name":"OpenAI: GPT-3.5 Turbo (older v0613)","display_name":"OpenAI: GPT-3.5 Turbo (older v0613)","type":"chat","context_length":4096,"max_output_tokens":4096,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"source":"public-provider-conf"},"vision":false},{"id":"openai/gpt-3.5-turbo-16k","name":"OpenAI: GPT-3.5 Turbo 16k","display_name":"OpenAI: GPT-3.5 Turbo 16k","type":"chat","context_length":4096,"max_output_tokens":4096,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"source":"public-provider-conf"},"vision":false},{"id":"openai/gpt-3.5-turbo-instruct","name":"OpenAI: GPT-3.5 Turbo Instruct","display_name":"OpenAI: GPT-3.5 Turbo Instruct","type":"completion","context_length":4096,"max_output_tokens":4096,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"source":"public-provider-conf"},"vision":false},{"id":"openai/gpt-4","name":"OpenAI: GPT-4","display_name":"OpenAI: GPT-4","type":"chat","context_length":4096,"max_output_tokens":4096,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"source":"public-provider-conf"},"vision":false},{"id":"openai/gpt-4-0314","name":"OpenAI: GPT-4 (older v0314)","display_name":"OpenAI: GPT-4 (older v0314)","type":"chat","context_length":4096,"max_output_tokens":4096,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"source":"public-provider-conf"},"vision":false},{"id":"openai/gpt-4-turbo","name":"OpenAI: GPT-4 Turbo","display_name":"OpenAI: GPT-4 Turbo","type":"chat","context_length":4096,"max_output_tokens":4096,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"source":"public-provider-conf"},"vision":false},{"id":"openai/gpt-4-1106-preview","name":"OpenAI: GPT-4 Turbo (older v1106)","display_name":"OpenAI: GPT-4 Turbo (older v1106)","type":"chat","context_length":4096,"max_output_tokens":4096,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"source":"public-provider-conf"},"vision":false},{"id":"openai/gpt-4-turbo-preview","name":"OpenAI: GPT-4 Turbo Preview","display_name":"OpenAI: GPT-4 Turbo Preview","type":"chat","context_length":4096,"max_output_tokens":4096,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"source":"public-provider-conf"},"vision":false},{"id":"openai/gpt-4.1","name":"OpenAI: GPT-4.1","display_name":"OpenAI: GPT-4.1","type":"chat","context_length":4096,"max_output_tokens":4096,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"source":"public-provider-conf"},"vision":false},{"id":"openai/gpt-4.1-mini","name":"OpenAI: GPT-4.1 Mini","display_name":"OpenAI: GPT-4.1 Mini","type":"chat","context_length":4096,"max_output_tokens":4096,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"source":"public-provider-conf"},"vision":false},{"id":"openai/gpt-4.1-nano","name":"OpenAI: GPT-4.1 Nano","display_name":"OpenAI: GPT-4.1 Nano","type":"chat","context_length":4096,"max_output_tokens":4096,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"source":"public-provider-conf"},"vision":false},{"id":"openai/gpt-4o","name":"OpenAI: GPT-4o","display_name":"OpenAI: GPT-4o","type":"chat","context_length":4096,"max_output_tokens":4096,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"source":"public-provider-conf"},"vision":false},{"id":"openai/gpt-4o-2024-05-13","name":"OpenAI: GPT-4o (2024-05-13)","display_name":"OpenAI: GPT-4o (2024-05-13)","type":"chat","context_length":4096,"max_output_tokens":4096,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"source":"public-provider-conf"},"vision":false},{"id":"openai/gpt-4o-2024-08-06","name":"OpenAI: GPT-4o (2024-08-06)","display_name":"OpenAI: GPT-4o (2024-08-06)","type":"chat","context_length":4096,"max_output_tokens":4096,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"source":"public-provider-conf"},"vision":false},{"id":"openai/gpt-4o-2024-11-20","name":"OpenAI: GPT-4o (2024-11-20)","display_name":"OpenAI: GPT-4o (2024-11-20)","type":"chat","context_length":4096,"max_output_tokens":4096,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"source":"public-provider-conf"},"vision":false},{"id":"openai/gpt-4o:extended","name":"OpenAI: GPT-4o (extended)","display_name":"OpenAI: GPT-4o (extended)","type":"chat","context_length":4096,"max_output_tokens":4096,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"source":"public-provider-conf"},"vision":false},{"id":"openai/gpt-4o-audio-preview","name":"OpenAI: GPT-4o Audio","display_name":"OpenAI: GPT-4o Audio","type":"chat","context_length":4096,"max_output_tokens":4096,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"source":"public-provider-conf"},"vision":false},{"id":"openai/gpt-4o-search-preview","name":"OpenAI: GPT-4o Search Preview","display_name":"OpenAI: GPT-4o Search Preview","type":"chat","context_length":4096,"max_output_tokens":4096,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"source":"public-provider-conf"},"vision":false},{"id":"openai/gpt-4o-mini","name":"OpenAI: GPT-4o-mini","display_name":"OpenAI: GPT-4o-mini","type":"chat","context_length":4096,"max_output_tokens":4096,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"source":"public-provider-conf"},"vision":false},{"id":"openai/gpt-4o-mini-2024-07-18","name":"OpenAI: GPT-4o-mini (2024-07-18)","display_name":"OpenAI: GPT-4o-mini (2024-07-18)","type":"chat","context_length":4096,"max_output_tokens":4096,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"source":"public-provider-conf"},"vision":false},{"id":"openai/gpt-4o-mini-search-preview","name":"OpenAI: GPT-4o-mini Search Preview","display_name":"OpenAI: GPT-4o-mini Search Preview","type":"chat","context_length":4096,"max_output_tokens":4096,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"source":"public-provider-conf"},"vision":false},{"id":"openai/gpt-5","name":"OpenAI: GPT-5","display_name":"OpenAI: GPT-5","type":"chat","context_length":4096,"max_output_tokens":4096,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"source":"public-provider-conf"},"vision":false},{"id":"openai/gpt-5-chat","name":"OpenAI: GPT-5 Chat","display_name":"OpenAI: GPT-5 Chat","type":"chat","context_length":4096,"max_output_tokens":4096,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"source":"public-provider-conf"},"vision":false},{"id":"openai/gpt-5-codex","name":"OpenAI: GPT-5 Codex","display_name":"OpenAI: GPT-5 Codex","type":"chat","context_length":4096,"max_output_tokens":4096,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"source":"public-provider-conf"},"vision":false},{"id":"openai/gpt-5-mini","name":"OpenAI: GPT-5 Mini","display_name":"OpenAI: GPT-5 Mini","type":"chat","context_length":4096,"max_output_tokens":4096,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"source":"public-provider-conf"},"vision":false},{"id":"openai/gpt-5-nano","name":"OpenAI: GPT-5 Nano","display_name":"OpenAI: GPT-5 Nano","type":"chat","context_length":4096,"max_output_tokens":4096,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"source":"public-provider-conf"},"vision":false},{"id":"openai/gpt-oss-120b","name":"OpenAI: gpt-oss-120b","display_name":"OpenAI: gpt-oss-120b","type":"chat","context_length":4096,"max_output_tokens":4096,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"source":"public-provider-conf"},"vision":false},{"id":"openai/gpt-oss-20b","name":"OpenAI: gpt-oss-20b","display_name":"OpenAI: gpt-oss-20b","type":"chat","context_length":4096,"max_output_tokens":4096,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"source":"public-provider-conf"},"vision":false},{"id":"openai/o1","name":"OpenAI: o1","display_name":"OpenAI: o1","type":"chat","context_length":4096,"max_output_tokens":4096,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"source":"public-provider-conf"},"vision":false},{"id":"openai/o1-mini","name":"OpenAI: o1-mini","display_name":"OpenAI: o1-mini","type":"chat","context_length":4096,"max_output_tokens":4096,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"source":"public-provider-conf"},"vision":false},{"id":"openai/o1-mini-2024-09-12","name":"OpenAI: o1-mini (2024-09-12)","display_name":"OpenAI: o1-mini (2024-09-12)","type":"chat","context_length":4096,"max_output_tokens":4096,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"source":"public-provider-conf"},"vision":false},{"id":"openai/o1-pro","name":"OpenAI: o1-pro","display_name":"OpenAI: o1-pro","type":"chat","context_length":4096,"max_output_tokens":4096,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"source":"public-provider-conf"},"vision":false},{"id":"openai/o3","name":"OpenAI: o3","display_name":"OpenAI: o3","type":"chat","context_length":4096,"max_output_tokens":4096,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"source":"public-provider-conf"},"vision":false},{"id":"openai/o3-mini","name":"OpenAI: o3 Mini","display_name":"OpenAI: o3 Mini","type":"chat","context_length":4096,"max_output_tokens":4096,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"source":"public-provider-conf"},"vision":false},{"id":"openai/o3-mini-high","name":"OpenAI: o3 Mini High","display_name":"OpenAI: o3 Mini High","type":"chat","context_length":4096,"max_output_tokens":4096,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"source":"public-provider-conf"},"vision":false},{"id":"openai/o3-pro","name":"OpenAI: o3 Pro","display_name":"OpenAI: o3 Pro","type":"chat","context_length":4096,"max_output_tokens":4096,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"source":"public-provider-conf"},"vision":false},{"id":"openai/o4-mini","name":"OpenAI: o4 Mini","display_name":"OpenAI: o4 Mini","type":"chat","context_length":4096,"max_output_tokens":4096,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"source":"public-provider-conf"},"vision":false},{"id":"openai/o4-mini-high","name":"OpenAI: o4 Mini High","display_name":"OpenAI: o4 Mini High","type":"chat","context_length":4096,"max_output_tokens":4096,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"source":"public-provider-conf"},"vision":false},{"id":"opengvlab/internvl3-78b","name":"OpenGVLab: InternVL3 78B","display_name":"OpenGVLab: InternVL3 78B","type":"chat","context_length":4096,"max_output_tokens":4096,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"source":"public-provider-conf"},"vision":false},{"id":"perplexity/r1-1776","name":"Perplexity: R1 1776","display_name":"Perplexity: R1 1776","type":"chat","context_length":4096,"max_output_tokens":4096,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"source":"public-provider-conf"},"vision":false},{"id":"perplexity/sonar","name":"Perplexity: Sonar","display_name":"Perplexity: Sonar","type":"chat","context_length":4096,"max_output_tokens":4096,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"source":"public-provider-conf"},"vision":false},{"id":"perplexity/sonar-deep-research","name":"Perplexity: Sonar Deep Research","display_name":"Perplexity: Sonar Deep Research","type":"chat","context_length":4096,"max_output_tokens":4096,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"source":"public-provider-conf"},"vision":false},{"id":"perplexity/sonar-pro","name":"Perplexity: Sonar Pro","display_name":"Perplexity: Sonar Pro","type":"chat","context_length":4096,"max_output_tokens":4096,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"source":"public-provider-conf"},"vision":false},{"id":"perplexity/sonar-reasoning","name":"Perplexity: Sonar Reasoning","display_name":"Perplexity: Sonar Reasoning","type":"chat","context_length":4096,"max_output_tokens":4096,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"source":"public-provider-conf"},"vision":false},{"id":"perplexity/sonar-reasoning-pro","name":"Perplexity: Sonar Reasoning Pro","display_name":"Perplexity: Sonar Reasoning Pro","type":"chat","context_length":4096,"max_output_tokens":4096,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"source":"public-provider-conf"},"vision":false},{"id":"qwen/qwen-plus-2025-07-28","name":"Qwen: Qwen Plus 0728","display_name":"Qwen: Qwen Plus 0728","type":"chat","context_length":4096,"max_output_tokens":4096,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"source":"public-provider-conf"},"vision":false},{"id":"qwen/qwen-plus-2025-07-28:thinking","name":"Qwen: Qwen Plus 0728 (thinking)","display_name":"Qwen: Qwen Plus 0728 (thinking)","type":"chat","context_length":4096,"max_output_tokens":4096,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"source":"public-provider-conf"},"vision":false},{"id":"qwen/qwen-vl-max","name":"Qwen: Qwen VL Max","display_name":"Qwen: Qwen VL Max","type":"chat","context_length":4096,"max_output_tokens":4096,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"source":"public-provider-conf"},"vision":false},{"id":"qwen/qwen-vl-plus","name":"Qwen: Qwen VL Plus","display_name":"Qwen: Qwen VL Plus","type":"chat","context_length":4096,"max_output_tokens":4096,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"source":"public-provider-conf"},"vision":false},{"id":"qwen/qwen-max","name":"Qwen: Qwen-Max","display_name":"Qwen: Qwen-Max","type":"chat","context_length":4096,"max_output_tokens":4096,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"source":"public-provider-conf"},"vision":false},{"id":"qwen/qwen-plus","name":"Qwen: Qwen-Plus","display_name":"Qwen: Qwen-Plus","type":"chat","context_length":4096,"max_output_tokens":4096,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"source":"public-provider-conf"},"vision":false},{"id":"qwen/qwen-turbo","name":"Qwen: Qwen-Turbo","display_name":"Qwen: Qwen-Turbo","type":"chat","context_length":4096,"max_output_tokens":4096,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"source":"public-provider-conf"},"vision":false},{"id":"qwen/qwen2.5-vl-32b-instruct","name":"Qwen: Qwen2.5 VL 32B Instruct","display_name":"Qwen: Qwen2.5 VL 32B Instruct","type":"completion","context_length":4096,"max_output_tokens":4096,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"source":"public-provider-conf"},"vision":false},{"id":"qwen/qwen2.5-vl-72b-instruct","name":"Qwen: Qwen2.5 VL 72B Instruct","display_name":"Qwen: Qwen2.5 VL 72B Instruct","type":"completion","context_length":4096,"max_output_tokens":4096,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"source":"public-provider-conf"},"vision":false},{"id":"qwen/qwen-2.5-vl-7b-instruct","name":"Qwen: Qwen2.5-VL 7B Instruct","display_name":"Qwen: Qwen2.5-VL 7B Instruct","type":"completion","context_length":4096,"max_output_tokens":4096,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"source":"public-provider-conf"},"vision":false},{"id":"qwen/qwen3-14b","name":"Qwen: Qwen3 14B","display_name":"Qwen: Qwen3 14B","type":"chat","context_length":4096,"max_output_tokens":4096,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"source":"public-provider-conf"},"vision":false},{"id":"qwen/qwen3-235b-a22b","name":"Qwen: Qwen3 235B A22B","display_name":"Qwen: Qwen3 235B A22B","type":"chat","context_length":4096,"max_output_tokens":4096,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"source":"public-provider-conf"},"vision":false},{"id":"qwen/qwen3-235b-a22b-2507","name":"Qwen: Qwen3 235B A22B Instruct 2507","display_name":"Qwen: Qwen3 235B A22B Instruct 2507","type":"chat","context_length":4096,"max_output_tokens":4096,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"source":"public-provider-conf"},"vision":false},{"id":"qwen/qwen3-235b-a22b-thinking-2507","name":"Qwen: Qwen3 235B A22B Thinking 2507","display_name":"Qwen: Qwen3 235B A22B Thinking 2507","type":"chat","context_length":4096,"max_output_tokens":4096,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"source":"public-provider-conf"},"vision":false},{"id":"qwen/qwen3-30b-a3b","name":"Qwen: Qwen3 30B A3B","display_name":"Qwen: Qwen3 30B A3B","type":"chat","context_length":4096,"max_output_tokens":4096,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"source":"public-provider-conf"},"vision":false},{"id":"qwen/qwen3-30b-a3b-instruct-2507","name":"Qwen: Qwen3 30B A3B Instruct 2507","display_name":"Qwen: Qwen3 30B A3B Instruct 2507","type":"completion","context_length":4096,"max_output_tokens":4096,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"source":"public-provider-conf"},"vision":false},{"id":"qwen/qwen3-30b-a3b-thinking-2507","name":"Qwen: Qwen3 30B A3B Thinking 2507","display_name":"Qwen: Qwen3 30B A3B Thinking 2507","type":"chat","context_length":4096,"max_output_tokens":4096,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"source":"public-provider-conf"},"vision":false},{"id":"qwen/qwen3-32b","name":"Qwen: Qwen3 32B","display_name":"Qwen: Qwen3 32B","type":"chat","context_length":4096,"max_output_tokens":4096,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"source":"public-provider-conf"},"vision":false},{"id":"qwen/qwen3-8b","name":"Qwen: Qwen3 8B","display_name":"Qwen: Qwen3 8B","type":"chat","context_length":4096,"max_output_tokens":4096,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"source":"public-provider-conf"},"vision":false},{"id":"qwen/qwen3-coder-30b-a3b-instruct","name":"Qwen: Qwen3 Coder 30B A3B Instruct","display_name":"Qwen: Qwen3 Coder 30B A3B Instruct","type":"completion","context_length":4096,"max_output_tokens":4096,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"source":"public-provider-conf"},"vision":false},{"id":"qwen/qwen3-coder","name":"Qwen: Qwen3 Coder 480B A35B","display_name":"Qwen: Qwen3 Coder 480B A35B","type":"chat","context_length":4096,"max_output_tokens":4096,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"source":"public-provider-conf"},"vision":false},{"id":"qwen/qwen3-coder-480b-a35b-instruct","name":"Qwen: Qwen3 Coder 480B A35B Instruct","display_name":"Qwen: Qwen3 Coder 480B A35B Instruct","type":"completion","context_length":4096,"max_output_tokens":4096,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"source":"public-provider-conf"},"vision":false},{"id":"qwen/qwen3-coder-flash","name":"Qwen: Qwen3 Coder Flash","display_name":"Qwen: Qwen3 Coder Flash","type":"chat","context_length":4096,"max_output_tokens":4096,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"source":"public-provider-conf"},"vision":false},{"id":"qwen/qwen3-coder-plus","name":"Qwen: Qwen3 Coder Plus","display_name":"Qwen: Qwen3 Coder Plus","type":"chat","context_length":4096,"max_output_tokens":4096,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"source":"public-provider-conf"},"vision":false},{"id":"qwen/qwen3-max","name":"Qwen: Qwen3 Max","display_name":"Qwen: Qwen3 Max","type":"chat","context_length":4096,"max_output_tokens":4096,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"source":"public-provider-conf"},"vision":false},{"id":"qwen/qwen3-next-80b-a3b-instruct","name":"Qwen: Qwen3 Next 80B A3B Instruct","display_name":"Qwen: Qwen3 Next 80B A3B Instruct","type":"completion","context_length":4096,"max_output_tokens":4096,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"source":"public-provider-conf"},"vision":false},{"id":"qwen/qwen3-next-80b-a3b-thinking","name":"Qwen: Qwen3 Next 80B A3B Thinking","display_name":"Qwen: Qwen3 Next 80B A3B Thinking","type":"chat","context_length":4096,"max_output_tokens":4096,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"source":"public-provider-conf"},"vision":false},{"id":"qwen/qwen3-vl-235b-a22b-instruct","name":"Qwen: Qwen3 VL 235B A22B Instruct","display_name":"Qwen: Qwen3 VL 235B A22B Instruct","type":"completion","context_length":4096,"max_output_tokens":4096,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"source":"public-provider-conf"},"vision":false},{"id":"qwen/qwen3-vl-235b-a22b-thinking","name":"Qwen: Qwen3 VL 235B A22B Thinking","display_name":"Qwen: Qwen3 VL 235B A22B Thinking","type":"chat","context_length":4096,"max_output_tokens":4096,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"source":"public-provider-conf"},"vision":false},{"id":"qwen/qwq-32b","name":"Qwen: QwQ 32B","display_name":"Qwen: QwQ 32B","type":"chat","context_length":4096,"max_output_tokens":4096,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"source":"public-provider-conf"},"vision":false},{"id":"qwen/text-embedding-v3","name":"Qwen: Text Embedding v3","display_name":"Qwen: Text Embedding v3","type":"embedding","context_length":4096,"max_output_tokens":4096,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"source":"public-provider-conf"},"vision":false},{"id":"qwen/text-embedding-v4","name":"Qwen: Text Embedding v4","display_name":"Qwen: Text Embedding v4","type":"embedding","context_length":4096,"max_output_tokens":4096,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"source":"public-provider-conf"},"vision":false},{"id":"qwen/qwen-2.5-72b-instruct","name":"Qwen2.5 72B Instruct","display_name":"Qwen2.5 72B Instruct","type":"completion","context_length":4096,"max_output_tokens":4096,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"source":"public-provider-conf"},"vision":false},{"id":"qwen/qwen-2.5-7b-instruct","name":"Qwen2.5 7B Instruct","display_name":"Qwen2.5 7B Instruct","type":"completion","context_length":4096,"max_output_tokens":4096,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"source":"public-provider-conf"},"vision":false},{"id":"qwen/qwen-2.5-coder-32b-instruct","name":"Qwen2.5 Coder 32B Instruct","display_name":"Qwen2.5 Coder 32B Instruct","type":"completion","context_length":4096,"max_output_tokens":4096,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"source":"public-provider-conf"},"vision":false},{"id":"undi95/remm-slerp-l2-13b","name":"ReMM SLERP 13B","display_name":"ReMM SLERP 13B","type":"chat","context_length":4096,"max_output_tokens":4096,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"source":"public-provider-conf"},"vision":false},{"id":"sao10k/l3-lunaris-8b","name":"Sao10K: Llama 3 8B Lunaris","display_name":"Sao10K: Llama 3 8B Lunaris","type":"chat","context_length":4096,"max_output_tokens":4096,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"source":"public-provider-conf"},"vision":false},{"id":"sao10k/l3-euryale-70b","name":"Sao10k: Llama 3 Euryale 70B v2.1","display_name":"Sao10k: Llama 3 Euryale 70B v2.1","type":"chat","context_length":4096,"max_output_tokens":4096,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"source":"public-provider-conf"},"vision":false},{"id":"sao10k/l3.1-euryale-70b","name":"Sao10K: Llama 3.1 Euryale 70B v2.2","display_name":"Sao10K: Llama 3.1 Euryale 70B v2.2","type":"chat","context_length":4096,"max_output_tokens":4096,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"source":"public-provider-conf"},"vision":false},{"id":"sao10k/l3.3-euryale-70b","name":"Sao10K: Llama 3.3 Euryale 70B","display_name":"Sao10K: Llama 3.3 Euryale 70B","type":"chat","context_length":4096,"max_output_tokens":4096,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"source":"public-provider-conf"},"vision":false},{"id":"shisa-ai/shisa-v2-llama3.3-70b","name":"Shisa AI: Shisa V2 Llama 3.3 70B","display_name":"Shisa AI: Shisa V2 Llama 3.3 70B","type":"chat","context_length":4096,"max_output_tokens":4096,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"source":"public-provider-conf"},"vision":false},{"id":"raifle/sorcererlm-8x22b","name":"SorcererLM 8x22B","display_name":"SorcererLM 8x22B","type":"chat","context_length":4096,"max_output_tokens":4096,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"source":"public-provider-conf"},"vision":false},{"id":"stepfun-ai/step3","name":"StepFun: Step3","display_name":"StepFun: Step3","type":"chat","context_length":4096,"max_output_tokens":4096,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"source":"public-provider-conf"},"vision":false},{"id":"switchpoint/router","name":"Switchpoint Router","display_name":"Switchpoint Router","type":"chat","context_length":4096,"max_output_tokens":4096,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"source":"public-provider-conf"},"vision":false},{"id":"tencent/hunyuan-a13b-instruct","name":"Tencent: Hunyuan A13B Instruct","display_name":"Tencent: Hunyuan A13B Instruct","type":"completion","context_length":4096,"max_output_tokens":4096,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"source":"public-provider-conf"},"vision":false},{"id":"thedrummer/anubis-70b-v1.1","name":"TheDrummer: Anubis 70B V1.1","display_name":"TheDrummer: Anubis 70B V1.1","type":"chat","context_length":4096,"max_output_tokens":4096,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"source":"public-provider-conf"},"vision":false},{"id":"thedrummer/anubis-pro-105b-v1","name":"TheDrummer: Anubis Pro 105B V1","display_name":"TheDrummer: Anubis Pro 105B V1","type":"chat","context_length":4096,"max_output_tokens":4096,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"source":"public-provider-conf"},"vision":false},{"id":"thedrummer/rocinante-12b","name":"TheDrummer: Rocinante 12B","display_name":"TheDrummer: Rocinante 12B","type":"chat","context_length":4096,"max_output_tokens":4096,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"source":"public-provider-conf"},"vision":false},{"id":"thedrummer/skyfall-36b-v2","name":"TheDrummer: Skyfall 36B V2","display_name":"TheDrummer: Skyfall 36B V2","type":"chat","context_length":4096,"max_output_tokens":4096,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"source":"public-provider-conf"},"vision":false},{"id":"thedrummer/unslopnemo-12b","name":"TheDrummer: UnslopNemo 12B","display_name":"TheDrummer: UnslopNemo 12B","type":"chat","context_length":4096,"max_output_tokens":4096,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"source":"public-provider-conf"},"vision":false},{"id":"thudm/glm-4.1v-9b-thinking","name":"THUDM: GLM 4.1V 9B Thinking","display_name":"THUDM: GLM 4.1V 9B Thinking","type":"chat","context_length":4096,"max_output_tokens":4096,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"source":"public-provider-conf"},"vision":false},{"id":"thudm/glm-z1-32b","name":"THUDM: GLM Z1 32B","display_name":"THUDM: GLM Z1 32B","type":"chat","context_length":4096,"max_output_tokens":4096,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"source":"public-provider-conf"},"vision":false},{"id":"tngtech/deepseek-r1t-chimera","name":"TNG: DeepSeek R1T Chimera","display_name":"TNG: DeepSeek R1T Chimera","type":"chat","context_length":4096,"max_output_tokens":4096,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"source":"public-provider-conf"},"vision":false},{"id":"tngtech/deepseek-r1t2-chimera","name":"TNG: DeepSeek R1T2 Chimera","display_name":"TNG: DeepSeek R1T2 Chimera","type":"chat","context_length":4096,"max_output_tokens":4096,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"source":"public-provider-conf"},"vision":false},{"id":"alibaba/tongyi-deepresearch-30b-a3b","name":"Tongyi DeepResearch 30B A3B","display_name":"Tongyi DeepResearch 30B A3B","type":"chat","context_length":4096,"max_output_tokens":4096,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"source":"public-provider-conf"},"vision":false},{"id":"microsoft/wizardlm-2-8x22b","name":"WizardLM-2 8x22B","display_name":"WizardLM-2 8x22B","type":"chat","context_length":4096,"max_output_tokens":4096,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"source":"public-provider-conf"},"vision":false},{"id":"x-ai/grok-3","name":"xAI: Grok 3","display_name":"xAI: Grok 3","type":"chat","context_length":4096,"max_output_tokens":4096,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"source":"public-provider-conf"},"vision":false},{"id":"x-ai/grok-3-beta","name":"xAI: Grok 3 Beta","display_name":"xAI: Grok 3 Beta","type":"chat","context_length":4096,"max_output_tokens":4096,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"source":"public-provider-conf"},"vision":false},{"id":"x-ai/grok-3-mini","name":"xAI: Grok 3 Mini","display_name":"xAI: Grok 3 Mini","type":"chat","context_length":4096,"max_output_tokens":4096,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"source":"public-provider-conf"},"vision":false},{"id":"x-ai/grok-3-mini-beta","name":"xAI: Grok 3 Mini Beta","display_name":"xAI: Grok 3 Mini Beta","type":"chat","context_length":4096,"max_output_tokens":4096,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"source":"public-provider-conf"},"vision":false},{"id":"x-ai/grok-4","name":"xAI: Grok 4","display_name":"xAI: Grok 4","type":"chat","context_length":4096,"max_output_tokens":4096,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"source":"public-provider-conf"},"vision":false},{"id":"x-ai/grok-4-fast","name":"xAI: Grok 4 Fast","display_name":"xAI: Grok 4 Fast","type":"chat","context_length":4096,"max_output_tokens":4096,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"source":"public-provider-conf"},"vision":false},{"id":"x-ai/grok-code-fast-1","name":"xAI: Grok Code Fast 1","display_name":"xAI: Grok Code Fast 1","type":"chat","context_length":4096,"max_output_tokens":4096,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"source":"public-provider-conf"},"vision":false},{"id":"z-ai/glm-4-32b","name":"Z.AI: GLM 4 32B","display_name":"Z.AI: GLM 4 32B","type":"chat","context_length":4096,"max_output_tokens":4096,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"source":"public-provider-conf"},"vision":false},{"id":"z-ai/glm-4.5","name":"Z.AI: GLM 4.5","display_name":"Z.AI: GLM 4.5","type":"chat","context_length":4096,"max_output_tokens":4096,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"source":"public-provider-conf"},"vision":false},{"id":"z-ai/glm-4.5-air","name":"Z.AI: GLM 4.5 Air","display_name":"Z.AI: GLM 4.5 Air","type":"chat","context_length":4096,"max_output_tokens":4096,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"source":"public-provider-conf"},"vision":false},{"id":"z-ai/glm-4.5v","name":"Z.AI: GLM 4.5V","display_name":"Z.AI: GLM 4.5V","type":"chat","context_length":4096,"max_output_tokens":4096,"capabilities":{"vision":false,"function_calling":false,"reasoning":false,"tool_calling":false},"reasoning":false,"tool_call":false,"metadata":{"source":"public-provider-conf"},"vision":false}],"metadata":{"source":"public-provider-conf"}}},"updated_at":"2025-10-03T14:35:07.409Z"}