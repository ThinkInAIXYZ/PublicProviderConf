{
  "provider": "ppinfra",
  "providerName": "PPInfra",
  "lastUpdated": "2025-08-30T12:47:53.920316Z",
  "models": [
    {
      "id": "deepseek/deepseek-v3.1",
      "name": "Deepseek V3.1",
      "contextLength": 163840,
      "maxTokens": 163840,
      "vision": false,
      "functionCall": true,
      "reasoning": true,
      "type": "chat",
      "description": "DeepSeek-V3.1 是 DeepSeek最新的模型，支持思考和非思考混合模式。 该模型是在 DeepSeek-V3.1-Base 基础上进行后期训练的，而该基础模型是通过两阶段长上下文扩展方法从原始 V3 基础检查点发展而来，该方法遵循了原始 DeepSeek-V3 报告中概述的技术路线。我们通过收集更多长文本文档显著扩展了训练数据集，并大幅延长了两个训练阶段的规模：32K 上下文扩展阶段的训练量提升10倍达到6300亿token，128K扩展阶段则扩大3.3倍至2090亿token。"
    },
    {
      "id": "qwen/qwen3-coder-480b-a35b-instruct",
      "name": "Qwen3 Coder 480B A35B Instruct",
      "contextLength": 262144,
      "maxTokens": 260000,
      "vision": false,
      "functionCall": true,
      "reasoning": false,
      "type": "chat",
      "description": "Qwen3-Coder-480B-A35B-Instruct 是由Qwen推出的尖端开源编程模型，在智能体编程（Agentic Coding）、浏览器自动化及核心开发任务中达到与Claude Sonnet同等的性能水平。该模型原生支持256K上下文窗口（通过YaRN技术可扩展至1M token），擅长仓库级代码分析，并针对Qwen Code、CLINE等平台设计了专用函数调用协议——使其成为复杂实际开发工作流的理想选择。"
    },
    {
      "id": "moonshotai/kimi-k2-instruct",
      "name": "Kimi K2 Instruct",
      "contextLength": 131072,
      "maxTokens": 128000,
      "vision": true,
      "functionCall": true,
      "reasoning": false,
      "type": "chat",
      "description": "Kimi K2 是一种最先进的专家混合 （MoE） 语言模型，具有 320 亿个激活参数和 1 万亿个总参数。使用 Muon 优化器进行训练，Kimi K2 在前沿知识、推理和编码任务方面实现了卓越的性能，同时针对代理功能进行了精心优化，专为工具使用、推理和自主解决问题而设计。"
    },
    {
      "id": "deepseek/deepseek-v3-0324",
      "name": "DeepSeek V3 0324",
      "contextLength": 163840,
      "maxTokens": 163840,
      "vision": false,
      "functionCall": true,
      "reasoning": false,
      "type": "chat",
      "description": "DeepSeek V3 0324 是深度求索（DeepSeek）团队旗舰级对话模型系列的最新版本，采用混合专家（Mixture-of-Experts, MoE）架构，参数量达685B参数。"
    },
    {
      "id": "qwen/qwen3-235b-a22b-thinking-2507",
      "name": "Qwen3 235B A22b Thinking 2507",
      "contextLength": 131072,
      "maxTokens": 114688,
      "vision": false,
      "functionCall": true,
      "reasoning": true,
      "type": "chat",
      "description": "Qwen3-235B-A22B-Thinking-2507是Qwen3系列最新推出的具备思维能力的突破性模型，在推理能力方面实现了跨越式提升。这款先进AI在逻辑推理、数学运算、科学分析、编程任务以及学术基准测试中均展现出显著增强的性能表现，其水平已达到甚至超越人类专家级别，在开源思维模型中树立了全新的性能标杆。除了卓越的推理能力外，该模型在通用能力方面也有显著提升，包括更精准的指令理解与执行、更复杂的工具调用能力、高度拟真的文本生成效果，以及与人类偏好更契合的输出表现。同时，其增强的256K超长上下文理解能力，使其能够精准把握长篇文档和复杂讨论的深层逻辑关联。"
    },
    {
      "id": "qwen/qwen3-235b-a22b-instruct-2507",
      "name": "Qwen3 235B A22B Instruct 2507",
      "contextLength": 262144,
      "maxTokens": 260000,
      "vision": false,
      "functionCall": true,
      "reasoning": false,
      "type": "chat",
      "description": "Qwen3-235B-A22B-Instruct-2507 是基于 Qwen3-235B 架构的多语言指令微调混合专家语言模型，每次前向推理激活 220 亿参数。该模型针对通用文本生成任务优化，涵盖指令遵循、逻辑推理、数学计算、代码生成及工具调用等能力。其原生支持 26.2 万 token 的超长上下文窗口，且未采用 \"<think>\" 思维链显式标注模式。\n相较于基础版本，本版本在知识覆盖广度、长文本推理能力、编程基准测试以及开放性任务对齐度等方面实现显著提升。模型尤其擅长多语言理解、数学推理（如美国数学邀请赛 AIME、哈佛-麻省理工数学锦标赛 HMMT），并在 Arena-Hard 综合评测与写作专项评测 WritingBench 中表现优异。"
    },
    {
      "id": "baichuan/baichuan-m2-32b",
      "name": "BaiChuan M2 32B",
      "contextLength": 131072,
      "maxTokens": 131072,
      "vision": false,
      "functionCall": false,
      "reasoning": true,
      "type": "chat",
      "description": "百川M2是一款专为真实医疗场景设计的智能推理模型。我们从实际医疗问题出发，基于大规模验证系统进行强化学习训练，在保持通用能力的同时，实现了医疗推理能力的突破性提升。作为当前全球领先的开源医疗大模型，百川M2在HealthBench医疗基准测试中表现优异：超越所有开源模型（包括GPT-OSS-120B），优于众多前沿闭源模型，是目前最接近GPT-5医疗能力的开源模型\n实践证明：强大的验证系统是连接模型能力与现实应用的关键，端到端的强化学习方法能显著提升医疗推理能力\n百川M2的发布，标志着医疗人工智能领域的技术突破，为智慧医疗发展提供了全新可能。"
    },
    {
      "id": "zai-org/glm-4.5v",
      "name": "GLM 4.5V",
      "contextLength": 65536,
      "maxTokens": 65536,
      "vision": true,
      "functionCall": true,
      "reasoning": true,
      "type": "chat",
      "description": "Z.ai推出的GLM-4.5V视觉推理模型树立了行业新标杆，在42项基准测试中均达到同规模开源模型的最高水平。该模型不仅擅长基准测试，更通过混合训练技术在真实场景中展现出卓越性能，具备全方位的视觉理解能力——包括图像/视频分析、图形界面交互、复杂文档处理以及精准的视觉元素定位等核心功能。\n在中国GeoGuessr地理定位挑战赛中，GLM-4.5V仅用16小时就超越了99%的人类选手（共21000人参与），一周内攀升至第66名。该模型基于GLM-4.5-Air基础架构开发，继承了GLM-4.1V-Thinking的技术路线，采用1060亿参数的混合专家（MoE）架构实现高效扩展。作为连接前沿AI研究与实际应用的桥梁，GLM-4.5V正在重新定义视觉智能的行业标准"
    },
    {
      "id": "zai-org/glm-4.5",
      "name": "GLM-4.5",
      "contextLength": 131072,
      "maxTokens": 131000,
      "vision": false,
      "functionCall": true,
      "reasoning": true,
      "type": "chat",
      "description": "GLM-4.5系列模型是专为智能体（Agent）研发的基座模型。旗舰款GLM-4.5拥有3550亿总参数（320亿激活参数），通过融合推理、编程与智能体能力，满足复杂场景需求。\n作为混合推理系统，它提供双工作模式：\n- 思考模式：支持复杂推理、工具调用和策略规划\n- 即时响应模式：实现低延迟交互，快速生成反馈\n该架构在保持高性能的同时，为动态智能体环境提供自适应解决方案。"
    },
    {
      "id": "minimaxai/minimax-m1-80k",
      "name": "MiniMaxAI/MiniMax-M1-80k",
      "contextLength": 128000,
      "maxTokens": 40000,
      "vision": false,
      "functionCall": true,
      "reasoning": true,
      "type": "chat",
      "description": "MiniMax-M1世界上第一个开放权重、大规模混合注意力推理模型。MiniMax-M1 采用混合专家 （MoE） 架构，并结合闪电注意力机制。该模型总共包含 4560 亿个参数，每个令牌激活了 459 亿个参数。M1 模型原生支持 100 万个令牌的上下文长度，是 DeepSeek R1 上下文大小的 8 倍。同时MiniMax-M1  结合 CISPO 算法与混合注意力设计的高效强化学习训练，在长输入推理与真实软件工程场景中实现了业界领先的性能。"
    },
    {
      "id": "qwen/qwen3-235b-a22b-fp8",
      "name": "Qwen3-235B-A22B",
      "contextLength": 40960,
      "maxTokens": 20000,
      "vision": false,
      "functionCall": false,
      "reasoning": true,
      "type": "chat",
      "description": "实现推理模式和非推理模式的有效融合，可在对话中切换模式。推理能力显著超过QwQ、通用能力显著超过Qwen2.5-72B-Instruct，达到同规模业界SOTA水平。"
    },
    {
      "id": "deepseek/deepseek-r1-0528-qwen3-8b",
      "name": "DeepSeek-R1-0528-Qwen3-8B",
      "contextLength": 128000,
      "maxTokens": 32000,
      "vision": false,
      "functionCall": false,
      "reasoning": true,
      "type": "chat",
      "description": "DeepSeek-R1-0528-Qwen3-8B 是基于 Qwen3 8B Base 模型，通过融合 DeepSeek-R1-0528 的思维链（Chain-of-Thought）优化训练而成的高性能推理模型。在 AIME 2024 评测中，该模型以开源模型身份达到最先进（SOTA）水平，性能较原版 Qwen3 8B 提升 10%，并展现出与 2350 亿参数的 Qwen3-235B-thinking 相当的推理能力。"
    },
    {
      "id": "qwen/qwen3-32b-fp8",
      "name": "Qwen3 32B",
      "contextLength": 128000,
      "maxTokens": 20000,
      "vision": false,
      "functionCall": false,
      "reasoning": true,
      "type": "chat",
      "description": "实现推理模式和非推理模式的有效融合，可在对话中切换模式。推理能力显著超过QwQ、通用能力显著超过Qwen2.5-32B-Instruct，达到同规模业界SOTA水平。"
    },
    {
      "id": "qwen/qwen3-30b-a3b-fp8",
      "name": "Qwen3-30B-A3B",
      "contextLength": 128000,
      "maxTokens": 20000,
      "vision": false,
      "functionCall": false,
      "reasoning": true,
      "type": "chat",
      "description": "实现推理模式和非推理模式的有效融合，可在对话中切换模式。推理能力以更小参数规模比肩QwQ-32B、通用能力显著超过Qwen2.5-14B，达到同规模业界SOTA水平。"
    },
    {
      "id": "deepseek/deepseek-prover-v2-671b",
      "name": "Deepseek Prover V2 671B",
      "contextLength": 160000,
      "maxTokens": 160000,
      "vision": false,
      "functionCall": false,
      "reasoning": false,
      "type": "chat",
      "description": "Deepseek 全新开源模型 DeepSeek-Prover-V2-671B，专注于数学定理证明任务。该模型基于混合专家 (MoE) 架构，并利用 Lean 4 框架进行形式化推理训练。该模型参数规模达 6710 亿，结合强化学习和大规模合成数据，显著提升了自动化证明能力。"
    },
    {
      "id": "deepseek/deepseek-r1-turbo",
      "name": "DeepSeek R1 (Turbo)",
      "contextLength": 64000,
      "maxTokens": 16000,
      "vision": false,
      "functionCall": true,
      "reasoning": true,
      "type": "chat",
      "description": "DeepSeek R1 (Turbo)是派欧算力云平台提供的最新高性能DeepSeek R1 模型。DeepSeek R1是DeepSeek团队发布的最新开源模型，具备非常强悍的推理性能，尤其在数学、编程和推理任务上达到了与OpenAI的o1模型相当的水平。"
    },
    {
      "id": "thudm/glm-4.1v-9b-thinking",
      "name": "GLM 4.1V 9B Thinking",
      "contextLength": 65536,
      "maxTokens": 32000,
      "vision": true,
      "functionCall": false,
      "reasoning": true,
      "type": "chat",
      "description": "GLM-4.1V-9B-Thinking 是由智谱 AI 与清华大学 KEG 实验室联合发布的开源视觉语言模型（VLM），专为处理复杂的多模态认知任务设计。该模型是基于 GLM-4-9B-0414 基础模型，通过引入“思维链”（CoT）推理机制和采用强化学习策略，显著提升了跨模态的推理能力和稳定性。作为一个 9B 参数规模的轻量级模型，它在部署效率和性能之间取得了平衡，在 28 项权威评测基准中，有 18 项的表现持平甚至超越了 72B 参数规模的 Qwen-2.5-VL-72B。该模型不仅在图文理解、数学科学推理、视频理解等任务上表现卓越，还支持高达 4K 分辨率的图像和任意宽高比输入"
    },
    {
      "id": "deepseek/deepseek-r1-0528",
      "name": "deepseek/deepseek-r1-0528",
      "contextLength": 163840,
      "maxTokens": 163840,
      "vision": false,
      "functionCall": true,
      "reasoning": true,
      "type": "chat",
      "description": "DeepSeek R1 0528 是派欧云平台提供的最新高性能DeepSeek R1 模型。DeepSeek R1 0528 是DeepSeek团队发布的最新开源模型，具备非常强悍的推理性能，尤其在编程、数学、推理任务上达到了开源模型最先进的水平。"
    },
    {
      "id": "deepseek/deepseek-v3-turbo",
      "name": "DeepSeek V3 (Turbo)",
      "contextLength": 64000,
      "maxTokens": 16000,
      "vision": false,
      "functionCall": true,
      "reasoning": false,
      "type": "chat",
      "description": "DeepSeek V3 (Turbo) 是派欧算力云平台提供的最新高性能DeepSeek V3 模型。DeepSeek-V3 在推理速度方面实现了比之前模型的重大突破。在开源模型中排名第一，并可与全球最先进的闭源模型相媲美。DeepSeek-V3 采用了多头潜在注意力 （MLA） 和 DeepSeekMoE 架构，这些架构在 DeepSeek-V2 中得到了全面验证。此外，DeepSeek-V3 开创了一种用于负载均衡的辅助无损策略，并设定了多标记预测训练目标以获得更强的性能。"
    },
    {
      "id": "deepseek/deepseek-v3/community",
      "name": "DeepSeek V3 (Community)",
      "contextLength": 64000,
      "maxTokens": 4000,
      "vision": false,
      "functionCall": true,
      "reasoning": false,
      "type": "chat",
      "description": "DeepSeek-V3在推理速度方面实现了比之前模型的重大突破。在开源模型中排名第一，并可与全球最先进的闭源模型相媲美。DeepSeek-V3 采用了多头潜在注意力 （MLA） 和 DeepSeekMoE 架构，这些架构在 DeepSeek-V2 中得到了全面验证。此外，DeepSeek-V3 开创了一种用于负载均衡的辅助无损策略，并设定了多标记预测训练目标以获得更强的性能。"
    },
    {
      "id": "deepseek/deepseek-r1/community",
      "name": "DeepSeek R1 (Community)",
      "contextLength": 64000,
      "maxTokens": 4000,
      "vision": false,
      "functionCall": true,
      "reasoning": true,
      "type": "chat",
      "description": "DeepSeek R1是DeepSeek团队发布的最新开源模型，具备非常强悍的推理性能，尤其在数学、编程和推理任务上达到了与OpenAI的o1模型相当的水平。"
    },
    {
      "id": "deepseek/deepseek-r1-distill-qwen-32b",
      "name": "DeepSeek: DeepSeek R1 Distill Qwen 32B",
      "contextLength": 64000,
      "maxTokens": 8000,
      "vision": false,
      "functionCall": false,
      "reasoning": true,
      "type": "chat",
      "description": "DeepSeek R1 Distill Qwen 32B 是一种基于 Qwen 2.5 32B 的蒸馏大语言模型，通过使用 DeepSeek R1 的输出进行训练而得。该模型在多个基准测试中超越了 OpenAI 的 o1-mini，取得了密集模型（dense models）的最新技术领先成果（state-of-the-art）。以下是一些基准测试的结果：\nAIME 2024 pass@1: 72.6\nMATH-500 pass@1: 94.3\nCodeForces Rating: 1691\n该模型通过从 DeepSeek R1 的输出中进行微调，展现了与更大规模的前沿模型相当的竞争性能。"
    },
    {
      "id": "baidu/ernie-4.5-vl-424b-a47b",
      "name": "ERNIE-4.5-VL-424B-A47B",
      "contextLength": 123000,
      "maxTokens": 16000,
      "vision": true,
      "functionCall": true,
      "reasoning": true,
      "type": "chat",
      "description": "文心4.5系列开源模型为MoE 架构，是一种创新性的多模态异构模型结构，通过跨模态参数共享机制实现模态间知识融合，同时为各单一模态保留专用参数空间。此架构非常适用于从大语言模型向多模态模型的持续预训练范式，在保持甚至提升文本任务性能的基础上，显著增强多模态理解能力。该模型均使用飞桨深度学习框架进行高效训练、推理和部署。在大语言模型的预训练中，模型FLOPs利用率（MFU）达到47%。实验结果显示，该系列模型在多个文本和多模态基准测试中达到SOTA水平，在指令遵循、世界知识记忆、视觉理解和多模态推理任务上效果尤为突出。"
    },
    {
      "id": "deepseek/deepseek-r1-distill-qwen-14b",
      "name": "DeepSeek: DeepSeek R1 Distill Qwen 14B",
      "contextLength": 64000,
      "maxTokens": 8000,
      "vision": false,
      "functionCall": false,
      "reasoning": true,
      "type": "chat",
      "description": "DeepSeek R1 Distill Qwen 14B 是一种基于 Qwen 2.5 14B 的蒸馏大语言模型，通过使用 DeepSeek R1 的输出进行训练而得。该模型在多个基准测试中超越了 OpenAI 的 o1-mini，取得了密集模型（dense models）的最新技术领先成果（state-of-the-art）。以下是一些基准测试的结果：\nAIME 2024 pass@1: 69.7\nMATH-500 pass@1: 93.9\nCodeForces Rating: 1481\n该模型通过从 DeepSeek R1 的输出中进行微调，展现了与更大规模的前沿模型相当的竞争性能。"
    },
    {
      "id": "baidu/ernie-4.5-300b-a47b-paddle",
      "name": "ERNIE-4.5-300B-A47B",
      "contextLength": 123000,
      "maxTokens": 12000,
      "vision": false,
      "functionCall": true,
      "reasoning": false,
      "type": "chat",
      "description": "文心4.5系列开源模型为MoE 架构，是一种创新性的多模态异构模型结构，通过跨模态参数共享机制实现模态间知识融合，同时为各单一模态保留专用参数空间。此架构非常适用于从大语言模型向多模态模型的持续预训练范式，在保持甚至提升文本任务性能的基础上，显著增强多模态理解能力。该模型均使用飞桨深度学习框架进行高效训练、推理和部署。在大语言模型的预训练中，模型FLOPs利用率（MFU）达到47%。实验结果显示，该系列模型在多个文本和多模态基准测试中达到SOTA水平，在指令遵循、世界知识记忆、视觉理解和多模态推理任务上效果尤为突出。"
    },
    {
      "id": "deepseek/deepseek-r1-distill-llama-70b",
      "name": "DeepSeek R1 Distill Llama 70B",
      "contextLength": 32000,
      "maxTokens": 8000,
      "vision": false,
      "functionCall": false,
      "reasoning": true,
      "type": "chat",
      "description": "DeepSeek R1 Distill Llama 70B是基于Llama3.3  70B的大型语言模型，该模型利用DeepSeek R1输出的微调，实现了与大型前沿模型相当的竞争性能。"
    },
    {
      "id": "deepseek/deepseek-r1-distill-llama-8b",
      "name": "DeepSeek: DeepSeek R1 Distill Llama 8B",
      "contextLength": 32000,
      "maxTokens": 8000,
      "vision": false,
      "functionCall": false,
      "reasoning": true,
      "type": "chat",
      "description": "DeepSeek R1 Distill Llama 8B 是一种基于 Llama-3.1-8B-Instruct 的蒸馏大语言模型，通过使用 DeepSeek R1 的输出进行训练而得。"
    },
    {
      "id": "qwen/qwen-2.5-72b-instruct",
      "name": "Qwen2.5 72B Instruct",
      "contextLength": 32000,
      "maxTokens": 16000,
      "vision": false,
      "functionCall": true,
      "reasoning": false,
      "type": "chat",
      "description": "Qwen2.5-72B-Instruct 是阿里云发布的最新大语言模型系列之一。该 72B 模型在编码和数学等领域具有显著改进的能力。该模型还提供了多语言支持，覆盖超过 29 种语言，包括中文、英文等。模型在指令跟随、理解结构化数据以及生成结构化输出（尤其是 JSON）方面都有显著提升。"
    },
    {
      "id": "qwen/qwen3-8b-fp8",
      "name": "Qwen3 8B",
      "contextLength": 128000,
      "maxTokens": 20000,
      "vision": false,
      "functionCall": false,
      "reasoning": true,
      "type": "chat",
      "description": "实现思考模式和非思考模式的有效融合，可在对话中切换模式。推理能力达到同规模业界SOTA水平、通用能力显著超过Qwen2.5-7B。"
    },
    {
      "id": "qwen/qwen2.5-vl-72b-instruct",
      "name": "Qwen2.5 VL 72B Instruct",
      "contextLength": 32768,
      "maxTokens": 32768,
      "vision": true,
      "functionCall": false,
      "reasoning": false,
      "type": "chat",
      "description": "Qwen2.5-VL 是 Qwen2.5 系列最新推出的视觉语言模型。该模型在多方面有显著提升：具备更强的视觉理解能力，能够识别常见物体、分析文本、图表和布局；作为视觉代理能够推理并动态指导工具使用；支持理解超过 1 小时的长视频并捕捉关键事件；能够通过生成边界框或点准确定位图像中的物体；支持生成结构化输出，尤其适用于发票、表格等扫描数据。模型在多项基准测试中表现出色，包括图像、视频和代理任务评测。"
    },
    {
      "id": "qwen/qwen2.5-32b-instruct",
      "name": "Qwen2.5 32B Instruct",
      "contextLength": 32000,
      "maxTokens": 32000,
      "vision": false,
      "functionCall": true,
      "reasoning": false,
      "type": "chat",
      "description": "Qwen2.5-32B-Instruct 是阿里云发布的最新大语言模型系列之一。该 32B 模型在编码和数学等领域具有显著改进的能力。该模型提供了多语言支持，覆盖超过 29 种语言，包括中文、英文等。模型在指令跟随、理解结构化数据以及生成结构化输出（尤其是 JSON）方面都有显著提升。"
    },
    {
      "id": "thudm/glm-4-32b-0414",
      "name": "THUDM/GLM-4-32B-0414",
      "contextLength": 32000,
      "maxTokens": 32000,
      "vision": false,
      "functionCall": true,
      "reasoning": false,
      "type": "chat",
      "description": "GLM-4-32B-0414 是 GLM 系列的新一代开源模型，拥有 320 亿参数。该模型性能可与 OpenAI 的 GPT 系列和 DeepSeek 的 V3/R1 系列相媲美，并支持非常用户友好的本地部署功能。GLM-4-32B-Base-0414 是在 15T 高质量数据上预训练的，包括大量推理类型的合成数据，为后续的强化学习扩展奠定了基础。在后训练阶段，除了对话场景的人类偏好对齐外，研究团队还使用拒绝采样和强化学习等技术增强了模型在指令遵循、工程代码和函数调用方面的表现，加强了代理任务所需的原子能力。GLM-4-32B-0414 在工程代码、Artifact 生成、函数调用、基于搜索的问答和报告生成等领域取得了良好的成果，部分 Benchmark 指标已接近甚至超越 GPT-4o、DeepSeek-V3-0324（671B）等更大模型的水平。"
    },
    {
      "id": "qwen/qwen2.5-7b-instruct",
      "name": "Qwen 2.5 7B Instruct",
      "contextLength": 32000,
      "maxTokens": 32000,
      "vision": false,
      "functionCall": true,
      "reasoning": false,
      "type": "chat",
      "description": "Qwen2.5 是 Qwen 大语言模型的最新系列。在 Qwen2.5 中，发布了多个基础语言模型和指令微调语言模型，参数规模从 0.5 亿到 720 亿不等。相比 Qwen2，Qwen2.5 带来了以下显著提升：\n- 知识储备显著提升，并在编程和数学能力上有大幅增强，这得益于我们在这些领域训练的专业专家模型。\n- 在指令理解与执行、生成长文本（超过8K tokens）、理解结构化数据（如表格）、以及生成结构化输出（尤其是 JSON）方面表现大幅提升。对多样化的系统提示更具适应性，增强了角色扮演实现和聊天机器人的条件设定能力。\n- 长上下文支持扩展至最多 128K tokens，最多可生成 8K tokens 的内容。\n- 多语言支持涵盖超过 29 种语言，包括中文、英文、法语、西班牙语、葡萄牙语、德语、意大利语、俄语、日语、韩语、越南语、泰语、阿拉伯语等。"
    },
    {
      "id": "baidu/ernie-4.5-0.3b",
      "name": "ERNIE-4.5-0.3B",
      "contextLength": 120000,
      "maxTokens": 8000,
      "vision": false,
      "functionCall": true,
      "reasoning": false,
      "type": "chat",
      "description": "文心4.5系列开源模型为MoE 架构，是一种创新性的多模态异构模型结构，通过跨模态参数共享机制实现模态间知识融合，同时为各单一模态保留专用参数空间。此架构非常适用于从大语言模型向多模态模型的持续预训练范式，在保持甚至提升文本任务性能的基础上，显著增强多模态理解能力。该模型均使用飞桨深度学习框架进行高效训练、推理和部署。在大语言模型的预训练中，模型FLOPs利用率（MFU）达到47%。实验结果显示，该系列模型在多个文本和多模态基准测试中达到SOTA水平，在指令遵循、世界知识记忆、视觉理解和多模态推理任务上效果尤为突出。"
    },
    {
      "id": "baidu/ernie-4.5-21B-a3b",
      "name": "ERNIE-4.5-21B-A3B",
      "contextLength": 120000,
      "maxTokens": 8000,
      "vision": false,
      "functionCall": true,
      "reasoning": false,
      "type": "chat",
      "description": "\n文心4.5系列开源模型为MoE 架构，是一种创新性的多模态异构模型结构，通过跨模态参数共享机制实现模态间知识融合，同时为各单一模态保留专用参数空间。此架构非常适用于从大语言模型向多模态模型的持续预训练范式，在保持甚至提升文本任务性能的基础上，显著增强多模态理解能力。该模型均使用飞桨深度学习框架进行高效训练、推理和部署。在大语言模型的预训练中，模型FLOPs利用率（MFU）达到47%。实验结果显示，该系列模型在多个文本和多模态基准测试中达到SOTA水平，在指令遵循、世界知识记忆、视觉理解和多模态推理任务上效果尤为突出。"
    },
    {
      "id": "baidu/ernie-4.5-vl-28b-a3b",
      "name": "ERNIE-4.5-VL-28B-A3B",
      "contextLength": 30000,
      "maxTokens": 8000,
      "vision": true,
      "functionCall": true,
      "reasoning": true,
      "type": "chat",
      "description": "\n文心4.5系列开源模型为MoE 架构，是一种创新性的多模态异构模型结构，通过跨模态参数共享机制实现模态间知识融合，同时为各单一模态保留专用参数空间。此架构非常适用于从大语言模型向多模态模型的持续预训练范式，在保持甚至提升文本任务性能的基础上，显著增强多模态理解能力。该模型均使用飞桨深度学习框架进行高效训练、推理和部署。在大语言模型的预训练中，模型FLOPs利用率（MFU）达到47%。实验结果显示，该系列模型在多个文本和多模态基准测试中达到SOTA水平，在指令遵循、世界知识记忆、视觉理解和多模态推理任务上效果尤为突出。"
    },
    {
      "id": "qwen/qwen3-4b-fp8",
      "name": "Qwen3 4B",
      "contextLength": 128000,
      "maxTokens": 20000,
      "vision": false,
      "functionCall": false,
      "reasoning": true,
      "type": "chat",
      "description": "实现思考模式和非思考模式的有效融合，可在对话中切换模式。推理能力达到同规模业界SOTA水平、模型人类偏好能力显著增强，创意写作、角色扮演、多轮对话、指令遵循能力均有明显提升，用户体验预期明显更佳。"
    },
    {
      "id": "thudm/glm-4-9b-chat",
      "name": "GLM4 9B Chat",
      "contextLength": 32000,
      "maxTokens": 8000,
      "vision": false,
      "functionCall": false,
      "reasoning": false,
      "type": "chat",
      "description": "智谱AI发布的GLM-4系列最新一代预训练模型的开源版本。"
    }
  ]
}